{"2025-06-26T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.21538v1","updated":"2025-06-26T17:55:34Z","published":"2025-06-26T17:55:34Z","title":"Maximal Matching Matters: Preventing Representation Collapse for Robust\n  Cross-Modal Retrieval","summary":"  Cross-modal image-text retrieval is challenging because of the diverse\npossible associations between content from different modalities. Traditional\nmethods learn a single-vector embedding to represent semantics of each sample,\nbut struggle to capture nuanced and diverse relationships that can exist across\nmodalities. Set-based approaches, which represent each sample with multiple\nembeddings, offer a promising alternative, as they can capture richer and more\ndiverse relationships. In this paper, we show that, despite their promise,\nthese set-based representations continue to face issues including sparse\nsupervision and set collapse, which limits their effectiveness. To address\nthese challenges, we propose Maximal Pair Assignment Similarity to optimize\none-to-one matching between embedding sets which preserve semantic diversity\nwithin the set. We also introduce two loss functions to further enhance the\nrepresentations: Global Discriminative Loss to enhance distinction among\nembeddings, and Intra-Set Divergence Loss to prevent collapse within each set.\nOur method achieves state-of-the-art performance on MS-COCO and Flickr30k\nwithout relying on external data.\n","authors":["Hani Alomari","Anushka Sivakumar","Andrew Zhang","Chris Thomas"],"pdf_url":"https://arxiv.org/pdf/2506.21538v1.pdf","comment":"Accepted at the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025 Main)"},{"id":"http://arxiv.org/abs/2506.21508v1","updated":"2025-06-26T17:35:04Z","published":"2025-06-26T17:35:04Z","title":"skLEP: A Slovak General Language Understanding Benchmark","summary":"  In this work, we introduce skLEP, the first comprehensive benchmark\nspecifically designed for evaluating Slovak natural language understanding\n(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span\ntoken-level, sentence-pair, and document-level challenges, thereby offering a\nthorough assessment of model capabilities. To create this benchmark, we curated\nnew, original datasets tailored for Slovak and meticulously translated\nestablished English NLU resources. Within this paper, we also present the first\nsystematic and extensive evaluation of a wide array of Slovak-specific,\nmultilingual, and English pre-trained language models using the skLEP tasks.\nFinally, we also release the complete benchmark data, an open-source toolkit\nfacilitating both fine-tuning and evaluation of models, and a public\nleaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering\nreproducibility and drive future research in Slovak NLU.\n","authors":["Marek Šuppa","Andrej Ridzik","Daniel Hládek","Tomáš Javůrek","Viktória Ondrejová","Kristína Sásiková","Martin Tamajka","Marián Šimko"],"pdf_url":"https://arxiv.org/pdf/2506.21508v1.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2311.00635v3","updated":"2025-06-26T17:31:17Z","published":"2023-11-01T16:36:19Z","title":"GATSY: Graph Attention Network for Music Artist Similarity","summary":"  The artist similarity quest has become a crucial subject in social and\nscientific contexts, driven by the desire to enhance music discovery according\nto user preferences. Modern research solutions facilitate music discovery\naccording to user tastes. However, defining similarity among artists remains\nchallenging due to its inherently subjective nature, which can impact\nrecommendation accuracy. This paper introduces GATSY, a novel recommendation\nsystem built upon graph attention networks and driven by a clusterized\nembedding of artists. The proposed framework leverages the graph topology of\nthe input data to achieve outstanding performance results without relying\nheavily on hand-crafted features. This flexibility allows us to include\nfictitious artists within a music dataset, facilitating connections between\npreviously unlinked artists and enabling diverse recommendations from various\nand heterogeneous sources. Experimental results prove the effectiveness of the\nproposed method with respect to state-of-the-art solutions while maintaining\nflexibility. The code to reproduce these experiments is available at\nhttps://github.com/difra100/GATSY-Music_Artist_Similarity.\n","authors":["Andrea Giuseppe Di Francesco","Giuliano Giampietro","Indro Spinelli","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2311.00635v3.pdf","comment":"Camera-Ready version, Accepted at IJCNN 2025"},{"id":"http://arxiv.org/abs/2506.18959v2","updated":"2025-06-26T17:18:00Z","published":"2025-06-23T17:27:19Z","title":"From Web Search towards Agentic Deep Research: Incentivizing Search with\n  Reasoning Agents","summary":"  Information retrieval is a cornerstone of modern knowledge acquisition,\nenabling billions of queries each day across diverse domains. However,\ntraditional keyword-based search engines are increasingly inadequate for\nhandling complex, multi-step information needs. Our position is that Large\nLanguage Models (LLMs), endowed with reasoning and agentic capabilities, are\nushering in a new paradigm termed Agentic Deep Research. These systems\ntranscend conventional information search techniques by tightly integrating\nautonomous reasoning, iterative retrieval, and information synthesis into a\ndynamic feedback loop. We trace the evolution from static web search to\ninteractive, agent-based systems that plan, explore, and learn. We also\nintroduce a test-time scaling law to formalize the impact of computational\ndepth on reasoning and search. Supported by benchmark results and the rise of\nopen-source implementations, we demonstrate that Agentic Deep Research not only\nsignificantly outperforms existing approaches, but is also poised to become the\ndominant paradigm for future information seeking. All the related resources,\nincluding industry products, research papers, benchmark datasets, and\nopen-source implementations, are collected for the community in\nhttps://github.com/DavidZWZ/Awesome-Deep-Research.\n","authors":["Weizhi Zhang","Yangning Li","Yuanchen Bei","Junyu Luo","Guancheng Wan","Liangwei Yang","Chenxuan Xie","Yuyao Yang","Wei-Chieh Huang","Chunyu Miao","Henry Peng Zou","Xiao Luo","Yusheng Zhao","Yankai Chen","Chunkit Chan","Peilin Zhou","Xinyang Zhang","Chenwei Zhang","Jingbo Shang","Ming Zhang","Yangqiu Song","Irwin King","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2506.18959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21445v1","updated":"2025-06-26T16:31:10Z","published":"2025-06-26T16:31:10Z","title":"Text2Cypher Across Languages: Evaluating Foundational Models Beyond\n  English","summary":"  Recent advances in large language models have enabled natural language\ninterfaces that translate user questions into database queries, such as\nText2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database\naccessibility, most research today focuses solely on English, with limited\nevaluation in other languages. This paper investigates the performance of\nfoundational LLMs on the Text2Cypher task across multiple languages. We create\nand release a multilingual test set by translating English questions into\nSpanish and Turkish while preserving the original Cypher queries, enabling fair\ncross-lingual comparison. We evaluate multiple foundational models using\nstandardized prompts and metrics. Our results show a consistent performance\npattern: highest on English, then Spanish, and lowest on Turkish. We attribute\nthis to differences in training data availability and linguistic\ncharacteristics. Additionally, we explore the impact of translating task\nprompts into Spanish and Turkish. Results show little to no change in\nevaluation metrics, suggesting prompt translation has minor impact. Our\nfindings highlight the need for more inclusive evaluation and development in\nmultilingual query generation. Future work includes schema localization and\nfine-tuning across diverse languages.\n","authors":["Makbule Gulcin Ozsoy","William Tai"],"pdf_url":"https://arxiv.org/pdf/2506.21445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21384v1","updated":"2025-06-26T15:35:12Z","published":"2025-06-26T15:35:12Z","title":"Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented\n  Generation","summary":"  Real-world live retrieval-augmented generation (RAG) systems face significant\nchallenges when processing user queries that are often noisy, ambiguous, and\ncontain multiple intents. While RAG enhances large language models (LLMs) with\nexternal knowledge, current systems typically struggle with such complex\ninputs, as they are often trained or evaluated on cleaner data. This paper\nintroduces Omni-RAG, a novel framework designed to improve the robustness and\neffectiveness of RAG systems in live, open-domain settings. Omni-RAG employs\nLLM-assisted query understanding to preprocess user inputs through three key\nmodules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs\nwith tailored prompts to denoise queries (e.g., correcting spelling errors) and\ndecompose multi-intent queries into structured sub-queries; (2) Intent-Aware\nKnowledge Retrieval, which performs retrieval for each sub-query from a corpus\n(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking\nand Generation, where a reranker (i.e., BGE) refines document selection before\na final response is generated by an LLM (i.e., Falcon-10B) using a\nchain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG\ncapabilities and the demands of real-world applications, such as those\nhighlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex\nand noisy queries.\n","authors":["Guanting Dong","Xiaoxi Li","Yuyao Zhang","Mengjie Deng"],"pdf_url":"https://arxiv.org/pdf/2506.21384v1.pdf","comment":"Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)"},{"id":"http://arxiv.org/abs/2506.21368v1","updated":"2025-06-26T15:16:44Z","published":"2025-06-26T15:16:44Z","title":"Real-time and personalized product recommendations for large e-commerce\n  platforms","summary":"  We present a methodology to provide real-time and personalized product\nrecommendations for large e-commerce platforms, specifically focusing on\nfashion retail. Our approach aims to achieve accurate and scalable\nrecommendations with minimal response times, ensuring user satisfaction,\nleveraging Graph Neural Networks and parsimonious learning methodologies.\nExtensive experimentation with datasets from one of the largest e-commerce\nplatforms demonstrates the effectiveness of our approach in forecasting\npurchase sequences and handling multi-interaction scenarios, achieving\nefficient personalized recommendations under real-world constraints.\n","authors":["Matteo Tolloso","Davide Bacciu","Shahab Mokarizadeh","Marco Varesi"],"pdf_url":"https://arxiv.org/pdf/2506.21368v1.pdf","comment":"This paper has been accepted for publication at the International\n  Conference on Artificial Neural Networks (ICANN) 2025. The final\n  authenticated version will be available for purchase through the publisher's\n  website. The conference proceedings will be published by Springer in the\n  Lecture Notes in Computer Science (LNCS) series"},{"id":"http://arxiv.org/abs/2506.21288v1","updated":"2025-06-26T14:09:41Z","published":"2025-06-26T14:09:41Z","title":"Small Encoders Can Rival Large Decoders in Detecting Groundedness","summary":"  Augmenting large language models (LLMs) with external context significantly\nimproves their performance in natural language processing (NLP) tasks. However,\nLLMs struggle to answer queries reliably when the provided context lacks\ninformation, often resorting to ungrounded speculation or internal knowledge.\nGroundedness - generating responses strictly supported by the context - is\nessential for ensuring factual consistency and trustworthiness. This study\nfocuses on detecting whether a given query is grounded in a document provided\nin context before the costly answer generation by LLMs. Such a detection\nmechanism can significantly reduce both inference time and resource\nconsumption. We show that lightweight, task specific encoder models such as\nRoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy\ncomparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in\ngroundedness detection while reducing inference latency by orders of magnitude.\nThe code is available at : https://github.com/chandarlab/Hallucinate-less\n","authors":["Istabrak Abbes","Gabriele Prato","Quentin Fournier","Fernando Rodriguez","Alaa Boukhary","Adam Elwood","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2506.21288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21222v1","updated":"2025-06-26T13:14:52Z","published":"2025-06-26T13:14:52Z","title":"Enhancing Automatic Term Extraction with Large Language Models via\n  Syntactic Retrieval","summary":"  Automatic Term Extraction (ATE) identifies domain-specific expressions that\nare crucial for downstream tasks such as machine translation and information\nretrieval. Although large language models (LLMs) have significantly advanced\nvarious NLP tasks, their potential for ATE has scarcely been examined. We\npropose a retrieval-based prompting strategy that, in the few-shot setting,\nselects demonstrations according to \\emph{syntactic} rather than semantic\nsimilarity. This syntactic retrieval method is domain-agnostic and provides\nmore reliable guidance for capturing term boundaries. We evaluate the approach\nin both in-domain and cross-domain settings, analyzing how lexical overlap\nbetween the query sentence and its retrieved examples affects performance.\nExperiments on three specialized ATE benchmarks show that syntactic retrieval\nimproves F1-score. These findings highlight the importance of syntactic cues\nwhen adapting LLMs to terminology-extraction tasks.\n","authors":["Yongchan Chun","Minhyuk Kim","Dongjun Kim","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2506.21222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21086v1","updated":"2025-06-26T08:29:48Z","published":"2025-06-26T08:29:48Z","title":"PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time\n  Stretching","summary":"  This work introduces PeakNetFP, the first neural audio fingerprinting (AFP)\nsystem designed specifically around spectral peaks. This novel system is\ndesigned to leverage the sparse spectral coordinates typically computed by\ntraditional peak-based AFP methods. PeakNetFP performs hierarchical point\nfeature extraction techniques similar to the computer vision model PointNet++,\nand is trained using contrastive learning like in the state-of-the-art deep\nlearning AFP, NeuralFP. This combination allows PeakNetFP to outperform\nconventional AFP systems and achieves comparable performance to NeuralFP when\nhandling challenging time-stretched audio data. In extensive evaluation,\nPeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging\nfrom 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages:\ncompared to NeuralFP, it has 100 times fewer parameters and uses 11 times\nsmaller input data. These features make PeakNetFP a lightweight and efficient\nsolution for AFP tasks where time stretching is involved. Overall, this system\nrepresents a promising direction for future AFP technologies, as it\nsuccessfully merges the lightweight nature of peak-based AFP with the\nadaptability and pattern recognition capabilities of neural network-based\napproaches, paving the way for more scalable and efficient solutions in the\nfield.\n","authors":["Guillem Cortès-Sebastià","Benjamin Martin","Emilio Molina","Xavier Serra","Romain Hennequin"],"pdf_url":"https://arxiv.org/pdf/2506.21086v1.pdf","comment":"Accepted at ISMIR 2025"},{"id":"http://arxiv.org/abs/2506.21049v1","updated":"2025-06-26T06:52:33Z","published":"2025-06-26T06:52:33Z","title":"A Semi-supervised Scalable Unified Framework for E-commerce Query\n  Classification","summary":"  Query classification, including multiple subtasks such as intent and category\nprediction, is vital to e-commerce applications. E-commerce queries are usually\nshort and lack context, and the information between labels cannot be used,\nresulting in insufficient prior information for modeling. Most existing\nindustrial query classification methods rely on users' posterior click behavior\nto construct training samples, resulting in a Matthew vicious cycle.\nFurthermore, the subtasks of query classification lack a unified framework,\nleading to low efficiency for algorithm optimization.\n  In this paper, we propose a novel Semi-supervised Scalable Unified Framework\n(SSUF), containing multiple enhanced modules to unify the query classification\ntasks. The knowledge-enhanced module uses world knowledge to enhance query\nrepresentations and solve the problem of insufficient query information. The\nlabel-enhanced module uses label semantics and semi-supervised signals to\nreduce the dependence on posterior labels. The structure-enhanced module\nenhances the label representation based on the complex label relations. Each\nmodule is highly pluggable, and input features can be added or removed as\nneeded according to each subtask. We conduct extensive offline and online A/B\nexperiments, and the results show that SSUF significantly outperforms the\nstate-of-the-art models.\n","authors":["Chunyuan Yuan","Chong Zhang","Zheng Fang","Ming Pang","Xue Jiang","Changping Peng","Zhangang Lin","Ching Law"],"pdf_url":"https://arxiv.org/pdf/2506.21049v1.pdf","comment":"Accepted by ACL 2025"},{"id":"http://arxiv.org/abs/2504.05312v2","updated":"2025-06-26T06:44:43Z","published":"2025-02-19T04:23:12Z","title":"Towards Adaptive Memory-Based Optimization for Enhanced\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge\nfrom external knowledge bases into models, has emerged as a promising approach\nto enhancing response accuracy while mitigating factual errors and\nhallucinations. This method has been widely applied in tasks such as Question\nAnswering (QA). However, existing RAG methods struggle with open-domain QA\ntasks because they perform independent retrieval operations and directly\nincorporate the retrieved information into generation without maintaining a\nsummarizing memory or using adaptive retrieval strategies, leading to noise\nfrom redundant information and insufficient information integration. To address\nthese challenges, we propose Adaptive memory-based optimization for enhanced\nRAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory\nUpdater, an Adaptive Information Collector, and a Multi-granular Content\nFilter, working together within an iterative memory updating paradigm.\nSpecifically, Amber integrates and optimizes the language model's memory\nthrough a multi-agent collaborative approach, ensuring comprehensive knowledge\nintegration from previous retrieval steps. It dynamically adjusts retrieval\nqueries and decides when to stop retrieval based on the accumulated knowledge,\nenhancing retrieval efficiency and effectiveness. Additionally, it reduces\nnoise by filtering irrelevant content at multiple levels, retaining essential\ninformation to improve overall model performance. We conduct extensive\nexperiments on several open-domain QA datasets, and the results demonstrate the\nsuperiority and effectiveness of our method and its components. The source code\nis available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.\n","authors":["Qitao Qin","Yucong Luo","Yihang Lu","Zhibo Chu","Xianwei Meng"],"pdf_url":"https://arxiv.org/pdf/2504.05312v2.pdf","comment":"8pages. arXiv admin note: text overlap with arXiv:2410.08821 by other\n  authors"},{"id":"http://arxiv.org/abs/2506.21032v1","updated":"2025-06-26T06:14:42Z","published":"2025-06-26T06:14:42Z","title":"RecCoT: Enhancing Recommendation via Chain-of-Thought","summary":"  In real-world applications, users always interact with items in multiple\naspects, such as through implicit binary feedback (e.g., clicks, dislikes, long\nviews) and explicit feedback (e.g., comments, reviews). Modern recommendation\nsystems (RecSys) learn user-item collaborative signals from these implicit\nfeedback signals as a large-scale binary data-streaming, subsequently\nrecommending other highly similar items based on users' personalized historical\ninteractions. However, from this collaborative-connection perspective, the\nRecSys does not focus on the actual content of the items themselves but instead\nprioritizes higher-probability signals of behavioral co-occurrence among items.\nConsequently, under this binary learning paradigm, the RecSys struggles to\nunderstand why a user likes or dislikes certain items. To alleviate it, some\nworks attempt to utilize the content-based reviews to capture the semantic\nknowledge to enhance recommender models. However, most of these methods focus\non predicting the ratings of reviews, but do not provide a human-understandable\nexplanation.\n","authors":["Shuo Yang","Jiangxia Cao","Haipeng Li","Yuqi Mao","Shuchao Pang"],"pdf_url":"https://arxiv.org/pdf/2506.21032v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.20978v1","updated":"2025-06-26T03:52:56Z","published":"2025-06-26T03:52:56Z","title":"Response Quality Assessment for Retrieval-Augmented Generation via\n  Conditional Conformal Factuality","summary":"  Existing research on Retrieval-Augmented Generation (RAG) primarily focuses\non improving overall question-answering accuracy, often overlooking the quality\nof sub-claims within generated responses. Recent methods that attempt to\nimprove RAG trustworthiness, such as through auto-evaluation metrics, lack\nprobabilistic guarantees or require ground truth answers. To address these\nlimitations, we propose Conformal-RAG, a novel framework inspired by recent\napplications of conformal prediction (CP) on large language models (LLMs).\nConformal-RAG leverages CP and internal information from the RAG mechanism to\noffer statistical guarantees on response quality. It ensures group-conditional\ncoverage spanning multiple sub-domains without requiring manual labelling of\nconformal sets, making it suitable for complex RAG applications. Compared to\nexisting RAG auto-evaluation methods, Conformal-RAG offers statistical\nguarantees on the quality of refined sub-claims, ensuring response reliability\nwithout the need for ground truth answers. Additionally, our experiments\ndemonstrate that by leveraging information from the RAG system, Conformal-RAG\nretains up to 60\\% more high-quality sub-claims from the response compared to\ndirect applications of CP to LLMs, while maintaining the same reliability\nguarantee.\n","authors":["Naihe Feng","Yi Sui","Shiyi Hou","Jesse C. Cresswell","Ga Wu"],"pdf_url":"https://arxiv.org/pdf/2506.20978v1.pdf","comment":"Accepted by SIGIR 2025 short paper, 5 pages, Code is available at\n  https://github.com/n4feng/ResponseQualityAssessment"},{"id":"http://arxiv.org/abs/2410.09942v2","updated":"2025-06-26T03:06:17Z","published":"2024-10-13T17:53:50Z","title":"Learning to Rank for Multiple Retrieval-Augmented Models through\n  Iterative Utility Maximization","summary":"  This paper investigates the design of a unified search engine to serve\nmultiple retrieval-augmented generation (RAG) agents, each with a distinct\ntask, backbone large language model (LLM), and RAG strategy. We introduce an\niterative approach where the search engine generates retrieval results for the\nRAG agents and gathers feedback on the quality of the retrieved documents\nduring an offline phase. This feedback is then used to iteratively optimize the\nsearch engine using an expectation-maximization algorithm, with the goal of\nmaximizing each agent's utility function. Additionally, we adapt this to an\nonline setting, allowing the search engine to refine its behavior based on\nreal-time individual agents feedback to better serve the results for each of\nthem. Experiments on datasets from the Knowledge-Intensive Language Tasks\n(KILT) benchmark demonstrates that our approach significantly on average\noutperforms baselines across 18 RAG models. We demonstrate that our method\neffectively ``personalizes'' the retrieval for each RAG agent based on the\ncollected feedback. Finally, we provide a comprehensive ablation study to\nexplore various aspects of our method.\n","authors":["Alireza Salemi","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2410.09942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20963v1","updated":"2025-06-26T03:01:33Z","published":"2025-06-26T03:01:33Z","title":"EraRAG: Efficient and Incremental Retrieval Augmented Generation for\n  Growing Corpora","summary":"  Graph-based Retrieval-Augmented Generation (Graph-RAG) enhances large\nlanguage models (LLMs) by structuring retrieval over an external corpus.\nHowever, existing approaches typically assume a static corpus, requiring\nexpensive full-graph reconstruction whenever new documents arrive, limiting\ntheir scalability in dynamic, evolving environments. To address these\nlimitations, we introduce EraRAG, a novel multi-layered Graph-RAG framework\nthat supports efficient and scalable dynamic updates. Our method leverages\nhyperplane-based Locality-Sensitive Hashing (LSH) to partition and organize the\noriginal corpus into hierarchical graph structures, enabling efficient and\nlocalized insertions of new data without disrupting the existing topology. The\ndesign eliminates the need for retraining or costly recomputation while\npreserving high retrieval accuracy and low latency. Experiments on large-scale\nbenchmarks demonstrate that EraRag achieves up to an order of magnitude\nreduction in update time and token consumption compared to existing Graph-RAG\nsystems, while providing superior accuracy performance. This work offers a\npractical path forward for RAG systems that must operate over continually\ngrowing corpora, bridging the gap between retrieval efficiency and\nadaptability. Our code and data are available at\nhttps://github.com/EverM0re/EraRAG-Official.\n","authors":["Fangyuan Zhang","Zhengjun Huang","Yingli Zhou","Qintian Guo","Zhixun Li","Wensheng Luo","Di Jiang","Yixiang Fang","Xiaofang Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.20963v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2506.20918v1","updated":"2025-06-26T00:55:47Z","published":"2025-06-26T00:55:47Z","title":"Metadata Enrichment of Long Text Documents using Large Language Models","summary":"  In this project, we semantically enriched and enhanced the metadata of long\ntext documents, theses and dissertations, retrieved from the HathiTrust Digital\nLibrary in English published from 1920 to 2020 through a combination of manual\nefforts and large language models. This dataset provides a valuable resource\nfor advancing research in areas such as computational social science, digital\nhumanities, and information science. Our paper shows that enriching metadata\nusing LLMs is particularly beneficial for digital repositories by introducing\nadditional metadata access points that may not have originally been foreseen to\naccommodate various content types. This approach is particularly effective for\nrepositories that have significant missing data in their existing metadata\nfields, enhancing search results and improving the accessibility of the digital\nrepository.\n","authors":["Manika Lamba","You Peng","Sophie Nikolov","Glen Layne-Worthey","J. Stephen Downie"],"pdf_url":"https://arxiv.org/pdf/2506.20918v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.21203v1","updated":"2025-06-26T13:00:09Z","published":"2025-06-26T13:00:09Z","title":"Condensed Representation of RDF and its Application on Graph Versioning","summary":"  The study of the evolving phenomena in a domain helps to understand the\nrelationships between entities at different points in time and predict future\ntrends. These phenomena, often complex, can be represented using knowledge\ngraphs, which have the capability to model heterogeneous data from multiple\nsources. Nowadays, a considerable amount of sources delivering periodic updates\nto knowledge graphs in various domains is openly available. The evolution of\ndata is of interest to knowledge graph management systems, and therefore it is\ncrucial to organize these constantly evolving data to make them easily\naccessible and exploitable for analyzes. In this article, we will present and\nformalize the condensed representation of these evolving graphs.\n","authors":["Jey Puget Gil","Emmanuel Coquery","John Samuel","Gilles Gesquiere"],"pdf_url":"https://arxiv.org/pdf/2506.21203v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.13918v2","updated":"2025-06-26T12:52:26Z","published":"2024-12-18T14:58:06Z","title":"Localized RETE for Incremental Graph Queries with Nested Graph\n  Conditions","summary":"  The growing size of graph-based modeling artifacts in model-driven\nengineering calls for techniques that enable efficient execution of graph\nqueries. Incremental approaches based on the RETE algorithm provide an adequate\nsolution in many scenarios, but are generally designed to search for query\nresults over the entire graph. However, in certain situations, a user may only\nbe interested in query results for a subgraph, for instance when a developer is\nworking on a large model of which only a part is loaded into their workspace.\nIn this case, the global execution semantics can result in significant\ncomputational overhead.\n  To mitigate the outlined shortcoming, in this article we propose an extension\nof the RETE approach that enables local, yet fully incremental execution of\ngraph queries, while still guaranteeing completeness of results with respect to\nthe relevant subgraph.\n  We empirically evaluate the presented approach via experiments inspired by a\nscenario from software development and with queries and data from an\nindependent social network benchmark. The experimental results indicate that\nthe proposed technique can significantly improve performance regarding memory\nconsumption and execution time in favorable cases, but may incur a noticeable\noverhead in unfavorable cases.\n","authors":["Matthias Barkowsky","Holger Giese"],"pdf_url":"https://arxiv.org/pdf/2412.13918v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.01145"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2506.21552v1","updated":"2025-06-26T17:59:59Z","published":"2025-06-26T17:59:59Z","title":"Whole-Body Conditioned Egocentric Video Prediction","summary":"  We train models to Predict Ego-centric Video from human Actions (PEVA), given\nthe past video and an action represented by the relative 3D body pose. By\nconditioning on kinematic pose trajectories, structured by the joint hierarchy\nof the body, our model learns to simulate how physical human actions shape the\nenvironment from a first-person point of view. We train an auto-regressive\nconditional diffusion transformer on Nymeria, a large-scale dataset of\nreal-world egocentric video and body pose capture. We further design a\nhierarchical evaluation protocol with increasingly challenging tasks, enabling\na comprehensive analysis of the model's embodied prediction and control\nabilities. Our work represents an initial attempt to tackle the challenges of\nmodeling complex real-world environments and embodied agent behaviors with\nvideo prediction from the perspective of a human.\n","authors":["Yutong Bai","Danny Tran","Amir Bar","Yann LeCun","Trevor Darrell","Jitendra Malik"],"pdf_url":"https://arxiv.org/pdf/2506.21552v1.pdf","comment":"Project Page: https://dannytran123.github.io/PEVA"},{"id":"http://arxiv.org/abs/2506.21550v1","updated":"2025-06-26T17:59:58Z","published":"2025-06-26T17:59:58Z","title":"mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and\n  Model Selection at Scale","summary":"  Multivariate time series anomaly detection (MTS-AD) is critical in domains\nlike healthcare, cybersecurity, and industrial monitoring, yet remains\nchallenging due to complex inter-variable dependencies, temporal dynamics, and\nsparse anomaly labels. We introduce mTSBench, the largest benchmark to date for\nMTS-AD and unsupervised model selection, spanning 344 labeled time series\nacross 19 datasets and 12 diverse application domains. mTSBench evaluates 24\nanomaly detection methods, including large language model (LLM)-based detectors\nfor multivariate time series, and systematically benchmarks unsupervised model\nselection techniques under standardized conditions. Consistent with prior\nfindings, our results confirm that no single detector excels across datasets,\nunderscoring the importance of model selection. However, even state-of-the-art\nselection methods remain far from optimal, revealing critical gaps. mTSBench\nprovides a unified evaluation suite to enable rigorous, reproducible\ncomparisons and catalyze future advances in adaptive anomaly detection and\nrobust model selection.\n","authors":["Xiaona Zhou","Constantin Brif","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2506.21550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21546v1","updated":"2025-06-26T17:59:12Z","published":"2025-06-26T17:59:12Z","title":"HalluSegBench: Counterfactual Visual Reasoning for Segmentation\n  Hallucination Evaluation","summary":"  Recent progress in vision-language segmentation has significantly advanced\ngrounded visual understanding. However, these models often exhibit\nhallucinations by producing segmentation masks for objects not grounded in the\nimage content or by incorrectly labeling irrelevant regions. Existing\nevaluation protocols for segmentation hallucination primarily focus on label or\ntextual hallucinations without manipulating the visual context, limiting their\ncapacity to diagnose critical failures. In response, we introduce\nHalluSegBench, the first benchmark specifically designed to evaluate\nhallucinations in visual grounding through the lens of counterfactual visual\nreasoning. Our benchmark consists of a novel dataset of 1340 counterfactual\ninstance pairs spanning 281 unique object classes, and a set of newly\nintroduced metrics that quantify hallucination sensitivity under visually\ncoherent scene edits. Experiments on HalluSegBench with state-of-the-art\nvision-language segmentation models reveal that vision-driven hallucinations\nare significantly more prevalent than label-driven ones, with models often\npersisting in false segmentation, highlighting the need for counterfactual\nreasoning to diagnose grounding fidelity.\n","authors":["Xinzhuo Li","Adheesh Juvekar","Xingyou Liu","Muntasir Wahed","Kiet A. Nguyen","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2506.21546v1.pdf","comment":"Project webpage: https://plan-lab.github.io/hallusegbench/"},{"id":"http://arxiv.org/abs/2506.21539v1","updated":"2025-06-26T17:55:40Z","published":"2025-06-26T17:55:40Z","title":"WorldVLA: Towards Autoregressive Action World Model","summary":"  We present WorldVLA, an autoregressive action world model that unifies action\nand image understanding and generation. Our WorldVLA intergrates\nVision-Language-Action (VLA) model and world model in one single framework. The\nworld model predicts future images by leveraging both action and image\nunderstanding, with the purpose of learning the underlying physics of the\nenvironment to improve action generation. Meanwhile, the action model generates\nthe subsequent actions based on image observations, aiding in visual\nunderstanding and in turn helps visual generation of the world model. We\ndemonstrate that WorldVLA outperforms standalone action and world models,\nhighlighting the mutual enhancement between the world model and the action\nmodel. In addition, we find that the performance of the action model\ndeteriorates when generating sequences of actions in an autoregressive manner.\nThis phenomenon can be attributed to the model's limited generalization\ncapability for action prediction, leading to the propagation of errors from\nearlier actions to subsequent ones. To address this issue, we propose an\nattention mask strategy that selectively masks prior actions during the\ngeneration of the current action, which shows significant performance\nimprovement in the action chunk generation task.\n","authors":["Jun Cen","Chaohui Yu","Hangjie Yuan","Yuming Jiang","Siteng Huang","Jiayan Guo","Xin Li","Yibing Song","Hao Luo","Fan Wang","Deli Zhao","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2506.21539v1.pdf","comment":"Code: https://github.com/alibaba-damo-academy/WorldVLA"},{"id":"http://arxiv.org/abs/2506.21536v1","updated":"2025-06-26T17:54:42Z","published":"2025-06-26T17:54:42Z","title":"PsyLite Technical Report","summary":"  With the rapid development of digital technology, AI-driven psychological\ncounseling has gradually become an important research direction in the field of\nmental health. However, existing models still have deficiencies in dialogue\nsafety, detailed scenario handling, and lightweight deployment. To address\nthese issues, this study proposes PsyLite, a lightweight psychological\ncounseling large language model agent developed based on the base model\nInternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation\ndata fine-tuning and ORPO preference optimization), PsyLite enhances the\nmodel's deep-reasoning ability, psychological counseling ability, and safe\ndialogue ability. After deployment using Ollama and Open WebUI, a custom\nworkflow is created with Pipelines. An innovative conditional RAG is designed\nto introduce crosstalk humor elements at appropriate times during psychological\ncounseling to enhance user experience and decline dangerous requests to\nstrengthen dialogue safety. Evaluations show that PsyLite outperforms the\nbaseline models in the Chinese general evaluation (CEval), psychological\ncounseling professional evaluation (CPsyCounE), and dialogue safety evaluation\n(SafeDialBench), particularly in psychological counseling professionalism\n(CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score\nimprovement of 2.4\\%). Additionally, the model uses quantization technology\n(GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient\nfor operation), providing a feasible solution for psychological counseling\napplications in resource-constrained environments.\n","authors":["Fangjun Ding","Renyu Zhang","Xinyu Feng","Chengye Xie","Zheng Zhang","Yanting Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.21536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21532v1","updated":"2025-06-26T17:52:18Z","published":"2025-06-26T17:52:18Z","title":"\"What's Up, Doc?\": Analyzing How Users Seek Health Information in\n  Large-Scale Conversational AI Datasets","summary":"  People are increasingly seeking healthcare information from large language\nmodels (LLMs) via interactive chatbots, yet the nature and inherent risks of\nthese conversations remain largely unexplored. In this paper, we filter\nlarge-scale conversational AI datasets to achieve HealthChat-11K, a curated\ndataset of 11K real-world conversations composed of 25K user messages. We use\nHealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs\nwhen seeking healthcare information in order to systematically study user\ninteractions across 21 distinct health specialties. Our analysis reveals\ninsights into the nature of how and why users seek health information, such as\ncommon interactions, instances of incomplete context, affective behaviors, and\ninteractions (e.g., leading questions) that can induce sycophancy, underscoring\nthe need for improvements in the healthcare support capabilities of LLMs\ndeployed as conversational AI. Code and artifacts to retrieve our analyses and\ncombine them into a curated dataset can be found here:\nhttps://github.com/yahskapar/HealthChat\n","authors":["Akshay Paruchuri","Maryam Aziz","Rohit Vartak","Ayman Ali","Best Uchehara","Xin Liu","Ishan Chatterjee","Monica Agrawal"],"pdf_url":"https://arxiv.org/pdf/2506.21532v1.pdf","comment":"25 pages, 6 figures, 4 tables, corresponds to initial HealthChat-11K\n  dataset release"},{"id":"http://arxiv.org/abs/2506.21521v1","updated":"2025-06-26T17:41:35Z","published":"2025-06-26T17:41:35Z","title":"Potemkin Understanding in Large Language Models","summary":"  Large language models (LLMs) are regularly evaluated using benchmark\ndatasets. But what justifies making inferences about an LLM's capabilities\nbased on its answers to a curated set of questions? This paper first introduces\na formal framework to address this question. The key is to note that the\nbenchmarks used to test LLMs -- such as AP exams -- are also those used to test\npeople. However, this raises an implication: these benchmarks are only valid\ntests if LLMs misunderstand concepts in ways that mirror human\nmisunderstandings. Otherwise, success on benchmarks only demonstrates potemkin\nunderstanding: the illusion of understanding driven by answers irreconcilable\nwith how any human would interpret a concept. We present two procedures for\nquantifying the existence of potemkins: one using a specially designed\nbenchmark in three domains, the other using a general procedure that provides a\nlower-bound on their prevalence. We find that potemkins are ubiquitous across\nmodels, tasks, and domains. We also find that these failures reflect not just\nincorrect understanding, but deeper internal incoherence in concept\nrepresentations.\n","authors":["Marina Mancoridis","Bec Weeks","Keyon Vafa","Sendhil Mullainathan"],"pdf_url":"https://arxiv.org/pdf/2506.21521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21508v1","updated":"2025-06-26T17:35:04Z","published":"2025-06-26T17:35:04Z","title":"skLEP: A Slovak General Language Understanding Benchmark","summary":"  In this work, we introduce skLEP, the first comprehensive benchmark\nspecifically designed for evaluating Slovak natural language understanding\n(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span\ntoken-level, sentence-pair, and document-level challenges, thereby offering a\nthorough assessment of model capabilities. To create this benchmark, we curated\nnew, original datasets tailored for Slovak and meticulously translated\nestablished English NLU resources. Within this paper, we also present the first\nsystematic and extensive evaluation of a wide array of Slovak-specific,\nmultilingual, and English pre-trained language models using the skLEP tasks.\nFinally, we also release the complete benchmark data, an open-source toolkit\nfacilitating both fine-tuning and evaluation of models, and a public\nleaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering\nreproducibility and drive future research in Slovak NLU.\n","authors":["Marek Šuppa","Andrej Ridzik","Daniel Hládek","Tomáš Javůrek","Viktória Ondrejová","Kristína Sásiková","Martin Tamajka","Marián Šimko"],"pdf_url":"https://arxiv.org/pdf/2506.21508v1.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2506.21506v1","updated":"2025-06-26T17:32:50Z","published":"2025-06-26T17:32:50Z","title":"Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge","summary":"  Agentic search such as Deep Research systems, where large language models\nautonomously browse the web, synthesize information, and return comprehensive\ncitation-backed answers, represents a major shift in how users interact with\nweb-scale information. While promising greater efficiency and cognitive\noffloading, the growing complexity and open-endedness of agentic search have\noutpaced existing evaluation benchmarks and methodologies, which largely assume\nshort search horizons and static answers. In this paper, we introduce Mind2Web\n2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that\nrequire real-time web browsing and extensive information synthesis, constructed\nwith over 1,000 hours of human labor. To address the challenge of evaluating\ntime-varying and complex answers, we propose a novel Agent-as-a-Judge\nframework. Our method constructs task-specific judge agents based on a\ntree-structured rubric design to automatically assess both answer correctness\nand source attribution. We conduct a comprehensive evaluation of nine frontier\nagentic search systems and human performance, along with a detailed error\nanalysis to draw insights for future development. The best-performing system,\nOpenAI Deep Research, can already achieve 50-70% of human performance while\nspending half the time, showing a great potential. Altogether, Mind2Web 2\nprovides a rigorous foundation for developing and benchmarking the next\ngeneration of agentic search systems.\n","authors":["Boyu Gou","Zanming Huang","Yuting Ning","Yu Gu","Michael Lin","Weijian Qi","Andrei Kopanev","Botao Yu","Bernal Jiménez Gutiérrez","Yiheng Shu","Chan Hee Song","Jiaman Wu","Shijie Chen","Hanane Nour Moussa","Tianshu Zhang","Jian Xie","Yifei Li","Tianci Xue","Zeyi Liao","Kai Zhang","Boyuan Zheng","Zhaowei Cai","Viktor Rozgic","Morteza Ziyadi","Huan Sun","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2506.21506v1.pdf","comment":"Project Homepage: https://osu-nlp-group.github.io/Mind2Web2/"},{"id":"http://arxiv.org/abs/2506.21502v1","updated":"2025-06-26T17:29:37Z","published":"2025-06-26T17:29:37Z","title":"Process mining-driven modeling and simulation to enhance fault diagnosis\n  in cyber-physical systems","summary":"  Fault diagnosis in Cyber-Physical Systems (CPSs) is essential for ensuring\nsystem dependability and operational efficiency by accurately detecting\nanomalies and identifying their root causes. However, the manual modeling of\nfaulty behaviors often demands extensive domain expertise and produces models\nthat are complex, error-prone, and difficult to interpret. To address this\nchallenge, we present a novel unsupervised fault diagnosis methodology that\nintegrates collective anomaly detection in multivariate time series, process\nmining, and stochastic simulation. Initially, collective anomalies are detected\nfrom low-level sensor data using multivariate time-series analysis. These\nanomalies are then transformed into structured event logs, enabling the\ndiscovery of interpretable process models through process mining. By\nincorporating timing distributions into the extracted Petri nets, the approach\nsupports stochastic simulation of faulty behaviors, thereby enhancing root\ncause analysis and behavioral understanding. The methodology is validated using\nthe Robotic Arm Dataset (RoAD), a widely recognized benchmark in smart\nmanufacturing. Experimental results demonstrate its effectiveness in modeling,\nsimulating, and classifying faulty behaviors in CPSs. This enables the creation\nof comprehensive fault dictionaries that support predictive maintenance and the\ndevelopment of digital twins for industrial environments.\n","authors":["Francesco Vitale","Nicola Dall'Ora","Sebastiano Gaiardelli","Enrico Fraccaroli","Nicola Mazzocca","Franco Fummi"],"pdf_url":"https://arxiv.org/pdf/2506.21502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02398v3","updated":"2025-06-26T17:22:53Z","published":"2024-11-04T18:59:51Z","title":"Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin\n  Script Languages","summary":"  Although multilingual LLMs have achieved remarkable performance across\nbenchmarks, we find they continue to underperform on non-Latin script languages\nacross contemporary LLM families. This discrepancy arises from the fact that\nLLMs are pretrained with orthographic scripts, which are dominated by Latin\ncharacters that obscure their shared phonology with non-Latin scripts. We\npropose leveraging phonemic transcriptions as complementary signals to induce\nscript-invariant representations. Our study demonstrates that integrating\nphonemic signals improves performance across both non-Latin and Latin script\nlanguages, with a particularly significant impact on closing the performance\ngap between the two. Through detailed experiments, we show that phonemic and\northographic scripts retrieve distinct examples for in-context learning (ICL).\nThis motivates our proposed Mixed-ICL retrieval strategy, where further\naggregation from both leads to our significant performance improvements for\nboth Latin script languages (up to 12.6%) and non-Latin script languages (up to\n15.1%) compared to randomized ICL retrieval.\n","authors":["Hoang H Nguyen","Khyati Mahajan","Vikas Yadav","Julian Salazar","Philip S. Yu","Masoud Hashemi","Rishabh Maheshwary"],"pdf_url":"https://arxiv.org/pdf/2411.02398v3.pdf","comment":"Accepted to NAACL 2025 (Main Conference). This version contains minor\n  improvements to the camera-ready"},{"id":"http://arxiv.org/abs/2506.19014v2","updated":"2025-06-26T17:21:45Z","published":"2025-06-23T18:10:06Z","title":"IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection","summary":"  Advancements in audio deepfake technology offers benefits like AI assistants,\nbetter accessibility for speech impairments, and enhanced entertainment.\nHowever, it also poses significant risks to security, privacy, and trust in\ndigital communications. Detecting and mitigating these threats requires\ncomprehensive datasets. Existing datasets lack diverse ethnic accents, making\nthem inadequate for many real-world scenarios. Consequently, models trained on\nthese datasets struggle to detect audio deepfakes in diverse linguistic and\ncultural contexts such as in South-Asian countries. Ironically, there is a\nstark lack of South-Asian speaker samples in the existing datasets despite\nconstituting a quarter of the worlds population. This work introduces the\nIndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio\nfrom 50 English speaking Indian speakers. IFD offers balanced data distribution\nand includes speaker-level characterization, absent in datasets like ASVspoof21\n(DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF)\nand In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to\nbe more challenging compared to benchmark ITW dataset. The complete dataset,\nalong with documentation and sample reference clips, is publicly accessible for\nresearch use on project website.\n","authors":["Abhay Kumar","Kunal Verma","Omkar More"],"pdf_url":"https://arxiv.org/pdf/2506.19014v2.pdf","comment":"Project Website: https://indie-fake-dataset.netlify.app/"},{"id":"http://arxiv.org/abs/2506.21490v1","updated":"2025-06-26T17:19:52Z","published":"2025-06-26T17:19:52Z","title":"Ad-Hoc Human-AI Coordination Challenge","summary":"  Achieving seamless coordination between AI agents and humans is crucial for\nreal-world applications, yet it remains a significant open challenge. Hanabi is\na cooperative card game featuring imperfect information, constrained\ncommunication, theory of mind requirements, and coordinated action -- making it\nan ideal testbed for human-AI coordination. However, its use for human-AI\ninteraction has been limited by the challenges of human evaluation. In this\nwork, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to\novercome the constraints of costly and difficult-to-reproduce human\nevaluations. We develop \\textit{human proxy agents} on a large-scale human\ndataset that serve as robust, cheap, and reproducible human-like evaluation\npartners in AH2AC2. To encourage the development of data-efficient methods, we\nopen-source a dataset of 3,079 games, deliberately limiting the amount of\navailable human gameplay data. We present baseline results for both two- and\nthree- player Hanabi scenarios. To ensure fair evaluation, we host the proxy\nagents through a controlled evaluation system rather than releasing them\npublicly. The code is available at\n\\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.\n","authors":["Tin Dizdarević","Ravi Hammond","Tobias Gessler","Anisoara Calinescu","Jonathan Cook","Matteo Gallici","Andrei Lupu","Jakob Nicolaus Foerster"],"pdf_url":"https://arxiv.org/pdf/2506.21490v1.pdf","comment":"Published at ICML 2025"},{"id":"http://arxiv.org/abs/2506.19686v2","updated":"2025-06-26T17:18:54Z","published":"2025-06-24T14:55:43Z","title":"From Memories to Maps: Mechanisms of In-Context Reinforcement Learning\n  in Transformers","summary":"  Humans and animals show remarkable learning efficiency, adapting to new\nenvironments with minimal experience. This capability is not well captured by\nstandard reinforcement learning algorithms that rely on incremental value\nupdates. Rapid adaptation likely depends on episodic memory -- the ability to\nretrieve specific past experiences to guide decisions in novel contexts.\nTransformers provide a useful setting for studying these questions because of\ntheir ability to learn rapidly in-context and because their key-value\narchitecture resembles episodic memory systems in the brain. We train a\ntransformer to in-context reinforcement learn in a distribution of planning\ntasks inspired by rodent behavior. We then characterize the learning algorithms\nthat emerge in the model. We first find that representation learning is\nsupported by in-context structure learning and cross-context alignment, where\nrepresentations are aligned across environments with different sensory stimuli.\nWe next demonstrate that the reinforcement learning strategies developed by the\nmodel are not interpretable as standard model-free or model-based planning.\nInstead, we show that in-context reinforcement learning is supported by caching\nintermediate computations within the model's memory tokens, which are then\naccessed at decision time. Overall, we find that memory may serve as a\ncomputational resource, storing both raw experience and cached computations to\nsupport flexible behavior. Furthermore, the representations developed in the\nmodel resemble computations associated with the hippocampal-entorhinal system\nin the brain, suggesting that our findings may be relevant for natural\ncognition. Taken together, our work offers a mechanistic hypothesis for the\nrapid adaptation that underlies in-context learning in artificial and natural\nsettings.\n","authors":["Ching Fang","Kanaka Rajan"],"pdf_url":"https://arxiv.org/pdf/2506.19686v2.pdf","comment":"Updates: added other funding sources; formatted title correctly"},{"id":"http://arxiv.org/abs/2506.21484v1","updated":"2025-06-26T17:12:58Z","published":"2025-06-26T17:12:58Z","title":"TITAN: Query-Token based Domain Adaptive Adversarial Learning","summary":"  We focus on the source-free domain adaptive object detection (SF-DAOD)\nproblem when source data is unavailable during adaptation and the model must\nadapt to an unlabeled target domain. The majority of approaches for the problem\nemploy a self-supervised approach using a student-teacher (ST) framework where\npseudo-labels are generated via a source-pretrained model for further\nfine-tuning. We observe that the performance of a student model often degrades\ndrastically, due to the collapse of the teacher model, primarily caused by high\nnoise in pseudo-labels, resulting from domain bias, discrepancies, and a\nsignificant domain shift across domains. To obtain reliable pseudo-labels, we\npropose a Target-based Iterative Query-Token Adversarial Network (TITAN), which\nseparates the target images into two subsets: those similar to the source\n(easy) and those dissimilar (hard). We propose a strategy to estimate variance\nto partition the target domain. This approach leverages the insight that higher\ndetection variances correspond to higher recall and greater similarity to the\nsource domain. Also, we incorporate query-token-based adversarial modules into\na student-teacher baseline framework to reduce the domain gaps between two\nfeature representations. Experiments conducted on four natural imaging datasets\nand two challenging medical datasets have substantiated the superior\nperformance of TITAN compared to existing state-of-the-art (SOTA)\nmethodologies. We report an mAP improvement of +22.7, +22.2, +21.1, and +3.7\npercent over the current SOTA on C2F, C2B, S2C, and K2C benchmarks,\nrespectively.\n","authors":["Tajamul Ashraf","Janibul Bashir"],"pdf_url":"https://arxiv.org/pdf/2506.21484v1.pdf","comment":"ICCV 2025"},{"id":"http://arxiv.org/abs/2506.21478v1","updated":"2025-06-26T17:07:45Z","published":"2025-06-26T17:07:45Z","title":"SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis\n  with Multi-Resolution Architecture","summary":"  Singing voice synthesis (SVS) aims to generate expressive and high-quality\nvocals from musical scores, requiring precise modeling of pitch, duration, and\narticulation. While diffusion-based models have achieved remarkable success in\nimage and video generation, their application to SVS remains challenging due to\nthe complex acoustic and musical characteristics of singing, often resulting in\nartifacts that degrade naturalness. In this work, we propose SmoothSinger, a\nconditional diffusion model designed to synthesize high quality and natural\nsinging voices. Unlike prior methods that depend on vocoders as a final stage\nand often introduce distortion, SmoothSinger refines low-quality synthesized\naudio directly in a unified framework, mitigating the degradation associated\nwith two-stage pipelines. The model adopts a reference-guided dual-branch\narchitecture, using low-quality audio from any baseline system as a reference\nto guide the denoising process, enabling more expressive and context-aware\nsynthesis. Furthermore, it enhances the conventional U-Net with a parallel\nlow-frequency upsampling path, allowing the model to better capture pitch\ncontours and long term spectral dependencies. To improve alignment during\ntraining, we replace reference audio with degraded ground truth audio,\naddressing temporal mismatch between reference and target signals. Experiments\non the Opencpop dataset, a large-scale Chinese singing corpus, demonstrate that\nSmoothSinger achieves state-of-the-art results in both objective and subjective\nevaluations. Extensive ablation studies confirm its effectiveness in reducing\nartifacts and improving the naturalness of synthesized voices.\n","authors":["Kehan Sui","Jinxu Xiang","Fang Jin"],"pdf_url":"https://arxiv.org/pdf/2506.21478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17859v2","updated":"2025-06-26T16:54:57Z","published":"2025-06-21T23:49:08Z","title":"In-Context Learning Strategies Emerge Rationally","summary":"  Recent work analyzing in-context learning (ICL) has identified a broad set of\nstrategies that describe model behavior in different experimental conditions.\nWe aim to unify these findings by asking why a model learns these disparate\nstrategies in the first place. Specifically, we start with the observation that\nwhen trained to learn a mixture of tasks, as is popular in the literature, the\nstrategies learned by a model for performing ICL can be captured by a family of\nBayesian predictors: a memorizing predictor, which assumes a discrete prior on\nthe set of seen tasks, and a generalizing predictor, where the prior matches\nthe underlying task distribution. Adopting the normative lens of rational\nanalysis, where a learner's behavior is explained as an optimal adaptation to\ndata given computational constraints, we develop a hierarchical Bayesian\nframework that almost perfectly predicts Transformer next-token predictions\nthroughout training -- without assuming access to its weights. Under this\nframework, pretraining is viewed as a process of updating the posterior\nprobability of different strategies, and inference-time behavior as a\nposterior-weighted average over these strategies' predictions. Our framework\ndraws on common assumptions about neural network learning dynamics, which make\nexplicit a tradeoff between loss and complexity among candidate strategies:\nbeyond how well it explains the data, a model's preference towards implementing\na strategy is dictated by its complexity. This helps explain well-known ICL\nphenomena, while offering novel predictions: e.g., we show a superlinear trend\nin the timescale for transitioning from generalization to memorization as task\ndiversity increases. Overall, our work advances an explanatory and predictive\naccount of ICL grounded in tradeoffs between strategy loss and complexity.\n","authors":["Daniel Wurgaft","Ekdeep Singh Lubana","Core Francisco Park","Hidenori Tanaka","Gautam Reddy","Noah D. Goodman"],"pdf_url":"https://arxiv.org/pdf/2506.17859v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.18019v2","updated":"2025-06-26T16:54:14Z","published":"2025-06-22T12:59:12Z","title":"Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities","summary":"  AI agents have experienced a paradigm shift, from early dominance by\nreinforcement learning (RL) to the rise of agents powered by large language\nmodels (LLMs), and now further advancing towards a synergistic fusion of RL and\nLLM capabilities. This progression has endowed AI agents with increasingly\nstrong abilities. Despite these advances, to accomplish complex real-world\ntasks, agents are required to plan and execute effectively, maintain reliable\nmemory, and coordinate smoothly with other agents. Achieving these capabilities\ninvolves contending with ever-present intricate information, operations, and\ninteractions. In light of this challenge, data structurization can play a\npromising role by transforming intricate and disorganized data into\nwell-structured forms that agents can more effectively understand and process.\nIn this context, graphs, with their natural advantage in organizing, managing,\nand harnessing intricate data relationships, present a powerful data paradigm\nfor structurization to support the capabilities demanded by advanced AI agents.\nTo this end, this survey presents a first systematic review of how graphs can\nempower AI agents. Specifically, we explore the integration of graph techniques\nwith core agent functionalities, highlight notable applications, and identify\nprospective avenues for future research. By comprehensively surveying this\nburgeoning intersection, we hope to inspire the development of next-generation\nAI agents equipped to tackle increasingly sophisticated challenges with graphs.\nRelated resources are collected and continuously updated for the community in\nthe Github link.\n","authors":["Yuanchen Bei","Weizhi Zhang","Siwen Wang","Weizhi Chen","Sheng Zhou","Hao Chen","Yong Li","Jiajun Bu","Shirui Pan","Yizhou Yu","Irwin King","Fakhri Karray","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2506.18019v2.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.21465v1","updated":"2025-06-26T16:51:22Z","published":"2025-06-26T16:51:22Z","title":"Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach\n  for Efficiency and Low Storage","summary":"  Extended Stability Runge-Kutta (ESRK) methods are crucial for solving\nlarge-scale computational problems in science and engineering, including\nweather forecasting, aerodynamic analysis, and complex biological modelling.\nHowever, balancing accuracy, stability, and computational efficiency remains\nchallenging, particularly for high-order, low-storage schemes. This study\nintroduces a hybrid Genetic Algorithm (GA) and Reinforcement Learning (RL)\napproach for automated heuristic discovery, optimising low-storage ESRK\nmethods. Unlike traditional approaches that rely on manually designed\nheuristics or exhaustive numerical searches, our method leverages GA-driven\nmutations for search-space exploration and an RL-inspired state transition\nmechanism to refine heuristic selection dynamically. This enables systematic\nparameter reduction, preserving fourth-order accuracy while significantly\nimproving computational efficiency.The proposed GA-RL heuristic optimisation\nframework is validated through rigorous testing on benchmark problems,\nincluding the 1D and 2D Brusselator systems and the steady-state Navier-Stokes\nequations. The best-performing heuristic achieves a 25\\% reduction in IPOPT\nruntime compared to traditional ESRK optimisation processes while maintaining\nnumerical stability and accuracy. These findings demonstrate the potential of\nadaptive heuristic discovery to improve resource efficiency in high-fidelity\nsimulations and broaden the applicability of low-storage Runge-Kutta methods in\nreal-world computational fluid dynamics, physics simulations, and other\ndemanding fields. This work establishes a new paradigm in heuristic\noptimisation for numerical methods, opening pathways for further exploration\nusing Deep RL and AutoML-based heuristic search\n","authors":["Gavin Lee Goodship","Luis Miralles-Pechuan","Stephen O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2506.21465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13846v2","updated":"2025-06-26T16:39:32Z","published":"2025-06-16T17:59:40Z","title":"Fake it till You Make it: Reward Modeling as Discriminative Prediction","summary":"  An effective reward model plays a pivotal role in reinforcement learning for\npost-training enhancement of visual generative models. However, current\napproaches of reward modeling suffer from implementation complexity due to\ntheir reliance on extensive human-annotated preference data or meticulously\nengineered quality dimensions that are often incomplete and\nengineering-intensive. Inspired by adversarial training in generative\nadversarial networks (GANs), this paper proposes GAN-RM, an efficient reward\nmodeling framework that eliminates manual preference annotation and explicit\nquality dimension engineering. Our method trains the reward model through\ndiscrimination between a small set of representative, unpaired target\nsamples(denoted as Preference Proxy Data) and model-generated ordinary outputs,\nrequiring only a few hundred target samples. Comprehensive experiments\ndemonstrate our GAN-RM's effectiveness across multiple key applications\nincluding test-time scaling implemented as Best-of-N sample filtering,\npost-training approaches like Supervised Fine-Tuning (SFT) and Direct\nPreference Optimization (DPO). Code and data will be released at\nhttps://github.com/Visualignment/GAN-RM.\n","authors":["Runtao Liu","Jiahao Zhan","Yingqing He","Chen Wei","Alan Yuille","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2506.13846v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21458v1","updated":"2025-06-26T16:38:19Z","published":"2025-06-26T16:38:19Z","title":"Spatial Mental Modeling from Limited Views","summary":"  Can Vision Language Models (VLMs) imagine the full scene from just a few\nviews, like humans do? Humans form spatial mental models, internal\nrepresentations of unseen space, to reason about layout, perspective, and\nmotion. Our new MindCube benchmark with 21,154 questions across 3,268 images\nexposes this critical gap, where existing VLMs exhibit near-random performance.\nUsing MindCube, we systematically evaluate how well VLMs build robust spatial\nmental models through representing positions (cognitive mapping), orientations\n(perspective-taking), and dynamics (mental simulation for \"what-if\" movements).\nWe then explore three approaches to help VLMs approximate spatial mental\nmodels, including unseen intermediate views, natural language reasoning chains,\nand cognitive maps. The significant improvement comes from a synergistic\napproach, \"map-then-reason\", that jointly trains the model to first generate a\ncognitive map and then reason upon it. By training models to reason over these\ninternal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding\nreinforcement learning pushed performance even further to 70.7% (+32.9%). Our\nkey insight is that such scaffolding of spatial mental models, actively\nconstructing and utilizing internal structured spatial representations with\nflexible reasoning processes, significantly improves understanding of\nunobservable space.\n","authors":["Baiqiao Yin","Qineng Wang","Pingyue Zhang","Jianshu Zhang","Kangrui Wang","Zihan Wang","Jieyu Zhang","Keshigeyan Chandrasegaran","Han Liu","Ranjay Krishna","Saining Xie","Manling Li","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2506.21458v1.pdf","comment":"Preprint version"},{"id":"http://arxiv.org/abs/2506.21443v1","updated":"2025-06-26T16:29:45Z","published":"2025-06-26T16:29:45Z","title":"Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection","summary":"  Detecting deceptive conversations on dynamic platforms is increasingly\ndifficult due to evolving language patterns and Concept Drift (CD)-i.e.,\nsemantic or topical shifts that alter the context or intent of interactions\nover time. These shifts can obscure malicious intent or mimic normal dialogue,\nmaking accurate classification challenging. While Large Language Models (LLMs)\nshow strong performance in natural language tasks, they often struggle with\ncontextual ambiguity and hallucinations in risk-sensitive scenarios. To address\nthese challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework\nthat integrates pretrained LLMs with structured, task-specific insights to\nperform fraud and concept drift detection. The proposed architecture consists\nof three main components: (1) a DK-LLM module to detect fake or deceptive\nconversations; (2) a drift detection unit (OCDD) to determine whether a\nsemantic shift has occurred; and (3) a second DK-LLM module to classify the\ndrift as either benign or fraudulent. We first validate the value of domain\nknowledge using a fake review dataset and then apply our full framework to\nSEConvo, a multiturn dialogue dataset that includes various types of fraud and\nspam attacks. Results show that our system detects fake conversations with high\naccuracy and effectively classifies the nature of drift. Guided by structured\nprompts, the LLaMA-based implementation achieves 98% classification accuracy.\nComparative studies against zero-shot baselines demonstrate that incorporating\ndomain knowledge and drift awareness significantly improves performance,\ninterpretability, and robustness in high-stakes NLP applications.\n","authors":["Ali Şenol","Garima Agrawal","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2506.21443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03717v2","updated":"2025-06-26T16:22:07Z","published":"2025-01-07T11:52:01Z","title":"Materialist: Physically Based Editing Using Single-Image Inverse\n  Rendering","summary":"  Achieving physically consistent image editing remains a significant challenge\nin computer vision. Existing image editing methods typically rely on neural\nnetworks, which struggle to accurately handle shadows and refractions.\nConversely, physics-based inverse rendering often requires multi-view\noptimization, limiting its practicality in single-image scenarios. In this\npaper, we propose Materialist, a method combining a learning-based approach\nwith physically based progressive differentiable rendering. Given an image, our\nmethod leverages neural networks to predict initial material properties.\nProgressive differentiable rendering is then used to optimize the environment\nmap and refine the material properties with the goal of closely matching the\nrendered result to the input image. Our approach enables a range of\napplications, including material editing, object insertion, and relighting,\nwhile also introducing an effective method for editing material transparency\nwithout requiring full scene geometry. Furthermore, Our envmap estimation\nmethod also achieves state-of-the-art performance, further enhancing the\naccuracy of image editing task. Experiments demonstrate strong performance\nacross synthetic and real-world datasets, excelling even on challenging\nout-of-domain images. Project website:\nhttps://lez-s.github.io/materialist_project/\n","authors":["Lezhong Wang","Duc Minh Tran","Ruiqi Cui","Thomson TG","Anders Bjorholm Dahl","Siavash Arjomand Bigdeli","Jeppe Revall Frisvad","Manmohan Chandraker"],"pdf_url":"https://arxiv.org/pdf/2501.03717v2.pdf","comment":"Add acknowledgements, more authors and more results. Project website:\n  https://lez-s.github.io/materialist_project/"},{"id":"http://arxiv.org/abs/2505.21657v3","updated":"2025-06-26T16:16:59Z","published":"2025-05-27T18:32:38Z","title":"Explainability of Large Language Models using SMILE: Statistical\n  Model-agnostic Interpretability with Local Explanations","summary":"  Large language models like GPT, LLAMA, and Claude have become incredibly\npowerful at generating text, but they are still black boxes, so it is hard to\nunderstand how they decide what to say. That lack of transparency can be\nproblematic, especially in fields where trust and accountability matter. To\nhelp with this, we introduce SMILE, a new method that explains how these models\nrespond to different parts of a prompt. SMILE is model-agnostic and works by\nslightly changing the input, measuring how the output changes, and then\nhighlighting which words had the most impact. Create simple visual heat maps\nshowing which parts of a prompt matter the most. We tested SMILE on several\nleading LLMs and used metrics such as accuracy, consistency, stability, and\nfidelity to show that it gives clear and reliable explanations. By making these\nmodels easier to understand, SMILE brings us one step closer to making AI more\ntransparent and trustworthy.\n","authors":["Zeinab Dehghani","Mohammed Naveed Akram","Koorosh Aslansefat","Adil Khan"],"pdf_url":"https://arxiv.org/pdf/2505.21657v3.pdf","comment":"The submission contains incorrect references that require substantial\n  revision"},{"id":"http://arxiv.org/abs/2501.08005v3","updated":"2025-06-26T16:11:14Z","published":"2025-01-14T10:49:26Z","title":"DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved\n  Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection holds significant importance across many\napplications. While semantic and domain-shift OOD problems are well-studied,\nthis work focuses on covariate shifts - subtle variations in the data\ndistribution that can degrade machine learning performance. We hypothesize that\ndetecting these subtle shifts can improve our understanding of in-distribution\nboundaries, ultimately improving OOD detection. In adversarial discriminators\ntrained with Batch Normalization (BN), real and adversarial samples form\ndistinct domains with unique batch statistics - a property we exploit for OOD\ndetection. We introduce DisCoPatch, an unsupervised Adversarial Variational\nAutoencoder (VAE) framework that harnesses this mechanism. During inference,\nbatches consist of patches from the same image, ensuring a consistent data\ndistribution that allows the model to rely on batch statistics. DisCoPatch uses\nthe VAE's suboptimal outputs (generated and reconstructed) as negative samples\nto train the discriminator, thereby improving its ability to delineate the\nboundary between in-distribution samples and covariate shifts. By tightening\nthis boundary, DisCoPatch achieves state-of-the-art results in public OOD\ndetection benchmarks. The proposed model not only excels in detecting covariate\nshifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior\nmethods on public Near-OOD (95.0%) benchmarks. With a compact model size of\n25MB, it achieves high OOD detection performance at notably lower latency than\nexisting methods, making it an efficient and practical solution for real-world\nOOD detection applications. The code is publicly available.\n","authors":["Francisco Caetano","Christiaan Viviers","Luis A. Zavala-Mondragón","Peter H. N. de With","Fons van der Sommen"],"pdf_url":"https://arxiv.org/pdf/2501.08005v3.pdf","comment":"ICCV 2025"},{"id":"http://arxiv.org/abs/2506.04202v3","updated":"2025-06-26T16:09:36Z","published":"2025-06-04T17:48:16Z","title":"TracLLM: A Generic Framework for Attributing Long Context LLMs","summary":"  Long context large language models (LLMs) are deployed in many real-world\napplications such as RAG, agent, and broad LLM-integrated applications. Given\nan instruction and a long context (e.g., documents, PDF files, webpages), a\nlong context LLM can generate an output grounded in the provided context,\naiming to provide more accurate, up-to-date, and verifiable outputs while\nreducing hallucinations and unsupported claims. This raises a research\nquestion: how to pinpoint the texts (e.g., sentences, passages, or paragraphs)\nin the context that contribute most to or are responsible for the generated\noutput by an LLM? This process, which we call context traceback, has various\nreal-world applications, such as 1) debugging LLM-based systems, 2) conducting\npost-attack forensic analysis for attacks (e.g., prompt injection attack,\nknowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources\nto enhance the trust of users towards outputs generated by LLMs. When applied\nto context traceback for long context LLMs, existing feature attribution\nmethods such as Shapley have sub-optimal performance and/or incur a large\ncomputational cost. In this work, we develop TracLLM, the first generic context\ntraceback framework tailored to long context LLMs. Our framework can improve\nthe effectiveness and efficiency of existing feature attribution methods. To\nimprove the efficiency, we develop an informed search based algorithm in\nTracLLM. We also develop contribution score ensemble/denoising techniques to\nimprove the accuracy of TracLLM. Our evaluation results show TracLLM can\neffectively identify texts in a long context that lead to the output of an LLM.\nOur code and data are at: https://github.com/Wang-Yanting/TracLLM.\n","authors":["Yanting Wang","Wei Zou","Runpeng Geng","Jinyuan Jia"],"pdf_url":"https://arxiv.org/pdf/2506.04202v3.pdf","comment":"To appear in USENIX Security Symposium 2025. The code and data are\n  at: https://github.com/Wang-Yanting/TracLLM"},{"id":"http://arxiv.org/abs/2307.04345v3","updated":"2025-06-26T16:08:44Z","published":"2023-07-10T05:06:41Z","title":"Continual Learning as Computationally Constrained Reinforcement Learning","summary":"  An agent that efficiently accumulates knowledge to develop increasingly\nsophisticated skills over a long lifetime could advance the frontier of\nartificial intelligence capabilities. The design of such agents, which remains\na long-standing challenge of artificial intelligence, is addressed by the\nsubject of continual learning. This monograph clarifies and formalizes concepts\nof continual learning, introducing a framework and set of tools to stimulate\nfurther research.\n","authors":["Saurabh Kumar","Henrik Marklund","Ashish Rao","Yifan Zhu","Hong Jun Jeon","Yueyang Liu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2307.04345v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21408v1","updated":"2025-06-26T15:54:45Z","published":"2025-06-26T15:54:45Z","title":"Scalable Bayesian Low-Rank Adaptation of Large Language Models via\n  Stochastic Variational Subspace Inference","summary":"  Despite their widespread use, large language models (LLMs) are known to\nhallucinate incorrect information and be poorly calibrated. This makes the\nuncertainty quantification of these models of critical importance, especially\nin high-stakes domains, such as autonomy and healthcare. Prior work has made\nBayesian deep learning-based approaches to this problem more tractable by\nperforming inference over the low-rank adaptation (LoRA) parameters of a\nfine-tuned model. While effective, these approaches struggle to scale to larger\nLLMs due to requiring further additional parameters compared to LoRA. In this\nwork we present $\\textbf{Scala}$ble $\\textbf{B}$ayesian $\\textbf{L}$ow-Rank\nAdaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform\nBayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By\nrepurposing the LoRA parameters as projection matrices, we are able to map\nsamples from this subspace into the full weight space of the LLM. This allows\nus to learn all the parameters of our approach using stochastic variational\ninference. Despite the low dimensionality of our subspace, we are able to\nachieve competitive performance with state-of-the-art approaches while only\nrequiring ${\\sim}1000$ additional parameters. Furthermore, it allows us to\nscale up to the largest Bayesian LLM to date, with four times as a many base\nparameters as prior work.\n","authors":["Colin Samplawski","Adam D. Cobb","Manoj Acharya","Ramneet Kaur","Susmit Jha"],"pdf_url":"https://arxiv.org/pdf/2506.21408v1.pdf","comment":"Accepted at UAI 2025"},{"id":"http://arxiv.org/abs/2506.21393v1","updated":"2025-06-26T15:41:34Z","published":"2025-06-26T15:41:34Z","title":"TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in\n  Multimodal Table Understanding","summary":"  Multimodal understanding of tables in real-world contexts is challenging due\nto the complexity of structure, symbolic density, and visual degradation (blur,\nskew, watermarking, incomplete structures or fonts, multi-span or\nhierarchically nested layouts). Existing multimodal large language models\n(MLLMs) struggle with such WildStruct conditions, resulting in limited\nperformance and poor generalization. To address these challenges, we propose\nTableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture\nspecifically designed for robust, structured reasoning over multimodal table\ndata. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which\npredicts latent semantic token roles (e.g., header, data cell, axis, formula)\nand dynamically routes table elements to specialized experts (Table-to-HTML,\nTable-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed\nby symbolic reasoning graphs. To facilitate effective alignment-driven\npretraining, we introduce the large-scale TableMoE-Align dataset, consisting of\n1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and\nindustry, utilized exclusively for model pretraining. For evaluation, we curate\nand release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,\nWMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models\nunder real-world multimodal degradation and structural complexity. Experimental\nresults demonstrate that TableMoE significantly surpasses existing\nstate-of-the-art models. Extensive ablation studies validate each core\ncomponent, emphasizing the critical role of Neuro-Symbolic Routing and\nstructured expert alignment. Through qualitative analyses, we further showcase\nTableMoE's interpretability and enhanced robustness, underscoring the\neffectiveness of integrating neuro-symbolic reasoning for multimodal table\nunderstanding.\n","authors":["Junwen Zhang","Pu Chen","Yin Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.21393v1.pdf","comment":"43 pages and 11 figures"},{"id":"http://arxiv.org/abs/2506.21384v1","updated":"2025-06-26T15:35:12Z","published":"2025-06-26T15:35:12Z","title":"Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented\n  Generation","summary":"  Real-world live retrieval-augmented generation (RAG) systems face significant\nchallenges when processing user queries that are often noisy, ambiguous, and\ncontain multiple intents. While RAG enhances large language models (LLMs) with\nexternal knowledge, current systems typically struggle with such complex\ninputs, as they are often trained or evaluated on cleaner data. This paper\nintroduces Omni-RAG, a novel framework designed to improve the robustness and\neffectiveness of RAG systems in live, open-domain settings. Omni-RAG employs\nLLM-assisted query understanding to preprocess user inputs through three key\nmodules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs\nwith tailored prompts to denoise queries (e.g., correcting spelling errors) and\ndecompose multi-intent queries into structured sub-queries; (2) Intent-Aware\nKnowledge Retrieval, which performs retrieval for each sub-query from a corpus\n(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking\nand Generation, where a reranker (i.e., BGE) refines document selection before\na final response is generated by an LLM (i.e., Falcon-10B) using a\nchain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG\ncapabilities and the demands of real-world applications, such as those\nhighlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex\nand noisy queries.\n","authors":["Guanting Dong","Xiaoxi Li","Yuyao Zhang","Mengjie Deng"],"pdf_url":"https://arxiv.org/pdf/2506.21384v1.pdf","comment":"Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)"},{"id":"http://arxiv.org/abs/2501.02648v3","updated":"2025-06-26T15:34:13Z","published":"2025-01-05T20:26:49Z","title":"Representation Learning of Lab Values via Masked AutoEncoders","summary":"  Accurate imputation of missing laboratory values in electronic health records\n(EHRs) is critical to enable robust clinical predictions and reduce biases in\nAI systems in healthcare. Existing methods, such as XGBoost, softimpute, GAIN,\nExpectation Maximization (EM), and MICE, struggle to model the complex temporal\nand contextual dependencies in EHR data, particularly in underrepresented\ngroups. In this work, we propose Lab-MAE, a novel transformer-based masked\nautoencoder framework that leverages self-supervised learning for the\nimputation of continuous sequential lab values. Lab-MAE introduces a structured\nencoding scheme that jointly models laboratory test values and their\ncorresponding timestamps, enabling explicit capturing temporal dependencies.\nEmpirical evaluation on the MIMIC-IV dataset demonstrates that Lab-MAE\nsignificantly outperforms state-of-the-art baselines such as XGBoost,\nsoftimpute, GAIN, EM, and MICE across multiple metrics, including root mean\nsquare error (RMSE), R-squared (R2), and Wasserstein distance (WD). Notably,\nLab-MAE achieves equitable performance across demographic groups of patients,\nadvancing fairness in clinical predictions. We further investigate the role of\nfollow-up laboratory values as potential shortcut features, revealing Lab-MAE's\nrobustness in scenarios where such data is unavailable. The findings suggest\nthat our transformer-based architecture, adapted to the characteristics of EHR\ndata, offers a foundation model for more accurate and fair clinical imputation.\nIn addition, we measure and compare the carbon footprint of Lab-MAE with the a\nXGBoost model, highlighting its environmental requirements.\n","authors":["David Restrepo","Chenwei Wu","Yueran Jia","Jaden K. Sun","Jack Gallifant","Catherine G. Bielick","Yugang Jia","Leo A. Celi"],"pdf_url":"https://arxiv.org/pdf/2501.02648v3.pdf","comment":"14 pages of main text, 11 appendix"},{"id":"http://arxiv.org/abs/2506.21382v1","updated":"2025-06-26T15:34:06Z","published":"2025-06-26T15:34:06Z","title":"Temporal-Aware Graph Attention Network for Cryptocurrency Transaction\n  Fraud Detection","summary":"  Cryptocurrency transaction fraud detection faces the dual challenges of\nincreasingly complex transaction patterns and severe class imbalance.\nTraditional methods rely on manual feature engineering and struggle to capture\ntemporal and structural dependencies in transaction networks. This paper\nproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that\nenhances detection performance through three modules: (1) designing an advanced\ntemporal embedding module that fuses multi-scale time difference features with\nperiodic position encoding; (2) constructing a temporal-aware triple attention\nmechanism that jointly optimizes structural, temporal, and global context\nattention; (3) employing weighted BCE loss to address class imbalance.\nExperiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT\nachieves an AUC of 0.9130, representing a 9.2% improvement over the best\ntraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This\nmethod not only validates the enhancement effect of temporal awareness and\ntriple attention mechanisms on graph neural networks, but also provides\nfinancial institutions with more reliable fraud detection tools, with its\ndesign principles generalizable to other temporal graph anomaly detection\ntasks.\n","authors":["Zhi Zheng","Bochuan Zhou","Yuping Song"],"pdf_url":"https://arxiv.org/pdf/2506.21382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21374v1","updated":"2025-06-26T15:22:55Z","published":"2025-06-26T15:22:55Z","title":"Pay Attention to Small Weights","summary":"  Finetuning large pretrained neural networks is known to be\nresource-intensive, both in terms of memory and computational cost. To mitigate\nthis, a common approach is to restrict training to a subset of the model\nparameters. By analyzing the relationship between gradients and weights during\nfinetuning, we observe a notable pattern: large gradients are often associated\nwith small-magnitude weights. This correlation is more pronounced in finetuning\nsettings than in training from scratch. Motivated by this observation, we\npropose NANOADAM, which dynamically updates only the small-magnitude weights\nduring finetuning and offers several practical advantages: first, this\ncriterion is gradient-free -- the parameter subset can be determined without\ngradient computation; second, it preserves large-magnitude weights, which are\nlikely to encode critical features learned during pretraining, thereby reducing\nthe risk of catastrophic forgetting; thirdly, it permits the use of larger\nlearning rates and consistently leads to better generalization performance in\nexperiments. We demonstrate this for both NLP and vision tasks.\n","authors":["Chao Zhou","Tom Jacobs","Advait Gadhikar","Rebekka Burkholz"],"pdf_url":"https://arxiv.org/pdf/2506.21374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21368v1","updated":"2025-06-26T15:16:44Z","published":"2025-06-26T15:16:44Z","title":"Real-time and personalized product recommendations for large e-commerce\n  platforms","summary":"  We present a methodology to provide real-time and personalized product\nrecommendations for large e-commerce platforms, specifically focusing on\nfashion retail. Our approach aims to achieve accurate and scalable\nrecommendations with minimal response times, ensuring user satisfaction,\nleveraging Graph Neural Networks and parsimonious learning methodologies.\nExtensive experimentation with datasets from one of the largest e-commerce\nplatforms demonstrates the effectiveness of our approach in forecasting\npurchase sequences and handling multi-interaction scenarios, achieving\nefficient personalized recommendations under real-world constraints.\n","authors":["Matteo Tolloso","Davide Bacciu","Shahab Mokarizadeh","Marco Varesi"],"pdf_url":"https://arxiv.org/pdf/2506.21368v1.pdf","comment":"This paper has been accepted for publication at the International\n  Conference on Artificial Neural Networks (ICANN) 2025. The final\n  authenticated version will be available for purchase through the publisher's\n  website. The conference proceedings will be published by Springer in the\n  Lecture Notes in Computer Science (LNCS) series"},{"id":"http://arxiv.org/abs/2506.21367v1","updated":"2025-06-26T15:16:35Z","published":"2025-06-26T15:16:35Z","title":"rQdia: Regularizing Q-Value Distributions With Image Augmentation","summary":"  rQdia regularizes Q-value distributions with augmented images in pixel-based\ndeep reinforcement learning. With a simple auxiliary loss, that equalizes these\ndistributions via MSE, rQdia boosts DrQ and SAC on 9/12 and 10/12 tasks\nrespectively in the MuJoCo Continuous Control Suite from pixels, and\nData-Efficient Rainbow on 18/26 Atari Arcade environments. Gains are measured\nin both sample efficiency and longer-term training. Moreover, the addition of\nrQdia finally propels model-free continuous control from pixels over the state\nencoding baseline.\n","authors":["Sam Lerman","Jing Bi"],"pdf_url":"https://arxiv.org/pdf/2506.21367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21364v1","updated":"2025-06-26T15:15:18Z","published":"2025-06-26T15:15:18Z","title":"CA-I2P: Channel-Adaptive Registration Network with Global Optimal\n  Selection","summary":"  Detection-free methods typically follow a coarse-to-fine pipeline, extracting\nimage and point cloud features for patch-level matching and refining dense\npixel-to-point correspondences. However, differences in feature channel\nattention between images and point clouds may lead to degraded matching\nresults, ultimately impairing registration accuracy. Furthermore, similar\nstructures in the scene could lead to redundant correspondences in cross-modal\nmatching. To address these issues, we propose Channel Adaptive Adjustment\nModule (CAA) and Global Optimal Selection Module (GOS). CAA enhances\nintra-modal features and suppresses cross-modal sensitivity, while GOS replaces\nlocal selection with global optimization. Experiments on RGB-D Scenes V2 and\n7-Scenes demonstrate the superiority of our method, achieving state-of-the-art\nperformance in image-to-point cloud registration.\n","authors":["Zhixin Cheng","Jiacheng Deng","Xinjun Li","Xiaotian Yin","Bohao Liao","Baoqun Yin","Wenfei Yang","Tianzhu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.21364v1.pdf","comment":"ICCV 2025 accepted"},{"id":"http://arxiv.org/abs/2506.12113v3","updated":"2025-06-26T15:09:42Z","published":"2025-06-13T13:39:00Z","title":"Semantic Preprocessing for LLM-based Malware Analysis","summary":"  In a context of malware analysis, numerous approaches rely on Artificial\nIntelligence to handle a large volume of data. However, these techniques focus\non data view (images, sequences) and not on an expert's view. Noticing this\nissue, we propose a preprocessing that focuses on expert knowledge to improve\nmalware semantic analysis and result interpretability. We propose a new\npreprocessing method which creates JSON reports for Portable Executable files.\nThese reports gather features from both static and behavioral analysis, and\nincorporate packer signature detection, MITRE ATT\\&CK and Malware Behavior\nCatalog (MBC) knowledge. The purpose of this preprocessing is to gather a\nsemantic representation of binary files, understandable by malware analysts,\nand that can enhance AI models' explainability for malicious files analysis.\nUsing this preprocessing to train a Large Language Model for Malware\nclassification, we achieve a weighted-average F1-score of 0.94 on a complex\ndataset, representative of market reality.\n","authors":["Benjamin Marais","Tony Quertier","Grégoire Barrue"],"pdf_url":"https://arxiv.org/pdf/2506.12113v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10586v2","updated":"2025-06-26T15:00:42Z","published":"2024-01-19T09:54:23Z","title":"PuriDefense: Randomized Local Implicit Adversarial Purification for\n  Defending Black-box Query-based Attacks","summary":"  Black-box query-based attacks constitute significant threats to Machine\nLearning as a Service (MLaaS) systems since they can generate adversarial\nexamples without accessing the target model's architecture and parameters.\nTraditional defense mechanisms, such as adversarial training, gradient masking,\nand input transformations, either impose substantial computational costs or\ncompromise the test accuracy of non-adversarial inputs. To address these\nchallenges, we propose an efficient defense mechanism, PuriDefense, that\nemploys random patch-wise purifications with an ensemble of lightweight\npurification models at a low level of inference cost. These models leverage the\nlocal implicit function and rebuild the natural image manifold. Our theoretical\nanalysis suggests that this approach slows down the convergence of query-based\nattacks by incorporating randomness into purifications. Extensive experiments\non CIFAR-10 and ImageNet validate the effectiveness of our proposed\npurifier-based defense mechanism, demonstrating significant improvements in\nrobustness against query-based attacks.\n","authors":["Ping Guo","Xiang Li","Zhiyuan Yang","Xi Lin","Qingchuan Zhao","Qingfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.10586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21333v1","updated":"2025-06-26T14:44:52Z","published":"2025-06-26T14:44:52Z","title":"A Systematic Review of Human-AI Co-Creativity","summary":"  The co creativity community is making significant progress in developing more\nsophisticated and tailored systems to support and enhance human creativity.\nDesign considerations from prior work can serve as a valuable and efficient\nfoundation for future systems. To support this effort, we conducted a\nsystematic literature review of 62 papers on co-creative systems. These papers\ncover a diverse range of applications, including visual arts, design, and\nwriting, where the AI acts not just as a tool but as an active collaborator in\nthe creative process. From this review, we identified several key dimensions\nrelevant to system design: phase of the creative process, creative task,\nproactive behavior of the system, user control, system embodiment, and AI model\ntype. Our findings suggest that systems offering high user control lead to\ngreater satisfaction, trust, and a stronger sense of ownership over creative\noutcomes. Furthermore, proactive systems, when adaptive and context sensitive,\ncan enhance collaboration. We also extracted 24 design considerations,\nhighlighting the value of encouraging users to externalize their thoughts and\nof increasing the system's social presence and transparency to foster trust.\nDespite recent advancements, important gaps remain, such as limited support for\nearly creative phases like problem clarification, and challenges related to\nuser adaptation to AI systems.\n","authors":["Saloni Singh","Koen Hndriks","Drik Heylen","Kim Baraka"],"pdf_url":"https://arxiv.org/pdf/2506.21333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21330v1","updated":"2025-06-26T14:43:57Z","published":"2025-06-26T14:43:57Z","title":"Holistic Surgical Phase Recognition with Hierarchical Input Dependent\n  State Space Models","summary":"  Surgical workflow analysis is essential in robot-assisted surgeries, yet the\nlong duration of such procedures poses significant challenges for comprehensive\nvideo analysis. Recent approaches have predominantly relied on transformer\nmodels; however, their quadratic attention mechanism restricts efficient\nprocessing of lengthy surgical videos. In this paper, we propose a novel\nhierarchical input-dependent state space model that leverages the linear\nscaling property of state space models to enable decision making on full-length\nvideos while capturing both local and global dynamics. Our framework\nincorporates a temporally consistent visual feature extractor, which appends a\nstate space model head to a visual feature extractor to propagate temporal\ninformation. The proposed model consists of two key modules: a\nlocal-aggregation state space model block that effectively captures intricate\nlocal dynamics, and a global-relation state space model block that models\ntemporal dependencies across the entire video. The model is trained using a\nhybrid discrete-continuous supervision strategy, where both signals of discrete\nphase labels and continuous phase progresses are propagated through the\nnetwork. Experiments have shown that our method outperforms the current\nstate-of-the-art methods by a large margin (+2.8% on Cholec80, +4.3% on\nMICCAI2016, and +12.9% on Heichole datasets). Code will be publicly available\nafter paper acceptance.\n","authors":["Haoyang Wu","Tsun-Hsuan Wang","Mathias Lechner","Ramin Hasani","Jennifer A. Eckhoff","Paul Pak","Ozanan R. Meireles","Guy Rosman","Yutong Ban","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2506.21330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21329v1","updated":"2025-06-26T14:43:04Z","published":"2025-06-26T14:43:04Z","title":"Active Inference AI Systems for Scientific Discovery","summary":"  The rapid evolution of artificial intelligence has led to expectations of\ntransformative scientific discovery, yet current systems remain fundamentally\nlimited by their operational architectures, brittle reasoning mechanisms, and\ntheir separation from experimental reality. Building on earlier work, we\ncontend that progress in AI-driven science now depends on closing three\nfundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap\n-- rather than on model size/data/test time compute. Scientific reasoning\ndemands internal representations that support simulation of actions and\nresponse, causal structures that distinguish correlation from mechanism, and\ncontinuous calibration. We define active inference AI systems for scientific\ndiscovery as those that (i) maintain long-lived research memories grounded in\ncausal self-supervised foundation models, (ii) symbolic or neuro-symbolic\nplanners equipped with Bayesian guardrails, (iii) grow persistent knowledge\ngraphs where thinking generates novel conceptual nodes, reasoning establishes\ncausal edges, and real-world interaction prunes false connections while\nstrengthening verified pathways, and (iv) refine their internal representations\nthrough closed-loop interaction with both high-fidelity simulators and\nautomated laboratories - an operational loop where mental simulation guides\naction and empirical surprise reshapes understanding. In essence, we outline an\narchitecture where discovery arises from the interplay between internal models\nthat enable counterfactual reasoning and external validation that grounds\nhypotheses in reality. It is also argued that the inherent ambiguity in\nfeedback from simulations and experiments, and underlying uncertainties makes\nhuman judgment indispensable, not as a temporary scaffold but as a permanent\narchitectural component.\n","authors":["Karthik Duraisamy"],"pdf_url":"https://arxiv.org/pdf/2506.21329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12558v2","updated":"2025-06-26T14:33:44Z","published":"2024-11-19T15:18:50Z","title":"Recall and Refine: A Simple but Effective Source-free Open-set Domain\n  Adaptation Framework","summary":"  Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source\ndomain to an unlabeled target domain, where novel classes - also referred to as\ntarget-private unknown classes - are present. Source-free Open-set Domain\nAdaptation (SF-OSDA) methods address OSDA without accessing labeled source\ndata, making them particularly relevant under privacy constraints. However,\nSF-OSDA presents significant challenges due to distribution shifts and the\nintroduction of novel classes. Existing SF-OSDA methods typically rely on\nthresholding the prediction entropy of a sample to identify it as either a\nknown or unknown class, but fail to explicitly learn discriminative features\nfor the target-private unknown classes. We propose Recall and Refine (RRDA), a\nnovel SF-OSDA framework designed to address these limitations by explicitly\nlearning features for target-private unknown classes. RRDA employs a two-stage\nprocess. First, we enhance the model's capacity to recognize unknown classes by\ntraining a target classifier with an additional decision boundary,guided by\nsynthetic samples generated from target domain features. This enables the\nclassifier to effectively separate known and unknown classes. Second, we adapt\nthe entire model to the target domain, addressing both domain shifts and\ndistinguishability to unknown classes. Any off-the-shelf source-free domain\nadaptation method (e.g. SHOT, AaD) can be seamlessly integrated into our\nframework at this stage. Extensive experiments on three benchmark datasets\ndemonstrate that RRDA significantly outperforms existing SF-OSDA and OSDA\nmethods.\n","authors":["Ismail Nejjar","Hao Dong","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2411.12558v2.pdf","comment":"Accepted at TMLR 2025"},{"id":"http://arxiv.org/abs/2506.21310v1","updated":"2025-06-26T14:28:13Z","published":"2025-06-26T14:28:13Z","title":"IXAII: An Interactive Explainable Artificial Intelligence Interface for\n  Decision Support Systems","summary":"  Although several post-hoc methods for explainable AI have been developed,\nmost are static and neglect the user perspective, limiting their effectiveness\nfor the target audience. In response, we developed the interactive explainable\nintelligent system called IXAII that offers explanations from four explainable\nAI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored\nviews for five user groups and gives users agency over the explanations'\ncontent and their format. We evaluated IXAII through interviews with experts\nand lay users. Our results indicate that IXAII, which provides different\nexplanations with multiple visualization options, is perceived as helpful to\nincrease transparency. By bridging the gaps between explainable AI methods,\ninteractivity, and practical implementation, we provide a novel perspective on\nAI explanation practices and human-AI interaction.\n","authors":["Pauline Speckmann","Mario Nadj","Christian Janiesch"],"pdf_url":"https://arxiv.org/pdf/2506.21310v1.pdf","comment":"9 pages, 2 figures, accepted to DESRIST 2025 Prototype Track"},{"id":"http://arxiv.org/abs/2506.21306v1","updated":"2025-06-26T14:25:32Z","published":"2025-06-26T14:25:32Z","title":"On Uniform Weighted Deep Polynomial approximation","summary":"  It is a classical result in rational approximation theory that certain\nnon-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be\nefficiently approximated using rational functions with root-exponential\nconvergence in terms of degrees of freedom \\cite{Sta, GN}. In contrast,\npolynomial approximations admit only algebraic convergence by Jackson's theorem\n\\cite{Lub2}. Recent work shows that composite polynomial architectures can\nrecover exponential approximation rates even without smoothness \\cite{KY}. In\nthis work, we introduce and analyze a class of weighted deep polynomial\napproximants tailored for functions with asymmetric behavior-growing unbounded\non one side and decaying on the other. By multiplying a learnable deep\npolynomial with a one-sided weight, we capture both local non-smoothness and\nglobal growth. We show numerically that this framework outperforms Taylor,\nChebyshev, and standard deep polynomial approximants, even when all use the\nsame number of parameters. To optimize these approximants in practice, we\npropose a stable graph-based parameterization strategy building on \\cite{Jar}.\n","authors":["Kingsley Yeon","Steven B. Damelin"],"pdf_url":"https://arxiv.org/pdf/2506.21306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19683v2","updated":"2025-06-26T14:20:13Z","published":"2025-06-24T14:49:40Z","title":"Semantic Scene Graph for Ultrasound Image Explanation and Scanning\n  Guidance","summary":"  Understanding medical ultrasound imaging remains a long-standing challenge\ndue to significant visual variability caused by differences in imaging and\nacquisition parameters. Recent advancements in large language models (LLMs)\nhave been used to automatically generate terminology-rich summaries orientated\nto clinicians with sufficient physiological knowledge. Nevertheless, the\nincreasing demand for improved ultrasound interpretability and basic scanning\nguidance among non-expert users, e.g., in point-of-care settings, has not yet\nbeen explored. In this study, we first introduce the scene graph (SG) for\nultrasound images to explain image content to ordinary and provide guidance for\nultrasound scanning. The ultrasound SG is first computed using a\ntransformer-based one-stage method, eliminating the need for explicit object\ndetection. To generate a graspable image explanation for ordinary, the user\nquery is then used to further refine the abstract SG representation through\nLLMs. Additionally, the predicted SG is explored for its potential in guiding\nultrasound scanning toward missing anatomies within the current imaging view,\nassisting ordinary users in achieving more standardized and complete anatomical\nexploration. The effectiveness of this SG-based image explanation and scanning\nguidance has been validated on images from the left and right neck regions,\nincluding the carotid and thyroid, across five volunteers. The results\ndemonstrate the potential of the method to maximally democratize ultrasound by\nenhancing its interpretability and usability for ordinaries.\n","authors":["Xuesong Li","Dianye Huang","Yameng Zhang","Nassir Navab","Zhongliang Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.19683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21298v1","updated":"2025-06-26T14:18:39Z","published":"2025-06-26T14:18:39Z","title":"Exploring Adapter Design Tradeoffs for Low Resource Music Generation","summary":"  Fine-tuning large-scale music generation models, such as MusicGen and\nMustango, is a computationally expensive process, often requiring updates to\nbillions of parameters and, therefore, significant hardware resources.\nParameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based\nmethods, have emerged as a promising alternative, enabling adaptation with\nminimal trainable parameters while preserving model performance. However, the\ndesign choices for adapters, including their architecture, placement, and size,\nare numerous, and it is unclear which of these combinations would produce\noptimal adapters and why, for a given case of low-resource music genre. In this\npaper, we attempt to answer this question by studying various adapter\nconfigurations for two AI music models, MusicGen and Mustango, on two genres:\nHindustani Classical and Turkish Makam music.\n  Our findings reveal distinct trade-offs: convolution-based adapters excel in\ncapturing fine-grained local musical details such as ornamentations and short\nmelodic phrases, while transformer-based adapters better preserve long-range\ndependencies crucial for structured improvisation. Additionally, we analyze\ncomputational resource requirements across different adapter scales,\ndemonstrating how mid-sized adapters (40M parameters) achieve an optimal\nbalance between expressivity and quality. Furthermore, we find that Mustango, a\ndiffusion-based model, generates more diverse outputs with better adherence to\nthe description in the input prompt while lacking in providing stability in\nnotes, rhythm alignment, and aesthetics. Also, it is computationally intensive\nand requires significantly more time to train. In contrast, autoregressive\nmodels like MusicGen offer faster training and are more efficient, and can\nproduce better quality output in comparison, but have slightly higher\nredundancy in their generations.\n","authors":["Atharva Mehta","Shivam Chauhan","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2506.21298v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2506.21294v1","updated":"2025-06-26T14:14:20Z","published":"2025-06-26T14:14:20Z","title":"Detecting Referring Expressions in Visually Grounded Dialogue with\n  Autoregressive Language Models","summary":"  In this paper, we explore the use of a text-only, autoregressive language\nmodeling approach for the extraction of referring expressions from visually\ngrounded dialogue. More specifically, the aim is to investigate the extent to\nwhich the linguistic context alone can inform the detection of mentions that\nhave a (visually perceivable) referent in the visual context of the\nconversation. To this end, we adapt a pretrained large language model (LLM) to\nperform a relatively course-grained annotation of mention spans in unfolding\nconversations by demarcating mention span boundaries in text via next-token\nprediction. Our findings indicate that even when using a moderately sized LLM,\nrelatively small datasets, and parameter-efficient fine-tuning, a text-only\napproach can be effective, highlighting the relative importance of the\nlinguistic context for this task. Nevertheless, we argue that the task\nrepresents an inherently multimodal problem and discuss limitations fundamental\nto unimodal approaches.\n","authors":["Bram Willemsen","Gabriel Skantze"],"pdf_url":"https://arxiv.org/pdf/2506.21294v1.pdf","comment":"Accepted for publication at XLLM @ ACL 2025"},{"id":"http://arxiv.org/abs/2506.21288v1","updated":"2025-06-26T14:09:41Z","published":"2025-06-26T14:09:41Z","title":"Small Encoders Can Rival Large Decoders in Detecting Groundedness","summary":"  Augmenting large language models (LLMs) with external context significantly\nimproves their performance in natural language processing (NLP) tasks. However,\nLLMs struggle to answer queries reliably when the provided context lacks\ninformation, often resorting to ungrounded speculation or internal knowledge.\nGroundedness - generating responses strictly supported by the context - is\nessential for ensuring factual consistency and trustworthiness. This study\nfocuses on detecting whether a given query is grounded in a document provided\nin context before the costly answer generation by LLMs. Such a detection\nmechanism can significantly reduce both inference time and resource\nconsumption. We show that lightweight, task specific encoder models such as\nRoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy\ncomparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in\ngroundedness detection while reducing inference latency by orders of magnitude.\nThe code is available at : https://github.com/chandarlab/Hallucinate-less\n","authors":["Istabrak Abbes","Gabriele Prato","Quentin Fournier","Fernando Rodriguez","Alaa Boukhary","Adam Elwood","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2506.21288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.13379v2","updated":"2025-06-26T14:06:49Z","published":"2025-05-19T17:24:16Z","title":"Thinkless: LLM Learns When to Think","summary":"  Reasoning Language Models, capable of extended chain-of-thought reasoning,\nhave demonstrated remarkable performance on tasks requiring complex logical\ninference. However, applying elaborate reasoning for all queries often results\nin substantial computational inefficiencies, particularly when many problems\nadmit straightforward solutions. This motivates an open question: Can LLMs\nlearn when to think? To answer this, we propose Thinkless, a learnable\nframework that empowers an LLM to adaptively select between short-form and\nlong-form reasoning, based on both task complexity and the model's ability.\nThinkless is trained under a reinforcement learning paradigm and employs two\ncontrol tokens, <short> for concise responses and <think> for detailed\nreasoning. At the core of our method is a Decoupled Group Relative Policy\nOptimization (DeGRPO) algorithm, which decomposes the learning objective of\nhybrid reasoning into two components: (1) a control token loss that governs the\nselection of the reasoning mode, and (2) a response loss that improves the\naccuracy of the generated answers. This decoupled formulation enables\nfine-grained control over the contributions of each objective, stabilizing\ntraining and effectively preventing collapse observed in vanilla GRPO.\nEmpirically, on several benchmarks such as Minerva Algebra, MATH-500, and\nGSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% -\n90%, significantly improving the efficiency of Reasoning Language Models. The\ncode is available at https://github.com/VainF/Thinkless\n","authors":["Gongfan Fang","Xinyin Ma","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2505.13379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10612v4","updated":"2025-06-26T14:04:51Z","published":"2025-04-14T18:10:58Z","title":"Energy Matching: Unifying Flow Matching and Energy-Based Models for\n  Generative Modeling","summary":"  The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.\n","authors":["Michal Balcerak","Tamaz Amiranashvili","Antonio Terpin","Suprosanna Shit","Lea Bogensperger","Sebastian Kaltenbach","Petros Koumoutsakos","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2504.10612v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21278v1","updated":"2025-06-26T14:01:51Z","published":"2025-06-26T14:01:51Z","title":"Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy\n  Distribution","summary":"  We propose a novel variational autoencoder (VAE) architecture that employs a\nspherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian\nlatent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy\nprovides a more natural hyperspherical representation of latent variables,\nbetter capturing directional data while maintaining flexibility. Its\nheavy-tailed nature prevents over-regularization, ensuring efficient latent\nspace utilization while offering a more expressive representation.\nAdditionally, spCauchy circumvents the numerical instabilities inherent to vMF,\nwhich arise from computing normalization constants involving Bessel functions.\nInstead, it enables a fully differentiable and efficient reparameterization\ntrick via M\\\"obius transformations, allowing for stable and scalable training.\nThe KL divergence can be computed through a rapidly converging power series,\neliminating concerns of underflow or overflow associated with evaluation of\nratios of hypergeometric functions. These properties make spCauchy a compelling\nalternative for VAEs, offering both theoretical advantages and practical\nefficiency in high-dimensional generative modeling.\n","authors":["Lukas Sablica","Kurt Hornik"],"pdf_url":"https://arxiv.org/pdf/2506.21278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12641v2","updated":"2025-06-26T14:00:55Z","published":"2024-12-17T08:03:53Z","title":"Lagrangian Index Policy for Restless Bandits with Average Reward","summary":"  We study the Lagrange Index Policy (LIP) for restless multi-armed bandits\nwith long-run average reward. In particular, we compare the performance of LIP\nwith the performance of the Whittle Index Policy (WIP), both heuristic policies\nknown to be asymptotically optimal under certain natural conditions. Even\nthough in most cases their performances are very similar, in the cases when WIP\nshows bad performance, LIP continues to perform very well. We then propose\nreinforcement learning algorithms, both tabular and NN-based, to obtain online\nlearning schemes for LIP in the model-free setting. The proposed reinforcement\nlearning schemes for LIP require significantly less memory than the analogous\nschemes for WIP. We calculate analytically the Lagrange index for the restart\nmodel, which applies to the optimal web crawling and the minimization of the\nweighted age of information. We also give a new proof of asymptotic optimality\nin case of homogeneous arms as the number of arms goes to infinity, based on\nexchangeability and de Finetti's theorem.\n","authors":["Konstantin Avrachenkov","Vivek S. Borkar","Pratik Shah"],"pdf_url":"https://arxiv.org/pdf/2412.12641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16717v2","updated":"2025-06-26T13:54:56Z","published":"2024-08-29T17:07:43Z","title":"A GREAT Architecture for Edge-Based Graph Problems Like TSP","summary":"  In the last years, many learning-based approaches have been proposed to\ntackle combinatorial optimization problems such as routing problems. Many of\nthese approaches are based on graph neural networks (GNNs) or related\ntransformers, operating on the Euclidean coordinates representing the routing\nproblems. However, models operating on Euclidean coordinates are ill-suited for\nnon-Euclidean, asymmetric problem instances that are often found in real-world\nsettings. To overcome this limitation, we propose a novel GNN-based and\nedge-focused neural model called Graph Edge Attention Network (GREAT). Using\nGREAT as an encoder to capture the properties of a routing problem instance, we\nbuild a reinforcement learning framework which we apply to Euclidean and\nnon-Euclidean variants of vehicle routing problems such as Traveling Salesman\nProblem, Capacitated Vehicle Routing Problem and Orienteering Problem. Our\nframework is among the first to tackle non-Euclidean variants of these problems\nand achieves competitive results among learning-based solvers.\n","authors":["Attila Lischka","Filip Rydin","Jiaming Wu","Morteza Haghir Chehreghani","Balázs Kulcsár"],"pdf_url":"https://arxiv.org/pdf/2408.16717v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.21269v1","updated":"2025-06-26T13:53:22Z","published":"2025-06-26T13:53:22Z","title":"Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management:\n  A Study on Speed Classification in Suzhou","summary":"  This study presents and publicly releases the Suzhou Urban Road Acoustic\nDataset (SZUR-Acoustic Dataset), which is accompanied by comprehensive\ndata-acquisition protocols and annotation guidelines to ensure transparency and\nreproducibility of the experimental workflow. To model the coupling between\nvehicular noise and driving speed, we propose a bimodal-feature-fusion deep\nconvolutional neural network (BMCNN). During preprocessing, an adaptive\ndenoising and normalization strategy is applied to suppress environmental\nbackground interference; in the network architecture, parallel branches extract\nMel-frequency cepstral coefficients (MFCCs) and wavelet-packet energy features,\nwhich are subsequently fused via a cross-modal attention mechanism in the\nintermediate feature space to fully exploit time-frequency information.\nExperimental results demonstrate that BMCNN achieves a classification accuracy\nof 87.56% on the SZUR-Acoustic Dataset and 96.28% on the public IDMT-Traffic\ndataset. Ablation studies and robustness tests on the Suzhou dataset further\nvalidate the contributions of each module to performance improvement and\noverfitting mitigation. The proposed acoustics-based speed classification\nmethod can be integrated into smart-city traffic management systems for\nreal-time noise monitoring and speed estimation, thereby optimizing traffic\nflow control, reducing roadside noise pollution, and supporting sustainable\nurban planning.\n","authors":["Pengfei Fan","Yuli Zhang","Xinheng Wang","Ruiyuan Jiang","Hankang Gu","Dongyao Jia","Shangbo Wang"],"pdf_url":"https://arxiv.org/pdf/2506.21269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18221v2","updated":"2025-06-26T13:50:38Z","published":"2025-06-23T01:04:29Z","title":"These Are Not All the Features You Are Looking For: A Fundamental\n  Bottleneck in Supervised Pretraining","summary":"  Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.\n","authors":["Xingyu Alice Yang","Jianyu Zhang","Léon Bottou"],"pdf_url":"https://arxiv.org/pdf/2506.18221v2.pdf","comment":"10 pages, 7 figures, Preprint. Under review"},{"id":"http://arxiv.org/abs/2506.21263v1","updated":"2025-06-26T13:45:04Z","published":"2025-06-26T13:45:04Z","title":"DiLoCoX: A Low-Communication Large-Scale Training Framework for\n  Decentralized Cluster","summary":"  The distributed training of foundation models, particularly large language\nmodels (LLMs), demands a high level of communication. Consequently, it is\nhighly dependent on a centralized cluster with fast and reliable interconnects.\nCan we conduct training on slow networks and thereby unleash the power of\ndecentralized clusters when dealing with models exceeding 100 billion\nparameters? In this paper, we propose DiLoCoX, a low-communication large-scale\ndecentralized cluster training framework. It combines Pipeline Parallelism with\nDual Optimizer Policy, One-Step-Delay Overlap of Communication and Local\nTraining, and an Adaptive Gradient Compression Scheme. This combination\nsignificantly improves the scale of parameters and the speed of model\npre-training. We justify the benefits of one-step-delay overlap of\ncommunication and local training, as well as the adaptive gradient compression\nscheme, through a theoretical analysis of convergence. Empirically, we\ndemonstrate that DiLoCoX is capable of pre-training a 107B foundation model\nover a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x\nspeedup in distributed training while maintaining negligible degradation in\nmodel convergence. To the best of our knowledge, this is the first\ndecentralized training framework successfully applied to models with over 100\nbillion parameters.\n","authors":["Ji Qi","WenPeng Zhu","Li Li","Ming Wu","YingJun Wu","Wu He","Xun Gao","Jason Zeng","Michael Heinrich"],"pdf_url":"https://arxiv.org/pdf/2506.21263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21252v1","updated":"2025-06-26T13:36:12Z","published":"2025-06-26T13:36:12Z","title":"Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling\n  across Perception, Planning, and Safety in Real-World Multimodal Agents","summary":"  As Multimodal Large Language Models (MLLMs) advance, multimodal agents show\npromise in real-world tasks like web navigation and embodied intelligence.\nHowever, due to limitations in a lack of external feedback, these agents\nstruggle with self-correction and generalization. A promising approach is to\nuse reward models as external feedback, but there is no clear on how to select\nreward models for agents. Thus, there is an urgent need to build a reward bench\ntargeted at agents. To address these challenges, we propose Agent-RewardBench,\na benchmark designed to evaluate reward modeling ability in MLLMs. The\nbenchmark is characterized by three key features: (1) Multiple dimensions and\nreal-world agent scenarios evaluation. It covers perception, planning, and\nsafety with 7 scenarios; (2) Step-level reward evaluation. It allows for the\nassessment of agent capabilities at the individual steps of a task, providing a\nmore granular view of performance during the planning process; and (3)\nAppropriately difficulty and high-quality. We carefully sample from 10 diverse\nmodels, difficulty control to maintain task challenges, and manual verification\nto ensure the integrity of the data. Experiments demonstrate that even\nstate-of-the-art multimodal models show limited performance, highlighting the\nneed for specialized training in agent reward modeling. Code is available at\ngithub.\n","authors":["Tianyi Men","Zhuoran Jin","Pengfei Cao","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.21252v1.pdf","comment":"ACL 2025 Main"},{"id":"http://arxiv.org/abs/2506.21246v1","updated":"2025-06-26T13:29:19Z","published":"2025-06-26T13:29:19Z","title":"From On-chain to Macro: Assessing the Importance of Data Source\n  Diversity in Cryptocurrency Market Forecasting","summary":"  This study investigates the impact of data source diversity on the\nperformance of cryptocurrency forecasting models by integrating various data\ncategories, including technical indicators, on-chain metrics, sentiment and\ninterest metrics, traditional market indices, and macroeconomic indicators. We\nintroduce the Crypto100 index, representing the top 100 cryptocurrencies by\nmarket capitalization, and propose a novel feature reduction algorithm to\nidentify the most impactful and resilient features from diverse data sources.\nOur comprehensive experiments demonstrate that data source diversity\nsignificantly enhances the predictive performance of forecasting models across\ndifferent time horizons. Key findings include the paramount importance of\non-chain metrics for both short-term and long-term predictions, the growing\nrelevance of traditional market indices and macroeconomic indicators for\nlonger-term forecasts, and substantial improvements in model accuracy when\ndiverse data sources are utilized. These insights help demystify the short-term\nand long-term driving factors of the cryptocurrency market and lay the\ngroundwork for developing more accurate and resilient forecasting models.\n","authors":["Giorgos Demosthenous","Chryssis Georgiou","Eliada Polydorou"],"pdf_url":"https://arxiv.org/pdf/2506.21246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21230v1","updated":"2025-06-26T13:20:55Z","published":"2025-06-26T13:20:55Z","title":"World-aware Planning Narratives Enhance Large Vision-Language Model\n  Planner","summary":"  Large Vision-Language Models (LVLMs) show promise for embodied planning tasks\nbut struggle with complex scenarios involving unfamiliar environments and\nmulti-step goals. Current approaches rely on environment-agnostic imitation\nlearning that disconnects instructions from environmental contexts, causing\nmodels to struggle with context-sensitive instructions and rely on\nsupplementary cues rather than visual reasoning during long-horizon\ninteractions. In this work, we propose World-Aware Planning Narrative\nEnhancement (WAP), a framework that infuses LVLMs with comprehensive\nenvironmental understanding through four cognitive capabilities (visual\nappearance modeling, spatial reasoning, functional abstraction, and syntactic\ngrounding) while developing and evaluating models using only raw visual\nobservations through curriculum learning. Evaluations on the EB-ALFRED\nbenchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a\n60.7 absolute improvement in task success rates, particularly in commonsense\nreasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced\nopen-source models outperform proprietary systems like GPT-4o and\nClaude-3.5-Sonnet by a large margin.\n","authors":["Junhao Shi","Zhaoye Fei","Siyin Wang","Qipeng Guo","Jingjing Gong","Xipeng QIu"],"pdf_url":"https://arxiv.org/pdf/2506.21230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00488v3","updated":"2025-06-26T13:16:22Z","published":"2024-08-31T15:47:31Z","title":"Rapid Gyroscope Calibration: A Deep Learning Approach","summary":"  Low-cost gyroscope calibration is essential for ensuring the accuracy and\nreliability of gyroscope measurements. Stationary calibration estimates the\ndeterministic parts of measurement errors. To this end, a common practice is to\naverage the gyroscope readings during a predefined period and estimate the\ngyroscope bias. Calibration duration plays a crucial role in performance,\ntherefore, longer periods are preferred. However, some applications require\nquick startup times and calibration is therefore allowed only for a short time.\nIn this work, we focus on reducing low-cost gyroscope calibration time using\ndeep learning methods. We propose an end-to-end convolutional neural network\nfor the application of gyroscope calibration. We explore the possibilities of\nusing multiple real and virtual gyroscopes to improve the calibration\nperformance of single gyroscopes. To train and validate our approach, we\nrecorded a dataset consisting of 186.6 hours of gyroscope readings, using 36\ngyroscopes of four different brands. We also created a virtual dataset\nconsisting of simulated gyroscope readings. The six datasets were used to\nevaluate our proposed approach. One of our key achievements in this work is\nreducing gyroscope calibration time by up to 89% using three low-cost\ngyroscopes. Our dataset is publicly available to allow reproducibility of our\nwork and to increase research in the field.\n","authors":["Yair Stolero","Itzik Klein"],"pdf_url":"https://arxiv.org/pdf/2409.00488v3.pdf","comment":"10 Pages, 14 Figures"},{"id":"http://arxiv.org/abs/2506.21215v1","updated":"2025-06-26T13:11:01Z","published":"2025-06-26T13:11:01Z","title":"Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?","summary":"  Causal reasoning capability is critical in advancing large language models\n(LLMs) toward strong artificial intelligence. While versatile LLMs appear to\nhave demonstrated capabilities in understanding contextual causality and\nproviding responses that obey the laws of causality, it remains unclear whether\nthey perform genuine causal reasoning akin to humans. However, current evidence\nindicates the contrary. Specifically, LLMs are only capable of performing\nshallow (level-1) causal reasoning, primarily attributed to the causal\nknowledge embedded in their parameters, but they lack the capacity for genuine\nhuman-like (level-2) causal reasoning. To support this hypothesis,\nmethodologically, we delve into the autoregression mechanism of\ntransformer-based LLMs, revealing that it is not inherently causal.\nEmpirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,\nwhose corpora are fresh and nearly unseen for the studied LLMs. The LLMs\nexhibit a significant performance drop on CausalProbe-2024 compared to earlier\nbenchmarks, indicating the fact that they primarily engage in level-1 causal\nreasoning. To bridge the gap towards level-2 causal reasoning, we draw\ninspiration from the fact that human reasoning is usually facilitated by\ngeneral knowledge and intended goals. We propose G^2-Reasoner, a method that\nincorporates general knowledge and goal-oriented prompts into LLMs' causal\nreasoning processes. Experiments demonstrate that G^2-Reasoner significantly\nenhances LLMs' causal reasoning capability, particularly in fresh and\ncounterfactual contexts. This work sheds light on a new path for LLMs to\nadvance towards genuine causal reasoning, going beyond level-1 and making\nstrides towards level-2.\n","authors":["Haoang Chi","He Li","Wenjing Yang","Feng Liu","Long Lan","Xiaoguang Ren","Tongliang Liu","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2506.21215v1.pdf","comment":"24 pages, accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2506.21211v1","updated":"2025-06-26T13:04:28Z","published":"2025-06-26T13:04:28Z","title":"$T^3$: Multi-level Tree-based Automatic Program Repair with Large\n  Language Models","summary":"  Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.\n","authors":["Quanming Liu","Xupeng Bu","Zhichao Yan","Ru Li"],"pdf_url":"https://arxiv.org/pdf/2506.21211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21209v1","updated":"2025-06-26T13:03:13Z","published":"2025-06-26T13:03:13Z","title":"BitMark for Infinity: Watermarking Bitwise Autoregressive Image\n  Generative Models","summary":"  State-of-the-art text-to-image models like Infinity generate photorealistic\nimages at an unprecedented speed. These models operate in a bitwise\nautoregressive manner over a discrete set of tokens that is practically\ninfinite in size. However, their impressive generative power comes with a\ngrowing risk: as their outputs increasingly populate the Internet, they are\nlikely to be scraped and reused as training data-potentially by the very same\nmodels. This phenomenon has been shown to lead to model collapse, where\nrepeated training on generated content, especially from the models' own\nprevious versions, causes a gradual degradation in performance. A promising\nmitigation strategy is watermarking, which embeds human-imperceptible yet\ndetectable signals into generated images-enabling the identification of\ngenerated content. In this work, we introduce BitMark, a robust bitwise\nwatermarking framework for Infinity. Our method embeds a watermark directly at\nthe bit level of the token stream across multiple scales (also referred to as\nresolutions) during Infinity's image generation process. Our bitwise watermark\nsubtly influences the bits to preserve visual fidelity and generation speed\nwhile remaining robust against a spectrum of removal techniques. Furthermore,\nit exhibits high radioactivity, i.e., when watermarked generated images are\nused to train another image generative model, this second model's outputs will\nalso carry the watermark. The radioactive traces remain detectable even when\nonly fine-tuning diffusion or image autoregressive models on images watermarked\nwith our BitMark. Overall, our approach provides a principled step toward\npreventing model collapse in image generative models by enabling reliable\ndetection of generated outputs.\n","authors":["Louis Kerner","Michel Meintz","Bihe Zhao","Franziska Boenisch","Adam Dziedzic"],"pdf_url":"https://arxiv.org/pdf/2506.21209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21184v1","updated":"2025-06-26T12:43:43Z","published":"2025-06-26T12:43:43Z","title":"Task-Aware KV Compression For Cost-Effective Long Video Understanding","summary":"  Long-video understanding (LVU) remains a severe challenge for existing\nmultimodal large language models (MLLMs), primarily due to the prohibitive\ncomputational cost. Recent approaches have explored KV compression to mitigate\nthis issue, but they often suffer from significant information loss at high\ncompression ratios. In this paper, we introduce Video-X^2L, which flexibly\npreserves critical video information for each LVU task. Video-X^2L involves two\nkey operations. The first one is called bi-level KV compression. During the\nMLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs:\nlow-compression KVs (L-KVs) to capture fine-grained video details and\nhigh-compression KVs (H-KVs) to offer compact video representations. The second\none is called selective KV re-loading. During the MLLM's decoding stage,\nVideo-X^2L selectively re-loads L-KVs for the most critical video chunks while\nusing H-KVs for other less important ones. This allows the MLLM to fully\nutilize task-specific information while maintaining the overall compactness.\nVideo-X^2L is simple yet effective: it is free from additional training and\ndirectly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2L\nwith a variety of popular LVU benchmarks, including VideoMME, MLVU,\nLongVideoBench, and VNBench. Our experiment result shows that Video-X^2L\noutperforms existing KV-compression methods by a huge advantage while\nsubstantially saving the computation cost.\n","authors":["Minghao Qin","Yan Shu","Peitian Zhang","Kun Lun","Huaying Yuan","Juenjie Zhou","Shitao Xiao","Bo Zhao","Zheng Liu"],"pdf_url":"https://arxiv.org/pdf/2506.21184v1.pdf","comment":"14 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2506.21182v1","updated":"2025-06-26T12:40:48Z","published":"2025-06-26T12:40:48Z","title":"Maintaining MTEB: Towards Long Term Usability and Reproducibility of\n  Embedding Benchmarks","summary":"  The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation\nplatform for text embedding models. While previous work has established the\ncore benchmark methodology, this paper focuses on the engineering aspects that\nensure MTEB's continued reproducibility and extensibility. We present our\napproach to maintaining robust continuous integration pipelines that validate\ndataset integrity, automate test execution, and assess benchmark results'\ngeneralizability. We detail the design choices that collectively enhance\nreproducibility and usability. Furthermore, we discuss our strategies for\nhandling community contributions and extending the benchmark with new tasks and\ndatasets. These engineering practices have been instrumental in scaling MTEB to\nbecome more comprehensive while maintaining quality and, ultimately, relevance\nto the field. Our experiences offer valuable insights for benchmark maintainers\nfacing similar challenges in ensuring reproducibility and usability in machine\nlearning evaluation frameworks. The MTEB repository is available at:\nhttps://github.com/embeddings-benchmark/mteb\n","authors":["Isaac Chung","Imene Kerboua","Marton Kardos","Roman Solomatin","Kenneth Enevoldsen"],"pdf_url":"https://arxiv.org/pdf/2506.21182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21167v1","updated":"2025-06-26T11:56:11Z","published":"2025-06-26T11:56:11Z","title":"A Hierarchical Deep Learning Approach for Minority Instrument Detection","summary":"  Identifying instrument activities within audio excerpts is vital in music\ninformation retrieval, with significant implications for music cataloging and\ndiscovery. Prior deep learning endeavors in musical instrument recognition have\npredominantly emphasized instrument classes with ample data availability.\nRecent studies have demonstrated the applicability of hierarchical\nclassification in detecting instrument activities in orchestral music, even\nwith limited fine-grained annotations at the instrument level. Based on the\nHornbostel-Sachs classification, such a hierarchical classification system is\nevaluated using the MedleyDB dataset, renowned for its diversity and richness\nconcerning various instruments and music genres. This work presents various\nstrategies to integrate hierarchical structures into models and tests a new\nclass of models for hierarchical music prediction. This study showcases more\nreliable coarse-level instrument detection by bridging the gap between detailed\ninstrument identification and group-level recognition, paving the way for\nfurther advancements in this domain.\n","authors":["Dylan Sechet","Francesca Bugiotti","Matthieu Kowalski","Edouard d'Hérouville","Filip Langiewicz"],"pdf_url":"https://arxiv.org/pdf/2506.21167v1.pdf","comment":"International Conference on Digital Audio Effects (DAFx)"},{"id":"http://arxiv.org/abs/2506.13056v2","updated":"2025-06-26T11:45:11Z","published":"2025-06-16T02:56:13Z","title":"Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model\n  Learning","summary":"  Recent advancements in large language models (LLMs) have witnessed a surge in\nthe development of advanced reasoning paradigms, which are now being integrated\ninto multimodal large language models (MLLMs). However, existing approaches\noften fall short: methods solely employing reinforcement learning (RL) can\nstruggle with sample inefficiency and activating entirely absent reasoning\ncapabilities, while conventional pipelines that initiate with a cold-start\nsupervised fine-tuning (SFT) phase before RL may restrict the model's\nexploratory capacity and face suboptimal convergence. In this work, we\nintroduce \\textbf{Metis-RISE} (\\textbf{R}L \\textbf{I}ncentivizes and\n\\textbf{S}FT \\textbf{E}nhances) for multimodal reasoning model learning. Unlike\nconventional approaches, Metis-RISE distinctively omits an initial SFT stage,\nbeginning instead with an RL phase (e.g., using a Group Relative Policy\nOptimization variant) to incentivize and activate the model's latent reasoning\ncapacity. Subsequently, the targeted SFT stage addresses two key challenges\nidentified during RL: (1) \\textit{inefficient trajectory sampling} for tasks\nwhere the model possesses but inconsistently applies correct reasoning, which\nwe tackle using self-distilled reasoning trajectories from the RL model itself;\nand (2) \\textit{fundamental capability absence}, which we address by injecting\nexpert-augmented knowledge for prompts where the model entirely fails. This\nstrategic application of RL for incentivization followed by SFT for enhancement\nforms the core of Metis-RISE, leading to two versions of our MLLMs (7B and 72B\nparameters). Evaluations on the OpenCompass Multimodal Reasoning Leaderboard\ndemonstrate that both models achieve state-of-the-art performance among\nsimilar-sized models, with the 72B version ranking fourth overall. Please refer\nto our project page for open-source information.\n","authors":["Haibo Qiu","Xiaohan Lan","Fanfan Liu","Xiaohu Sun","Delian Ruan","Peng Shi","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2506.13056v2.pdf","comment":"Project Page: https://github.com/MM-Thinking/Metis-RISE"},{"id":"http://arxiv.org/abs/2506.21162v1","updated":"2025-06-26T11:39:08Z","published":"2025-06-26T11:39:08Z","title":"A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver\n  Tumour Ablation","summary":"  3D ultrasound (US) imaging has shown significant benefits in enhancing the\noutcomes of percutaneous liver tumour ablation. Its clinical integration is\ncrucial for transitioning 3D US into the therapeutic domain. However,\nchallenges of tumour identification in US images continue to hinder its broader\nadoption. In this work, we propose a novel framework for integrating 3D US into\nthe standard ablation workflow. We present a key component, a clinically viable\n2D US-CT/MRI registration approach, leveraging 3D US as an intermediary to\nreduce registration complexity. To facilitate efficient verification of the\nregistration workflow, we also propose an intuitive multimodal image\nvisualization technique. In our study, 2D US-CT/MRI registration achieved a\nlandmark distance error of approximately 2-4 mm with a runtime of 0.22s per\nimage pair. Additionally, non-rigid registration reduced the mean alignment\nerror by approximately 40% compared to rigid registration. Results demonstrated\nthe efficacy of the proposed 2D US-CT/MRI registration workflow. Our\nintegration framework advanced the capabilities of 3D US imaging in improving\npercutaneous tumour ablation, demonstrating the potential to expand the\ntherapeutic role of 3D US in clinical interventions.\n","authors":["Shuwei Xing","Derek W. Cool","David Tessier","Elvis C. S. Chen","Terry M. Peters","Aaron Fenster"],"pdf_url":"https://arxiv.org/pdf/2506.21162v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2506.21154v1","updated":"2025-06-26T11:24:46Z","published":"2025-06-26T11:24:46Z","title":"Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation","summary":"  The real world naturally has dimensions of time and space. Therefore,\nestimating the counterfactual outcomes with spatial-temporal attributes is a\ncrucial problem. However, previous methods are based on classical statistical\nmodels, which still have limitations in performance and generalization. This\npaper proposes a novel framework for estimating counterfactual outcomes with\nspatial-temporal attributes using the Transformer, exhibiting stronger\nestimation ability. Under mild assumptions, the proposed estimator within this\nframework is consistent and asymptotically normal. To validate the\neffectiveness of our approach, we conduct simulation experiments and real data\nexperiments. Simulation experiments show that our estimator has a stronger\nestimation capability than baseline methods. Real data experiments provide a\nvaluable conclusion to the causal effect of conflicts on forest loss in\nColombia. The source code is available at\nhttps://github.com/lihe-maxsize/DeppSTCI_Release_Version-master.\n","authors":["He Li","Haoang Chi","Mingyu Liu","Wanrong Huang","Liyang Xu","Wenjing Yang"],"pdf_url":"https://arxiv.org/pdf/2506.21154v1.pdf","comment":"24 pages, accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2506.21151v1","updated":"2025-06-26T11:21:58Z","published":"2025-06-26T11:21:58Z","title":"Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI\n  with Noisy Labels","summary":"  The accurate segmentation of myocardial scars from cardiac MRI is essential\nfor clinical assessment and treatment planning. In this study, we propose a\nrobust deep-learning pipeline for fully automated myocardial scar detection and\nsegmentation by fine-tuning state-of-the-art models. The method explicitly\naddresses challenges of label noise from semi-automatic annotations, data\nheterogeneity, and class imbalance through the use of Kullback-Leibler loss and\nextensive data augmentation. We evaluate the model's performance on both acute\nand chronic cases and demonstrate its ability to produce accurate and smooth\nsegmentations despite noisy labels. In particular, our approach outperforms\nstate-of-the-art models like nnU-Net and shows strong generalizability in an\nout-of-distribution test set, highlighting its robustness across various\nimaging conditions and clinical tasks. These results establish a reliable\nfoundation for automated myocardial scar quantification and support the broader\nclinical adoption of deep learning in cardiac imaging.\n","authors":["Aida Moafi","Danial Moafi","Evgeny M. Mirkes","Gerry P. McCann","Abbas S. Alatrany","Jayanth R. Arnold","Mostafa Mehdipour Ghazi"],"pdf_url":"https://arxiv.org/pdf/2506.21151v1.pdf","comment":"MICCAI 2025"},{"id":"http://arxiv.org/abs/2506.21146v1","updated":"2025-06-26T11:04:12Z","published":"2025-06-26T11:04:12Z","title":"Linearity-based neural network compression","summary":"  In neural network compression, most current methods reduce unnecessary\nparameters by measuring importance and redundancy. To augment already highly\noptimized existing solutions, we propose linearity-based compression as a novel\nway to reduce weights in a neural network. It is based on the intuition that\nwith ReLU-like activation functions, neurons that are almost always activated\nbehave linearly, allowing for merging of subsequent layers. We introduce the\ntheory underlying this compression and evaluate our approach experimentally.\nOur novel method achieves a lossless compression down to 1/4 of the original\nmodel size in over the majority of tested models. Applying our method on\nalready importance-based pruned models shows very little interference between\ndifferent types of compression, demonstrating the option of successful\ncombination of techniques. Overall, our work lays the foundation for a new type\nof compression method that enables smaller and ultimately more efficient neural\nnetwork models.\n","authors":["Silas Dobler","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2506.21146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21140v1","updated":"2025-06-26T10:53:24Z","published":"2025-06-26T10:53:24Z","title":"DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding","summary":"  Electroencephalography (EEG)-based brain-computer interfaces (BCIs) transform\nspontaneous/evoked neural activity into control commands for external\ncommunication. While convolutional neural networks (CNNs) remain the mainstream\nbackbone for EEG decoding, their inherently short receptive field makes it\ndifficult to capture long-range temporal dependencies and global inter-channel\nrelationships. Recent CNN-Transformer (Conformers) hybrids partially address\nthis issue, but most adopt a serial design, resulting in suboptimal integration\nof local and global features, and often overlook explicit channel-wise\nmodeling. To address these limitations, we propose DBConformer, a dual-branch\nconvolutional Transformer network tailored for EEG decoding. It integrates a\ntemporal Conformer to model long-range temporal dependencies and a spatial\nConformer to extract inter-channel interactions, capturing both temporal\ndynamics and spatial patterns in EEG signals. A lightweight channel attention\nmodule further refines spatial representations by assigning data-driven\nimportance to EEG channels. Extensive experiments on five motor imagery (MI)\ndatasets and two seizure detection datasets under three evaluation settings\ndemonstrate that DBConformer consistently outperforms 10 competitive baseline\nmodels, with over eight times fewer parameters than the high-capacity EEG\nConformer baseline. Further, the visualization results confirm that the\nfeatures extracted by DBConformer are physiologically interpretable and aligned\nwith sensorimotor priors in MI. The superior performance and interpretability\nof DBConformer make it reliable for robust and explainable EEG decoding. Code\nis publicized at https://github.com/wzwvv/DBConformer.\n","authors":["Ziwei Wang","Hongbin Wang","Tianwang Jia","Xingyi He","Siyang Li","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2506.21140v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.21138v1","updated":"2025-06-26T10:52:07Z","published":"2025-06-26T10:52:07Z","title":"How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets\n  for AI4RE","summary":"  The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.\n","authors":["Abdelkarim El-Hajjami","Camille Salinesi"],"pdf_url":"https://arxiv.org/pdf/2506.21138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09225v3","updated":"2025-06-26T10:49:33Z","published":"2024-02-14T15:09:01Z","title":"Is my Data in your AI Model? Membership Inference Test with Application\n  to Face Images","summary":"  This article introduces the Membership Inference Test (MINT), a novel\napproach that aims to empirically assess if given data was used during the\ntraining of AI/ML models. Specifically, we propose two MINT architectures\ndesigned to learn the distinct activation patterns that emerge when an Audited\nModel is exposed to data used during its training process. These architectures\nare based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks\n(CNNs). The experimental framework focuses on the challenging task of Face\nRecognition, considering three state-of-the-art Face Recognition systems.\nExperiments are carried out using six publicly available databases, comprising\nover 22 million face images in total. Different experimental scenarios are\nconsidered depending on the context of the AI model to test. Our proposed MINT\napproach achieves promising results, with up to 90\\% accuracy, indicating the\npotential to recognize if an AI model has been trained with specific data. The\nproposed MINT approach can serve to enforce privacy and fairness in several AI\napplications, e.g., revealing if sensitive or private data was used for\ntraining or tuning Large Language Models (LLMs).\n","authors":["Daniel DeAlcala","Aythami Morales","Julian Fierrez","Gonzalo Mancera","Ruben Tolosana","Javier Ortega-Garcia"],"pdf_url":"https://arxiv.org/pdf/2402.09225v3.pdf","comment":"26 pages main text and 2 pages appendix"},{"id":"http://arxiv.org/abs/2506.21129v1","updated":"2025-06-26T10:10:41Z","published":"2025-06-26T10:10:41Z","title":"Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV\n  Deconfliction under Observation-Space Attacks","summary":"  Reinforcement learning (RL) policies deployed in safety-critical systems,\nsuch as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are\nvulnerable to out-ofdistribution (OOD) adversarial attacks in the observation\nspace. These attacks induce distributional shifts that significantly degrade\nvalue estimation, leading to unsafe or suboptimal decision making rendering the\nexisting policy fragile. To address this vulnerability, we propose an\nantifragile RL framework designed to adapt against curriculum of incremental\nadversarial perturbations. The framework introduces a simulated attacker which\nincrementally increases the strength of observation-space perturbations which\nenables the RL agent to adapt and generalize across a wider range of OOD\nobservations and anticipate previously unseen attacks. We begin with a\ntheoretical characterization of fragility, formally defining catastrophic\nforgetting as a monotonic divergence in value function distributions with\nincreasing perturbation strength. Building on this, we define antifragility as\nthe boundedness of such value shifts and derive adaptation conditions under\nwhich forgetting is stabilized. Our method enforces these bounds through\niterative expert-guided critic alignment using Wasserstein distance\nminimization across incrementally perturbed observations. We empirically\nevaluate the approach in a UAV deconfliction scenario involving dynamic 3D\nobstacles. Results show that the antifragile policy consistently outperforms\nstandard and robust RL baselines when subjected to both projected gradient\ndescent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative\nreward and over 30% fewer conflict events. These findings demonstrate the\npractical and theoretical viability of antifragile reinforcement learning for\nsecure and resilient decision-making in environments with evolving threat\nscenarios.\n","authors":["Deepak Kumar Panda","Adolfo Perrusquia","Weisi Guo"],"pdf_url":"https://arxiv.org/pdf/2506.21129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21127v1","updated":"2025-06-26T10:06:29Z","published":"2025-06-26T10:06:29Z","title":"Robust Policy Switching for Antifragile Reinforcement Learning for UAV\n  Deconfliction in Adversarial Environments","summary":"  The increasing automation of navigation for unmanned aerial vehicles (UAVs)\nhas exposed them to adversarial attacks that exploit vulnerabilities in\nreinforcement learning (RL) through sensor manipulation. Although existing\nrobust RL methods aim to mitigate such threats, their effectiveness has limited\ngeneralization to out-of-distribution shifts from the optimal value\ndistribution, as they are primarily designed to handle fixed perturbation. To\naddress this limitation, this paper introduces an antifragile RL framework that\nenhances adaptability to broader distributional shifts by incorporating a\nswitching mechanism based on discounted Thompson sampling (DTS). This mechanism\ndynamically selects among multiple robust policies to minimize adversarially\ninduced state-action-value distribution shifts. The proposed approach first\nderives a diverse ensemble of action robust policies by accounting for a range\nof perturbations in the policy space. These policies are then modeled as a\nmultiarmed bandit (MAB) problem, where DTS optimally selects policies in\nresponse to nonstationary Bernoulli rewards, effectively adapting to evolving\nadversarial strategies. Theoretical framework has also been provided where by\noptimizing the DTS to minimize the overall regrets due to distributional shift,\nresults in effective adaptation against unseen adversarial attacks thus\ninducing antifragility. Extensive numerical simulations validate the\neffectiveness of the proposed framework in complex navigation environments with\nmultiple dynamic three-dimensional obstacles and with stronger projected\ngradient descent (PGD) and spoofing attacks. Compared to conventional robust,\nnon-adaptive RL methods, the antifragile approach achieves superior\nperformance, demonstrating shorter navigation path lengths and a higher rate of\nconflict-free navigation trajectories compared to existing robust RL techniques\n","authors":["Deepak Kumar Panda","Weisi Guo"],"pdf_url":"https://arxiv.org/pdf/2506.21127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21119v1","updated":"2025-06-26T09:37:15Z","published":"2025-06-26T09:37:15Z","title":"Progtuning: Progressive Fine-tuning Framework for Transformer-based\n  Language Models","summary":"  Fine-tuning is a promising technique for leveraging Transformer-based\nlanguage models in downstream tasks. As model sizes continue to grow, updating\nall model parameters becomes increasingly costly. Parameter-efficient\nfine-tuning methods effectively address this issue by selectively updating a\nsmall subset of parameters. However, fine-tuning and most existing\nparameter-efficient fine-tuning methods require updating the same number of\nparameters as the initial size, ignoring the unequal contribution across\nTransformer blocks and leading to extremely inefficient allocation of computing\nresources. In this paper, we propose Progtuning, the novel fine-tuning\nframework combined with progressive learning for Transformer-based language\nmodels. Specifically, Progtuning progressively reduces the number of updated\ntransformer blocks based on the contribution. Remarkably, Progtuning optimizes\nresource allocation and reduces the number of updated parameters by\napproximately 25\\%, while still maintaining competitive performance. And it\nalso exhibits high adaptability with parameter-efficient fine-tuning methods,\ndemonstrating excellent performance across various adaptation scenarios.\n","authors":["Xiaoshuang Ji","Zhendong Zhao","Xiaojun Chen","Xin Zhao","Zeyao Liu"],"pdf_url":"https://arxiv.org/pdf/2506.21119v1.pdf","comment":"Accepted by ICONIP 2024"},{"id":"http://arxiv.org/abs/2506.21116v1","updated":"2025-06-26T09:30:57Z","published":"2025-06-26T09:30:57Z","title":"IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for\n  Multi-shot Scenes","summary":"  Video Large Language Models (VideoLLMs) have demonstrated remarkable\nunderstanding capabilities, but are found struggling to tackle multi-shot\nscenarios,e.g., video clips with varying camera angles or scene changes. This\nchallenge can render failures such as instance identity forgetting and key\nframe negligence. In this work, we first attribute the challenge to the lack of\nmulti-shot annotations among existing datasets and therefore we introduce a new\ndataset termed MultiClip-Bench, featuring dense descriptions and\ninstruction-based question-answering pairs tailored for multi-shot scenarios.\nWe empirically find that the training set significantly boosts the multi-shot\nperformance, while the testing benchmark provides a reliable measure of the\nmodel capability in multi-shot scenarios. By further analyzing and discovering\nthat current models only encode instance features in a discrete or lossy\nmanner, at the risk of missing identity information, we then contribute a new\nmodel IPFormer-VideoLLM. Its key idea is the injection of instance-level\nfeatures as instance prompts through an efficient attention-based connector.\nThis allows for the aggregation of instance-specific information across scenes.\nExperiments demonstrate that our proposed dataset and model not only enhance\nthe multi-scene video understanding significantly, but also offer distinct\nadvantages across various video benchmarks.\n","authors":["Yujia Liang","Jile Jiao","Zhicheng Wang","Xuetao Feng","Zixuan Ye","Yuan Wang","Hao Lu"],"pdf_url":"https://arxiv.org/pdf/2506.21116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21106v1","updated":"2025-06-26T09:04:55Z","published":"2025-06-26T09:04:55Z","title":"PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing\n  Detection Using Adaptive HTML Component Extraction","summary":"  Phishing attacks pose a significant cybersecurity threat, evolving rapidly to\nbypass detection mechanisms and exploit human vulnerabilities. This paper\nintroduces PhishKey to address the challenges of adaptability, robustness, and\nefficiency. PhishKey is a novel phishing detection method using automatic\nfeature extraction from hybrid sources. PhishKey combines character-level\nprocessing with Convolutional Neural Networks (CNN) for URL classification, and\na Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at\nthe word level. CAPE reduces noise and ensures complete sample processing\navoiding crop operations on the input data. The predictions from both modules\nare integrated using a soft-voting ensemble to achieve more accurate and\nreliable classifications. Experimental evaluations on four state-of-the-art\ndatasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1\nScore and shows strong resistance to adversarial manipulations such as\ninjection attacks with minimal performance degradation.\n","authors":["Felipe Castaño","Eduardo Fidalgo","Enrique Alegre","Rocio Alaiz-Rodríguez","Raul Orduna","Francesco Zola"],"pdf_url":"https://arxiv.org/pdf/2506.21106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21102v1","updated":"2025-06-26T08:56:55Z","published":"2025-06-26T08:56:55Z","title":"Interpretable Hierarchical Concept Reasoning through Attention-Guided\n  Graph Learning","summary":"  Concept-Based Models (CBMs) are a class of deep learning models that provide\ninterpretability by explaining predictions through high-level concepts. These\nmodels first predict concepts and then use them to perform a downstream task.\nHowever, current CBMs offer interpretability only for the final task\nprediction, while the concept predictions themselves are typically made via\nblack-box neural networks. To address this limitation, we propose Hierarchical\nConcept Memory Reasoner (H-CMR), a new CBM that provides interpretability for\nboth concept and task predictions. H-CMR models relationships between concepts\nusing a learned directed acyclic graph, where edges represent logic rules that\ndefine concepts in terms of other concepts. During inference, H-CMR employs a\nneural attention mechanism to select a subset of these rules, which are then\napplied hierarchically to predict all concepts and the final task. Experimental\nresults demonstrate that H-CMR matches state-of-the-art performance while\nenabling strong human interaction through concept and model interventions. The\nformer can significantly improve accuracy at inference time, while the latter\ncan enhance data efficiency during training when background knowledge is\navailable.\n","authors":["David Debot","Pietro Barbiero","Gabriele Dominici","Giuseppe Marra"],"pdf_url":"https://arxiv.org/pdf/2506.21102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21098v1","updated":"2025-06-26T08:48:16Z","published":"2025-06-26T08:48:16Z","title":"ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for\n  Real-time Community Question Answering in Industry","summary":"  Community Question Answering (CQA) platforms can be deemed as important\nknowledge bases in community, but effectively leveraging historical\ninteractions and domain knowledge in real-time remains a challenge. Existing\nmethods often underutilize external knowledge, fail to incorporate dynamic\nhistorical QA context, or lack memory mechanisms suited for industrial\ndeployment. We propose ComRAG, a retrieval-augmented generation framework for\nreal-time industrial CQA that integrates static knowledge with dynamic\nhistorical QA pairs via a centroid-based memory mechanism designed for\nretrieval, generation, and efficient storage. Evaluated on three industrial CQA\ndatasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%\nimprovement in vector similarity, reducing latency by 8.7% to 23.3%, and\nlowering chunk growth from 20.23% to 2.06% over iterations.\n","authors":["Qinwen Chen","Wenbiao Tao","Zhiwei Zhu","Mingfan Xi","Liangzhong Guo","Yuan Wang","Wei Wang","Yunshi Lan"],"pdf_url":"https://arxiv.org/pdf/2506.21098v1.pdf","comment":"7 pages, 4 figures. Accepted at ACL 2025 Industry Track"},{"id":"http://arxiv.org/abs/2408.17443v4","updated":"2025-06-26T08:46:37Z","published":"2024-08-30T17:52:55Z","title":"HERMES: temporal-coHERent long-forM understanding with Episodes and\n  Semantics","summary":"  Long-form video understanding presents unique challenges that extend beyond\ntraditional short-video analysis approaches, particularly in capturing\nlong-range dependencies, processing redundant information efficiently, and\nextracting high-level semantic concepts. To address these challenges, we\npropose a novel approach that more accurately reflects human cognition. This\npaper introduces HERMES: temporal-coHERent long-forM understanding with\nEpisodes and Semantics, featuring two versatile modules that can enhance\nexisting video-language models or operate as a standalone system. Our Episodic\nCOmpressor (ECO) efficiently aggregates representations from micro to\nsemi-macro levels, reducing computational overhead while preserving temporal\ndependencies. Our Semantics ReTRiever (SeTR) enriches these representations\nwith semantic information by focusing on broader context, dramatically reducing\nfeature dimensionality while preserving relevant macro-level information. We\ndemonstrate that these modules can be seamlessly integrated into existing SOTA\nmodels, consistently improving their performance while reducing inference\nlatency by up to 43% and memory usage by 46%. As a standalone system, HERMES\nachieves state-of-the-art performance across multiple long-video understanding\nbenchmarks in both zero-shot and fully-supervised settings.\n","authors":["Gueter Josmy Faure","Jia-Fong Yeh","Min-Hung Chen","Hung-Ting Su","Shang-Hong Lai","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2408.17443v4.pdf","comment":"Accepted for ICCV 2025. Project page:\n  https://joslefaure.github.io/assets/html/hermes.html"},{"id":"http://arxiv.org/abs/2506.19874v2","updated":"2025-06-26T08:45:10Z","published":"2025-06-23T11:57:41Z","title":"Towards Provable (In)Secure Model Weight Release Schemes","summary":"  Recent secure weight release schemes claim to enable open-source model\ndistribution while protecting model ownership and preventing misuse. However,\nthese approaches lack rigorous security foundations and provide only informal\nsecurity guarantees. Inspired by established works in cryptography, we\nformalize the security of weight release schemes by introducing several\nconcrete security definitions. We then demonstrate our definition's utility\nthrough a case study of TaylorMLP, a prominent secure weight release scheme.\nOur analysis reveals vulnerabilities that allow parameter extraction thus\nshowing that TaylorMLP fails to achieve its informal security goals. We hope\nthis work will advocate for rigorous research at the intersection of machine\nlearning and security communities and provide a blueprint for how future weight\nrelease schemes should be designed and evaluated.\n","authors":["Xin Yang","Bintao Tang","Yuhao Wang","Zimo Ji","Terry Jingchen Zhang","Wenyuan Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.19874v2.pdf","comment":"8 pages, 2 figures; author name typos and institutions corrected"},{"id":"http://arxiv.org/abs/2506.21095v1","updated":"2025-06-26T08:43:12Z","published":"2025-06-26T08:43:12Z","title":"FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation","summary":"  Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing clients' private data. However, fairness remains a key\nconcern, as biases in local clients' datasets can impact the entire federated\nsystem. Heterogeneous data distributions across clients may lead to models that\nare fairer for some clients than others. Although several fairness-enhancing\nsolutions are present in the literature, most focus on mitigating bias for a\nsingle sensitive attribute, typically binary, overlooking the diverse and\nsometimes conflicting fairness needs of different clients. This limited\nperspective can limit the effectiveness of fairness interventions for the\ndifferent clients. To support more robust and reproducible fairness research in\nFL, we aim to enable a consistent benchmarking of fairness-aware FL methods at\nboth the global and client levels. In this paper, we contribute in three ways:\n(1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to\nevaluating fair FL methods under heterogeneous client bias; (2) we release four\nbias-heterogeneous datasets and corresponding benchmarks to compare fairness\nmitigation methods in a controlled environment; (3) we provide ready-to-use\nfunctions for evaluating fairness outcomes for these datasets.\n","authors":["Xenia Heilmann","Luca Corbucci","Mattia Cerrato","Anna Monreale"],"pdf_url":"https://arxiv.org/pdf/2506.21095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21085v1","updated":"2025-06-26T08:28:07Z","published":"2025-06-26T08:28:07Z","title":"CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and\n  Solutions","summary":"  Molecular docking plays a crucial role in predicting the binding mode of\nligands to target proteins, and covalent interactions, which involve the\nformation of a covalent bond between the ligand and the target, are\nparticularly valuable due to their strong, enduring binding nature. However,\nmost existing docking methods and deep learning approaches hardly account for\nthe formation of covalent bonds and the associated structural changes. To\naddress this gap, we introduce a comprehensive benchmark for covalent docking,\nCovDocker, which is designed to better capture the complexities of covalent\nbinding. We decompose the covalent docking process into three main tasks:\nreactive location prediction, covalent reaction prediction, and covalent\ndocking. By adapting state-of-the-art models, such as Uni-Mol and Chemformer,\nwe establish baseline performances and demonstrate the effectiveness of the\nbenchmark in accurately predicting interaction sites and modeling the molecular\ntransformations involved in covalent binding. These results confirm the role of\nthe benchmark as a rigorous framework for advancing research in covalent drug\ndesign. It underscores the potential of data-driven approaches to accelerate\nthe discovery of selective covalent inhibitors and addresses critical\nchallenges in therapeutic development.\n","authors":["Yangzhe Peng","Kaiyuan Gao","Liang He","Yuheng Cong","Haiguang Liu","Kun He","Lijun Wu"],"pdf_url":"https://arxiv.org/pdf/2506.21085v1.pdf","comment":"Accepted to KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2506.21080v1","updated":"2025-06-26T08:09:16Z","published":"2025-06-26T08:09:16Z","title":"EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for\n  Efficient Egocentric Perception","summary":"  Modern perception models, particularly those designed for multisensory\negocentric tasks, have achieved remarkable performance but often come with\nsubstantial computational costs. These high demands pose challenges for\nreal-world deployment, especially in resource-constrained environments. In this\npaper, we introduce EgoAdapt, a framework that adaptively performs cross-modal\ndistillation and policy learning to enable efficient inference across different\negocentric perception tasks, including egocentric action recognition, active\nspeaker localization, and behavior anticipation. Our proposed policy module is\nadaptable to task-specific action spaces, making it broadly applicable.\nExperimental results on three challenging egocentric datasets EPIC-Kitchens,\nEasyCom, and Aria Everyday Activities demonstrate that our method significantly\nenhances efficiency, reducing GMACs by up to 89.09%, parameters up to 82.02%,\nand energy up to 9.6x, while still on-par and in many cases outperforming, the\nperformance of corresponding state-of-the-art models.\n","authors":["Sanjoy Chowdhury","Subrata Biswas","Sayan Nag","Tushar Nagarajan","Calvin Murdock","Ishwarya Ananthabhotla","Yijun Qian","Vamsi Krishna Ithapu","Dinesh Manocha","Ruohan Gao"],"pdf_url":"https://arxiv.org/pdf/2506.21080v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2505.11277v3","updated":"2025-06-26T06:52:37Z","published":"2025-05-16T14:11:29Z","title":"Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning\n  of LLMs","summary":"  Large language models have demonstrated impressive reasoning capabilities but\nare inherently limited by their knowledge reservoir. Retrieval-augmented\nreasoning mitigates this limitation by allowing LLMs to query external\nresources, but existing methods often retrieve irrelevant or noisy information,\nhindering accurate reasoning. In this paper, we propose AutoRefine, a\nreinforcement learning post-training framework that adopts a new\n``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit\nknowledge refinement steps between successive search calls, enabling the model\nto iteratively filter, distill, and organize evidence before generating an\nanswer. Furthermore, we incorporate tailored retrieval-specific rewards\nalongside answer correctness rewards using group relative policy optimization.\nExperiments on single-hop and multi-hop QA benchmarks demonstrate that\nAutoRefine significantly outperforms existing approaches, particularly in\ncomplex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine\nissues frequent, higher-quality searches and synthesizes evidence effectively.\n","authors":["Yaorui Shi","Sihang Li","Chang Wu","Zhiyuan Liu","Junfeng Fang","Hengxing Cai","An Zhang","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2505.11277v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21049v1","updated":"2025-06-26T06:52:33Z","published":"2025-06-26T06:52:33Z","title":"A Semi-supervised Scalable Unified Framework for E-commerce Query\n  Classification","summary":"  Query classification, including multiple subtasks such as intent and category\nprediction, is vital to e-commerce applications. E-commerce queries are usually\nshort and lack context, and the information between labels cannot be used,\nresulting in insufficient prior information for modeling. Most existing\nindustrial query classification methods rely on users' posterior click behavior\nto construct training samples, resulting in a Matthew vicious cycle.\nFurthermore, the subtasks of query classification lack a unified framework,\nleading to low efficiency for algorithm optimization.\n  In this paper, we propose a novel Semi-supervised Scalable Unified Framework\n(SSUF), containing multiple enhanced modules to unify the query classification\ntasks. The knowledge-enhanced module uses world knowledge to enhance query\nrepresentations and solve the problem of insufficient query information. The\nlabel-enhanced module uses label semantics and semi-supervised signals to\nreduce the dependence on posterior labels. The structure-enhanced module\nenhances the label representation based on the complex label relations. Each\nmodule is highly pluggable, and input features can be added or removed as\nneeded according to each subtask. We conduct extensive offline and online A/B\nexperiments, and the results show that SSUF significantly outperforms the\nstate-of-the-art models.\n","authors":["Chunyuan Yuan","Chong Zhang","Zheng Fang","Ming Pang","Xue Jiang","Changping Peng","Zhangang Lin","Ching Law"],"pdf_url":"https://arxiv.org/pdf/2506.21049v1.pdf","comment":"Accepted by ACL 2025"},{"id":"http://arxiv.org/abs/2506.21045v1","updated":"2025-06-26T06:46:03Z","published":"2025-06-26T06:46:03Z","title":"Improving Diffusion-Based Image Editing Faithfulness via Guidance and\n  Scheduling","summary":"  Text-guided diffusion models have become essential for high-quality image\nsynthesis, enabling dynamic image editing. In image editing, two crucial\naspects are editability, which determines the extent of modification, and\nfaithfulness, which reflects how well unaltered elements are preserved.\nHowever, achieving optimal results is challenging because of the inherent\ntrade-off between editability and faithfulness. To address this, we propose\nFaithfulness Guidance and Scheduling (FGS), which enhances faithfulness with\nminimal impact on editability. FGS incorporates faithfulness guidance to\nstrengthen the preservation of input image information and introduces a\nscheduling strategy to resolve misalignment between editability and\nfaithfulness. Experimental results demonstrate that FGS achieves superior\nfaithfulness while maintaining editability. Moreover, its compatibility with\nvarious editing methods enables precise, high-quality image edits across\ndiverse tasks.\n","authors":["Hansam Cho","Seoung Bum Kim"],"pdf_url":"https://arxiv.org/pdf/2506.21045v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2506.21044v1","updated":"2025-06-26T06:45:59Z","published":"2025-06-26T06:45:59Z","title":"Efficient Skill Discovery via Regret-Aware Optimization","summary":"  Unsupervised skill discovery aims to learn diverse and distinguishable\nbehaviors in open-ended reinforcement learning. For existing methods, they\nfocus on improving diversity through pure exploration, mutual information\noptimization, and learning temporal representation. Despite that they perform\nwell on exploration, they remain limited in terms of efficiency, especially for\nthe high-dimensional situations. In this work, we frame skill discovery as a\nmin-max game of skill generation and policy learning, proposing a regret-aware\nmethod on top of temporal representation learning that expands the discovered\nskill space along the direction of upgradable policy strength. The key insight\nbehind the proposed method is that the skill discovery is adversarial to the\npolicy learning, i.e., skills with weak strength should be further explored\nwhile less exploration for the skills with converged strength. As an\nimplementation, we score the degree of strength convergence with regret, and\nguide the skill discovery with a learnable skill generator. To avoid\ndegeneration, skill generation comes from an up-gradable population of skill\ngenerators. We conduct experiments on environments with varying complexities\nand dimension sizes. Empirical results show that our method outperforms\nbaselines in both efficiency and diversity. Moreover, our method achieves a 15%\nzero shot improvement in high-dimensional environments, compared to existing\nmethods.\n","authors":["He Zhang","Ming Zhou","Shaopeng Zhai","Ying Sun","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2506.21044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.05312v2","updated":"2025-06-26T06:44:43Z","published":"2025-02-19T04:23:12Z","title":"Towards Adaptive Memory-Based Optimization for Enhanced\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge\nfrom external knowledge bases into models, has emerged as a promising approach\nto enhancing response accuracy while mitigating factual errors and\nhallucinations. This method has been widely applied in tasks such as Question\nAnswering (QA). However, existing RAG methods struggle with open-domain QA\ntasks because they perform independent retrieval operations and directly\nincorporate the retrieved information into generation without maintaining a\nsummarizing memory or using adaptive retrieval strategies, leading to noise\nfrom redundant information and insufficient information integration. To address\nthese challenges, we propose Adaptive memory-based optimization for enhanced\nRAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory\nUpdater, an Adaptive Information Collector, and a Multi-granular Content\nFilter, working together within an iterative memory updating paradigm.\nSpecifically, Amber integrates and optimizes the language model's memory\nthrough a multi-agent collaborative approach, ensuring comprehensive knowledge\nintegration from previous retrieval steps. It dynamically adjusts retrieval\nqueries and decides when to stop retrieval based on the accumulated knowledge,\nenhancing retrieval efficiency and effectiveness. Additionally, it reduces\nnoise by filtering irrelevant content at multiple levels, retaining essential\ninformation to improve overall model performance. We conduct extensive\nexperiments on several open-domain QA datasets, and the results demonstrate the\nsuperiority and effectiveness of our method and its components. The source code\nis available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.\n","authors":["Qitao Qin","Yucong Luo","Yihang Lu","Zhibo Chu","Xianwei Meng"],"pdf_url":"https://arxiv.org/pdf/2504.05312v2.pdf","comment":"8pages. arXiv admin note: text overlap with arXiv:2410.08821 by other\n  authors"},{"id":"http://arxiv.org/abs/2503.03921v2","updated":"2025-06-26T06:42:04Z","published":"2025-03-05T21:42:46Z","title":"CREStE: Scalable Mapless Navigation with Internet Scale Priors and\n  Counterfactual Guidance","summary":"  We introduce CREStE, a scalable learning-based mapless navigation framework\nto address the open-world generalization and robustness challenges of outdoor\nurban navigation. Key to achieving this is learning perceptual representations\nthat generalize to open-set factors (e.g. novel semantic classes, terrains,\ndynamic entities) and inferring expert-aligned navigation costs from limited\ndemonstrations. CREStE addresses both these issues, introducing 1) a visual\nfoundation model (VFM) distillation objective for learning open-set structured\nbird's-eye-view perceptual representations, and 2) counterfactual inverse\nreinforcement learning (IRL), a novel active learning formulation that uses\ncounterfactual trajectory demonstrations to reason about the most important\ncues when inferring navigation costs. We evaluate CREStE on the task of\nkilometer-scale mapless navigation in a variety of city, offroad, and\nresidential environments and find that it outperforms all state-of-the-art\napproaches with 70% fewer human interventions, including a 2-kilometer mission\nin an unseen environment with just 1 intervention; showcasing its robustness\nand effectiveness for long-horizon mapless navigation. Videos and additional\nmaterials can be found on the project page: https://amrl.cs.utexas.edu/creste\n","authors":["Arthur Zhang","Harshit Sikchi","Amy Zhang","Joydeep Biswas"],"pdf_url":"https://arxiv.org/pdf/2503.03921v2.pdf","comment":"18 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2506.21041v1","updated":"2025-06-26T06:42:03Z","published":"2025-06-26T06:42:03Z","title":"V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative\n  Autonomous Driving with Adaptive Long-Tail Modeling","summary":"  Ensuring robust planning and decision-making under rare, diverse, and\nvisually degraded long-tail scenarios remains a fundamental challenge for\nautonomous driving in urban environments. This issue becomes more critical in\ncooperative settings, where vehicles and infrastructure jointly perceive and\nreason across complex environments. To address this challenge, we propose\nV2X-REALM, a vision-language model (VLM)-based framework with adaptive\nmultimodal learning for robust cooperative autonomous driving under long-tail\nscenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven\nlong-tail scenario generation and evaluation pipeline that leverages foundation\nmodels to synthesize realistic long-tail conditions such as snow and fog across\nvehicle- and infrastructure-side views, enriching training diversity\nefficiently; (ii) a gated multi-scenario adaptive attention module that\nmodulates the visual stream using scenario priors to recalibrate ambiguous or\ncorrupted features; and (iii) a multi-task scenario-aware contrastive learning\nobjective that improves multimodal alignment and promotes cross-scenario\nfeature separability. Extensive experiments demonstrate that V2X-REALM\nsignificantly outperforms existing baselines in robustness, semantic reasoning,\nsafety, and planning accuracy under complex, challenging driving conditions,\nadvancing the scalability of end-to-end cooperative autonomous driving.\n","authors":["Junwei You","Pei Li","Zhuoyu Jiang","Zilin Huang","Rui Gan","Haotian Shi","Bin Ran"],"pdf_url":"https://arxiv.org/pdf/2506.21041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21039v1","updated":"2025-06-26T06:35:42Z","published":"2025-06-26T06:35:42Z","title":"Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical\n  Reinforcement Learning","summary":"  Long-horizon goal-conditioned tasks pose fundamental challenges for\nreinforcement learning (RL), particularly when goals are distant and rewards\nare sparse. While hierarchical and graph-based methods offer partial solutions,\nthey often suffer from subgoal infeasibility and inefficient planning. We\nintroduce Strict Subgoal Execution (SSE), a graph-based hierarchical RL\nframework that enforces single-step subgoal reachability by structurally\nconstraining high-level decision-making. To enhance exploration, SSE employs a\ndecoupled exploration policy that systematically traverses underexplored\nregions of the goal space. Furthermore, a failure-aware path refinement, which\nrefines graph-based planning by dynamically adjusting edge costs according to\nobserved low-level success rates, thereby improving subgoal reliability.\nExperimental results across diverse long-horizon benchmarks demonstrate that\nSSE consistently outperforms existing goal-conditioned RL and hierarchical RL\napproaches in both efficiency and success rate.\n","authors":["Jaebak Hwang","Sanghyeon Lee","Jeongmo Kim","Seungyul Han"],"pdf_url":"https://arxiv.org/pdf/2506.21039v1.pdf","comment":"9 technical page followed by references and appendix"},{"id":"http://arxiv.org/abs/2405.18113v2","updated":"2025-06-26T06:33:55Z","published":"2024-05-28T12:23:16Z","title":"MockLLM: A Multi-Agent Behavior Collaboration Framework for Online Job\n  Seeking and Recruiting","summary":"  Online recruitment platforms have reshaped job-seeking and recruiting\nprocesses, driving increased demand for applications that enhance person-job\nmatching. Traditional methods generally rely on analyzing textual data from\nresumes and job descriptions, limiting the dynamic, interactive aspects crucial\nto effective recruitment. Recent advances in Large Language Models (LLMs) have\nrevealed remarkable potential in simulating adaptive, role-based dialogues,\nmaking them well-suited for recruitment scenarios. In this paper, we propose\n\\textbf{MockLLM}, a novel framework to generate and evaluate mock interview\ninteractions. The system consists of two key components: mock interview\ngeneration and two-sided evaluation in handshake protocol. By simulating both\ninterviewer and candidate roles, MockLLM enables consistent and collaborative\ninteractions for real-time and two-sided matching. To further improve the\nmatching quality, MockLLM further incorporates reflection memory generation and\ndynamic strategy modification, refining behaviors based on previous experience.\nWe evaluate MockLLM on real-world data Boss Zhipin, a major Chinese recruitment\nplatform. The experimental results indicate that MockLLM outperforms existing\nmethods in matching accuracy, scalability, and adaptability across job domains,\nhighlighting its potential to advance candidate assessment and online\nrecruitment.\n","authors":["Hongda Sun","Hongzhan Lin","Haiyu Yan","Yang Song","Xin Gao","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2405.18113v2.pdf","comment":"Accepted by KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2505.00482v2","updated":"2025-06-26T06:21:40Z","published":"2025-05-01T12:21:23Z","title":"JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers","summary":"  We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.\n","authors":["Kwon Byung-Ki","Qi Dai","Lee Hyoseok","Chong Luo","Tae-Hyun Oh"],"pdf_url":"https://arxiv.org/pdf/2505.00482v2.pdf","comment":"Accepted to IEEE/CVF International Conference on Computer Vision\n  (ICCV) 2025. Project page: https://byungki-k.github.io/JointDiT/ Code:\n  https://github.com/ByungKi-K/JointDiT-code"},{"id":"http://arxiv.org/abs/2506.05432v2","updated":"2025-06-26T06:17:49Z","published":"2025-06-05T08:58:58Z","title":"PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar\n  Coordinate Decoupling","summary":"  Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.\n","authors":["Yuxuan Yue","Zukang Xu","Zhihang Yuan","Dawei Yang","Jianlong Wu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2506.05432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21031v1","updated":"2025-06-26T06:10:37Z","published":"2025-06-26T06:10:37Z","title":"Large Language Models Acing Chartered Accountancy","summary":"  Advanced intelligent systems, particularly Large Language Models (LLMs), are\nsignificantly reshaping financial practices through advancements in Natural\nLanguage Processing (NLP). However, the extent to which these models\neffectively capture and apply domain-specific financial knowledge remains\nuncertain. Addressing a critical gap in the expansive Indian financial context,\nthis paper introduces CA-Ben, a Chartered Accountancy benchmark specifically\ndesigned to evaluate the financial, legal, and quantitative reasoning\ncapabilities of LLMs. CA-Ben comprises structured question-answer datasets\nderived from the rigorous examinations conducted by the Institute of Chartered\nAccountants of India (ICAI), spanning foundational, intermediate, and advanced\nCA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1\n405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated\nusing standardized protocols. Results indicate variations in performance, with\nClaude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and\nlegal reasoning. Notable challenges emerged in numerical computations and legal\ninterpretations. The findings emphasize the strengths and limitations of\ncurrent LLMs, suggesting future improvements through hybrid reasoning and\nretrieval-augmented generation methods, particularly for quantitative analysis\nand accurate legal interpretation.\n","authors":["Jatin Gupta","Akhil Sharma","Saransh Singhania","Mohammad Adnan","Sakshi Deo","Ali Imam Abidi","Keshav Gupta"],"pdf_url":"https://arxiv.org/pdf/2506.21031v1.pdf","comment":"Accepted for publication at MoStart 2025: International Conference on\n  Digital Transformation in Education and Applications of Artificial\n  Intelligence, Bosnia and Herzegovina, 2025"},{"id":"http://arxiv.org/abs/2506.20401v2","updated":"2025-06-26T06:02:57Z","published":"2025-06-25T13:15:52Z","title":"Smart Ride and Delivery Services with Electric Vehicles: Leveraging\n  Bidirectional Charging for Profit Optimisation","summary":"  With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.\n","authors":["Jinchun Du","Bojie Shen","Muhammad Aamir Cheema","Adel N. Toosi"],"pdf_url":"https://arxiv.org/pdf/2506.20401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21017v1","updated":"2025-06-26T05:28:57Z","published":"2025-06-26T05:28:57Z","title":"Multimodal Prompt Alignment for Facial Expression Recognition","summary":"  Prompt learning has been widely adopted to efficiently adapt vision-language\nmodels (VLMs) like CLIP for various downstream tasks. Despite their success,\ncurrent VLM-based facial expression recognition (FER) methods struggle to\ncapture fine-grained textual-visual relationships, which are essential for\ndistinguishing subtle differences between facial expressions. To address this\nchallenge, we propose a multimodal prompt alignment framework for FER, called\nMPA-FER, that provides fine-grained semantic guidance to the learning process\nof prompted visual features, resulting in more precise and interpretable\nrepresentations. Specifically, we introduce a multi-granularity hard prompt\ngeneration strategy that utilizes a large language model (LLM) like ChatGPT to\ngenerate detailed descriptions for each facial expression. The LLM-based\nexternal knowledge is injected into the soft prompts by minimizing the feature\ndiscrepancy between the soft prompts and the hard prompts. To preserve the\ngeneralization abilities of the pretrained CLIP model, our approach\nincorporates prototype-guided visual feature alignment, ensuring that the\nprompted visual features from the frozen image encoder align closely with\nclass-specific prototypes. Additionally, we propose a cross-modal global-local\nalignment module that focuses on expression-relevant facial features, further\nimproving the alignment between textual and visual features. Extensive\nexperiments demonstrate our framework outperforms state-of-the-art methods on\nthree FER benchmark datasets, while retaining the benefits of the pretrained\nmodel and minimizing computational costs.\n","authors":["Fuyan Ma","Yiran He","Bin Sun","Shutao Li"],"pdf_url":"https://arxiv.org/pdf/2506.21017v1.pdf","comment":"To appear in ICCV2025"},{"id":"http://arxiv.org/abs/2506.14539v2","updated":"2025-06-26T05:18:19Z","published":"2025-06-17T14:01:39Z","title":"Doppelganger Method: Breaking Role Consistency in LLM Agent via\n  Prompt-based Transferable Adversarial Attack","summary":"  Since the advent of large language models, prompt engineering now enables the\nrapid, low-effort creation of diverse autonomous agents that are already in\nwidespread use. Yet this convenience raises urgent concerns about the safety,\nrobustness, and behavioral consistency of the underlying prompts, along with\nthe pressing challenge of preventing those prompts from being exposed to user's\nattempts. In this paper, we propose the ''Doppelganger method'' to demonstrate\nthe risk of an agent being hijacked, thereby exposing system instructions and\ninternal information. Next, we define the ''Prompt Alignment Collapse under\nAdversarial Transfer (PACAT)'' level to evaluate the vulnerability to this\nadversarial transfer attack. We also propose a ''Caution for Adversarial\nTransfer (CAT)'' prompt to counter the Doppelganger method. The experimental\nresults demonstrate that the Doppelganger method can compromise the agent's\nconsistency and expose its internal information. In contrast, CAT prompts\nenable effective defense against this adversarial attack.\n","authors":["Daewon Kang","YeongHwan Shin","Doyeon Kim","Kyu-Hwan Jung","Meong Hi Son"],"pdf_url":"https://arxiv.org/pdf/2506.14539v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05770v3","updated":"2025-06-26T05:07:48Z","published":"2022-11-10T18:55:48Z","title":"Efficient Image Generation with Variadic Attention Heads","summary":"  While the integration of transformers in vision models have yielded\nsignificant improvements on vision tasks they still require significant amounts\nof computation for both training and inference. Restricted attention mechanisms\nsignificantly reduce these computational burdens but come at the cost of losing\neither global or local coherence. We propose a simple, yet powerful method to\nreduce these trade-offs: allow the attention heads of a single transformer to\nattend to multiple receptive fields.\n  We demonstrate our method utilizing Neighborhood Attention (NA) and integrate\nit into a StyleGAN based architecture for image generation. With this work,\ndubbed StyleNAT, we are able to achieve a FID of 2.05 on FFHQ, a 6% improvement\nover StyleGAN-XL, while utilizing 28% fewer parameters and with 4$\\times$ the\nthroughput capacity. StyleNAT achieves the Pareto Frontier on FFHQ-256 and\ndemonstrates powerful and efficient image generation on other datasets. Our\ncode and model checkpoints are publicly available at:\nhttps://github.com/SHI-Labs/StyleNAT\n","authors":["Steven Walton","Ali Hassani","Xingqian Xu","Zhangyang Wang","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2211.05770v3.pdf","comment":"Published in eLVM @ CVPR\n  (https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Walton_Efficient_Image_Generation_with_Variadic_Attention_Heads_CVPRW_2025_paper)\n  | Formerly named StyleNAT: Giving Each Head a New Perspective |"},{"id":"http://arxiv.org/abs/2505.19197v3","updated":"2025-06-26T04:56:31Z","published":"2025-05-25T15:45:46Z","title":"Structuring the Unstructured: A Multi-Agent System for Extracting and\n  Querying Financial KPIs and Guidance","summary":"  Extracting structured and quantitative insights from unstructured financial\nfilings is essential in investment research, yet remains time-consuming and\nresource-intensive. Conventional approaches in practice rely heavily on\nlabor-intensive manual processes, limiting scalability and delaying the\nresearch workflow. In this paper, we propose an efficient and scalable method\nfor accurately extracting quantitative insights from unstructured financial\ndocuments, leveraging a multi-agent system composed of large language models.\nOur proposed multi-agent system consists of two specialized agents: the\n\\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The\n\\textit{Extraction Agent} automatically identifies key performance indicators\nfrom unstructured financial text, standardizes their formats, and verifies\ntheir accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates\nexecutable SQL statements from natural language queries, allowing users to\naccess structured data accurately without requiring familiarity with the\ndatabase schema. Through experiments, we demonstrate that our proposed system\neffectively transforms unstructured text into structured data accurately and\nenables precise retrieval of key information. First, we demonstrate that our\nsystem achieves approximately 95\\% accuracy in transforming financial filings\ninto structured data, matching the performance level typically attained by\nhuman annotators. Second, in a human evaluation of the retrieval task -- where\nnatural language queries are used to search information from structured data --\n91\\% of the responses were rated as correct by human evaluators. In both\nevaluations, our system generalizes well across financial document types,\nconsistently delivering reliable performance.\n","authors":["Chanyeol Choi","Alejandro Lopez-Lira","Yongjae Lee","Jihoon Kwon","Minjae Kim","Juneha Hwang","Minsoo Ha","Chaewoon Kim","Jaeseon Ha","Suyeol Yun","Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2505.19197v3.pdf","comment":"7 pages, FinIR'25"},{"id":"http://arxiv.org/abs/2210.09394v2","updated":"2025-06-26T04:44:25Z","published":"2022-10-17T19:54:38Z","title":"Review learning: Real world validation of privacy preserving continual\n  learning across medical institutions","summary":"  When a deep learning model is trained sequentially on different datasets, it\noften forgets the knowledge learned from previous data, a problem known as\ncatastrophic forgetting. This damages the model's performance on diverse\ndatasets, which is critical in privacy-preserving deep learning (PPDL)\napplications based on transfer learning (TL). To overcome this, we introduce\n\"review learning\" (RevL), a low cost continual learning algorithm for diagnosis\nprediction using electronic health records (EHR) within a PPDL framework. RevL\ngenerates data samples from the model which are used to review knowledge from\nprevious datasets. Six simulated institutional experiments and one real-world\nexperiment involving three medical institutions were conducted to validate\nRevL, using three binary classification EHR data. In the real-world experiment\nwith data from 106,508 patients, the mean global area under the receiver\noperating curve was 0.710 for RevL and 0.655 for TL. These results demonstrate\nRevL's ability to retain previously learned knowledge and its effectiveness in\nreal-world PPDL scenarios. Our work establishes a realistic pipeline for PPDL\nresearch based on model transfers across institutions and highlights the\npracticality of continual learning in real-world medical settings using private\nEHR data.\n","authors":["Jaesung Yoo","Sunghyuk Choi","Ye Seul Yang","Suhyeon Kim","Jieun Choi","Dongkyeong Lim","Yaeji Lim","Hyung Joon Joo","Dae Jung Kim","Rae Woong Park","Hyeong-Jin Yoon","Kwangsoo Kim"],"pdf_url":"https://arxiv.org/pdf/2210.09394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01787v3","updated":"2025-06-26T04:26:18Z","published":"2024-11-29T08:24:49Z","title":"Pretrained Reversible Generation as Unsupervised Visual Representation\n  Learning","summary":"  Recent generative models based on score matching and flow matching have\nsignificantly advanced generation tasks, but their potential in discriminative\ntasks remains underexplored. Previous approaches, such as generative\nclassifiers, have not fully leveraged the capabilities of these models for\ndiscriminative tasks due to their intricate designs. We propose Pretrained\nReversible Generation (PRG), which extracts unsupervised representations by\nreversing the generative process of a pretrained continuous generation model.\nPRG effectively reuses unsupervised generative models, leveraging their high\ncapacity to serve as robust and generalizable feature extractors for downstream\ntasks. This framework enables the flexible selection of feature hierarchies\ntailored to specific downstream tasks. Our method consistently outperforms\nprior approaches across multiple benchmarks, achieving state-of-the-art\nperformance among generative model based methods, including 78% top-1 accuracy\non ImageNet at a resolution of 64*64. Extensive ablation studies, including\nout-of-distribution evaluations, further validate the effectiveness of our\napproach. Code is available at https://github.com/opendilab/PRG.\n","authors":["Rongkun Xue","Jinouwen Zhang","Yazhe Niu","Dazhong Shen","Bingqi Ma","Yu Liu","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2412.01787v3.pdf","comment":"Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2506.20993v1","updated":"2025-06-26T04:12:15Z","published":"2025-06-26T04:12:15Z","title":"SAC: A Framework for Measuring and Inducing Personality Traits in LLMs\n  with Dynamic Intensity Control","summary":"  Large language models (LLMs) have gained significant traction across a wide\nrange of fields in recent years. There is also a growing expectation for them\nto display human-like personalities during interactions. To meet this\nexpectation, numerous studies have proposed methods for modelling LLM\npersonalities through psychometric evaluations. However, most existing models\nface two major limitations: they rely on the Big Five (OCEAN) framework, which\nonly provides coarse personality dimensions, and they lack mechanisms for\ncontrolling trait intensity. In this paper, we address this gap by extending\nthe Machine Personality Inventory (MPI), which originally used the Big Five\nmodel, to incorporate the 16 Personality Factor (16PF) model, allowing\nexpressive control over sixteen distinct traits. We also developed a structured\nframework known as Specific Attribute Control (SAC) for evaluating and\ndynamically inducing trait intensity in LLMs. Our method introduces\nadjective-based semantic anchoring to guide trait intensity expression and\nleverages behavioural questions across five intensity factors:\n\\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and\n\\textit{Willingness}. Through experimentation, we find that modelling intensity\nas a continuous spectrum yields substantially more consistent and controllable\npersonality expression compared to binary trait toggling. Moreover, we observe\nthat changes in target trait intensity systematically influence closely related\ntraits in psychologically coherent directions, suggesting that LLMs internalize\nmulti-dimensional personality structures rather than treating traits in\nisolation. Our work opens new pathways for controlled and nuanced human-machine\ninteractions in domains such as healthcare, education, and interviewing\nprocesses, bringing us one step closer to truly human-like social machines.\n","authors":["Adithya Chittem","Aishna Shrivastava","Sai Tarun Pendela","Jagat Sesh Challa","Dhruv Kumar"],"pdf_url":"https://arxiv.org/pdf/2506.20993v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2506.20081v2","updated":"2025-06-26T04:06:50Z","published":"2025-06-25T01:44:28Z","title":"SACL: Understanding and Combating Textual Bias in Code Retrieval with\n  Semantic-Augmented Reranking and Localization","summary":"  Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant. Based on our discoveries, we propose SACL, a framework that\nenriches textual information and reduces bias by augmenting code or structural\nknowledge with semantic information. Extensive experiments show that SACL\nsubstantially improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on\nHumanEval / MBPP / SWE-Bench-Lite), which also leads to better code generation\nperformance (e.g., by 4.88% Pass@1 on HumanEval).\n","authors":["Dhruv Gupta","Gayathri Ganesh Lakshmy","Yiqing Xie"],"pdf_url":"https://arxiv.org/pdf/2506.20081v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20988v1","updated":"2025-06-26T04:01:40Z","published":"2025-06-26T04:01:40Z","title":"Segment Anything in Pathology Images with Natural Language","summary":"  Pathology image segmentation is crucial in computational pathology for\nanalyzing histological features relevant to cancer diagnosis and prognosis.\nHowever, current methods face major challenges in clinical applications due to\nlimited annotated data and restricted category definitions. To address these\nlimitations, we propose PathSegmentor, the first text-prompted segmentation\nfoundation model designed specifically for pathology images. We also introduce\nPathSeg , the largest and most comprehensive dataset for pathology\nsegmentation, built from 17 public sources and containing 275k image-mask-label\ntriples across 160 diverse categories. With PathSegmentor, users can perform\nsemantic segmentation using natural language prompts, eliminating the need for\nlaborious spatial inputs such as points or boxes. Extensive experiments\ndemonstrate that PathSegmentor outperforms specialized models with higher\naccuracy and broader applicability, while maintaining a compact architecture.\nIt significantly surpasses existing spatial- and text-prompted models by 0.145\nand 0.429 in overall Dice scores, respectively, showing strong robustness in\nsegmenting complex structures and generalizing to external datasets. Moreover,\nPathSegmentor's outputs enhance the interpretability of diagnostic models\nthrough feature importance estimation and imaging biomarker discovery, offering\npathologists evidence-based support for clinical decision-making. This work\nadvances the development of explainable AI in precision oncology.\n","authors":["Zhixuan Chen","Junlin Hou","Liqi Lin","Yihui Wang","Yequan Bie","Xi Wang","Yanning Zhou","Ronald Cheong Kin Chan","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2506.20988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.18313v2","updated":"2025-06-26T03:57:07Z","published":"2025-03-24T03:32:13Z","title":"Will LLMs be Professional at Fund Investment? DeepFund: A Live Arena\n  Perspective","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities across\nvarious domains, but their effectiveness in financial decision-making remains\ninadequately evaluated. Current benchmarks primarily assess LLMs' understanding\non financial documents rather than the ability to manage assets or dig out\ntrading opportunities in dynamic market conditions. Despite the release of new\nbenchmarks for evaluating diversified tasks on the financial domain, we\nidentified four major problems in these benchmarks, which are data leakage,\nnavel-gazing, over-intervention, and maintenance-hard. To pave the research\ngap, we introduce DeepFund, a comprehensive arena platform for evaluating\nLLM-based trading strategies in a live environment. Our approach implements a\nmulti-agent framework where they serve as multiple key roles that realize the\nreal-world investment decision processes. Moreover, we provide a web interface\nthat visualizes LLMs' performance with fund investment metrics across different\nmarket conditions, enabling detailed comparative analysis. Through DeepFund, we\naim to provide a more realistic and fair assessment on LLM's capabilities in\nfund investment, offering diversified insights and revealing their potential\napplications in real-world financial markets. Our code is publicly available at\nhttps://github.com/HKUSTDial/DeepFund.\n","authors":["Changlun Li","Yao Shi","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.18313v2.pdf","comment":"6 pages, 3 figures, perspective paper"},{"id":"http://arxiv.org/abs/2412.03359v2","updated":"2025-06-26T03:55:53Z","published":"2024-12-04T14:45:09Z","title":"WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems\n  Through Game-Based Analysis","summary":"  Recent advancements in autonomous multi-agent systems (MAS) based on large\nlanguage models (LLMs) have enhanced the application scenarios and improved the\ncapability of LLMs to handle complex tasks. Despite demonstrating\neffectiveness, existing studies still evidently struggle to evaluate, analysis,\nand reproducibility of LLM-based MAS. In this paper, to facilitate the research\non LLM-based MAS, we introduce an open, scalable, and real-time updated\nplatform for accessing and analyzing the LLM-based MAS based on the games Who\nis Spy?\" (WiS). Our platform is featured with three main worths: (1) a unified\nmodel evaluate interface that supports models available on Hugging Face; (2)\nreal-time updated leaderboard for model evaluation; (3) a comprehensive\nevaluation covering game-winning rates, attacking, defense strategies, and\nreasoning of LLMs. To rigorously test WiS, we conduct extensive experiments\ncoverage of various open- and closed-source LLMs, we find that different agents\nexhibit distinct and intriguing behaviors in the game. The experimental results\ndemonstrate the effectiveness and efficiency of our platform in evaluating\nLLM-based MAS. Our platform and its documentation are publicly available at\nhttps://whoisspy.ai/.\n","authors":["Chengwei Hu","Jianhui Zheng","Yancheng He","Hangyu Guo","Junguang Jiang","Han Zhu","Kai Sun","Yuning Jiang","Wenbo Su","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.03359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20980v1","updated":"2025-06-26T03:54:06Z","published":"2025-06-26T03:54:06Z","title":"Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in\n  Heterogeneous Graphs","summary":"  Real-world networks usually have a property of node heterophily, that is, the\nconnected nodes usually have different features or different labels. This\nheterophily issue has been extensively studied in homogeneous graphs but\nremains under-explored in heterogeneous graphs, where there are multiple types\nof nodes and edges. Capturing node heterophily in heterogeneous graphs is very\nchallenging since both node/edge heterogeneity and node heterophily should be\ncarefully taken into consideration. Existing methods typically convert\nheterogeneous graphs into homogeneous ones to learn node heterophily, which\nwill inevitably lose the potential heterophily conveyed by heterogeneous\nrelations. To bridge this gap, we propose Relation-Aware Separation of\nHomophily and Heterophily (RASH), a novel contrastive learning framework that\nexplicitly models high-order semantics of heterogeneous interactions and\nadaptively separates homophilic and heterophilic patterns. Particularly, RASH\nintroduces dual heterogeneous hypergraphs to encode multi-relational bipartite\nsubgraphs and dynamically constructs homophilic graphs and heterophilic graphs\nbased on relation importance. A multi-relation contrastive loss is designed to\nalign heterogeneous and homophilic/heterophilic views by maximizing mutual\ninformation. In this way, RASH simultaneously resolves the challenges of\nheterogeneity and heterophily in heterogeneous graphs. Extensive experiments on\nbenchmark datasets demonstrate the effectiveness of RASH across various\ndownstream tasks. The code is available at:\nhttps://github.com/zhengziyu77/RASH.\n","authors":["Ziyu Zheng","Yaming Yang","Ziyu Guan","Wei Zhao","Weigang Lu"],"pdf_url":"https://arxiv.org/pdf/2506.20980v1.pdf","comment":"accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2506.20977v1","updated":"2025-06-26T03:48:28Z","published":"2025-06-26T03:48:28Z","title":"From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan\n  Face Aging","summary":"  Face aging has become a crucial task in computer vision, with applications\nranging from entertainment to healthcare. However, existing methods struggle\nwith achieving a realistic and seamless transformation across the entire\nlifespan, especially when handling large age gaps or extreme head poses. The\ncore challenge lies in balancing age accuracy and identity preservation--what\nwe refer to as the Age-ID trade-off. Most prior methods either prioritize age\ntransformation at the expense of identity consistency or vice versa. In this\nwork, we address this issue by proposing a two-pass face aging framework, named\nCradle2Cane, based on few-step text-to-image (T2I) diffusion models. The first\npass focuses on solving age accuracy by introducing an adaptive noise injection\n(AdaNI) mechanism. This mechanism is guided by including prompt descriptions of\nage and gender for the given person as the textual condition. Also, by\nadjusting the noise level, we can control the strength of aging while allowing\nmore flexibility in transforming the face. However, identity preservation is\nweakly ensured here to facilitate stronger age transformations. In the second\npass, we enhance identity preservation while maintaining age-specific features\nby conditioning the model on two identity-aware embeddings (IDEmb): SVR-ArcFace\nand Rotate-CLIP. This pass allows for denoising the transformed image from the\nfirst pass, ensuring stronger identity preservation without compromising the\naging accuracy. Both passes are jointly trained in an end-to-end way. Extensive\nexperiments on the CelebA-HQ test dataset, evaluated through Face++ and Qwen-VL\nprotocols, show that our Cradle2Cane outperforms existing face aging methods in\nage accuracy and identity consistency.\n","authors":["Tao Liu","Dafeng Zhang","Gengchen Li","Shizhuo Liu","Yongqi Song","Senmao Li","Shiqi Yang","Boqian Li","Kai Wang","Yaxing Wang"],"pdf_url":"https://arxiv.org/pdf/2506.20977v1.pdf","comment":"30 pages, 12 figures"},{"id":"http://arxiv.org/abs/2501.18867v3","updated":"2025-06-26T03:43:38Z","published":"2025-01-31T03:20:09Z","title":"UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent","summary":"  Recent advancements in Vision-Language-Action (VLA) models have leveraged\npre-trained Vision-Language Models (VLMs) to improve the generalization\ncapabilities. VLMs, typically pre-trained on vision-language understanding\ntasks, provide rich semantic knowledge and reasoning abilities. However, prior\nresearch has shown that VLMs often focus on high-level semantic content and\nneglect low-level features, limiting their ability to capture detailed spatial\ninformation and understand physical dynamics. These aspects, which are crucial\nfor embodied control tasks, remain underexplored in existing pre-training\nparadigms. In this paper, we investigate the training paradigm for VLAs, and\nintroduce \\textbf{UP-VLA}, a \\textbf{U}nified VLA model training with both\nmulti-modal \\textbf{U}nderstanding and future \\textbf{P}rediction objectives,\nenhancing both high-level semantic comprehension and low-level spatial\nunderstanding. Experimental results show that UP-VLA achieves a 33% improvement\non the Calvin ABC-D benchmark compared to the previous state-of-the-art method.\nAdditionally, UP-VLA demonstrates improved success rates in real-world\nmanipulation tasks, particularly those requiring precise spatial information.\n","authors":["Jianke Zhang","Yanjiang Guo","Yucheng Hu","Xiaoyu Chen","Xiang Zhu","Jianyu Chen"],"pdf_url":"https://arxiv.org/pdf/2501.18867v3.pdf","comment":"Accepted to ICML2025"},{"id":"http://arxiv.org/abs/2501.19324v3","updated":"2025-06-26T03:14:46Z","published":"2025-01-31T17:19:57Z","title":"Reward-Guided Speculative Decoding for Efficient LLM Reasoning","summary":"  We introduce Reward-Guided Speculative Decoding (RSD), a novel framework\naimed at improving the efficiency of inference in large language models (LLMs).\nRSD synergistically combines a lightweight draft model with a more powerful\ntarget model, incorporating a controlled bias to prioritize high-reward\noutputs, in contrast to existing speculative decoding methods that enforce\nstrict unbiasedness. RSD employs a process reward model to evaluate\nintermediate decoding steps and dynamically decide whether to invoke the target\nmodel, optimizing the trade-off between computational cost and output quality.\nWe theoretically demonstrate that a threshold-based mixture strategy achieves\nan optimal balance between resource utilization and performance. Extensive\nevaluations on challenging reasoning benchmarks, including Olympiad-level\ntasks, show that RSD delivers significant efficiency gains against decoding\nwith the target model only (up to 4.4x fewer FLOPs), while achieving\nsignificant better accuracy than parallel decoding method on average (up to\n+3.5). These results highlight RSD as a robust and cost-effective approach for\ndeploying LLMs in resource-intensive scenarios. The code is available at\nhttps://github.com/BaohaoLiao/RSD.\n","authors":["Baohao Liao","Yuhui Xu","Hanze Dong","Junnan Li","Christof Monz","Silvio Savarese","Doyen Sahoo","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2501.19324v3.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2506.20967v1","updated":"2025-06-26T03:10:13Z","published":"2025-06-26T03:10:13Z","title":"DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing","summary":"  The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in\nvideo generation. However, directly applying existing video editing methods to\nVideo DiTs often incurs substantial computational overhead, due to\nresource-intensive attention modification or finetuning. To alleviate this\nproblem, we present DFVEdit, an efficient zero-shot video editing method\ntailored for Video DiTs. DFVEdit eliminates the need for both attention\nmodification and fine-tuning by directly operating on clean latents via flow\ntransformation. To be more specific, we observe that editing and sampling can\nbe unified under the continuous flow perspective. Building upon this\nfoundation, we propose the Conditional Delta Flow Vector (CDFV) -- a\ntheoretically unbiased estimation of DFV -- and integrate Implicit Cross\nAttention (ICA) guidance as well as Embedding Reinforcement (ER) to further\nenhance editing quality. DFVEdit excels in practical efficiency, offering at\nleast 20x inference speed-up and 85\\% memory reduction on Video DiTs compared\nto attention-engineering-based editing methods. Extensive quantitative and\nqualitative experiments demonstrate that DFVEdit can be seamlessly applied to\npopular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art\nperformance on structural fidelity, spatial-temporal consistency, and editing\nquality.\n","authors":["Lingling Cai","Kang Zhao","Hangjie Yuan","Xiang Wang","Yingya Zhang","Kejie Huang"],"pdf_url":"https://arxiv.org/pdf/2506.20967v1.pdf","comment":"Zero-shot video editing"},{"id":"http://arxiv.org/abs/2412.03934v2","updated":"2025-06-26T03:10:09Z","published":"2024-12-05T07:32:20Z","title":"InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene\n  Generation with World-Guided Video Models","summary":"  We present InfiniCube, a scalable method for generating unbounded dynamic 3D\ndriving scenes with high fidelity and controllability. Previous methods for\nscene generation either suffer from limited scales or lack geometric and\nappearance consistency along generated sequences. In contrast, we leverage the\nrecent advancements in scalable 3D representation and video models to achieve\nlarge dynamic scene generation that allows flexible controls through HD maps,\nvehicle bounding boxes, and text descriptions. First, we construct a\nmap-conditioned sparse-voxel-based 3D generative model to unleash its power for\nunbounded voxel world generation. Then, we re-purpose a video model and ground\nit on the voxel world through a set of carefully designed pixel-aligned\nguidance buffers, synthesizing a consistent appearance. Finally, we propose a\nfast feed-forward approach that employs both voxel and pixel branches to lift\nthe dynamic videos to dynamic 3D Gaussians with controllable objects. Our\nmethod can generate controllable and realistic 3D driving scenes, and extensive\nexperiments validate the effectiveness and superiority of our model.\n","authors":["Yifan Lu","Xuanchi Ren","Jiawei Yang","Tianchang Shen","Zhangjie Wu","Jun Gao","Yue Wang","Siheng Chen","Mike Chen","Sanja Fidler","Jiahui Huang"],"pdf_url":"https://arxiv.org/pdf/2412.03934v2.pdf","comment":"ICCV 2025. Project Page:\n  https://research.nvidia.com/labs/toronto-ai/infinicube/"},{"id":"http://arxiv.org/abs/2506.20966v1","updated":"2025-06-26T03:06:57Z","published":"2025-06-26T03:06:57Z","title":"Parallels Between VLA Model Post-Training and Human Motor Learning:\n  Progress, Challenges, and Trends","summary":"  Vision-language-action (VLA) models extend vision-language models (VLM) by\nintegrating action generation modules for robotic manipulation. Leveraging\nstrengths of VLM in vision perception and instruction understanding, VLA models\nexhibit promising generalization across diverse manipulation tasks. However,\napplications demanding high precision and accuracy reveal performance gaps\nwithout further adaptation. Evidence from multiple domains highlights the\ncritical role of post-training to align foundational models with downstream\napplications, spurring extensive research on post-training VLA models. VLA\nmodel post-training aims to address the challenge of improving an embodiment's\nability to interact with the environment for the given tasks, analogous to the\nprocess of humans motor skills acquisition. Accordingly, this paper reviews\npost-training strategies for VLA models through the lens of human motor\nlearning, focusing on three dimensions: environments, embodiments, and tasks. A\nstructured taxonomy is introduced aligned with human learning mechanisms: (1)\nenhancing environmental perception, (2) improving embodiment awareness, (3)\ndeepening task comprehension, and (4) multi-component integration. Finally, key\nchallenges and trends in post-training VLA models are identified, establishing\na conceptual framework to guide future research. This work delivers both a\ncomprehensive overview of current VLA model post-training methods from a human\nmotor learning perspective and practical insights for VLA model development.\n(Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)\n","authors":["Tian-Yu Xiang","Ao-Qun Jin","Xiao-Hu Zhou","Mei-Jiang Gui","Xiao-Liang Xie","Shi-Qi Liu","Shuang-Yi Wang","Sheng-Bin Duan","Fu-Chao Xie","Wen-Kai Wang","Si-Cheng Wang","Ling-Yun Li","Tian Tu","Zeng-Guang Hou"],"pdf_url":"https://arxiv.org/pdf/2506.20966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20964v1","updated":"2025-06-26T03:02:16Z","published":"2025-06-26T03:02:16Z","title":"Evidence-based diagnostic reasoning with multi-agent copilot for human\n  pathology","summary":"  Pathology is experiencing rapid digital transformation driven by whole-slide\nimaging and artificial intelligence (AI). While deep learning-based\ncomputational pathology has achieved notable success, traditional models\nprimarily focus on image analysis without integrating natural language\ninstruction or rich, text-based context. Current multimodal large language\nmodels (MLLMs) in computational pathology face limitations, including\ninsufficient training data, inadequate support and evaluation for multi-image\nunderstanding, and a lack of autonomous, diagnostic reasoning capabilities. To\naddress these limitations, we introduce PathChat+, a new MLLM specifically\ndesigned for human pathology, trained on over 1 million diverse,\npathology-specific instruction samples and nearly 5.5 million question answer\nturns. Extensive evaluations across diverse pathology benchmarks demonstrated\nthat PathChat+ substantially outperforms the prior PathChat copilot, as well as\nboth state-of-the-art (SOTA) general-purpose and other pathology-specific\nmodels. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI\nsystem leveraging PathChat+ to autonomously evaluate gigapixel whole-slide\nimages (WSIs) through iterative, hierarchical diagnostic reasoning, reaching\nhigh accuracy on DDxBench, a challenging open-ended differential diagnosis\nbenchmark, while also capable of generating visually grounded,\nhumanly-interpretable summary reports.\n","authors":["Chengkuan Chen","Luca L. Weishaupt","Drew F. K. Williamson","Richard J. Chen","Tong Ding","Bowen Chen","Anurag Vaidya","Long Phi Le","Guillaume Jaume","Ming Y. Lu","Faisal Mahmood"],"pdf_url":"https://arxiv.org/pdf/2506.20964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20960v1","updated":"2025-06-26T02:54:24Z","published":"2025-06-26T02:54:24Z","title":"OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual,\n  Auditory, and Textual Inputs","summary":"  In this paper, we introduce OmniEval, a benchmark for evaluating\nomni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory,\nand textual inputs. Compared with existing benchmarks, our OmniEval has several\ndistinctive features: (i) Full-modal collaboration: We design evaluation tasks\nthat highlight the strong coupling between audio and video, requiring models to\neffectively leverage the collaborative perception of all modalities; (ii)\nDiversity of videos: OmniEval includes 810 audio-visual synchronized videos,\n285 Chinese videos and 525 English videos; (iii) Diversity and granularity of\ntasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended\nquestions and 1205 multiple-choice questions. These questions are divided into\n3 major task types and 12 sub-task types to achieve comprehensive evaluation.\nAmong them, we introduce a more granular video localization task named\nGrounding. Then we conduct experiments on OmniEval with several omni-modality\nmodels. We hope that our OmniEval can provide a platform for evaluating the\nability to construct and understand coherence from the context of all\nmodalities. Codes and data could be found at https://omnieval.github.io/.\n","authors":["Yiman Zhang","Ziheng Luo","Qiangyu Yan","Wei He","Borui Jiang","Xinghao Chen","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2506.20960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20957v1","updated":"2025-06-26T02:45:38Z","published":"2025-06-26T02:45:38Z","title":"Antibody Design and Optimization with Multi-scale Equivariant Graph\n  Diffusion Models for Accurate Complex Antigen Binding","summary":"  Antibody design remains a critical challenge in therapeutic and diagnostic\ndevelopment, particularly for complex antigens with diverse binding interfaces.\nCurrent computational methods face two main limitations: (1) capturing\ngeometric features while preserving symmetries, and (2) generalizing novel\nantigen interfaces. Despite recent advancements, these methods often fail to\naccurately capture molecular interactions and maintain structural integrity. To\naddress these challenges, we propose \\textbf{AbMEGD}, an end-to-end framework\nintegrating \\textbf{M}ulti-scale \\textbf{E}quivariant \\textbf{G}raph\n\\textbf{D}iffusion for antibody sequence and structure co-design. Leveraging\nadvanced geometric deep learning, AbMEGD combines atomic-level geometric\nfeatures with residue-level embeddings, capturing local atomic details and\nglobal sequence-structure interactions. Its E(3)-equivariant diffusion method\nensures geometric precision, computational efficiency, and robust\ngeneralizability for complex antigens. Furthermore, experiments using the\nSAbDab database demonstrate a 10.13\\% increase in amino acid recovery, 3.32\\%\nrise in improvement percentage, and a 0.062~\\AA\\ reduction in root mean square\ndeviation within the critical CDR-H3 region compared to DiffAb, a leading\nantibody design model. These results highlight AbMEGD's ability to balance\nstructural integrity with improved functionality, establishing a new benchmark\nfor sequence-structure co-design and affinity optimization. The code is\navailable at: https://github.com/Patrick221215/AbMEGD.\n","authors":["Jiameng Chen","Xiantao Cai","Jia Wu","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2506.20957v1.pdf","comment":"9 pages, 4 figures, accepted at IJCAI 2025"},{"id":"http://arxiv.org/abs/2506.20949v1","updated":"2025-06-26T02:28:58Z","published":"2025-06-26T02:28:58Z","title":"Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon\n  Simulation","summary":"  Given the growing influence of language model-based agents on high-stakes\nsocietal decisions, from public policy to healthcare, ensuring their beneficial\nimpact requires understanding the far-reaching implications of their\nsuggestions. We propose a proof-of-concept framework that projects how\nmodel-generated advice could propagate through societal systems on a\nmacroscopic scale over time, enabling more robust alignment. To assess the\nlong-term safety awareness of language models, we also introduce a dataset of\n100 indirect harm scenarios, testing models' ability to foresee adverse,\nnon-obvious outcomes from seemingly harmless user prompts. Our approach\nachieves not only over 20% improvement on the new dataset but also an average\nwin rate exceeding 70% against strong baselines on existing safety benchmarks\n(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer\nagents.\n","authors":["Chenkai Sun","Denghui Zhang","ChengXiang Zhai","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2506.20949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20946v1","updated":"2025-06-26T02:25:16Z","published":"2025-06-26T02:25:16Z","title":"Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion\n  and Temporal Video Models","summary":"  Current texture synthesis methods, which generate textures from fixed\nviewpoints, suffer from inconsistencies due to the lack of global context and\ngeometric understanding. Meanwhile, recent advancements in video generation\nmodels have demonstrated remarkable success in achieving temporally consistent\nvideos. In this paper, we introduce VideoTex, a novel framework for seamless\ntexture synthesis that leverages video generation models to address both\nspatial and temporal inconsistencies in 3D textures. Our approach incorporates\ngeometry-aware conditions, enabling precise utilization of 3D mesh structures.\nAdditionally, we propose a structure-wise UV diffusion strategy, which enhances\nthe generation of occluded areas by preserving semantic information, resulting\nin smoother and more coherent textures. VideoTex not only achieves smoother\ntransitions across UV boundaries but also ensures high-quality, temporally\nstable textures across video frames. Extensive experiments demonstrate that\nVideoTex outperforms existing methods in texture fidelity, seam blending, and\nstability, paving the way for dynamic real-time applications that demand both\nvisual quality and temporal coherence.\n","authors":["Donggoo Kang","Jangyeong Kim","Dasol Jeong","Junyoung Choi","Jeonga Wi","Hyunmin Lee","Joonho Gwon","Joonki Paik"],"pdf_url":"https://arxiv.org/pdf/2506.20946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.17404v4","updated":"2025-06-26T01:54:05Z","published":"2025-04-24T09:53:49Z","title":"Super Co-alignment for Sustainable Symbiotic Society","summary":"  As Artificial Intelligence (AI) advances toward Artificial General\nIntelligence (AGI) and eventually Artificial Superintelligence (ASI), it may\npotentially surpass human control, deviate from human values, and even lead to\nirreversible catastrophic consequences in extreme cases. This looming risk\nunderscores the critical importance of the \"superalignment\" problem - ensuring\nthat AI systems which are much smarter than humans, remain aligned with human\n(compatible) intentions and values. While current scalable oversight and\nweak-to-strong generalization methods demonstrate certain applicability, they\nexhibit fundamental flaws in addressing the superalignment paradigm - notably,\nthe unidirectional imposition of human values cannot accommodate\nsuperintelligence's autonomy or ensure AGI/ASI's stable learning. We contend\nthat the values for sustainable symbiotic society should be co-shaped by humans\nand living AI together, achieving \"Super Co-alignment.\" Guided by this vision,\nwe propose a concrete framework that integrates external oversight and\nintrinsic proactive alignment. External oversight superalignment should be\ngrounded in human-centered ultimate decision, supplemented by interpretable\nautomated evaluation and correction, to achieve continuous alignment with\nhumanity's evolving values. Intrinsic proactive superalignment is rooted in a\nprofound understanding of the Self, others, and society, integrating\nself-awareness, self-reflection, and empathy to spontaneously infer human\nintentions, distinguishing good from evil and proactively prioritizing human\nwell-being. The integration of externally-driven oversight with\nintrinsically-driven proactive alignment will co-shape symbiotic values and\nrules through iterative human-AGI/ASI co-alignment, paving the way for\nachieving safe and beneficial AGI and ASI for good, for human, and for a\nsymbiotic ecology.\n","authors":["Yi Zeng","Feifei Zhao","Yuwei Wang","Enmeng Lu","Yaodong Yang","Lei Wang","Chao Liu","Yitao Liang","Dongcheng Zhao","Bing Han","Haibo Tong","Yao Liang","Dongqi Liang","Kang Sun","Boyuan Chen","Jinyu Fan"],"pdf_url":"https://arxiv.org/pdf/2504.17404v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09498v2","updated":"2025-06-26T01:52:43Z","published":"2025-06-11T08:17:40Z","title":"Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse\n  Planning","summary":"  Diffusion models have recently emerged as a powerful approach for trajectory\nplanning. However, their inherently non-sequential nature limits their\neffectiveness in long-horizon reasoning tasks at test time. The recently\nproposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by\ncombining diffusion with tree-based search, achieving state-of-the-art\nperformance on complex planning problems. Despite its strengths, our analysis\nshows that MCTD incurs substantial computational overhead due to the sequential\nnature of tree search and the cost of iterative denoising. To address this, we\npropose Fast-MCTD, a more efficient variant that preserves the strengths of\nMCTD while significantly improving its speed and scalability. Fast-MCTD\nintegrates two techniques: Parallel MCTD, which enables parallel rollouts via\ndelayed tree updates and redundancy-aware selection; and Sparse MCTD, which\nreduces rollout length through trajectory coarsening. Experiments show that\nFast-MCTD achieves up to 100x speedup over standard MCTD while maintaining or\nimproving planning performance. Remarkably, it even outperforms Diffuser in\ninference speed on some tasks, despite Diffuser requiring no search and\nyielding weaker solutions. These results position Fast-MCTD as a practical and\nscalable solution for diffusion-based inference-time reasoning.\n","authors":["Jaesik Yoon","Hyeonseo Cho","Yoshua Bengio","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2506.09498v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.08483v7","updated":"2025-06-26T01:33:13Z","published":"2021-10-16T06:06:36Z","title":"Extremely Simple Streaming Forest","summary":"  Decision forests, including random forests and gradient boosting trees,\nremain the leading machine learning methods for many real-world data problems,\nespecially on tabular data. However, most of the current implementations only\noperate in batch mode, and therefore cannot incrementally update when more data\narrive. Several previous works developed streaming trees and ensembles to\novercome this limitation. Nonetheless, we found that those state-of-the-art\nalgorithms suffer from a number of drawbacks, including low accuracy on some\nproblems and high memory usage on others. We therefore developed an extremely\nsimple extension of decision trees: given new data, simply update existing\ntrees by continuing to grow them, and replace some old trees with new ones to\ncontrol the total number of trees. In a benchmark suite containing 72\nclassification problems (the OpenML-CC18 data suite), we illustrate that our\napproach, $\\textit{Extremely Simple Streaming Forest}$ (XForest), does not\nsuffer from either of the aforementioned limitations. On those datasets, we\nalso demonstrate that our approach often performs as well as, and sometimes\neven better than, conventional batch decision forest algorithms. With a\n$\\textit{zero-added-node}$ approach, XForest-Zero, we also further extend\nexisting splits to new tasks, and this very efficient method only requires\ninference time. Thus, XForests establish a simple standard for streaming trees\nand forests that could readily be applied to many real-world problems.\n","authors":["Haoyin Xu","Jayanta Dey","Sambit Panda","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2110.08483v7.pdf","comment":"Accepted at The Fourth Conference on Lifelong Learning Agents -\n  CoLLAs 2025"},{"id":"http://arxiv.org/abs/2503.23956v2","updated":"2025-06-26T01:30:43Z","published":"2025-03-31T11:13:18Z","title":"AirCache: Activating Inter-modal Relevancy KV Cache Compression for\n  Efficient Large Vision-Language Model Inference","summary":"  Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.\n","authors":["Kai Huang","Hao Zou","Bochen Wang","Ye Xi","Zhen Xie","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.23956v2.pdf","comment":"We have withdrawn this manuscript due to a critical error in the\n  methodology which affects the validity of the main results. We are currently\n  working to address this issue and will resubmit once the correction is\n  complete"},{"id":"http://arxiv.org/abs/2506.20927v1","updated":"2025-06-26T01:24:08Z","published":"2025-06-26T01:24:08Z","title":"Interpretable Representation Learning for Additive Rule Ensembles","summary":"  Small additive ensembles of symbolic rules offer interpretable prediction\nmodels. Traditionally, these ensembles use rule conditions based on\nconjunctions of simple threshold propositions $x \\geq t$ on a single input\nvariable $x$ and threshold $t$, resulting geometrically in axis-parallel\npolytopes as decision regions. While this form ensures a high degree of\ninterpretability for individual rules and can be learned efficiently using the\ngradient boosting approach, it relies on having access to a curated set of\nexpressive and ideally independent input features so that a small ensemble of\naxis-parallel regions can describe the target variable well. Absent such\nfeatures, reaching sufficient accuracy requires increasing the number and\ncomplexity of individual rules, which diminishes the interpretability of the\nmodel. Here, we extend classical rule ensembles by introducing logical\npropositions with learnable sparse linear transformations of input variables,\ni.e., propositions of the form $\\mathbf{x}^\\mathrm{T}\\mathbf{w} \\geq t$, where\n$\\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as\ngeneral polytopes with oblique faces. We propose a learning method using\nsequential greedy optimization based on an iteratively reweighted formulation\nof logistic regression. Experimental results demonstrate that the proposed\nmethod efficiently constructs rule ensembles with the same test risk as\nstate-of-the-art methods while significantly reducing model complexity across\nten benchmark datasets.\n","authors":["Shahrzad Behzadimanesh","Pierre Le Bodic","Geoffrey I. Webb","Mario Boley"],"pdf_url":"https://arxiv.org/pdf/2506.20927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17589v2","updated":"2025-06-26T01:13:31Z","published":"2025-06-21T05:01:02Z","title":"Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for\n  MLLMs to Conquer the Unknown","summary":"  The real value of knowledge lies not just in its accumulation, but in its\npotential to be harnessed effectively to conquer the unknown. Although recent\nmultimodal large language models (MLLMs) exhibit impressing multimodal\ncapabilities, they often fail in rarely encountered domain-specific tasks due\nto limited relevant knowledge. To explore this, we adopt visual game cognition\nas a testbed and select Monster Hunter: World as the target to construct a\nmultimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and\nintricate entity relations. We also design a series of challenging queries\nbased on MH-MMKG to evaluate the models' ability for complex knowledge\nretrieval and reasoning. Furthermore, we propose a multi-agent retriever that\nenables a model to autonomously search relevant knowledge without additional\ntraining. Experimental results show that our approach significantly enhances\nthe performance of MLLMs, providing a new perspective on multimodal\nknowledge-augmented reasoning and laying a solid foundation for future\nresearch.\n","authors":["Bowen Wang","Zhouqiang Jiang","Yasuaki Susumu","Shotaro Miwa","Tianwei Chen","Yuta Nakashima"],"pdf_url":"https://arxiv.org/pdf/2506.17589v2.pdf","comment":"Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2503.04065v3","updated":"2025-06-26T01:11:25Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13547v2","updated":"2025-06-26T01:05:54Z","published":"2024-11-20T18:56:22Z","title":"ToolScan: A Benchmark for Characterizing Errors in Tool-Use LLMs","summary":"  Evaluating Large Language Models (LLMs) is one of the most critical aspects\nof building a performant compound AI system. Since the output from LLMs\npropagate to downstream steps, identifying LLM errors is crucial to system\nperformance. A common task for LLMs in AI systems is tool use. While there are\nseveral benchmark environments for evaluating LLMs on this task, they typically\nonly give a success rate without any explanation of the failure cases. To solve\nthis problem, we introduce TOOLSCAN, a new benchmark to identify error patterns\nin LLM output on tool-use tasks. Our benchmark data set comprises of queries\nfrom diverse environments that can be used to test for the presence of seven\nnewly characterized error patterns. Using TOOLSCAN, we show that even the most\nprominent LLMs exhibit these error patterns in their outputs. Researchers can\nuse these insights from TOOLSCAN to guide their error mitigation strategies.\n","authors":["Shirley Kokane","Ming Zhu","Tulika Awalgaonkar","Jianguo Zhang","Thai Hoang","Akshara Prabhakar","Zuxin Liu","Tian Lan","Liangwei Yang","Juntao Tan","Rithesh Murthy","Weiran Yao","Zhiwei Liu","Juan Carlos Niebles","Huan Wang","Shelby Heinecke","Caiming Xiong","Silivo Savarese"],"pdf_url":"https://arxiv.org/pdf/2411.13547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20921v1","updated":"2025-06-26T01:03:44Z","published":"2025-06-26T01:03:44Z","title":"LLM-guided Chemical Process Optimization with a Multi-Agent Approach","summary":"  Chemical process optimization is crucial to maximize production efficiency\nand economic performance. Traditional methods, including gradient-based\nsolvers, evolutionary algorithms, and parameter grid searches, become\nimpractical when operating constraints are ill-defined or unavailable,\nrequiring engineers to rely on subjective heuristics to estimate feasible\nparameter ranges. To address this constraint definition bottleneck, we present\na multi-agent framework of large language model (LLM) agents that autonomously\ninfer operating constraints from minimal process descriptions, then\ncollaboratively guide optimization using the inferred constraints. Our\nAutoGen-based agentic framework employs OpenAI's o3 model, with specialized\nagents for constraint generation, parameter validation, simulation execution,\nand optimization guidance. Through two phases - autonomous constraint\ngeneration using embedded domain knowledge, followed by iterative multi-agent\noptimization - the framework eliminates the need for predefined operational\nbounds. Validated on the hydrodealkylation process across cost, yield, and\nyield-to-cost ratio metrics, the framework demonstrated competitive performance\nwith conventional optimization methods while achieving better computational\nefficiency, requiring fewer iterations to converge. Our approach converged in\nunder 20 minutes, achieving a 31-fold speedup over grid search. Beyond\ncomputational efficiency, the framework's reasoning-guided search demonstrates\nsophisticated process understanding, correctly identifying utility trade-offs,\nand applying domain-informed heuristics. This approach shows significant\npotential for optimization scenarios where operational constraints are poorly\ncharacterized or unavailable, particularly for emerging processes and retrofit\napplications.\n","authors":["Tong Zeng","Srivathsan Badrinarayanan","Janghoon Ock","Cheng-Kai Lai","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2506.20921v1.pdf","comment":"16 pages (main manuscript without references), 2 figures"},{"id":"http://arxiv.org/abs/2506.02280v3","updated":"2025-06-26T01:01:18Z","published":"2025-06-02T21:39:40Z","title":"The State of Large Language Models for African Languages: Progress and\n  Challenges","summary":"  Large Language Models (LLMs) are transforming Natural Language Processing\n(NLP), but their benefits are largely absent for Africa's 2,000 low-resource\nlanguages. This paper comparatively analyzes African language coverage across\nsix LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs).\nThe evaluation covers language coverage, training sets, technical limitations,\nscript problems, and language modelling roadmaps. The work identifies 42\nsupported African languages and 23 available public data sets, and it shows a\nbig gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are\nalways treated while there is over 98\\% of unsupported African languages.\nMoreover, the review shows that just Latin, Arabic, and Ge'ez scripts are\nidentified while 20 active scripts are neglected. Some of the primary\nchallenges are lack of data, tokenization biases, computational costs being\nvery high, and evaluation issues. These issues demand language standardization,\ncorpus development by the community, and effective adaptation methods for\nAfrican languages.\n","authors":["Kedir Yassin Hussen","Walelign Tewabe Sewunetie","Abinew Ali Ayele","Sukairaj Hafiz Imam","Shamsuddeen Hassan Muhammad","Seid Muhie Yimam"],"pdf_url":"https://arxiv.org/pdf/2506.02280v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18309v3","updated":"2025-06-26T00:54:18Z","published":"2024-11-27T12:58:23Z","title":"MvKeTR: Chest CT Report Generation with Multi-View Perception and\n  Knowledge Enhancement","summary":"  CT report generation (CTRG) aims to automatically generate diagnostic reports\nfor 3D volumes, relieving clinicians' workload and improving patient care.\nDespite clinical value, existing works fail to effectively incorporate\ndiagnostic information from multiple anatomical views and lack related clinical\nexpertise essential for accurate and reliable diagnosis. To resolve these\nlimitations, we propose a novel Multi-view perception Knowledge-enhanced\nTansfoRmer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as\nradiologists first examine CT scans from multiple planes, a Multi-View\nPerception Aggregator (MVPA) with view-aware attention is proposed to\nsynthesize diagnostic information from multiple anatomical views effectively.\nThen, inspired by how radiologists further refer to relevant clinical records\nto guide diagnostic decision-making, a Cross-Modal Knowledge Enhancer (CMKE) is\ndevised to retrieve the most similar reports based on the query volume to\nincorporate domain knowledge into the diagnosis procedure. Furthermore, instead\nof traditional MLPs, we employ Kolmogorov-Arnold Networks (KANs) as the\nfundamental building blocks of both modules, which exhibit superior parameter\nefficiency and reduced spectral bias to better capture high-frequency\ncomponents critical for CT interpretation while mitigating overfitting.\nExtensive experiments on the public CTRG-Chest-548 K dataset demonstrate that\nour method outpaces prior state-of-the-art (SOTA) models across almost all\nmetrics. The code is available at https://github.com/xiweideng/MvKeTR.\n","authors":["Xiwei Deng","Xianchun He","Jianfeng Bao","Yudan Zhou","Shuhui Cai","Congbo Cai","Zhong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.18309v3.pdf","comment":"Accepted for publication in IEEE Journal of Biomedical and Health\n  Informatics"},{"id":"http://arxiv.org/abs/2506.20917v1","updated":"2025-06-26T00:49:35Z","published":"2025-06-26T00:49:35Z","title":"Optimising Language Models for Downstream Tasks: A Post-Training\n  Perspective","summary":"  Language models (LMs) have demonstrated remarkable capabilities in NLP, yet\nadapting them efficiently and robustly to specific tasks remains challenging.\nAs their scale and complexity grow, fine-tuning LMs on labelled data often\nunderutilizes available unlabelled data, leads to overfitting on small\ntask-specific sets, and imposes significant computational costs. These\nlimitations hamper their application to the open-ended landscape of real-world\nlanguage tasks.\n  This thesis proposes a series of methods to better adapt LMs to downstream\napplications. First, we explore strategies for extracting task-relevant\nknowledge from unlabelled data, introducing a novel continued pre-training\ntechnique that outperforms state-of-the-art semi-supervised approaches. Next,\nwe present a parameter-efficient fine-tuning method that substantially reduces\nmemory and compute costs while maintaining competitive performance. We also\nintroduce improved supervised fine-tuning methods that enable LMs to better\nfollow instructions, especially when labelled data is scarce, enhancing their\nperformance across a range of NLP tasks, including open-ended generation.\nFinally, we develop new evaluation methods and benchmarks, such as multi-hop\nspatial reasoning tasks, to assess LM capabilities and adaptation more\ncomprehensively.\n  Through extensive empirical studies across diverse NLP tasks, our results\ndemonstrate that these approaches substantially improve LM robustness,\nefficiency, and generalization, making them more adaptable to a broad range of\napplications. These advances mark a significant step towards more robust and\nefficient LMs, bringing us closer to the goal of artificial general\nintelligence.\n","authors":["Zhengyan Shi"],"pdf_url":"https://arxiv.org/pdf/2506.20917v1.pdf","comment":"PhD Thesis"},{"id":"http://arxiv.org/abs/2506.20915v1","updated":"2025-06-26T00:49:02Z","published":"2025-06-26T00:49:02Z","title":"ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large\n  Language Models","summary":"  As the deployment of large language models (LLMs) grows in sensitive domains,\nensuring the integrity of their computational provenance becomes a critical\nchallenge, particularly in regulated sectors such as healthcare, where strict\nrequirements are applied in dataset usage. We introduce ZKPROV, a novel\ncryptographic framework that enables zero-knowledge proofs of LLM provenance.\nIt allows users to verify that a model is trained on a reliable dataset without\nrevealing sensitive information about it or its parameters. Unlike prior\napproaches that focus on complete verification of the training process\n(incurring significant computational cost) or depend on trusted execution\nenvironments, ZKPROV offers a distinct balance. Our method cryptographically\nbinds a trained model to its authorized training dataset(s) through\nzero-knowledge proofs while avoiding proof of every training step. By\nleveraging dataset-signed metadata and compact model parameter commitments,\nZKPROV provides sound and privacy-preserving assurances that the result of the\nLLM is derived from a model trained on the claimed authorized and relevant\ndataset. Experimental results demonstrate the efficiency and scalability of the\nZKPROV in generating this proof and verifying it, achieving a practical\nsolution for real-world deployments. We also provide formal security\nguarantees, proving that our approach preserves dataset confidentiality while\nensuring trustworthy dataset provenance.\n","authors":["Mina Namazi","Alexander Nemecek","Erman Ayday"],"pdf_url":"https://arxiv.org/pdf/2506.20915v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.09838v3","updated":"2025-06-26T00:46:53Z","published":"2024-06-14T08:46:44Z","title":"ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language\n  Models in Meteorology Anomalies Analysis","summary":"  Meteorological heatmaps play a vital role in deciphering extreme weather\nphenomena, yet their inherent complexities marked by irregular contours,\nunstructured patterns, and complex color variations present unique analytical\nhurdles for state-of-the-art Vision-Language Models (VLMs). Current\nstate-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks\nsuch as precise color identification and spatial localization, resulting in\ninaccurate or incomplete interpretations. To address these challenges, we\nintroduce Sparse Position and Outline Tracking (SPOT), a novel algorithm\nspecifically designed to process irregularly shaped colored regions in visual\ndata. SPOT identifies and localizes these regions by extracting their spatial\ncoordinates, enabling structured representations of irregular shapes. Building\non SPOT, we construct ClimateIQA, a novel meteorological visual question\nanswering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120\ninstruction samples for wind gust, total precipitation, wind chill index and\nheat index analysis. ClimateIQA enhances VLM training by incorporating spatial\ncues, geographic metadata, and reanalysis data, improving model accuracy in\ninterpreting and describing extreme weather features. Furthermore, we develop\nClimate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA,\nwhich significantly outperforms existing models in meteorological heatmap\ntasks.\n","authors":["Jian Chen","Peilin Zhou","Yining Hua","Dading Chong","Meng Cao","Yaowei Li","Wei Chen","Bing Zhu","Junwei Liang","Zixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2406.09838v3.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2506.21552v1","updated":"2025-06-26T17:59:59Z","published":"2025-06-26T17:59:59Z","title":"Whole-Body Conditioned Egocentric Video Prediction","summary":"  We train models to Predict Ego-centric Video from human Actions (PEVA), given\nthe past video and an action represented by the relative 3D body pose. By\nconditioning on kinematic pose trajectories, structured by the joint hierarchy\nof the body, our model learns to simulate how physical human actions shape the\nenvironment from a first-person point of view. We train an auto-regressive\nconditional diffusion transformer on Nymeria, a large-scale dataset of\nreal-world egocentric video and body pose capture. We further design a\nhierarchical evaluation protocol with increasingly challenging tasks, enabling\na comprehensive analysis of the model's embodied prediction and control\nabilities. Our work represents an initial attempt to tackle the challenges of\nmodeling complex real-world environments and embodied agent behaviors with\nvideo prediction from the perspective of a human.\n","authors":["Yutong Bai","Danny Tran","Amir Bar","Yann LeCun","Trevor Darrell","Jitendra Malik"],"pdf_url":"https://arxiv.org/pdf/2506.21552v1.pdf","comment":"Project Page: https://dannytran123.github.io/PEVA"},{"id":"http://arxiv.org/abs/2506.21550v1","updated":"2025-06-26T17:59:58Z","published":"2025-06-26T17:59:58Z","title":"mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and\n  Model Selection at Scale","summary":"  Multivariate time series anomaly detection (MTS-AD) is critical in domains\nlike healthcare, cybersecurity, and industrial monitoring, yet remains\nchallenging due to complex inter-variable dependencies, temporal dynamics, and\nsparse anomaly labels. We introduce mTSBench, the largest benchmark to date for\nMTS-AD and unsupervised model selection, spanning 344 labeled time series\nacross 19 datasets and 12 diverse application domains. mTSBench evaluates 24\nanomaly detection methods, including large language model (LLM)-based detectors\nfor multivariate time series, and systematically benchmarks unsupervised model\nselection techniques under standardized conditions. Consistent with prior\nfindings, our results confirm that no single detector excels across datasets,\nunderscoring the importance of model selection. However, even state-of-the-art\nselection methods remain far from optimal, revealing critical gaps. mTSBench\nprovides a unified evaluation suite to enable rigorous, reproducible\ncomparisons and catalyze future advances in adaptive anomaly detection and\nrobust model selection.\n","authors":["Xiaona Zhou","Constantin Brif","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2506.21550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21551v1","updated":"2025-06-26T17:59:58Z","published":"2025-06-26T17:59:58Z","title":"Where to find Grokking in LLM Pretraining? Monitor\n  Memorization-to-Generalization without Test","summary":"  Grokking, i.e., test performance keeps improving long after training loss\nconverged, has been recently witnessed in neural network training, making the\nmechanism of generalization and other emerging capabilities such as reasoning\nmysterious. While prior studies usually train small models on a few toy or\nhighly-specific tasks for thousands of epochs, we conduct the first study of\ngrokking on checkpoints during one-pass pretraining of a 7B large language\nmodel (LLM), i.e., OLMoE. We compute the training loss and evaluate\ngeneralization on diverse benchmark tasks, including math reasoning, code\ngeneration, and commonsense/domain-specific knowledge retrieval tasks.\n  Our study, for the first time, verifies that grokking still happens in the\npretraining of large-scale foundation models, though different data may enter\ngrokking stages asynchronously. We further demystify grokking's \"emergence of\ngeneralization\" by investigating LLM internal dynamics. Specifically, we find\nthat training samples' pathways (i.e., expert choices across layers) evolve\nfrom random, instance-specific to more structured and shareable between samples\nduring grokking. Also, the complexity of a sample's pathway reduces despite the\nconverged loss. These indicate a memorization-to-generalization conversion,\nproviding a mechanistic explanation of delayed generalization. In the study, we\ndevelop two novel metrics to quantify pathway distance and the complexity of a\nsingle pathway. We show their ability to predict the generalization improvement\non diverse downstream tasks. They are efficient, simple to compute and solely\ndependent on training data. Hence, they have practical value for pretraining,\nenabling us to monitor the generalization performance without finetuning and\ntest. Theoretically, we show that more structured pathways reduce model\ncomplexity and improve the generalization bound.\n","authors":["Ziyue Li","Chenrui Fan","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.21551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21546v1","updated":"2025-06-26T17:59:12Z","published":"2025-06-26T17:59:12Z","title":"HalluSegBench: Counterfactual Visual Reasoning for Segmentation\n  Hallucination Evaluation","summary":"  Recent progress in vision-language segmentation has significantly advanced\ngrounded visual understanding. However, these models often exhibit\nhallucinations by producing segmentation masks for objects not grounded in the\nimage content or by incorrectly labeling irrelevant regions. Existing\nevaluation protocols for segmentation hallucination primarily focus on label or\ntextual hallucinations without manipulating the visual context, limiting their\ncapacity to diagnose critical failures. In response, we introduce\nHalluSegBench, the first benchmark specifically designed to evaluate\nhallucinations in visual grounding through the lens of counterfactual visual\nreasoning. Our benchmark consists of a novel dataset of 1340 counterfactual\ninstance pairs spanning 281 unique object classes, and a set of newly\nintroduced metrics that quantify hallucination sensitivity under visually\ncoherent scene edits. Experiments on HalluSegBench with state-of-the-art\nvision-language segmentation models reveal that vision-driven hallucinations\nare significantly more prevalent than label-driven ones, with models often\npersisting in false segmentation, highlighting the need for counterfactual\nreasoning to diagnose grounding fidelity.\n","authors":["Xinzhuo Li","Adheesh Juvekar","Xingyou Liu","Muntasir Wahed","Kiet A. Nguyen","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2506.21546v1.pdf","comment":"Project webpage: https://plan-lab.github.io/hallusegbench/"},{"id":"http://arxiv.org/abs/2506.21538v1","updated":"2025-06-26T17:55:34Z","published":"2025-06-26T17:55:34Z","title":"Maximal Matching Matters: Preventing Representation Collapse for Robust\n  Cross-Modal Retrieval","summary":"  Cross-modal image-text retrieval is challenging because of the diverse\npossible associations between content from different modalities. Traditional\nmethods learn a single-vector embedding to represent semantics of each sample,\nbut struggle to capture nuanced and diverse relationships that can exist across\nmodalities. Set-based approaches, which represent each sample with multiple\nembeddings, offer a promising alternative, as they can capture richer and more\ndiverse relationships. In this paper, we show that, despite their promise,\nthese set-based representations continue to face issues including sparse\nsupervision and set collapse, which limits their effectiveness. To address\nthese challenges, we propose Maximal Pair Assignment Similarity to optimize\none-to-one matching between embedding sets which preserve semantic diversity\nwithin the set. We also introduce two loss functions to further enhance the\nrepresentations: Global Discriminative Loss to enhance distinction among\nembeddings, and Intra-Set Divergence Loss to prevent collapse within each set.\nOur method achieves state-of-the-art performance on MS-COCO and Flickr30k\nwithout relying on external data.\n","authors":["Hani Alomari","Anushka Sivakumar","Andrew Zhang","Chris Thomas"],"pdf_url":"https://arxiv.org/pdf/2506.21538v1.pdf","comment":"Accepted at the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025 Main)"},{"id":"http://arxiv.org/abs/2506.21535v1","updated":"2025-06-26T17:54:20Z","published":"2025-06-26T17:54:20Z","title":"Exploring the Design Space of 3D MLLMs for CT Report Generation","summary":"  Multimodal Large Language Models (MLLMs) have emerged as a promising way to\nautomate Radiology Report Generation (RRG). In this work, we systematically\ninvestigate the design space of 3D MLLMs, including visual input\nrepresentation, projectors, Large Language Models (LLMs), and fine-tuning\ntechniques for 3D CT report generation. We also introduce two knowledge-based\nreport augmentation methods that improve performance on the GREEN score by up\nto 10\\%, achieving the 2nd place on the MICCAI 2024 AMOS-MM challenge. Our\nresults on the 1,687 cases from the AMOS-MM dataset show that RRG is largely\nindependent of the size of LLM under the same training protocol. We also show\nthat larger volume size does not always improve performance if the original ViT\nwas pre-trained on a smaller volume size. Lastly, we show that using a\nsegmentation mask along with the CT volume improves performance. The code is\npublicly available at https://github.com/bowang-lab/AMOS-MM-Solution\n","authors":["Mohammed Baharoon","Jun Ma","Congyu Fang","Augustin Toma","Bo Wang"],"pdf_url":"https://arxiv.org/pdf/2506.21535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08165v2","updated":"2025-06-26T17:48:33Z","published":"2024-10-10T17:44:13Z","title":"Chain-of-Sketch: Enabling Global Visual Reasoning","summary":"  Modern vision models have achieved remarkable success in benchmarks where\nlocal features provide critical information about the target. There is now a\ngrowing interest in tackling tasks requiring more global reasoning, where local\nfeatures do not provide significant information. Minsky and Papert put forward\nsuch tasks in 1969 with their connectivity study, exposing the limitations of\nthe perceptron model. In this paper, we introduce an expanded set of global\nvisual datasets involving graphs, strings, mazes, and image grids. We show that\nlarge vision models still struggle to learn these tasks efficiently. Similarly,\nstate-of-the-art multi-modal LLMs perform poorly on these datasets. We explain\nthis learning inefficiency by means of the 'globality degree' measure. To\nmitigate this, we propose a method called chain-of-sketch (CoS). Similar to the\nchain-of-thought and scratchpad techniques used in language models, CoS breaks\nthe original task into intermediate visual steps to help learn a complex task.\nIn addition, we show that not all CoS strategies perform equally well. Our key\ninsight is to impose a Markovian structure on the CoS frames. This leads to the\nintroduction of 'inductive CoS' which achieves better out-of-distribution\ngeneralization and performs well even with smaller models compared to\nnon-inductive variants.\n","authors":["Aryo Lotfi","Enrico Fini","Samy Bengio","Moin Nabi","Emmanuel Abbe"],"pdf_url":"https://arxiv.org/pdf/2410.08165v2.pdf","comment":"additional experiments added, title changed from \"Visual Scratchpads:\n  Enabling Global Reasoning in Vision\" to \"Chain-of-Sketch: Enabling Global\n  Visual Reasoning\""},{"id":"http://arxiv.org/abs/2506.16656v2","updated":"2025-06-26T17:45:03Z","published":"2025-06-20T00:00:22Z","title":"Mesh-Informed Neural Operator : A Transformer Generative Approach","summary":"  Generative models in function spaces, situated at the intersection of\ngenerative modeling and operator learning, are attracting increasing attention\ndue to their immense potential in diverse scientific and engineering\napplications. While functional generative models are theoretically domain- and\ndiscretization-agnostic, current implementations heavily rely on the Fourier\nNeural Operator (FNO), limiting their applicability to regular grids and\nrectangular domains. To overcome these critical limitations, we introduce the\nMesh-Informed Neural Operator (MINO). By leveraging graph neural operators and\ncross-attention mechanisms, MINO offers a principled, domain- and\ndiscretization-agnostic backbone for generative modeling in function spaces.\nThis advancement significantly expands the scope of such models to more diverse\napplications in generative, inverse, and regression tasks. Furthermore, MINO\nprovides a unified perspective on integrating neural operators with general\nadvanced deep learning architectures. Finally, we introduce a suite of\nstandardized evaluation metrics that enable objective comparison of functional\ngenerative models, addressing another critical gap in the field.\n","authors":["Yaozhong Shi","Zachary E. Ross","Domniki Asimaki","Kamyar Azizzadenesheli"],"pdf_url":"https://arxiv.org/pdf/2506.16656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04712v2","updated":"2025-06-26T17:38:58Z","published":"2025-03-06T18:57:34Z","title":"Efficiently Escaping Saddle Points under Generalized Smoothness via\n  Self-Bounding Regularity","summary":"  We study the optimization of non-convex functions that are not necessarily\nsmooth (gradient and/or Hessian are Lipschitz) using first order methods.\nSmoothness is a restrictive assumption in machine learning in both theory and\npractice, motivating significant recent work on finding first order stationary\npoints of functions satisfying generalizations of smoothness with first order\nmethods. We develop a novel framework that lets us systematically study the\nconvergence of a large class of first-order optimization algorithms (which we\ncall decrease procedures) under generalizations of smoothness. We instantiate\nour framework to analyze the convergence of first order optimization algorithms\nto first and \\textit{second} order stationary points under generalizations of\nsmoothness. As a consequence, we establish the first convergence guarantees for\nfirst order methods to second order stationary points under generalizations of\nsmoothness. We demonstrate that several canonical examples fall under our\nframework, and highlight practical implications.\n","authors":["Daniel Yiming Cao","August Y. Chen","Karthik Sridharan","Benjamin Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21511v1","updated":"2025-06-26T17:36:10Z","published":"2025-06-26T17:36:10Z","title":"Gaussian Invariant Markov Chain Monte Carlo","summary":"  We develop sampling methods, which consist of Gaussian invariant versions of\nrandom walk Metropolis (RWM), Metropolis adjusted Langevin algorithm (MALA) and\nsecond order Hessian or Manifold MALA. Unlike standard RWM and MALA we show\nthat Gaussian invariant sampling can lead to ergodic estimators with improved\nstatistical efficiency. This is due to a remarkable property of Gaussian\ninvariance that allows us to obtain exact analytical solutions to the Poisson\nequation for Gaussian targets. These solutions can be used to construct\nefficient and easy to use control variates for variance reduction of estimators\nunder any intractable target. We demonstrate the new samplers and estimators in\nseveral examples, including high dimensional targets in latent Gaussian models\nwhere we compare against several advanced methods and obtain state-of-the-art\nresults. We also provide theoretical results regarding geometric ergodicity,\nand an optimal scaling analysis that shows the dependence of the optimal\nacceptance rate on the Gaussianity of the target.\n","authors":["Michalis K. Titsias","Angelos Alexopoulos","Siran Liu","Petros Dellaportas"],"pdf_url":"https://arxiv.org/pdf/2506.21511v1.pdf","comment":"29, 2 figures"},{"id":"http://arxiv.org/abs/2506.21508v1","updated":"2025-06-26T17:35:04Z","published":"2025-06-26T17:35:04Z","title":"skLEP: A Slovak General Language Understanding Benchmark","summary":"  In this work, we introduce skLEP, the first comprehensive benchmark\nspecifically designed for evaluating Slovak natural language understanding\n(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span\ntoken-level, sentence-pair, and document-level challenges, thereby offering a\nthorough assessment of model capabilities. To create this benchmark, we curated\nnew, original datasets tailored for Slovak and meticulously translated\nestablished English NLU resources. Within this paper, we also present the first\nsystematic and extensive evaluation of a wide array of Slovak-specific,\nmultilingual, and English pre-trained language models using the skLEP tasks.\nFinally, we also release the complete benchmark data, an open-source toolkit\nfacilitating both fine-tuning and evaluation of models, and a public\nleaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering\nreproducibility and drive future research in Slovak NLU.\n","authors":["Marek Šuppa","Andrej Ridzik","Daniel Hládek","Tomáš Javůrek","Viktória Ondrejová","Kristína Sásiková","Martin Tamajka","Marián Šimko"],"pdf_url":"https://arxiv.org/pdf/2506.21508v1.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2505.16946v3","updated":"2025-06-26T17:32:06Z","published":"2025-05-22T17:32:28Z","title":"NY Real Estate Racial Equity Analysis via Applied Machine Learning","summary":"  This study analyzes tract-level real estate ownership patterns in New York\nState (NYS) and New York City (NYC) to uncover racial disparities. We use an\nadvanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,\nvalidated at 89.2% accuracy) to compare the predicted racial composition of\nproperty owners to the resident population from census data. We examine both a\nFull Model (statewide) and a Name-Only LSTM Model (NYC) to assess how\nincorporating geospatial context affects our predictions and disparity\nestimates. The results reveal significant inequities: White individuals hold a\ndisproportionate share of properties and property value relative to their\npopulation, while Black, Hispanic, and Asian communities are underrepresented\nas property owners. These disparities are most pronounced in minority-majority\nneighborhoods, where ownership is predominantly White despite a predominantly\nnon-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates\nthese gaps by reducing owner-occupied opportunities in urban minority\ncommunities. We provide a breakdown of ownership vs. population by race for\nmajority-White, -Black, -Hispanic, and -Asian tracts, identify those with\nextreme ownership disparities, and compare patterns in urban, suburban, and\nrural contexts. The findings underscore persistent racial inequity in property\nownership, reflecting broader historical and socio-economic forces, and\nhighlight the importance of data-driven approaches to address these issues.\n","authors":["Sanjana Chalavadi","Andrei Pastor","Terry Leitch"],"pdf_url":"https://arxiv.org/pdf/2505.16946v3.pdf","comment":"updated/replaced stale reference links. Added narrative covering\n  gentrification, racial capitalism, financialization of housing, and\n  segregation. Moved model details to appendices. Added Nivea"},{"id":"http://arxiv.org/abs/2506.21502v1","updated":"2025-06-26T17:29:37Z","published":"2025-06-26T17:29:37Z","title":"Process mining-driven modeling and simulation to enhance fault diagnosis\n  in cyber-physical systems","summary":"  Fault diagnosis in Cyber-Physical Systems (CPSs) is essential for ensuring\nsystem dependability and operational efficiency by accurately detecting\nanomalies and identifying their root causes. However, the manual modeling of\nfaulty behaviors often demands extensive domain expertise and produces models\nthat are complex, error-prone, and difficult to interpret. To address this\nchallenge, we present a novel unsupervised fault diagnosis methodology that\nintegrates collective anomaly detection in multivariate time series, process\nmining, and stochastic simulation. Initially, collective anomalies are detected\nfrom low-level sensor data using multivariate time-series analysis. These\nanomalies are then transformed into structured event logs, enabling the\ndiscovery of interpretable process models through process mining. By\nincorporating timing distributions into the extracted Petri nets, the approach\nsupports stochastic simulation of faulty behaviors, thereby enhancing root\ncause analysis and behavioral understanding. The methodology is validated using\nthe Robotic Arm Dataset (RoAD), a widely recognized benchmark in smart\nmanufacturing. Experimental results demonstrate its effectiveness in modeling,\nsimulating, and classifying faulty behaviors in CPSs. This enables the creation\nof comprehensive fault dictionaries that support predictive maintenance and the\ndevelopment of digital twins for industrial environments.\n","authors":["Francesco Vitale","Nicola Dall'Ora","Sebastiano Gaiardelli","Enrico Fraccaroli","Nicola Mazzocca","Franco Fummi"],"pdf_url":"https://arxiv.org/pdf/2506.21502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21500v1","updated":"2025-06-26T17:29:00Z","published":"2025-06-26T17:29:00Z","title":"Devising a solution to the problems of Cancer awareness in Telangana","summary":"  According to the data, the percent of women who underwent screening for\ncervical cancer, breast and oral cancer in Telangana in the year 2020 was 3.3\npercent, 0.3 percent and 2.3 percent respectively. Although early detection is\nthe only way to reduce morbidity and mortality, people have very low awareness\nabout cervical and breast cancer signs and symptoms and screening practices. We\ndeveloped an ML classification model to predict if a person is susceptible to\nbreast or cervical cancer based on demographic factors. We devised a system to\nprovide suggestions for the nearest hospital or Cancer treatment centres based\non the users location or address. In addition to this, we can integrate the\nhealth card to maintain medical records of all individuals and conduct\nawareness drives and campaigns. For ML classification models, we used decision\ntree classification and support vector classification algorithms for cervical\ncancer susceptibility and breast cancer susceptibility respectively. Thus, by\ndevising this solution we come one step closer to our goal which is spreading\ncancer awareness, thereby, decreasing the cancer mortality and increasing\ncancer literacy among the people of Telangana.\n","authors":["Priyanka Avhad","Vedanti Kshirsagar","Urvi Ranjan","Mahek Nakhua"],"pdf_url":"https://arxiv.org/pdf/2506.21500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19780v2","updated":"2025-06-26T17:28:25Z","published":"2025-06-24T16:47:17Z","title":"Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference\n  Alignment","summary":"  While large-scale unsupervised language models (LMs) capture broad world\nknowledge and reasoning capabilities, steering their behavior toward desired\nobjectives remains challenging due to the lack of explicit supervision.\nExisting alignment techniques, such as reinforcement learning from human\nfeedback (RLHF), rely on training a reward model and performing reinforcement\nlearning to align with human preferences. However, RLHF is often\ncomputationally intensive, unstable, and sensitive to hyperparameters.\n  To address these limitations, Direct Preference Optimization (DPO) was\nintroduced as a lightweight and stable alternative, enabling direct alignment\nof language models with pairwise preference data via classification loss.\nHowever, DPO and its extensions generally assume a single static preference\ndistribution, limiting flexibility in multi-objective or dynamic alignment\nsettings.\n  In this paper, we propose a novel framework: Multi-Preference Lambda-weighted\nListwise DPO, which extends DPO to incorporate multiple human preference\ndimensions (e.g., helpfulness, harmlessness, informativeness) and enables\ndynamic interpolation through a controllable simplex-weighted formulation. Our\nmethod supports both listwise preference feedback and flexible alignment across\nvarying user intents without re-training. Empirical and theoretical analysis\ndemonstrates that our method is as effective as traditional DPO on static\nobjectives while offering greater generality and adaptability for real-world\ndeployment.\n","authors":["Yuhui Sun","Xiyao Wang","Zixi Li","Jinman Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.19780v2.pdf","comment":"10 pages, 4 figures, appendix included. To appear in Proceedings of\n  AAAI 2026. Code:\n  https://github.com/yuhui15/Multi-Preference-Lambda-weighted-DPO"},{"id":"http://arxiv.org/abs/2501.15499v2","updated":"2025-06-26T17:28:09Z","published":"2025-01-26T12:14:09Z","title":"One Model to Forecast Them All and in Entity Distributions Bind Them","summary":"  Probabilistic forecasting in power systems often involves multi-entity\ndatasets like households, feeders, and wind turbines, where generating reliable\nentity-specific forecasts presents significant challenges. Traditional\napproaches require training individual models for each entity, making them\ninefficient and hard to scale. This study addresses this problem using\nGUIDE-VAE, a conditional variational autoencoder that allows entity-specific\nprobabilistic forecasting using a single model. GUIDE-VAE provides flexible\noutputs, ranging from interpretable point estimates to full probability\ndistributions, thanks to its advanced covariance composition structure. These\ndistributions capture uncertainty and temporal dependencies, offering richer\ninsights than traditional methods. To evaluate our GUIDE-VAE-based forecaster,\nwe use household electricity consumption data as a case study due to its\nmulti-entity and highly stochastic nature. Experimental results demonstrate\nthat GUIDE-VAE outperforms conventional quantile regression techniques across\nkey metrics while ensuring scalability and versatility. These features make\nGUIDE-VAE a powerful and generalizable tool for probabilistic forecasting\ntasks, with potential applications beyond household electricity consumption.\n","authors":["Kutay Bölat","Simon Tindemans"],"pdf_url":"https://arxiv.org/pdf/2501.15499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02398v3","updated":"2025-06-26T17:22:53Z","published":"2024-11-04T18:59:51Z","title":"Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin\n  Script Languages","summary":"  Although multilingual LLMs have achieved remarkable performance across\nbenchmarks, we find they continue to underperform on non-Latin script languages\nacross contemporary LLM families. This discrepancy arises from the fact that\nLLMs are pretrained with orthographic scripts, which are dominated by Latin\ncharacters that obscure their shared phonology with non-Latin scripts. We\npropose leveraging phonemic transcriptions as complementary signals to induce\nscript-invariant representations. Our study demonstrates that integrating\nphonemic signals improves performance across both non-Latin and Latin script\nlanguages, with a particularly significant impact on closing the performance\ngap between the two. Through detailed experiments, we show that phonemic and\northographic scripts retrieve distinct examples for in-context learning (ICL).\nThis motivates our proposed Mixed-ICL retrieval strategy, where further\naggregation from both leads to our significant performance improvements for\nboth Latin script languages (up to 12.6%) and non-Latin script languages (up to\n15.1%) compared to randomized ICL retrieval.\n","authors":["Hoang H Nguyen","Khyati Mahajan","Vikas Yadav","Julian Salazar","Philip S. Yu","Masoud Hashemi","Rishabh Maheshwary"],"pdf_url":"https://arxiv.org/pdf/2411.02398v3.pdf","comment":"Accepted to NAACL 2025 (Main Conference). This version contains minor\n  improvements to the camera-ready"},{"id":"http://arxiv.org/abs/2506.18959v2","updated":"2025-06-26T17:18:00Z","published":"2025-06-23T17:27:19Z","title":"From Web Search towards Agentic Deep Research: Incentivizing Search with\n  Reasoning Agents","summary":"  Information retrieval is a cornerstone of modern knowledge acquisition,\nenabling billions of queries each day across diverse domains. However,\ntraditional keyword-based search engines are increasingly inadequate for\nhandling complex, multi-step information needs. Our position is that Large\nLanguage Models (LLMs), endowed with reasoning and agentic capabilities, are\nushering in a new paradigm termed Agentic Deep Research. These systems\ntranscend conventional information search techniques by tightly integrating\nautonomous reasoning, iterative retrieval, and information synthesis into a\ndynamic feedback loop. We trace the evolution from static web search to\ninteractive, agent-based systems that plan, explore, and learn. We also\nintroduce a test-time scaling law to formalize the impact of computational\ndepth on reasoning and search. Supported by benchmark results and the rise of\nopen-source implementations, we demonstrate that Agentic Deep Research not only\nsignificantly outperforms existing approaches, but is also poised to become the\ndominant paradigm for future information seeking. All the related resources,\nincluding industry products, research papers, benchmark datasets, and\nopen-source implementations, are collected for the community in\nhttps://github.com/DavidZWZ/Awesome-Deep-Research.\n","authors":["Weizhi Zhang","Yangning Li","Yuanchen Bei","Junyu Luo","Guancheng Wan","Liangwei Yang","Chenxuan Xie","Yuyao Yang","Wei-Chieh Huang","Chunyu Miao","Henry Peng Zou","Xiao Luo","Yusheng Zhao","Yankai Chen","Chunkit Chan","Peilin Zhou","Xinyang Zhang","Chenwei Zhang","Jingbo Shang","Ming Zhang","Yangqiu Song","Irwin King","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2506.18959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21486v1","updated":"2025-06-26T17:14:37Z","published":"2025-06-26T17:14:37Z","title":"Towards Reliable Detection of Empty Space: Conditional Marked Point\n  Processes for Object Detection","summary":"  Deep neural networks have set the state-of-the-art in computer vision tasks\nsuch as bounding box detection and semantic segmentation. Object detectors and\nsegmentation models assign confidence scores to predictions, reflecting the\nmodel's uncertainty in object detection or pixel-wise classification. However,\nthese confidence estimates are often miscalibrated, as their architectures and\nloss functions are tailored to task performance rather than probabilistic\nfoundation. Even with well calibrated predictions, object detectors fail to\nquantify uncertainty outside detected bounding boxes, i.e., the model does not\nmake a probability assessment of whether an area without detected objects is\ntruly free of obstacles. This poses a safety risk in applications such as\nautomated driving, where uncertainty in empty areas remains unexplored. In this\nwork, we propose an object detection model grounded in spatial statistics.\nBounding box data matches realizations of a marked point process, commonly used\nto describe the probabilistic occurrence of spatial point events identified as\nbounding box centers, where marks are used to describe the spatial extension of\nbounding boxes and classes. Our statistical framework enables a\nlikelihood-based training and provides well-defined confidence estimates for\nwhether a region is drivable, i.e., free of objects. We demonstrate the\neffectiveness of our method through calibration assessments and evaluation of\nperformance.\n","authors":["Tobias J. Riedlinger","Kira Maag","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2506.21486v1.pdf","comment":"15 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2506.21469v1","updated":"2025-06-26T16:56:59Z","published":"2025-06-26T16:56:59Z","title":"Evaluation of Traffic Signals for Daily Traffic Pattern","summary":"  The turning movement count data is crucial for traffic signal design,\nintersection geometry planning, traffic flow, and congestion analysis. This\nwork proposes three methods called dynamic, static, and hybrid configuration\nfor TMC-based traffic signals. A vision-based tracking system is developed to\nestimate the TMC of six intersections in Las Vegas using traffic cameras. The\nintersection design, route (e.g. vehicle movement directions), and signal\nconfiguration files with compatible formats are synthesized and imported into\nSimulation of Urban MObility for signal evaluation with realistic data. The\ninitial experimental results based on estimated waiting times indicate that the\ncycle time of 90 and 120 seconds works best for all intersections. In addition,\nfour intersections show better performance for dynamic signal timing\nconfiguration, and the other two with lower performance have a lower ratio of\ntotal vehicle count to total lanes of the intersection leg. Since daily traffic\nflow often exhibits a bimodal pattern, we propose a hybrid signal method that\nswitches between dynamic and static methods, adapting to peak and off-peak\ntraffic conditions for improved flow management. So, a built-in traffic\ngenerator module creates vehicle routes for 4 hours, including peak hours, and\na signal design module produces signal schedule cycles according to static,\ndynamic, and hybrid methods. Vehicle count distributions are weighted\ndifferently for each zone (i.e., West, North, East, South) to generate diverse\ntraffic patterns. The extended experimental results for 6 intersections with 4\nhours of simulation time imply that zone-based traffic pattern distributions\naffect signal design selection. Although the static method works great for\nevenly zone-based traffic distribution, the hybrid method works well for highly\nweighted traffic at intersection pairs of the West-East and North-South zones.\n","authors":["Mohammad Shokrolah Shirazi","Hung-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2506.21469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17859v2","updated":"2025-06-26T16:54:57Z","published":"2025-06-21T23:49:08Z","title":"In-Context Learning Strategies Emerge Rationally","summary":"  Recent work analyzing in-context learning (ICL) has identified a broad set of\nstrategies that describe model behavior in different experimental conditions.\nWe aim to unify these findings by asking why a model learns these disparate\nstrategies in the first place. Specifically, we start with the observation that\nwhen trained to learn a mixture of tasks, as is popular in the literature, the\nstrategies learned by a model for performing ICL can be captured by a family of\nBayesian predictors: a memorizing predictor, which assumes a discrete prior on\nthe set of seen tasks, and a generalizing predictor, where the prior matches\nthe underlying task distribution. Adopting the normative lens of rational\nanalysis, where a learner's behavior is explained as an optimal adaptation to\ndata given computational constraints, we develop a hierarchical Bayesian\nframework that almost perfectly predicts Transformer next-token predictions\nthroughout training -- without assuming access to its weights. Under this\nframework, pretraining is viewed as a process of updating the posterior\nprobability of different strategies, and inference-time behavior as a\nposterior-weighted average over these strategies' predictions. Our framework\ndraws on common assumptions about neural network learning dynamics, which make\nexplicit a tradeoff between loss and complexity among candidate strategies:\nbeyond how well it explains the data, a model's preference towards implementing\na strategy is dictated by its complexity. This helps explain well-known ICL\nphenomena, while offering novel predictions: e.g., we show a superlinear trend\nin the timescale for transitioning from generalization to memorization as task\ndiversity increases. Overall, our work advances an explanatory and predictive\naccount of ICL grounded in tradeoffs between strategy loss and complexity.\n","authors":["Daniel Wurgaft","Ekdeep Singh Lubana","Core Francisco Park","Hidenori Tanaka","Gautam Reddy","Noah D. Goodman"],"pdf_url":"https://arxiv.org/pdf/2506.17859v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.21465v1","updated":"2025-06-26T16:51:22Z","published":"2025-06-26T16:51:22Z","title":"Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach\n  for Efficiency and Low Storage","summary":"  Extended Stability Runge-Kutta (ESRK) methods are crucial for solving\nlarge-scale computational problems in science and engineering, including\nweather forecasting, aerodynamic analysis, and complex biological modelling.\nHowever, balancing accuracy, stability, and computational efficiency remains\nchallenging, particularly for high-order, low-storage schemes. This study\nintroduces a hybrid Genetic Algorithm (GA) and Reinforcement Learning (RL)\napproach for automated heuristic discovery, optimising low-storage ESRK\nmethods. Unlike traditional approaches that rely on manually designed\nheuristics or exhaustive numerical searches, our method leverages GA-driven\nmutations for search-space exploration and an RL-inspired state transition\nmechanism to refine heuristic selection dynamically. This enables systematic\nparameter reduction, preserving fourth-order accuracy while significantly\nimproving computational efficiency.The proposed GA-RL heuristic optimisation\nframework is validated through rigorous testing on benchmark problems,\nincluding the 1D and 2D Brusselator systems and the steady-state Navier-Stokes\nequations. The best-performing heuristic achieves a 25\\% reduction in IPOPT\nruntime compared to traditional ESRK optimisation processes while maintaining\nnumerical stability and accuracy. These findings demonstrate the potential of\nadaptive heuristic discovery to improve resource efficiency in high-fidelity\nsimulations and broaden the applicability of low-storage Runge-Kutta methods in\nreal-world computational fluid dynamics, physics simulations, and other\ndemanding fields. This work establishes a new paradigm in heuristic\noptimisation for numerical methods, opening pathways for further exploration\nusing Deep RL and AutoML-based heuristic search\n","authors":["Gavin Lee Goodship","Luis Miralles-Pechuan","Stephen O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2506.21465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.19856v2","updated":"2025-06-26T16:47:52Z","published":"2025-03-25T17:20:39Z","title":"Capacity-Constrained Online Learning with Delays: Scheduling Frameworks\n  and Regret Trade-offs","summary":"  We study online learning with oblivious losses and delays under a novel\n``capacity constraint'' that limits how many past rounds can be tracked\nsimultaneously for delayed feedback. Under ``clairvoyance'' (i.e., delay\ndurations are revealed upfront each round) and/or ``preemptibility'' (i.e., we\ncan stop tracking previously chosen round feedback), we establish matching\nupper and lower bounds (up to logarithmic terms) on achievable regret,\ncharacterizing the ``optimal capacity'' needed to match the minimax rates of\nclassical delayed online learning, which implicitly assume unlimited capacity.\nOur algorithms achieve minimax-optimal regret across all capacity levels, with\nperformance gracefully degrading under suboptimal capacity. For $K$ actions and\ntotal delay $D$ over $T$ rounds, under clairvoyance and assuming capacity $C =\n\\Omega(\\log(T))$, we achieve regret $\\widetilde{\\Theta}(\\sqrt{TK + DK/C +\nD\\log(K)})$ for bandits and $\\widetilde{\\Theta}(\\sqrt{(D+T)\\log(K)})$ for\nfull-information feedback. When replacing clairvoyance with preemptibility, we\nrequire a known maximum delay bound $d_{\\max}$, adding\n${\\widetilde{O}(d_{\\max})}$ to the regret. For fixed delays $d$ (i.e., $D=Td$),\nthe minimax regret is $\\Theta(\\sqrt{TK(1+d/C)+Td\\log(K)})$ and the optimal\ncapacity is $\\Theta(\\min\\{K/\\log(K),d\\})$ in the bandit setting, while in the\nfull-information feedback setting, the minimax regret is\n$\\Theta(\\sqrt{T(d+1)\\log(K)})$ and the optimal capacity is $\\Theta(1)$. For\nround-dependent and fixed delays, our upper bounds are achieved using novel\npreemptive and non-preemptive scheduling policies, based on Pareto-distributed\nproxy delays, and batching techniques, respectively. Crucially, our work\nunifies delayed bandits, label-efficient learning, and online scheduling\nframeworks, demonstrating that robust online learning under delayed feedback is\npossible with surprisingly modest tracking capacity.\n","authors":["Alexander Ryabchenko","Idan Attias","Daniel M. Roy"],"pdf_url":"https://arxiv.org/pdf/2503.19856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21463v1","updated":"2025-06-26T16:45:20Z","published":"2025-06-26T16:45:20Z","title":"Aligning Spoken Dialogue Models from User Interactions","summary":"  We propose a novel preference alignment framework for improving spoken\ndialogue models on real-time conversations from user interactions. Current\npreference learning methods primarily focus on text-based language models, and\nare not directly suited to the complexities of real-time speech interactions,\nwith richer dynamics (e.g. interruption, interjection) and no explicit\nsegmentation between speaker turns.We create a large-scale dataset of more than\n150,000 preference pairs from raw multi-turn speech conversations, annotated\nwith AI feedback, to cover preferences over both linguistic content and\ntemporal context variations. We leverage offline alignment methods to finetune\na full-duplex autoregressive speech-to-speech model. Extensive experiments\ndemonstrate that feedback on generic conversations can be consistently\neffective in improving spoken dialogue models to produce more factual, safer\nand more contextually aligned interactions. We deploy the finetuned model and\nconduct holistic human evaluations to assess the impact beyond single-turn\nconversations. Our findings shed light on the importance of a well-calibrated\nbalance among various dynamics, crucial for natural real-time speech dialogue\nsystems.\n","authors":["Anne Wu","Laurent Mazaré","Neil Zeghidour","Alexandre Défossez"],"pdf_url":"https://arxiv.org/pdf/2506.21463v1.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2506.21461v1","updated":"2025-06-26T16:42:49Z","published":"2025-06-26T16:42:49Z","title":"A Keyword-Based Technique to Evaluate Broad Question Answer Script","summary":"  Evaluation is the method of assessing and determining the educational system\nthrough various techniques such as verbal or viva-voice test, subjective or\nobjective written test. This paper presents an efficient solution to evaluate\nthe subjective answer script electronically. In this paper, we proposed and\nimplemented an integrated system that examines and evaluates the written answer\nscript. This article focuses on finding the keywords from the answer script and\nthen compares them with the keywords that have been parsed from both open and\nclosed domain. The system also checks the grammatical and spelling errors in\nthe answer script. Our proposed system tested with answer scripts of 100\nstudents and gives precision score 0.91.\n","authors":["Tamim Al Mahmud","Md Gulzar Hussain","Sumaiya Kabir","Hasnain Ahmad","Mahmudus Sobhan"],"pdf_url":"https://arxiv.org/pdf/2506.21461v1.pdf","comment":"ACM Conference Proceedings (9 Pages)"},{"id":"http://arxiv.org/abs/2506.21460v1","updated":"2025-06-26T16:41:55Z","published":"2025-06-26T16:41:55Z","title":"Wild refitting for black box prediction","summary":"  We describe and analyze a computionally efficient refitting procedure for\ncomputing high-probability upper bounds on the instance-wise mean-squared\nprediction error of penalized nonparametric estimates based on least-squares\nminimization. Requiring only a single dataset and black box access to the\nprediction method, it consists of three steps: computing suitable residuals,\nsymmetrizing and scaling them with a pre-factor $\\rho$, and using them to\ndefine and solve a modified prediction problem recentered at the current\nestimate. We refer to it as wild refitting, since it uses Rademacher residual\nsymmetrization as in a wild bootstrap variant. Under relatively mild conditions\nallowing for noise heterogeneity, we establish a high probability guarantee on\nits performance, showing that the wild refit with a suitably chosen wild noise\nscale $\\rho$ gives an upper bound on prediction error. This theoretical\nanalysis provides guidance into the design of such procedures, including how\nthe residuals should be formed, the amount of noise rescaling in the wild\nsub-problem needed for upper bounds, and the local stability properties of the\nblock-box procedure. We illustrate the applicability of this procedure to\nvarious problems, including non-rigid structure-from-motion recovery with\nstructured matrix penalties; plug-and-play image restoration with deep neural\nnetwork priors; and randomized sketching with kernel methods.\n","authors":["Martin J. Wainwright"],"pdf_url":"https://arxiv.org/pdf/2506.21460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13846v2","updated":"2025-06-26T16:39:32Z","published":"2025-06-16T17:59:40Z","title":"Fake it till You Make it: Reward Modeling as Discriminative Prediction","summary":"  An effective reward model plays a pivotal role in reinforcement learning for\npost-training enhancement of visual generative models. However, current\napproaches of reward modeling suffer from implementation complexity due to\ntheir reliance on extensive human-annotated preference data or meticulously\nengineered quality dimensions that are often incomplete and\nengineering-intensive. Inspired by adversarial training in generative\nadversarial networks (GANs), this paper proposes GAN-RM, an efficient reward\nmodeling framework that eliminates manual preference annotation and explicit\nquality dimension engineering. Our method trains the reward model through\ndiscrimination between a small set of representative, unpaired target\nsamples(denoted as Preference Proxy Data) and model-generated ordinary outputs,\nrequiring only a few hundred target samples. Comprehensive experiments\ndemonstrate our GAN-RM's effectiveness across multiple key applications\nincluding test-time scaling implemented as Best-of-N sample filtering,\npost-training approaches like Supervised Fine-Tuning (SFT) and Direct\nPreference Optimization (DPO). Code and data will be released at\nhttps://github.com/Visualignment/GAN-RM.\n","authors":["Runtao Liu","Jiahao Zhan","Yingqing He","Chen Wei","Alan Yuille","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2506.13846v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.10573v4","updated":"2025-06-26T16:38:11Z","published":"2025-05-13T20:36:22Z","title":"Measurement to Meaning: A Validity-Centered Framework for AI Evaluation","summary":"  While the capabilities and utility of AI systems have advanced, rigorous\nnorms for evaluating these systems have lagged. Grand claims, such as models\nachieving general reasoning capabilities, are supported with model performance\non narrow benchmarks, like performance on graduate-level exam questions, which\nprovide a limited and potentially misleading assessment. We provide a\nstructured approach for reasoning about the types of evaluative claims that can\nbe made given the available evidence. For instance, our framework helps\ndetermine whether performance on a mathematical benchmark is an indication of\nthe ability to solve problems on math tests or instead indicates a broader\nability to reason. Our framework is well-suited for the contemporary paradigm\nin machine learning, where various stakeholders provide measurements and\nevaluations that downstream users use to validate their claims and decisions.\nAt the same time, our framework also informs the construction of evaluations\ndesigned to speak to the validity of the relevant claims. By leveraging\npsychometrics' breakdown of validity, evaluations can prioritize the most\ncritical facets for a given claim, improving empirical utility and\ndecision-making efficacy. We illustrate our framework through detailed case\nstudies of vision and language model evaluations, highlighting how explicitly\nconsidering validity strengthens the connection between evaluation evidence and\nthe claims being made.\n","authors":["Olawale Salaudeen","Anka Reuel","Ahmed Ahmed","Suhana Bedi","Zachary Robertson","Sudharsan Sundar","Ben Domingue","Angelina Wang","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2505.10573v4.pdf","comment":"Correspondence to olawale@mit.edu"},{"id":"http://arxiv.org/abs/2506.18728v2","updated":"2025-06-26T16:35:54Z","published":"2025-06-23T15:05:54Z","title":"PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries","summary":"  LLM serving systems typically treat user prompts as monolithic inputs,\noptimizing inference through decoding tricks or inter-query batching. However,\nmany real-world prompts contain latent semantic parallelism--decomposable\nstructures where subtasks can be executed independently to reduce latency while\npreserving meaning. We introduce PARALLELPROMPT, the first benchmark for\nmeasuring intra-query parallelism in natural user prompts. Our dataset\ncomprises over 37,000 real-world prompts from public LLM chat logs, each\nannotated with a structured schema capturing task templates, shared context,\nand iteration inputs. These schemas are extracted using LLM-assisted prompting\nwith rule-based multilingual validation. To evaluate the benefits of\ndecomposition, we provide an execution suite that benchmarks serial vs.\nparallel strategies, measuring latency, structural adherence, and semantic\nfidelity. Our results show that intra-query parallelism can be successfully\nparsed in over 75% of curated datasets, unlocking up to 5x speedups on tasks\nlike translation, comprehension, and comparative analysis, with minimal quality\ndegradation. By releasing this benchmark, curation pipeline, and evaluation\nsuite, we provide the first standardized testbed for studying structure-aware\nexecution in LLM serving pipelines.\n","authors":["Steven Kolawole","Keshav Santhanam","Virginia Smith","Pratiksha Thaker"],"pdf_url":"https://arxiv.org/pdf/2506.18728v2.pdf","comment":"In Adaptive Foundation Models: Evolving AI for Personalized and\n  Efficient Learning"},{"id":"http://arxiv.org/abs/2506.21453v1","updated":"2025-06-26T16:34:47Z","published":"2025-06-26T16:34:47Z","title":"Towards an Optimal Control Perspective of ResNet Training","summary":"  We propose a training formulation for ResNets reflecting an optimal control\nproblem that is applicable for standard architectures and general loss\nfunctions. We suggest bridging both worlds via penalizing intermediate outputs\nof hidden states corresponding to stage cost terms in optimal control. For\nstandard ResNets, we obtain intermediate outputs by propagating the state\nthrough the subsequent skip connections and the output layer. We demonstrate\nthat our training dynamic biases the weights of the unnecessary deeper residual\nlayers to vanish. This indicates the potential for a theory-grounded layer\npruning strategy.\n","authors":["Jens Püttschneider","Simon Heilig","Asja Fischer","Timm Faulwasser"],"pdf_url":"https://arxiv.org/pdf/2506.21453v1.pdf","comment":"Accepted for presentation at the High-dimensional Learning Dynamics\n  (HiLD) workshop at ICML 2025"},{"id":"http://arxiv.org/abs/2506.21451v1","updated":"2025-06-26T16:33:49Z","published":"2025-06-26T16:33:49Z","title":"A Comprehensive Dataset for Underground Miner Detection in Diverse\n  Scenario","summary":"  Underground mining operations face significant safety challenges that make\nemergency response capabilities crucial. While robots have shown promise in\nassisting with search and rescue operations, their effectiveness depends on\nreliable miner detection capabilities. Deep learning algorithms offer potential\nsolutions for automated miner detection, but require comprehensive training\ndatasets, which are currently lacking for underground mining environments. This\npaper presents a novel thermal imaging dataset specifically designed to enable\nthe development and validation of miner detection systems for potential\nemergency applications. We systematically captured thermal imagery of various\nmining activities and scenarios to create a robust foundation for detection\nalgorithms. To establish baseline performance metrics, we evaluated several\nstate-of-the-art object detection algorithms including YOLOv8, YOLOv10, YOLO11,\nand RT-DETR on our dataset. While not exhaustive of all possible emergency\nsituations, this dataset serves as a crucial first step toward developing\nreliable thermal-based miner detection systems that could eventually be\ndeployed in real emergency scenarios. This work demonstrates the feasibility of\nusing thermal imaging for miner detection and establishes a foundation for\nfuture research in this critical safety application.\n","authors":["Cyrus Addy","Ajay Kumar Gurumadaiah","Yixiang Gao","Kwame Awuah-Offei"],"pdf_url":"https://arxiv.org/pdf/2506.21451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21440v1","updated":"2025-06-26T16:24:27Z","published":"2025-06-26T16:24:27Z","title":"Learnable Adaptive Time-Frequency Representation via Differentiable\n  Short-Time Fourier Transform","summary":"  The short-time Fourier transform (STFT) is widely used for analyzing\nnon-stationary signals. However, its performance is highly sensitive to its\nparameters, and manual or heuristic tuning often yields suboptimal results. To\novercome this limitation, we propose a unified differentiable formulation of\nthe STFT that enables gradient-based optimization of its parameters. This\napproach addresses the limitations of traditional STFT parameter tuning\nmethods, which often rely on computationally intensive discrete searches. It\nenables fine-tuning of the time-frequency representation (TFR) based on any\ndesired criterion. Moreover, our approach integrates seamlessly with neural\nnetworks, allowing joint optimization of the STFT parameters and network\nweights. The efficacy of the proposed differentiable STFT in enhancing TFRs and\nimproving performance in downstream tasks is demonstrated through experiments\non both simulated and real-world data.\n","authors":["Maxime Leiber","Yosra Marnissi","Axel Barrau","Sylvain Meignen","Laurent Massoulié"],"pdf_url":"https://arxiv.org/pdf/2506.21440v1.pdf","comment":"DSTFT, STFT, spectrogram, time-frequency, IEEE Transactions on Signal\n  Processing, 10 pages"},{"id":"http://arxiv.org/abs/2502.08730v2","updated":"2025-06-26T16:24:25Z","published":"2025-02-12T19:04:26Z","title":"New Bounds for Sparse Variational Gaussian Processes","summary":"  Sparse variational Gaussian processes (GPs) construct tractable posterior\napproximations to GP models. At the core of these methods is the assumption\nthat the true posterior distribution over training function values ${\\bf f}$\nand inducing variables ${\\bf u}$ is approximated by a variational distribution\nthat incorporates the conditional GP prior $p({\\bf f} | {\\bf u})$ in its\nfactorization. While this assumption is considered as fundamental, we show that\nfor model training we can relax it through the use of a more general\nvariational distribution $q({\\bf f} | {\\bf u})$ that depends on $N$ extra\nparameters, where $N$ is the number of training examples. In GP regression, we\ncan analytically optimize the evidence lower bound over the extra parameters\nand express a tractable collapsed bound that is tighter than the previous\nbound. The new bound is also amenable to stochastic optimization and its\nimplementation requires minor modifications to existing sparse GP code.\nFurther, we also describe extensions to non-Gaussian likelihoods. On several\ndatasets we demonstrate that our method can reduce bias when learning the\nhyperparameters and can lead to better predictive performance.\n","authors":["Michalis K. Titsias"],"pdf_url":"https://arxiv.org/pdf/2502.08730v2.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2505.21657v3","updated":"2025-06-26T16:16:59Z","published":"2025-05-27T18:32:38Z","title":"Explainability of Large Language Models using SMILE: Statistical\n  Model-agnostic Interpretability with Local Explanations","summary":"  Large language models like GPT, LLAMA, and Claude have become incredibly\npowerful at generating text, but they are still black boxes, so it is hard to\nunderstand how they decide what to say. That lack of transparency can be\nproblematic, especially in fields where trust and accountability matter. To\nhelp with this, we introduce SMILE, a new method that explains how these models\nrespond to different parts of a prompt. SMILE is model-agnostic and works by\nslightly changing the input, measuring how the output changes, and then\nhighlighting which words had the most impact. Create simple visual heat maps\nshowing which parts of a prompt matter the most. We tested SMILE on several\nleading LLMs and used metrics such as accuracy, consistency, stability, and\nfidelity to show that it gives clear and reliable explanations. By making these\nmodels easier to understand, SMILE brings us one step closer to making AI more\ntransparent and trustworthy.\n","authors":["Zeinab Dehghani","Mohammed Naveed Akram","Koorosh Aslansefat","Adil Khan"],"pdf_url":"https://arxiv.org/pdf/2505.21657v3.pdf","comment":"The submission contains incorrect references that require substantial\n  revision"},{"id":"http://arxiv.org/abs/2403.11872v2","updated":"2025-06-26T16:15:31Z","published":"2024-03-18T15:26:05Z","title":"Graph Neural Network for Neutrino Physics Event Reconstruction","summary":"  Liquid Argon Time Projection Chamber (LArTPC) detector technology offers a\nwealth of high-resolution information on particle interactions, and leveraging\nthat information to its full potential requires sophisticated automated\nreconstruction techniques. This article describes NuGraph2, a Graph Neural\nNetwork (GNN) for low-level reconstruction of simulated neutrino interactions\nin a LArTPC detector. Simulated neutrino interactions in the MicroBooNE\ndetector geometry are described as heterogeneous graphs, with energy\ndepositions on each detector plane forming nodes on planar subgraphs. The\nnetwork utilizes a multi-head attention message-passing mechanism to perform\nbackground filtering and semantic labelling on these graph nodes, identifying\nthose associated with the primary physics interaction with 98.0\\% efficiency\nand labelling them according to particle type with 94.9\\% efficiency. The\nnetwork operates directly on detector observables across multiple 2D\nrepresentations, but utilizes a 3D-context-aware mechanism to encourage\nconsistency between these representations. Model inference takes 0.12~s/event\non a CPU, and 0.005s/event batched on a GPU. This architecture is designed to\nbe a general-purpose solution for particle reconstruction in neutrino physics,\nwith the potential for deployment across a broad range of detector\ntechnologies, and offers a core convolution engine that can be leveraged for a\nvariety of tasks beyond the two described in this article.\n","authors":["V Hewes","Adam Aurisano","Giuseppe Cerati","Jim Kowalkowski","Claire Lee","Wei-keng Liao","Daniel Grzenda","Kaushal Gumpula","Xiaohe Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.11872v2.pdf","comment":"18 pages, 14 figures, published in Physical Review D"},{"id":"http://arxiv.org/abs/2410.23440v3","updated":"2025-06-26T16:15:09Z","published":"2024-10-30T20:32:30Z","title":"The Sample Complexity of Learning Lipschitz Operators with respect to\n  Gaussian Measures","summary":"  Operator learning, the approximation of mappings between infinite-dimensional\nfunction spaces using machine learning, has gained increasing research\nattention in recent years. Approximate operators, learned from data, can serve\nas efficient surrogate models for problems in computational science and\nengineering, complementing traditional methods. However, despite their\nempirical success, our understanding of the underlying mathematical theory is\nin large part still incomplete. In this paper, we study the approximation of\nLipschitz operators with respect to Gaussian measures. We prove higher Gaussian\nSobolev regularity of Lipschitz operators and establish lower and upper bounds\non the Hermite polynomial approximation error. We then study general\nreconstruction strategies of Lipschitz operators from $m$ arbitrary\n(potentially adaptive) linear samples. As a key finding, we tightly\ncharacterize the corresponding sample complexity, that is, the smallest\nachievable worst-case error among all possible choices of (adaptive) sampling\nand reconstruction strategies in terms of $m$. As a consequence, we identify an\ninherent curse of sample complexity: No method to approximate Lipschitz\noperators based on $m$ linear samples can achieve algebraic convergence rates\nin $m$. On the positive side, we prove that a sufficiently fast spectral decay\nof the covariance operator of the underlying Gaussian measure guarantees\nconvergence rates which are arbitrarily close to any algebraic rate. Overall,\nby tightly characterizing the sample complexity, our work confirms the\nintrinsic difficulty of learning Lipschitz operators, regardless of the data or\nlearning technique.\n","authors":["Ben Adcock","Michael Griebel","Gregor Maier"],"pdf_url":"https://arxiv.org/pdf/2410.23440v3.pdf","comment":"Section 6 about pointwise sampling in v2 of this paper has been cut\n  and will appear elsewhere"},{"id":"http://arxiv.org/abs/2506.21429v1","updated":"2025-06-26T16:11:42Z","published":"2025-06-26T16:11:42Z","title":"Deception Detection in Dyadic Exchanges Using Multimodal Machine\n  Learning: A Study on a Swedish Cohort","summary":"  This study investigates the efficacy of using multimodal machine learning\ntechniques to detect deception in dyadic interactions, focusing on the\nintegration of data from both the deceiver and the deceived. We compare early\nand late fusion approaches, utilizing audio and video data - specifically,\nAction Units and gaze information - across all possible combinations of\nmodalities and participants. Our dataset, newly collected from Swedish native\nspeakers engaged in truth or lie scenarios on emotionally relevant topics,\nserves as the basis for our analysis. The results demonstrate that\nincorporating both speech and facial information yields superior performance\ncompared to single-modality approaches. Moreover, including data from both\nparticipants significantly enhances deception detection accuracy, with the best\nperformance (71%) achieved using a late fusion strategy applied to both\nmodalities and participants. These findings align with psychological theories\nsuggesting differential control of facial and vocal expressions during initial\ninteractions. As the first study of its kind on a Scandinavian cohort, this\nresearch lays the groundwork for future investigations into dyadic\ninteractions, particularly within psychotherapy settings.\n","authors":["Franco Rugolon","Thomas Jack Samuels","Stephan Hau","Lennart Högman"],"pdf_url":"https://arxiv.org/pdf/2506.21429v1.pdf","comment":"40 pages, 2 figures, 2 tables. To be submitted in Behavior Research\n  Methods"},{"id":"http://arxiv.org/abs/2506.21427v1","updated":"2025-06-26T16:09:53Z","published":"2025-06-26T16:09:53Z","title":"Flow-Based Single-Step Completion for Efficient and Expressive Policy\n  Learning","summary":"  Generative models such as diffusion and flow-matching offer expressive\npolicies for offline reinforcement learning (RL) by capturing rich, multimodal\naction distributions, but their iterative sampling introduces high inference\ncosts and training instability due to gradient propagation across sampling\nsteps. We propose the \\textit{Single-Step Completion Policy} (SSCP), a\ngenerative policy trained with an augmented flow-matching objective to predict\ndirect completion vectors from intermediate flow samples, enabling accurate,\none-shot action generation. In an off-policy actor-critic framework, SSCP\ncombines the expressiveness of generative models with the training and\ninference efficiency of unimodal policies, without requiring long\nbackpropagation chains. Our method scales effectively to offline,\noffline-to-online, and online RL settings, offering substantial gains in speed\nand adaptability over diffusion-based baselines. We further extend SSCP to\ngoal-conditioned RL, enabling flat policies to exploit subgoal structures\nwithout explicit hierarchical inference. SSCP achieves strong results across\nstandard offline RL and behavior cloning benchmarks, positioning it as a\nversatile, expressive, and efficient framework for deep RL and sequential\ndecision-making.\n","authors":["Prajwal Koirala","Cody Fleming"],"pdf_url":"https://arxiv.org/pdf/2506.21427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04202v3","updated":"2025-06-26T16:09:36Z","published":"2025-06-04T17:48:16Z","title":"TracLLM: A Generic Framework for Attributing Long Context LLMs","summary":"  Long context large language models (LLMs) are deployed in many real-world\napplications such as RAG, agent, and broad LLM-integrated applications. Given\nan instruction and a long context (e.g., documents, PDF files, webpages), a\nlong context LLM can generate an output grounded in the provided context,\naiming to provide more accurate, up-to-date, and verifiable outputs while\nreducing hallucinations and unsupported claims. This raises a research\nquestion: how to pinpoint the texts (e.g., sentences, passages, or paragraphs)\nin the context that contribute most to or are responsible for the generated\noutput by an LLM? This process, which we call context traceback, has various\nreal-world applications, such as 1) debugging LLM-based systems, 2) conducting\npost-attack forensic analysis for attacks (e.g., prompt injection attack,\nknowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources\nto enhance the trust of users towards outputs generated by LLMs. When applied\nto context traceback for long context LLMs, existing feature attribution\nmethods such as Shapley have sub-optimal performance and/or incur a large\ncomputational cost. In this work, we develop TracLLM, the first generic context\ntraceback framework tailored to long context LLMs. Our framework can improve\nthe effectiveness and efficiency of existing feature attribution methods. To\nimprove the efficiency, we develop an informed search based algorithm in\nTracLLM. We also develop contribution score ensemble/denoising techniques to\nimprove the accuracy of TracLLM. Our evaluation results show TracLLM can\neffectively identify texts in a long context that lead to the output of an LLM.\nOur code and data are at: https://github.com/Wang-Yanting/TracLLM.\n","authors":["Yanting Wang","Wei Zou","Runpeng Geng","Jinyuan Jia"],"pdf_url":"https://arxiv.org/pdf/2506.04202v3.pdf","comment":"To appear in USENIX Security Symposium 2025. The code and data are\n  at: https://github.com/Wang-Yanting/TracLLM"},{"id":"http://arxiv.org/abs/2307.04345v3","updated":"2025-06-26T16:08:44Z","published":"2023-07-10T05:06:41Z","title":"Continual Learning as Computationally Constrained Reinforcement Learning","summary":"  An agent that efficiently accumulates knowledge to develop increasingly\nsophisticated skills over a long lifetime could advance the frontier of\nartificial intelligence capabilities. The design of such agents, which remains\na long-standing challenge of artificial intelligence, is addressed by the\nsubject of continual learning. This monograph clarifies and formalizes concepts\nof continual learning, introducing a framework and set of tools to stimulate\nfurther research.\n","authors":["Saurabh Kumar","Henrik Marklund","Ashish Rao","Yifan Zhu","Hong Jun Jeon","Yueyang Liu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2307.04345v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19644v2","updated":"2025-06-26T16:07:20Z","published":"2024-10-25T15:49:16Z","title":"Improving Stochastic Cubic Newton with Momentum","summary":"  We study stochastic second-order methods for solving general non-convex\noptimization problems. We propose using a special version of momentum to\nstabilize the stochastic gradient and Hessian estimates in Newton's method. We\nshow that momentum provably improves the variance of stochastic estimates and\nallows the method to converge for any noise level. Using the cubic\nregularization technique, we prove a global convergence rate for our method on\ngeneral non-convex problems to a second-order stationary point, even when using\nonly a single stochastic data sample per iteration. This starkly contrasts with\nall existing stochastic second-order methods for non-convex problems, which\ntypically require large batches. Therefore, we are the first to demonstrate\nglobal convergence for batches of arbitrary size in the non-convex case for the\nStochastic Cubic Newton. Additionally, we show improved speed on convex\nstochastic problems for our regularized Newton methods with momentum.\n","authors":["El Mahdi Chayti","Nikita Doikov","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2410.19644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.18506v3","updated":"2025-06-26T15:59:16Z","published":"2025-04-25T17:17:17Z","title":"Action-Minimization Meets Generative Modeling: Efficient Transition Path\n  Sampling with the Onsager-Machlup Functional","summary":"  Transition path sampling (TPS), which involves finding probable paths\nconnecting two points on an energy landscape, remains a challenge due to the\ncomplexity of real-world atomistic systems. Current machine learning approaches\nuse expensive, task-specific, and data-free training procedures, limiting their\nability to benefit from high-quality datasets and large-scale pre-trained\nmodels. In this work, we address TPS by interpreting candidate paths as\ntrajectories sampled from stochastic dynamics induced by the learned score\nfunction of pre-trained generative models, specifically denoising diffusion and\nflow matching. Under these dynamics, finding high-likelihood transition paths\nbecomes equivalent to minimizing the Onsager-Machlup (OM) action functional.\nThis enables us to repurpose pre-trained generative models for TPS in a\nzero-shot manner, in contrast with bespoke, task-specific approaches in\nprevious work. We demonstrate our approach on varied molecular systems,\nobtaining diverse, physically realistic transition pathways and generalizing\nbeyond the pre-trained model's original training dataset. Our method can be\neasily incorporated into new generative models, making it practically relevant\nas models continue to scale and improve with increased data availability. Code\nis available at github.com/ASK-Berkeley/OM-TPS.\n","authors":["Sanjeev Raja","Martin Šípka","Michael Psenka","Tobias Kreiman","Michal Pavelka","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2504.18506v3.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2506.21411v1","updated":"2025-06-26T15:58:14Z","published":"2025-06-26T15:58:14Z","title":"Distributed Cross-Channel Hierarchical Aggregation for Foundation Models","summary":"  Vision-based scientific foundation models hold significant promise for\nadvancing scientific discovery and innovation. This potential stems from their\nability to aggregate images from diverse sources such as varying physical\ngroundings or data acquisition systems and to learn spatio-temporal\ncorrelations using transformer architectures. However, tokenizing and\naggregating images can be compute-intensive, a challenge not fully addressed by\ncurrent distributed methods. In this work, we introduce the Distributed\nCross-Channel Hierarchical Aggregation (D-CHAG) approach designed for datasets\nwith a large number of channels across image modalities. Our method is\ncompatible with any model-parallel strategy and any type of vision transformer\narchitecture, significantly improving computational efficiency. We evaluated\nD-CHAG on hyperspectral imaging and weather forecasting tasks. When integrated\nwith tensor parallelism and model sharding, our approach achieved up to a 75%\nreduction in memory usage and more than doubled sustained throughput on up to\n1,024 AMD GPUs on the Frontier Supercomputer.\n","authors":["Aristeidis Tsaris","Isaac Lyngaas","John Lagregren","Mohamed Wahib","Larry York","Prasanna Balaprakash","Dan Lu","Feiyi Wang","Xiao Wang"],"pdf_url":"https://arxiv.org/pdf/2506.21411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21408v1","updated":"2025-06-26T15:54:45Z","published":"2025-06-26T15:54:45Z","title":"Scalable Bayesian Low-Rank Adaptation of Large Language Models via\n  Stochastic Variational Subspace Inference","summary":"  Despite their widespread use, large language models (LLMs) are known to\nhallucinate incorrect information and be poorly calibrated. This makes the\nuncertainty quantification of these models of critical importance, especially\nin high-stakes domains, such as autonomy and healthcare. Prior work has made\nBayesian deep learning-based approaches to this problem more tractable by\nperforming inference over the low-rank adaptation (LoRA) parameters of a\nfine-tuned model. While effective, these approaches struggle to scale to larger\nLLMs due to requiring further additional parameters compared to LoRA. In this\nwork we present $\\textbf{Scala}$ble $\\textbf{B}$ayesian $\\textbf{L}$ow-Rank\nAdaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform\nBayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By\nrepurposing the LoRA parameters as projection matrices, we are able to map\nsamples from this subspace into the full weight space of the LLM. This allows\nus to learn all the parameters of our approach using stochastic variational\ninference. Despite the low dimensionality of our subspace, we are able to\nachieve competitive performance with state-of-the-art approaches while only\nrequiring ${\\sim}1000$ additional parameters. Furthermore, it allows us to\nscale up to the largest Bayesian LLM to date, with four times as a many base\nparameters as prior work.\n","authors":["Colin Samplawski","Adam D. Cobb","Manoj Acharya","Ramneet Kaur","Susmit Jha"],"pdf_url":"https://arxiv.org/pdf/2506.21408v1.pdf","comment":"Accepted at UAI 2025"},{"id":"http://arxiv.org/abs/2506.21387v1","updated":"2025-06-26T15:36:37Z","published":"2025-06-26T15:36:37Z","title":"Early Stopping Tabular In-Context Learning","summary":"  Tabular foundation models have shown strong performance across various\ntabular learning tasks via in-context learning, offering robust generalization\nwithout any downstream finetuning. However, their inference-time costs remain\nhigh, particularly for larger datasets. To address this, we propose\nearly-stopping the in-context learning process. We achieve this by dynamically\nevaluating whether to stop in-context learning after each Transformer encoder\nlayer. Once stopped, we decode the embedding using a pre-trained layer-wise\ndecoder. Experiments across 34 small classification tasks size show that early\nstopping in-context learning accelerates inference by up to x1.3 with\nnegligible degradation in predictive performance. To assess scalability, we\nfurther evaluate our method on five larger classification tasks, achieving\nspeedups of up to x2.2. Our results demonstrate the potential of early exiting\nas an effective and practical strategy for improving the efficiency of tabular\nin-context learning.\n","authors":["Jaris Küken","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2506.21387v1.pdf","comment":"ICML Workshop Paper"},{"id":"http://arxiv.org/abs/2501.02648v3","updated":"2025-06-26T15:34:13Z","published":"2025-01-05T20:26:49Z","title":"Representation Learning of Lab Values via Masked AutoEncoders","summary":"  Accurate imputation of missing laboratory values in electronic health records\n(EHRs) is critical to enable robust clinical predictions and reduce biases in\nAI systems in healthcare. Existing methods, such as XGBoost, softimpute, GAIN,\nExpectation Maximization (EM), and MICE, struggle to model the complex temporal\nand contextual dependencies in EHR data, particularly in underrepresented\ngroups. In this work, we propose Lab-MAE, a novel transformer-based masked\nautoencoder framework that leverages self-supervised learning for the\nimputation of continuous sequential lab values. Lab-MAE introduces a structured\nencoding scheme that jointly models laboratory test values and their\ncorresponding timestamps, enabling explicit capturing temporal dependencies.\nEmpirical evaluation on the MIMIC-IV dataset demonstrates that Lab-MAE\nsignificantly outperforms state-of-the-art baselines such as XGBoost,\nsoftimpute, GAIN, EM, and MICE across multiple metrics, including root mean\nsquare error (RMSE), R-squared (R2), and Wasserstein distance (WD). Notably,\nLab-MAE achieves equitable performance across demographic groups of patients,\nadvancing fairness in clinical predictions. We further investigate the role of\nfollow-up laboratory values as potential shortcut features, revealing Lab-MAE's\nrobustness in scenarios where such data is unavailable. The findings suggest\nthat our transformer-based architecture, adapted to the characteristics of EHR\ndata, offers a foundation model for more accurate and fair clinical imputation.\nIn addition, we measure and compare the carbon footprint of Lab-MAE with the a\nXGBoost model, highlighting its environmental requirements.\n","authors":["David Restrepo","Chenwei Wu","Yueran Jia","Jaden K. Sun","Jack Gallifant","Catherine G. Bielick","Yugang Jia","Leo A. Celi"],"pdf_url":"https://arxiv.org/pdf/2501.02648v3.pdf","comment":"14 pages of main text, 11 appendix"},{"id":"http://arxiv.org/abs/2506.21382v1","updated":"2025-06-26T15:34:06Z","published":"2025-06-26T15:34:06Z","title":"Temporal-Aware Graph Attention Network for Cryptocurrency Transaction\n  Fraud Detection","summary":"  Cryptocurrency transaction fraud detection faces the dual challenges of\nincreasingly complex transaction patterns and severe class imbalance.\nTraditional methods rely on manual feature engineering and struggle to capture\ntemporal and structural dependencies in transaction networks. This paper\nproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that\nenhances detection performance through three modules: (1) designing an advanced\ntemporal embedding module that fuses multi-scale time difference features with\nperiodic position encoding; (2) constructing a temporal-aware triple attention\nmechanism that jointly optimizes structural, temporal, and global context\nattention; (3) employing weighted BCE loss to address class imbalance.\nExperiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT\nachieves an AUC of 0.9130, representing a 9.2% improvement over the best\ntraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This\nmethod not only validates the enhancement effect of temporal awareness and\ntriple attention mechanisms on graph neural networks, but also provides\nfinancial institutions with more reliable fraud detection tools, with its\ndesign principles generalizable to other temporal graph anomaly detection\ntasks.\n","authors":["Zhi Zheng","Bochuan Zhou","Yuping Song"],"pdf_url":"https://arxiv.org/pdf/2506.21382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19268v2","updated":"2025-06-26T15:23:54Z","published":"2025-06-24T02:59:14Z","title":"HARPT: A Corpus for Analyzing Consumers' Trust and Privacy Concerns in\n  Mobile Health Apps","summary":"  We present HARPT, a large-scale annotated corpus of mobile health app store\nreviews aimed at advancing research in user privacy and trust. The dataset\ncomprises over 480,000 user reviews labeled into seven categories that capture\ncritical aspects of trust in applications, trust in providers and privacy\nconcerns. Creating HARPT required addressing multiple complexities, such as\ndefining a nuanced label schema, isolating relevant content from large volumes\nof noisy data, and designing an annotation strategy that balanced scalability\nwith accuracy. This strategy integrated rule-based filtering, iterative manual\nlabeling with review, targeted data augmentation, and weak supervision using\ntransformer-based classifiers to accelerate coverage. In parallel, a carefully\ncurated subset of 7,000 reviews was manually annotated to support model\ndevelopment and evaluation. We benchmark a broad range of classification\nmodels, demonstrating that strong performance is achievable and providing a\nbaseline for future research. HARPT is released as a public resource to support\nwork in health informatics, cybersecurity, and natural language processing.\n","authors":["Timoteo Kelly","Abdulkadir Korkmaz","Samuel Mallet","Connor Souders","Sadra Aliakbarpour","Praveen Rao"],"pdf_url":"https://arxiv.org/pdf/2506.19268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21374v1","updated":"2025-06-26T15:22:55Z","published":"2025-06-26T15:22:55Z","title":"Pay Attention to Small Weights","summary":"  Finetuning large pretrained neural networks is known to be\nresource-intensive, both in terms of memory and computational cost. To mitigate\nthis, a common approach is to restrict training to a subset of the model\nparameters. By analyzing the relationship between gradients and weights during\nfinetuning, we observe a notable pattern: large gradients are often associated\nwith small-magnitude weights. This correlation is more pronounced in finetuning\nsettings than in training from scratch. Motivated by this observation, we\npropose NANOADAM, which dynamically updates only the small-magnitude weights\nduring finetuning and offers several practical advantages: first, this\ncriterion is gradient-free -- the parameter subset can be determined without\ngradient computation; second, it preserves large-magnitude weights, which are\nlikely to encode critical features learned during pretraining, thereby reducing\nthe risk of catastrophic forgetting; thirdly, it permits the use of larger\nlearning rates and consistently leads to better generalization performance in\nexperiments. We demonstrate this for both NLP and vision tasks.\n","authors":["Chao Zhou","Tom Jacobs","Advait Gadhikar","Rebekka Burkholz"],"pdf_url":"https://arxiv.org/pdf/2506.21374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05710v2","updated":"2025-06-26T15:21:59Z","published":"2025-06-06T03:20:32Z","title":"Latent Diffusion Model Based Denoising Receiver for 6G Semantic\n  Communication: From Stochastic Differential Theory to Application","summary":"  In this paper, a novel semantic communication framework empowered by\ngenerative artificial intelligence (GAI) is proposed, to enhance the robustness\nagainst both channel noise and transmission data distribution shifts. A\ntheoretical foundation is established using stochastic differential equations\n(SDEs), from which a closed-form mapping between any signal-to-noise ratio\n(SNR) and the optimal denoising timestep is derived. Moreover, to address\ndistribution mismatch, a mathematical scaling method is introduced to align\nreceived semantic features with the training distribution of the GAI. Built on\nthis theoretical foundation, a latent diffusion model (LDM)-based semantic\ncommunication framework is proposed that combines a variational autoencoder for\nsemantic features extraction, where a pretrained diffusion model is used for\ndenoising. The proposed system is a training-free framework that supports\nzero-shot generalization, and achieves superior performance under low-SNR and\nout-of-distribution conditions, offering a scalable and robust solution for\nfuture 6G semantic communication systems. Experimental results demonstrate that\nthe proposed semantic communication framework achieves state-of-the-art\nperformance in both pixel-level accuracy and semantic perceptual quality,\nconsistently outperforming baselines across a wide range of SNRs and data\ndistributions without any fine-tuning or post-training.\n","authors":["Xiucheng Wang","Honggang Jia","Nan Cheng","Dusit Niyato"],"pdf_url":"https://arxiv.org/pdf/2506.05710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21371v1","updated":"2025-06-26T15:21:12Z","published":"2025-06-26T15:21:12Z","title":"MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN\n  Hardware Accelerators","summary":"  Nowadays, the rapid growth of Deep Neural Network (DNN) architectures has\nestablished them as the defacto approach for providing advanced Machine\nLearning tasks with excellent accuracy. Targeting low-power DNN computing, this\npaper examines the interplay of fine-grained error resilience of DNN workloads\nin collaboration with hardware approximation techniques, to achieve higher\nlevels of energy efficiency. Utilizing the state-of-the-art ROUP approximate\nmultipliers, we systematically explore their fine-grained distribution across\nthe network according to our layer-, filter-, and kernel-level approaches, and\nexamine their impact on accuracy and energy. We use the ResNet-8 model on the\nCIFAR-10 dataset to evaluate our approximations. The proposed solution delivers\nup to 54% energy gains in exchange for up to 4% accuracy loss, compared to the\nbaseline quantized model, while it provides 2x energy gains with better\naccuracy versus the state-of-the-art DNN approximations.\n","authors":["Vasileios Leon","Georgios Makris","Sotirios Xydis","Kiamal Pekmestzi","Dimitrios Soudris"],"pdf_url":"https://arxiv.org/pdf/2506.21371v1.pdf","comment":"Presented at the 13th IEEE LASCAS Conference"},{"id":"http://arxiv.org/abs/2506.21367v1","updated":"2025-06-26T15:16:35Z","published":"2025-06-26T15:16:35Z","title":"rQdia: Regularizing Q-Value Distributions With Image Augmentation","summary":"  rQdia regularizes Q-value distributions with augmented images in pixel-based\ndeep reinforcement learning. With a simple auxiliary loss, that equalizes these\ndistributions via MSE, rQdia boosts DrQ and SAC on 9/12 and 10/12 tasks\nrespectively in the MuJoCo Continuous Control Suite from pixels, and\nData-Efficient Rainbow on 18/26 Atari Arcade environments. Gains are measured\nin both sample efficiency and longer-term training. Moreover, the addition of\nrQdia finally propels model-free continuous control from pixels over the state\nencoding baseline.\n","authors":["Sam Lerman","Jing Bi"],"pdf_url":"https://arxiv.org/pdf/2506.21367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21355v1","updated":"2025-06-26T15:08:18Z","published":"2025-06-26T15:08:18Z","title":"SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context\n  Learning","summary":"  Multimodal in-context learning (ICL) remains underexplored despite\nsignificant potential for domains such as medicine. Clinicians routinely\nencounter diverse, specialized tasks requiring adaptation from limited\nexamples, such as drawing insights from a few relevant prior cases or\nconsidering a constrained set of differential diagnoses. While multimodal large\nlanguage models (MLLMs) have shown advances in medical visual question\nanswering (VQA), their ability to learn multimodal tasks from context is\nlargely unknown. We introduce SMMILE, the first expert-driven multimodal ICL\nbenchmark for medical tasks. Eleven medical experts curated problems, each\nincluding a multimodal query and multimodal in-context examples as task\ndemonstrations. SMMILE encompasses 111 problems (517 question-image-answer\ntriplets) covering 6 medical specialties and 13 imaging modalities. We further\nintroduce SMMILE++, an augmented variant with 1038 permuted problems. A\ncomprehensive evaluation of 15 MLLMs demonstrates that most models exhibit\nmoderate to poor multimodal ICL ability in medical tasks. In open-ended\nevaluations, ICL contributes only 8% average improvement over zero-shot on\nSMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant\nin-context examples: even a single noisy or irrelevant example can degrade\nperformance by up to 9.5%. Moreover, example ordering exhibits a recency bias,\ni.e., placing the most relevant example last can lead to substantial\nperformance improvements by up to 71%. Our findings highlight critical\nlimitations and biases in current MLLMs when learning multimodal medical tasks\nfrom context.\n","authors":["Melanie Rieff","Maya Varma","Ossian Rabow","Subathra Adithan","Julie Kim","Ken Chang","Hannah Lee","Nidhi Rohatgi","Christian Bluethgen","Mohamed S. Muneer","Jean-Benoit Delbrouck","Michael Moor"],"pdf_url":"https://arxiv.org/pdf/2506.21355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21352v1","updated":"2025-06-26T15:03:54Z","published":"2025-06-26T15:03:54Z","title":"Lipschitz Bounds for Persistent Laplacian Eigenvalues under One-Simplex\n  Insertions","summary":"  Persistent Laplacians are matrix operators that track how the shape and\nstructure of data transform across scales and are popularly adopted in biology,\nphysics, and machine learning. Their eigenvalues are concise descriptors of\ngeometric and topological features in a filtration. Although earlier work\nestablished global algebraic stability for these operators, the precise change\nin a single eigenvalue when one simplex, such as a vertex, edge, or triangle,\nis added has remained unknown. This is important because downstream tools,\nincluding heat-kernel signatures and spectral neural networks, depend directly\non these eigenvalues. We close this gap by proving a uniform Lipschitz bound:\nafter inserting one simplex, every up-persistent Laplacian eigenvalue can vary\nby at most twice the Euclidean norm of that simplex's boundary, independent of\nfiltration scale and complex size. This result delivers the first\neigenvalue-level robustness guarantee for spectral topological data analysis.\nIt guarantees that spectral features remain stable under local updates and\nenables reliable error control in dynamic data settings.\n","authors":["Le Vu Anh","Mehmet Dik","Nguyen Viet Anh"],"pdf_url":"https://arxiv.org/pdf/2506.21352v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.11521v2","updated":"2025-06-26T15:02:44Z","published":"2024-12-16T07:56:54Z","title":"On the Ability of Deep Networks to Learn Symmetries from Data: A Neural\n  Kernel Theory","summary":"  Symmetries (transformations by group actions) are present in many datasets,\nand leveraging them holds considerable promise for improving predictions in\nmachine learning. In this work, we aim to understand when and how deep networks\n-- with standard architectures trained in a standard, supervised way -- learn\nsymmetries from data. Inspired by real-world scenarios, we study a\nclassification paradigm where data symmetries are only partially observed\nduring training: some classes include all transformations of a cyclic group,\nwhile others -- only a subset. In the infinite-width limit, where kernel\nanalogies apply, we derive a neural kernel theory of symmetry learning. The\ngroup-cyclic nature of the dataset allows us to analyze the Gram matrix of\nneural kernels in the Fourier domain; here we find a simple characterization of\nthe generalization error as a function of class separation (signal) and\nclass-orbit density (noise). This characterization reveals that generalization\ncan only be successful when the local structure of the data prevails over its\nnon-local, symmetry-induced structure, in the kernel space defined by the\narchitecture. We extend our theoretical treatment to any finite group,\nincluding non-abelian groups. Our framework also applies to equivariant\narchitectures (e.g., CNNs), and recovers their success in the special case\nwhere the architecture matches the inherent symmetry of the data. Empirically,\nour theory reproduces the generalization failure of finite-width networks (MLP,\nCNN, ViT) trained on partially observed versions of rotated-MNIST. We conclude\nthat conventional deep networks lack a mechanism to learn symmetries that have\nnot been explicitly embedded in their architecture a priori. Our framework\ncould be extended to guide the design of architectures and training procedures\nable to learn symmetries from data.\n","authors":["Andrea Perin","Stephane Deny"],"pdf_url":"https://arxiv.org/pdf/2412.11521v2.pdf","comment":"JMLR accepted version, including an extension of the theory to\n  general finite groups (including non-abelian groups)"},{"id":"http://arxiv.org/abs/2505.06978v2","updated":"2025-06-26T15:01:20Z","published":"2025-05-11T13:30:35Z","title":"Learning Value of Information towards Joint Communication and Control in\n  6G V2X","summary":"  As Cellular Vehicle-to-Everything (C-V2X) evolves towards future\nsixth-generation (6G) networks, Connected Autonomous Vehicles (CAVs) are\nemerging to become a key application. Leveraging data-driven Machine Learning\n(ML), especially Deep Reinforcement Learning (DRL), is expected to\nsignificantly enhance CAV decision-making in both vehicle control and V2X\ncommunication under uncertainty. These two decision-making processes are\nclosely intertwined, with the value of information (VoI) acting as a crucial\nbridge between them. In this paper, we introduce Sequential Stochastic Decision\nProcess (SSDP) models to define and assess VoI, demonstrating their application\nin optimizing communication systems for CAVs. Specifically, we formally define\nthe SSDP model and demonstrate that the MDP model is a special case of it. The\nSSDP model offers a key advantage by explicitly representing the set of\ninformation that can enhance decision-making when available. Furthermore, as\ncurrent research on VoI remains fragmented, we propose a systematic VoI\nmodeling framework grounded in the MDP, Reinforcement Learning (RL) and Optimal\nControl theories. We define different categories of VoI and discuss their\ncorresponding estimation methods. Finally, we present a structured approach to\nleverage the various VoI metrics for optimizing the ``When\", ``What\", and\n``How\" to communicate problems. For this purpose, SSDP models are formulated\nwith VoI-associated reward functions derived from VoI-based optimization\nobjectives. While we use a simple vehicle-following control problem to\nillustrate the proposed methodology, it holds significant potential to\nfacilitate the joint optimization of stochastic, sequential control and\ncommunication decisions in a wide range of networked control systems.\n","authors":["Lei Lei","Kan Zheng"," Xuemin"," Shen"],"pdf_url":"https://arxiv.org/pdf/2505.06978v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10586v2","updated":"2025-06-26T15:00:42Z","published":"2024-01-19T09:54:23Z","title":"PuriDefense: Randomized Local Implicit Adversarial Purification for\n  Defending Black-box Query-based Attacks","summary":"  Black-box query-based attacks constitute significant threats to Machine\nLearning as a Service (MLaaS) systems since they can generate adversarial\nexamples without accessing the target model's architecture and parameters.\nTraditional defense mechanisms, such as adversarial training, gradient masking,\nand input transformations, either impose substantial computational costs or\ncompromise the test accuracy of non-adversarial inputs. To address these\nchallenges, we propose an efficient defense mechanism, PuriDefense, that\nemploys random patch-wise purifications with an ensemble of lightweight\npurification models at a low level of inference cost. These models leverage the\nlocal implicit function and rebuild the natural image manifold. Our theoretical\nanalysis suggests that this approach slows down the convergence of query-based\nattacks by incorporating randomness into purifications. Extensive experiments\non CIFAR-10 and ImageNet validate the effectiveness of our proposed\npurifier-based defense mechanism, demonstrating significant improvements in\nrobustness against query-based attacks.\n","authors":["Ping Guo","Xiang Li","Zhiyuan Yang","Xi Lin","Qingchuan Zhao","Qingfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.10586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.06820v2","updated":"2025-06-26T14:54:55Z","published":"2025-04-09T12:25:00Z","title":"Regret Bounds for Robust Online Decision Making","summary":"  We propose a framework which generalizes \"decision making with structured\nobservations\" by allowing robust (i.e. multivalued) models. In this framework,\neach model associates each decision with a convex set of probability\ndistributions over outcomes. Nature can choose distributions out of this set in\nan arbitrary (adversarial) manner, that can be nonoblivious and depend on past\nhistory. The resulting framework offers much greater generality than classical\nbandits and reinforcement learning, since the realizability assumption becomes\nmuch weaker and more realistic. We then derive a theory of regret bounds for\nthis framework. Although our lower and upper bounds are not tight, they are\nsufficient to fully characterize power-law learnability. We demonstrate this\ntheory in two special cases: robust linear bandits and tabular robust online\nreinforcement learning. In both cases, we derive regret bounds that improve\nstate-of-the-art (except that we do not address computational efficiency).\n","authors":["Alexander Appel","Vanessa Kosoy"],"pdf_url":"https://arxiv.org/pdf/2504.06820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21343v1","updated":"2025-06-26T14:53:44Z","published":"2025-06-26T14:53:44Z","title":"DynamicBench: Evaluating Real-Time Report Generation in Large Language\n  Models","summary":"  Traditional benchmarks for large language models (LLMs) typically rely on\nstatic evaluations through storytelling or opinion expression, which fail to\ncapture the dynamic requirements of real-time information processing in\ncontemporary applications. To address this limitation, we present DynamicBench,\na benchmark designed to evaluate the proficiency of LLMs in storing and\nprocessing up-to-the-minute data. DynamicBench utilizes a dual-path retrieval\npipeline, integrating web searches with local report databases. It necessitates\ndomain-specific knowledge, ensuring accurate responses report generation within\nspecialized fields. By evaluating models in scenarios that either provide or\nwithhold external documents, DynamicBench effectively measures their capability\nto independently process recent information or leverage contextual\nenhancements. Additionally, we introduce an advanced report generation system\nadept at managing dynamic information synthesis. Our experimental results\nconfirm the efficacy of our approach, with our method achieving\nstate-of-the-art performance, surpassing GPT4o in document-free and\ndocument-assisted scenarios by 7.0% and 5.8%, respectively. The code and data\nwill be made publicly available.\n","authors":["Jingyao Li","Hao Sun","Zile Qiao","Yong Jiang","Pengjun Xie","Fei Huang","Hong Xu","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2506.21343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21338v1","updated":"2025-06-26T14:49:10Z","published":"2025-06-26T14:49:10Z","title":"AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG\n  Classification","summary":"  Brain-computer interface (BCI) technology utilizing electroencephalography\n(EEG) marks a transformative innovation, empowering motor-impaired individuals\nto engage with their environment on equal footing. Despite its promising\npotential, developing subject-invariant and session-invariant BCI systems\nremains a significant challenge due to the inherent complexity and variability\nof neural activity across individuals and over time, compounded by EEG hardware\nconstraints. While prior studies have sought to develop robust BCI systems,\nexisting approaches remain ineffective in capturing the intricate\nspatiotemporal dependencies within multichannel EEG signals. This study\naddresses this gap by introducing the attentive graph-temporal convolutional\nnetwork (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG)\nclassification. Specifically, AGTCNet leverages the topographic configuration\nof EEG electrodes as an inductive bias and integrates graph convolutional\nattention network (GCAT) to jointly learn expressive spatiotemporal EEG\nrepresentations. The proposed model significantly outperformed existing MI-EEG\nclassifiers, achieving state-of-the-art performance while utilizing a compact\narchitecture, underscoring its effectiveness and practicality for BCI\ndeployment. With a 49.87% reduction in model size, 64.65% faster inference\ntime, and shorter input EEG signal, AGTCNet achieved a moving average accuracy\nof 66.82% for subject-independent classification on the BCI Competition IV\nDataset 2a, which further improved to 82.88% when fine-tuned for\nsubject-specific classification. On the EEG Motor Movement/Imagery Dataset,\nAGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and\n2-class subject-independent classifications, respectively, with further\nimprovements to 72.13% and 90.54% for subject-specific classifications.\n","authors":["Galvin Brice S. Lim","Brian Godwin S. Lim","Argel A. Bandala","John Anthony C. Jose","Timothy Scott C. Chu","Edwin Sybingco"],"pdf_url":"https://arxiv.org/pdf/2506.21338v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.03083v2","updated":"2025-06-26T14:43:45Z","published":"2024-12-04T07:21:23Z","title":"A Scalable Quantum Neural Network for Approximate SRBB-Based Unitary\n  Synthesis","summary":"  In this work, a scalable quantum neural network is introduced as a means to\napproximate any unitary evolution through the Standard Recursive Block Basis\n(SRBB) and, subsequently, redesigned with a number of CNOTs asymptotically\nreduced by an exponential contribution. This algebraic approach to the problem\nof unitary synthesis exploits Lie algebras and their topological features to\nobtain scalable parameterizations of unitary operators. First, the original\nSRBB-based scalability scheme, already known in the literature only from a\ntheoretical point of view, is reformulated for efficient algorithm\nimplementation and complexity management. Remarkably, 2-qubit operators emerge\nas a special case outside the original scaling scheme. Furthermore, an\nalgorithm is proposed to reduce the number of CNOTs, thus deriving a new\nimplementable scaling scheme that requires only one layer of approximation. The\nscalable CNOT-reduced quantum neural network is implemented and its performance\nis assessed with a variety of different unitary matrices, both sparse and\ndense, up to 6 qubits via the PennyLane library. The effectiveness of the\napproximation is measured with different metrics in relation to two optimizers:\na gradient-based method and the Nelder-Mead method. The approximate\nCNOT-reduced SRBB-based synthesis algorithm is also tested on real hardware and\ncompared with other valid approximation and decomposition methods available in\nthe literature.\n","authors":["Giacomo Belli","Marco Mordacci","Michele Amoretti"],"pdf_url":"https://arxiv.org/pdf/2412.03083v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.15920v4","updated":"2025-06-26T14:41:32Z","published":"2025-04-22T14:05:11Z","title":"ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order\n  Neighboring Feature Fusion","summary":"  Graph Neural Networks (GNNs) have demonstrated impressive performance across\ndiverse graph-based tasks by leveraging message passing to capture complex node\nrelationships. However, when applied to large-scale real-world graphs, GNNs\nface two major challenges: First, it becomes increasingly difficult to ensure\nboth scalability and efficiency, as the repeated aggregation of large\nneighborhoods leads to significant computational overhead; Second, the\nover-smoothing problem arises, where excessive or deep propagation makes node\nrepresentations indistinguishable, severely hindering model expressiveness. To\ntackle these issues, we propose ScaleGNN, a novel framework that adaptively\nfuses multi-hop node features for both scalable and effective graph learning.\nFirst, we construct per-hop pure neighbor matrices that capture only the\nexclusive structural information at each hop, avoiding the redundancy of\nconventional aggregation. Then, an enhanced feature fusion strategy\nsignificantly balances low-order and high-order information, preserving both\nlocal detail and global correlations without incurring excessive complexity. To\nfurther reduce redundancy and over-smoothing, we introduce a Local Contribution\nScore (LCS)-based masking mechanism to filter out less relevant high-order\nneighbors, ensuring that only the most meaningful information is aggregated. In\naddition, learnable sparse constraints selectively integrate multi-hop valuable\nfeatures, emphasizing the most informative high-order neighbors. Extensive\nexperiments on real-world datasets demonstrate that ScaleGNN consistently\noutperforms state-of-the-art GNNs in both predictive accuracy and computational\nefficiency, highlighting its practical value for large-scale graph learning.\n","authors":["Xiang Li","Jianpeng Qi","Haobing Liu","Yuan Cao","Guoqing Chao","Zhongying Zhao","Junyu Dong","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2504.15920v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21328v1","updated":"2025-06-26T14:41:18Z","published":"2025-06-26T14:41:18Z","title":"Latent Prototype Routing: Achieving Near-Perfect Load Balancing in\n  Mixture-of-Experts","summary":"  Mixture-of-Experts (MoE) architectures have emerged as a key strategy for\nscaling large language models (LLMs) efficiently. However, current MoE systems\nsuffer from severe load imbalance, where only a small subset of experts is\nconsistently activated during training and inference, leading to significant\nunderutilization of model capacity and computational resources. In this work,\nwe revisit expert routing through a clustering perspective and propose Latent\nPrototype Routing (LPR), a novel routing framework that generalizes existing\napproaches while promoting balanced expert utilization without compromising\ndownstream performance. Extensive experiments across multiple open-source MoE\nmodels -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR\nreduces the Gini coefficient of expert load from 0.70 to 0.035 on average,\nimproves the min-max expert load ratio from 1e-6 to 0.70, achieving\nnear-perfect load balancing.\n","authors":["Jiajie Yang"],"pdf_url":"https://arxiv.org/pdf/2506.21328v1.pdf","comment":"15 pages,4 figures"},{"id":"http://arxiv.org/abs/2506.21324v1","updated":"2025-06-26T14:39:14Z","published":"2025-06-26T14:39:14Z","title":"Stochastic Quantum Spiking Neural Networks with Quantum Memory and Local\n  Learning","summary":"  Neuromorphic and quantum computing have recently emerged as promising\nparadigms for advancing artificial intelligence, each offering complementary\nstrengths. Neuromorphic systems built on spiking neurons excel at processing\ntime-series data efficiently through sparse, event-driven computation,\nconsuming energy only upon input events. Quantum computing, on the other hand,\nleverages superposition and entanglement to explore feature spaces that are\nexponentially large in the number of qubits. Hybrid approaches combining these\nparadigms have begun to show potential, but existing quantum spiking models\nhave important limitations. Notably, prior quantum spiking neuron\nimplementations rely on classical memory mechanisms on single qubits, requiring\nrepeated measurements to estimate firing probabilities, and they use\nconventional backpropagation on classical simulators for training. Here we\npropose a stochastic quantum spiking (SQS) neuron model that addresses these\nchallenges. The SQS neuron uses multi-qubit quantum circuits to realize a\nspiking unit with internal quantum memory, enabling event-driven probabilistic\nspike generation in a single shot. Furthermore, we outline how networks of SQS\nneurons -- dubbed SQS neural networks (SQSNNs) -- can be trained via a\nhardware-friendly local learning rule, eliminating the need for global\nclassical backpropagation. The proposed SQSNN model fuses the time-series\nefficiency of neuromorphic computing with the exponentially large inner state\nspace of quantum computing, paving the way for quantum spiking neural networks\nthat are modular, scalable, and trainable on quantum hardware.\n","authors":["Jiechen Chen","Bipin Rajendran","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2506.21324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21306v1","updated":"2025-06-26T14:25:32Z","published":"2025-06-26T14:25:32Z","title":"On Uniform Weighted Deep Polynomial approximation","summary":"  It is a classical result in rational approximation theory that certain\nnon-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be\nefficiently approximated using rational functions with root-exponential\nconvergence in terms of degrees of freedom \\cite{Sta, GN}. In contrast,\npolynomial approximations admit only algebraic convergence by Jackson's theorem\n\\cite{Lub2}. Recent work shows that composite polynomial architectures can\nrecover exponential approximation rates even without smoothness \\cite{KY}. In\nthis work, we introduce and analyze a class of weighted deep polynomial\napproximants tailored for functions with asymmetric behavior-growing unbounded\non one side and decaying on the other. By multiplying a learnable deep\npolynomial with a one-sided weight, we capture both local non-smoothness and\nglobal growth. We show numerically that this framework outperforms Taylor,\nChebyshev, and standard deep polynomial approximants, even when all use the\nsame number of parameters. To optimize these approximants in practice, we\npropose a stable graph-based parameterization strategy building on \\cite{Jar}.\n","authors":["Kingsley Yeon","Steven B. Damelin"],"pdf_url":"https://arxiv.org/pdf/2506.21306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15577v2","updated":"2025-06-26T14:22:27Z","published":"2025-02-21T16:38:45Z","title":"Context-Aware Doubly-Robust Semi-Supervised Learning","summary":"  The widespread adoption of artificial intelligence (AI) in next-generation\ncommunication systems is challenged by the heterogeneity of traffic and network\nconditions, which call for the use of highly contextual, site-specific, data. A\npromising solution is to rely not only on real-world data, but also on\nsynthetic pseudo-data generated by a network digital twin (NDT). However, the\neffectiveness of this approach hinges on the accuracy of the NDT, which can\nvary widely across different contexts. To address this problem, this paper\nintroduces context-aware doubly-robust (CDR) learning, a novel semi-supervised\nscheme that adapts its reliance on the pseudo-data to the different levels of\nfidelity of the NDT across contexts. CDR is evaluated on the task of downlink\nbeamforming where it outperforms previous state-of-the-art approaches,\nproviding a 24% loss decrease when compared to doubly-robust (DR)\nsemi-supervised learning in regimes with low labeled data availability.\n","authors":["Clement Ruah","Houssem Sifaou","Osvaldo Simeone","Bashir Al-Hashimi"],"pdf_url":"https://arxiv.org/pdf/2502.15577v2.pdf","comment":"This work has been accepted for publication in IEEE Signal Processing\n  Letters"},{"id":"http://arxiv.org/abs/2506.19683v2","updated":"2025-06-26T14:20:13Z","published":"2025-06-24T14:49:40Z","title":"Semantic Scene Graph for Ultrasound Image Explanation and Scanning\n  Guidance","summary":"  Understanding medical ultrasound imaging remains a long-standing challenge\ndue to significant visual variability caused by differences in imaging and\nacquisition parameters. Recent advancements in large language models (LLMs)\nhave been used to automatically generate terminology-rich summaries orientated\nto clinicians with sufficient physiological knowledge. Nevertheless, the\nincreasing demand for improved ultrasound interpretability and basic scanning\nguidance among non-expert users, e.g., in point-of-care settings, has not yet\nbeen explored. In this study, we first introduce the scene graph (SG) for\nultrasound images to explain image content to ordinary and provide guidance for\nultrasound scanning. The ultrasound SG is first computed using a\ntransformer-based one-stage method, eliminating the need for explicit object\ndetection. To generate a graspable image explanation for ordinary, the user\nquery is then used to further refine the abstract SG representation through\nLLMs. Additionally, the predicted SG is explored for its potential in guiding\nultrasound scanning toward missing anatomies within the current imaging view,\nassisting ordinary users in achieving more standardized and complete anatomical\nexploration. The effectiveness of this SG-based image explanation and scanning\nguidance has been validated on images from the left and right neck regions,\nincluding the carotid and thyroid, across five volunteers. The results\ndemonstrate the potential of the method to maximally democratize ultrasound by\nenhancing its interpretability and usability for ordinaries.\n","authors":["Xuesong Li","Dianye Huang","Yameng Zhang","Nassir Navab","Zhongliang Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.19683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21298v1","updated":"2025-06-26T14:18:39Z","published":"2025-06-26T14:18:39Z","title":"Exploring Adapter Design Tradeoffs for Low Resource Music Generation","summary":"  Fine-tuning large-scale music generation models, such as MusicGen and\nMustango, is a computationally expensive process, often requiring updates to\nbillions of parameters and, therefore, significant hardware resources.\nParameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based\nmethods, have emerged as a promising alternative, enabling adaptation with\nminimal trainable parameters while preserving model performance. However, the\ndesign choices for adapters, including their architecture, placement, and size,\nare numerous, and it is unclear which of these combinations would produce\noptimal adapters and why, for a given case of low-resource music genre. In this\npaper, we attempt to answer this question by studying various adapter\nconfigurations for two AI music models, MusicGen and Mustango, on two genres:\nHindustani Classical and Turkish Makam music.\n  Our findings reveal distinct trade-offs: convolution-based adapters excel in\ncapturing fine-grained local musical details such as ornamentations and short\nmelodic phrases, while transformer-based adapters better preserve long-range\ndependencies crucial for structured improvisation. Additionally, we analyze\ncomputational resource requirements across different adapter scales,\ndemonstrating how mid-sized adapters (40M parameters) achieve an optimal\nbalance between expressivity and quality. Furthermore, we find that Mustango, a\ndiffusion-based model, generates more diverse outputs with better adherence to\nthe description in the input prompt while lacking in providing stability in\nnotes, rhythm alignment, and aesthetics. Also, it is computationally intensive\nand requires significantly more time to train. In contrast, autoregressive\nmodels like MusicGen offer faster training and are more efficient, and can\nproduce better quality output in comparison, but have slightly higher\nredundancy in their generations.\n","authors":["Atharva Mehta","Shivam Chauhan","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2506.21298v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2506.09803v2","updated":"2025-06-26T14:18:21Z","published":"2025-06-11T14:46:11Z","title":"Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning\n  Protocols","summary":"  Graph neural networks (GNNs) have achieved significant success in graph\nrepresentation learning and have been applied to various domains. However, many\nreal-world graphs contain sensitive personal information, such as user profiles\nin social networks, raising serious privacy concerns when graph learning is\nperformed using GNNs. To address this issue, locally private graph learning\nprotocols have gained considerable attention. These protocols leverage the\nprivacy advantages of local differential privacy (LDP) and the effectiveness of\nGNN's message-passing in calibrating noisy data, offering strict privacy\nguarantees for users' local data while maintaining high utility (e.g., node\nclassification accuracy) for graph learning. Despite these advantages, such\nprotocols may be vulnerable to data poisoning attacks, a threat that has not\nbeen considered in previous research. Identifying and addressing these threats\nis crucial for ensuring the robustness and security of privacy-preserving graph\nlearning frameworks. This work introduces the first data poisoning attack\ntargeting locally private graph learning protocols. The attacker injects fake\nusers into the protocol, manipulates these fake users to establish links with\ngenuine users, and sends carefully crafted data to the server, ultimately\ncompromising the utility of private graph learning. The effectiveness of the\nattack is demonstrated both theoretically and empirically. In addition, several\ndefense strategies have also been explored, but their limited effectiveness\nhighlights the need for more robust defenses.\n","authors":["Longzhu He","Chaozhuo Li","Peng Tang","Li Sun","Sen Su","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2506.09803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21291v1","updated":"2025-06-26T14:10:40Z","published":"2025-06-26T14:10:40Z","title":"Improved seeding strategies for k-means and k-GMM","summary":"  We revisit the randomized seeding techniques for k-means clustering and k-GMM\n(Gaussian Mixture model fitting with Expectation-Maximization), formalizing\ntheir three key ingredients: the metric used for seed sampling, the number of\ncandidate seeds, and the metric used for seed selection. This analysis yields\nnovel families of initialization methods exploiting a lookahead\nprinciple--conditioning the seed selection to an enhanced coherence with the\nfinal metric used to assess the algorithm, and a multipass strategy to tame\ndown the effect of randomization.\n  Experiments show a consistent constant factor improvement over classical\ncontenders in terms of the final metric (SSE for k-means, log-likelihood for\nk-GMM), at a modest overhead. In particular, for k-means, our methods improve\non the recently designed multi-swap strategy, which was the first one to\noutperform the greedy k-means++ seeding.\n  Our experimental analysis also shed light on subtle properties of k-means\noften overlooked, including the (lack of) correlations between the SSE upon\nseeding and the final SSE, the variance reduction phenomena observed in\niterative seeding methods, and the sensitivity of the final SSE to the pool\nsize for greedy methods.\n  Practically, our most effective seeding methods are strong candidates to\nbecome one of the--if not the--standard techniques. From a theoretical\nperspective, our formalization of seeding opens the door to a new line of\nanalytical approaches.\n","authors":["Guillaume Carrière","Frédéric Cazals"],"pdf_url":"https://arxiv.org/pdf/2506.21291v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2506.21288v1","updated":"2025-06-26T14:09:41Z","published":"2025-06-26T14:09:41Z","title":"Small Encoders Can Rival Large Decoders in Detecting Groundedness","summary":"  Augmenting large language models (LLMs) with external context significantly\nimproves their performance in natural language processing (NLP) tasks. However,\nLLMs struggle to answer queries reliably when the provided context lacks\ninformation, often resorting to ungrounded speculation or internal knowledge.\nGroundedness - generating responses strictly supported by the context - is\nessential for ensuring factual consistency and trustworthiness. This study\nfocuses on detecting whether a given query is grounded in a document provided\nin context before the costly answer generation by LLMs. Such a detection\nmechanism can significantly reduce both inference time and resource\nconsumption. We show that lightweight, task specific encoder models such as\nRoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy\ncomparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in\ngroundedness detection while reducing inference latency by orders of magnitude.\nThe code is available at : https://github.com/chandarlab/Hallucinate-less\n","authors":["Istabrak Abbes","Gabriele Prato","Quentin Fournier","Fernando Rodriguez","Alaa Boukhary","Adam Elwood","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2506.21288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10612v4","updated":"2025-06-26T14:04:51Z","published":"2025-04-14T18:10:58Z","title":"Energy Matching: Unifying Flow Matching and Energy-Based Models for\n  Generative Modeling","summary":"  The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.\n","authors":["Michal Balcerak","Tamaz Amiranashvili","Antonio Terpin","Suprosanna Shit","Lea Bogensperger","Sebastian Kaltenbach","Petros Koumoutsakos","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2504.10612v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21278v1","updated":"2025-06-26T14:01:51Z","published":"2025-06-26T14:01:51Z","title":"Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy\n  Distribution","summary":"  We propose a novel variational autoencoder (VAE) architecture that employs a\nspherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian\nlatent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy\nprovides a more natural hyperspherical representation of latent variables,\nbetter capturing directional data while maintaining flexibility. Its\nheavy-tailed nature prevents over-regularization, ensuring efficient latent\nspace utilization while offering a more expressive representation.\nAdditionally, spCauchy circumvents the numerical instabilities inherent to vMF,\nwhich arise from computing normalization constants involving Bessel functions.\nInstead, it enables a fully differentiable and efficient reparameterization\ntrick via M\\\"obius transformations, allowing for stable and scalable training.\nThe KL divergence can be computed through a rapidly converging power series,\neliminating concerns of underflow or overflow associated with evaluation of\nratios of hypergeometric functions. These properties make spCauchy a compelling\nalternative for VAEs, offering both theoretical advantages and practical\nefficiency in high-dimensional generative modeling.\n","authors":["Lukas Sablica","Kurt Hornik"],"pdf_url":"https://arxiv.org/pdf/2506.21278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12641v2","updated":"2025-06-26T14:00:55Z","published":"2024-12-17T08:03:53Z","title":"Lagrangian Index Policy for Restless Bandits with Average Reward","summary":"  We study the Lagrange Index Policy (LIP) for restless multi-armed bandits\nwith long-run average reward. In particular, we compare the performance of LIP\nwith the performance of the Whittle Index Policy (WIP), both heuristic policies\nknown to be asymptotically optimal under certain natural conditions. Even\nthough in most cases their performances are very similar, in the cases when WIP\nshows bad performance, LIP continues to perform very well. We then propose\nreinforcement learning algorithms, both tabular and NN-based, to obtain online\nlearning schemes for LIP in the model-free setting. The proposed reinforcement\nlearning schemes for LIP require significantly less memory than the analogous\nschemes for WIP. We calculate analytically the Lagrange index for the restart\nmodel, which applies to the optimal web crawling and the minimization of the\nweighted age of information. We also give a new proof of asymptotic optimality\nin case of homogeneous arms as the number of arms goes to infinity, based on\nexchangeability and de Finetti's theorem.\n","authors":["Konstantin Avrachenkov","Vivek S. Borkar","Pratik Shah"],"pdf_url":"https://arxiv.org/pdf/2412.12641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16717v2","updated":"2025-06-26T13:54:56Z","published":"2024-08-29T17:07:43Z","title":"A GREAT Architecture for Edge-Based Graph Problems Like TSP","summary":"  In the last years, many learning-based approaches have been proposed to\ntackle combinatorial optimization problems such as routing problems. Many of\nthese approaches are based on graph neural networks (GNNs) or related\ntransformers, operating on the Euclidean coordinates representing the routing\nproblems. However, models operating on Euclidean coordinates are ill-suited for\nnon-Euclidean, asymmetric problem instances that are often found in real-world\nsettings. To overcome this limitation, we propose a novel GNN-based and\nedge-focused neural model called Graph Edge Attention Network (GREAT). Using\nGREAT as an encoder to capture the properties of a routing problem instance, we\nbuild a reinforcement learning framework which we apply to Euclidean and\nnon-Euclidean variants of vehicle routing problems such as Traveling Salesman\nProblem, Capacitated Vehicle Routing Problem and Orienteering Problem. Our\nframework is among the first to tackle non-Euclidean variants of these problems\nand achieves competitive results among learning-based solvers.\n","authors":["Attila Lischka","Filip Rydin","Jiaming Wu","Morteza Haghir Chehreghani","Balázs Kulcsár"],"pdf_url":"https://arxiv.org/pdf/2408.16717v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.18221v2","updated":"2025-06-26T13:50:38Z","published":"2025-06-23T01:04:29Z","title":"These Are Not All the Features You Are Looking For: A Fundamental\n  Bottleneck in Supervised Pretraining","summary":"  Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.\n","authors":["Xingyu Alice Yang","Jianyu Zhang","Léon Bottou"],"pdf_url":"https://arxiv.org/pdf/2506.18221v2.pdf","comment":"10 pages, 7 figures, Preprint. Under review"},{"id":"http://arxiv.org/abs/2506.21263v1","updated":"2025-06-26T13:45:04Z","published":"2025-06-26T13:45:04Z","title":"DiLoCoX: A Low-Communication Large-Scale Training Framework for\n  Decentralized Cluster","summary":"  The distributed training of foundation models, particularly large language\nmodels (LLMs), demands a high level of communication. Consequently, it is\nhighly dependent on a centralized cluster with fast and reliable interconnects.\nCan we conduct training on slow networks and thereby unleash the power of\ndecentralized clusters when dealing with models exceeding 100 billion\nparameters? In this paper, we propose DiLoCoX, a low-communication large-scale\ndecentralized cluster training framework. It combines Pipeline Parallelism with\nDual Optimizer Policy, One-Step-Delay Overlap of Communication and Local\nTraining, and an Adaptive Gradient Compression Scheme. This combination\nsignificantly improves the scale of parameters and the speed of model\npre-training. We justify the benefits of one-step-delay overlap of\ncommunication and local training, as well as the adaptive gradient compression\nscheme, through a theoretical analysis of convergence. Empirically, we\ndemonstrate that DiLoCoX is capable of pre-training a 107B foundation model\nover a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x\nspeedup in distributed training while maintaining negligible degradation in\nmodel convergence. To the best of our knowledge, this is the first\ndecentralized training framework successfully applied to models with over 100\nbillion parameters.\n","authors":["Ji Qi","WenPeng Zhu","Li Li","Ming Wu","YingJun Wu","Wu He","Xun Gao","Jason Zeng","Michael Heinrich"],"pdf_url":"https://arxiv.org/pdf/2506.21263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09925v2","updated":"2025-06-26T13:41:24Z","published":"2024-12-13T07:27:42Z","title":"Simulating Hard Attention Using Soft Attention","summary":"  We study conditions under which transformers using soft attention can\nsimulate hard attention, that is, effectively focus all attention on a subset\nof positions. First, we examine several subclasses of languages recognized by\nhard-attention transformers, which can be defined in variants of linear\ntemporal logic. We demonstrate how soft-attention transformers can compute\nformulas of these logics using unbounded positional embeddings or temperature\nscaling. Second, we demonstrate how temperature scaling allows softmax\ntransformers to simulate general hard-attention transformers, using a\ntemperature that depends on the minimum gap between the maximum attention\nscores and other attention scores.\n","authors":["Andy Yang","Lena Strobl","David Chiang","Dana Angluin"],"pdf_url":"https://arxiv.org/pdf/2412.09925v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2412.04833v3","updated":"2025-06-26T13:39:47Z","published":"2024-12-06T07:56:25Z","title":"Wavelet Diffusion Neural Operator","summary":"  Simulating and controlling physical systems described by partial differential\nequations (PDEs) are crucial tasks across science and engineering. Recently,\ndiffusion generative models have emerged as a competitive class of methods for\nthese tasks due to their ability to capture long-term dependencies and model\nhigh-dimensional states. However, diffusion models typically struggle with\nhandling system states with abrupt changes and generalizing to higher\nresolutions. In this work, we propose Wavelet Diffusion Neural Operator (WDNO),\na novel PDE simulation and control framework that enhances the handling of\nthese complexities. WDNO comprises two key innovations. Firstly, WDNO performs\ndiffusion-based generative modeling in the wavelet domain for the entire\ntrajectory to handle abrupt changes and long-term dependencies effectively.\nSecondly, to address the issue of poor generalization across different\nresolutions, which is one of the fundamental tasks in modeling physical\nsystems, we introduce multi-resolution training. We validate WDNO on five\nphysical systems, including 1D advection equation, three challenging physical\nsystems with abrupt changes (1D Burgers' equation, 1D compressible\nNavier-Stokes equation and 2D incompressible fluid), and a real-world dataset\nERA5, which demonstrates superior performance on both simulation and control\ntasks over state-of-the-art methods, with significant improvements in long-term\nand detail prediction accuracy. Remarkably, in the challenging context of the\n2D high-dimensional and indirect control task aimed at reducing smoke leakage,\nWDNO reduces the leakage by 78% compared to the second-best baseline. The code\ncan be found at https://github.com/AI4Science-WestlakeU/wdno.git.\n","authors":["Peiyan Hu","Rui Wang","Xiang Zheng","Tao Zhang","Haodong Feng","Ruiqi Feng","Long Wei","Yue Wang","Zhi-Ming Ma","Tailin Wu"],"pdf_url":"https://arxiv.org/pdf/2412.04833v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13472v2","updated":"2025-06-26T13:31:04Z","published":"2025-01-23T08:42:24Z","title":"Radio Map Estimation via Latent Domain Plug-and-Play Denoising","summary":"  Radio map estimation (RME), also known as spectrum cartography, aims to\nreconstruct the strength of radio interference across different domains (e.g.,\nspace and frequency) from sparsely sampled measurements. To tackle this typical\ninverse problem, state-of-the-art RME methods rely on handcrafted or\ndata-driven structural information of radio maps. However, the former often\nstruggles to model complex radio frequency (RF) environments and the latter\nrequires excessive training -- making it hard to quickly adapt to in situ\nsensing tasks. This work presents a spatio-spectral RME approach based on\nplug-and-play (PnP) denoising, a technique from computational imaging. The idea\nis to leverage the observation that the denoising operations of signals like\nnatural images and radio maps are similar -- despite the nontrivial differences\nof the signals themselves. Hence, sophisticated denoisers designed for or\nlearned from natural images can be directly employed to assist RME, avoiding\nusing radio map data for training. Unlike conventional PnP methods that operate\ndirectly in the data domain, the proposed method exploits the underlying\nphysical structure of radio maps and proposes an ADMM algorithm that denoises\nin a latent domain. This design significantly improves computational efficiency\nand enhances noise robustness. Theoretical aspects, e.g., recoverability of the\ncomplete radio map and convergence of the ADMM algorithm are analyzed.\nSynthetic and real data experiments are conducted to demonstrate the\neffectiveness of our approach.\n","authors":["Le Xu","Lei Cheng","Junting Chen","Wenqiang Pu","Xiao Fu"],"pdf_url":"https://arxiv.org/pdf/2501.13472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21246v1","updated":"2025-06-26T13:29:19Z","published":"2025-06-26T13:29:19Z","title":"From On-chain to Macro: Assessing the Importance of Data Source\n  Diversity in Cryptocurrency Market Forecasting","summary":"  This study investigates the impact of data source diversity on the\nperformance of cryptocurrency forecasting models by integrating various data\ncategories, including technical indicators, on-chain metrics, sentiment and\ninterest metrics, traditional market indices, and macroeconomic indicators. We\nintroduce the Crypto100 index, representing the top 100 cryptocurrencies by\nmarket capitalization, and propose a novel feature reduction algorithm to\nidentify the most impactful and resilient features from diverse data sources.\nOur comprehensive experiments demonstrate that data source diversity\nsignificantly enhances the predictive performance of forecasting models across\ndifferent time horizons. Key findings include the paramount importance of\non-chain metrics for both short-term and long-term predictions, the growing\nrelevance of traditional market indices and macroeconomic indicators for\nlonger-term forecasts, and substantial improvements in model accuracy when\ndiverse data sources are utilized. These insights help demystify the short-term\nand long-term driving factors of the cryptocurrency market and lay the\ngroundwork for developing more accurate and resilient forecasting models.\n","authors":["Giorgos Demosthenous","Chryssis Georgiou","Eliada Polydorou"],"pdf_url":"https://arxiv.org/pdf/2506.21246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21240v1","updated":"2025-06-26T13:23:57Z","published":"2025-06-26T13:23:57Z","title":"Zero-Shot Learning for Obsolescence Risk Forecasting","summary":"  Component obsolescence poses significant challenges in industries reliant on\nelectronic components, causing increased costs and disruptions in the security\nand availability of systems. Accurate obsolescence risk prediction is essential\nbut hindered by a lack of reliable data. This paper proposes a novel approach\nto forecasting obsolescence risk using zero-shot learning (ZSL) with large\nlanguage models (LLMs) to address data limitations by leveraging\ndomain-specific knowledge from tabular datasets. Applied to two real-world\ndatasets, the method demonstrates effective risk prediction. A comparative\nevaluation of four LLMs underscores the importance of selecting the right model\nfor specific forecasting tasks.\n","authors":["Elie Saad","Aya Mrabah","Mariem Besbes","Marc Zolghadri","Victor Czmil","Claude Baron","Vincent Bourgeois"],"pdf_url":"https://arxiv.org/pdf/2506.21240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13358v2","updated":"2025-06-26T13:21:53Z","published":"2024-07-18T10:01:09Z","title":"Capturing Style in Author and Document Representation","summary":"  A wide range of Deep Natural Language Processing (NLP) models integrates\ncontinuous and low dimensional representations of words and documents.\nSurprisingly, very few models study representation learning for authors. These\nrepresentations can be used for many NLP tasks, such as author identification\nand classification, or in recommendation systems. A strong limitation of\nexisting works is that they do not explicitly capture writing style, making\nthem hardly applicable to literary data. We therefore propose a new\narchitecture based on Variational Information Bottleneck (VIB) that learns\nembeddings for both authors and documents with a stylistic constraint. Our\nmodel fine-tunes a pre-trained document encoder. We stimulate the detection of\nwriting style by adding predefined stylistic features making the representation\naxis interpretable with respect to writing style indicators. We evaluate our\nmethod on three datasets: a literary corpus extracted from the Gutenberg\nProject, the Blog Authorship Corpus and IMDb62, for which we show that it\nmatches or outperforms strong/recent baselines in authorship attribution while\ncapturing much more accurately the authors stylistic aspects.\n","authors":["Enzo Terreau","Antoine Gourru","Julien Velcin"],"pdf_url":"https://arxiv.org/pdf/2407.13358v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00488v3","updated":"2025-06-26T13:16:22Z","published":"2024-08-31T15:47:31Z","title":"Rapid Gyroscope Calibration: A Deep Learning Approach","summary":"  Low-cost gyroscope calibration is essential for ensuring the accuracy and\nreliability of gyroscope measurements. Stationary calibration estimates the\ndeterministic parts of measurement errors. To this end, a common practice is to\naverage the gyroscope readings during a predefined period and estimate the\ngyroscope bias. Calibration duration plays a crucial role in performance,\ntherefore, longer periods are preferred. However, some applications require\nquick startup times and calibration is therefore allowed only for a short time.\nIn this work, we focus on reducing low-cost gyroscope calibration time using\ndeep learning methods. We propose an end-to-end convolutional neural network\nfor the application of gyroscope calibration. We explore the possibilities of\nusing multiple real and virtual gyroscopes to improve the calibration\nperformance of single gyroscopes. To train and validate our approach, we\nrecorded a dataset consisting of 186.6 hours of gyroscope readings, using 36\ngyroscopes of four different brands. We also created a virtual dataset\nconsisting of simulated gyroscope readings. The six datasets were used to\nevaluate our proposed approach. One of our key achievements in this work is\nreducing gyroscope calibration time by up to 89% using three low-cost\ngyroscopes. Our dataset is publicly available to allow reproducibility of our\nwork and to increase research in the field.\n","authors":["Yair Stolero","Itzik Klein"],"pdf_url":"https://arxiv.org/pdf/2409.00488v3.pdf","comment":"10 Pages, 14 Figures"},{"id":"http://arxiv.org/abs/2506.21220v1","updated":"2025-06-26T13:13:24Z","published":"2025-06-26T13:13:24Z","title":"Complexity-aware fine-tuning","summary":"  General-purpose Large Language Models (LLMs) are frequently fine-tuned\nthrough supervised fine-tuning (SFT) to enhance performance in specific\ndomains. Better results can be achieved by distilling the chain-of-thought of a\nlarger model at the cost of numerous expensive calls and a much greater amount\nof data. We propose a novel blueprint for efficient fine-tuning that uses\nreasoning only for complex data identified by entropy. Specifically, across two\nsmall open models ($\\approx 3B$) we split the training data into complexity\ncategories by a single token answer entropy (ROC AUC $0.73$), fine-tune large\nlanguage models (LLMs) via SFT and distillation, and show that our pipeline\nsignificantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average\naccuracy) and provides comparable with distillation performance while using\n$62\\%$ less data ($0.55$ average accuracy for both). We publish our code and\ndata to facilitate further research in this direction.\n","authors":["Andrey Goncharov","Daniil Vyazhev","Petr Sychev","Edvard Khalafyan","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2506.21220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14712v3","updated":"2025-06-26T13:12:25Z","published":"2023-12-22T14:10:07Z","title":"Balancing Privacy, Robustness, and Efficiency in Machine Learning","summary":"  This position paper argues that achieving robustness, privacy, and efficiency\nsimultaneously in machine learning systems is infeasible under prevailing\nthreat models. The tension between these goals arises not from algorithmic\nshortcomings but from structural limitations imposed by worst-case adversarial\nassumptions. We advocate for a systematic research agenda aimed at formalizing\nthe robustness-privacy-efficiency trilemma, exploring how principled\nrelaxations of threat models can unlock better trade-offs, and designing\nbenchmarks that expose rather than obscure the compromises made. By shifting\nfocus from aspirational universal guarantees to context-aware system design,\nthe machine learning community can build models that are truly appropriate for\nreal-world deployment.\n","authors":["Youssef Allouah","Rachid Guerraoui","John Stephan"],"pdf_url":"https://arxiv.org/pdf/2312.14712v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21215v1","updated":"2025-06-26T13:11:01Z","published":"2025-06-26T13:11:01Z","title":"Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?","summary":"  Causal reasoning capability is critical in advancing large language models\n(LLMs) toward strong artificial intelligence. While versatile LLMs appear to\nhave demonstrated capabilities in understanding contextual causality and\nproviding responses that obey the laws of causality, it remains unclear whether\nthey perform genuine causal reasoning akin to humans. However, current evidence\nindicates the contrary. Specifically, LLMs are only capable of performing\nshallow (level-1) causal reasoning, primarily attributed to the causal\nknowledge embedded in their parameters, but they lack the capacity for genuine\nhuman-like (level-2) causal reasoning. To support this hypothesis,\nmethodologically, we delve into the autoregression mechanism of\ntransformer-based LLMs, revealing that it is not inherently causal.\nEmpirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,\nwhose corpora are fresh and nearly unseen for the studied LLMs. The LLMs\nexhibit a significant performance drop on CausalProbe-2024 compared to earlier\nbenchmarks, indicating the fact that they primarily engage in level-1 causal\nreasoning. To bridge the gap towards level-2 causal reasoning, we draw\ninspiration from the fact that human reasoning is usually facilitated by\ngeneral knowledge and intended goals. We propose G^2-Reasoner, a method that\nincorporates general knowledge and goal-oriented prompts into LLMs' causal\nreasoning processes. Experiments demonstrate that G^2-Reasoner significantly\nenhances LLMs' causal reasoning capability, particularly in fresh and\ncounterfactual contexts. This work sheds light on a new path for LLMs to\nadvance towards genuine causal reasoning, going beyond level-1 and making\nstrides towards level-2.\n","authors":["Haoang Chi","He Li","Wenjing Yang","Feng Liu","Long Lan","Xiaoguang Ren","Tongliang Liu","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2506.21215v1.pdf","comment":"24 pages, accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2506.12025v2","updated":"2025-06-26T13:01:32Z","published":"2025-05-21T09:29:19Z","title":"Unsupervised Learning for Optimal Transport plan prediction between\n  unbalanced graphs","summary":"  Optimal transport between graphs, based on Gromov-Wasserstein and\n  other extensions, is a powerful tool for comparing and aligning\n  graph structures. However, solving the associated non-convex\n  optimization problems is computationally expensive, which limits the\n  scalability of these methods to large graphs. In this work, we\n  present Unbalanced Learning of Optimal Transport (ULOT), a deep\n  learning method that predicts optimal transport plans between two\n  graphs. Our method is trained by minimizing the fused unbalanced\n  Gromov-Wasserstein (FUGW) loss. We propose a novel neural\n  architecture with cross-attention that is conditioned on the FUGW\n  tradeoff hyperparameters. We evaluate ULOT on synthetic stochastic\n  block model (SBM) graphs and on real cortical surface data obtained\n  from fMRI. ULOT predicts transport plans with competitive loss up to\n  two orders of magnitude faster than classical solvers. Furthermore,\n  the predicted plan can be used as a warm start for classical solvers\n  to accelerate their convergence. Finally, the predicted transport\n  plan is fully differentiable with respect to the graph inputs and\n  FUGW hyperparameters, enabling the optimization of functionals of\n  the ULOT plan.\n","authors":["Sonia Mazelet","Rémi Flamary","Bertrand Thirion"],"pdf_url":"https://arxiv.org/pdf/2506.12025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00753v4","updated":"2025-06-26T12:53:30Z","published":"2025-05-01T08:29:26Z","title":"LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey","summary":"  Recent advances in large language models (LLMs) have sparked growing interest\nin building fully autonomous agents. However, fully autonomous LLM-based agents\nstill face significant challenges, including limited reliability due to\nhallucinations, difficulty in handling complex tasks, and substantial safety\nand ethical risks, all of which limit their feasibility and trustworthiness in\nreal-world applications. To overcome these limitations, LLM-based human-agent\nsystems (LLM-HAS) incorporate human-provided information, feedback, or control\ninto the agent system to enhance system performance, reliability and safety.\nThese human-agent collaboration systems enable humans and LLM-based agents to\ncollaborate effectively by leveraging their complementary strengths. This paper\nprovides the first comprehensive and structured survey of LLM-HAS. It clarifies\nfundamental concepts, systematically presents core components shaping these\nsystems, including environment & profiling, human feedback, interaction types,\norchestration and communication, explores emerging applications, and discusses\nunique challenges and opportunities arising from human-AI collaboration. By\nconsolidating current knowledge and offering a structured overview, we aim to\nfoster further research and innovation in this rapidly evolving\ninterdisciplinary field. Paper lists and resources are available at\nhttps://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems.\n","authors":["Henry Peng Zou","Wei-Chieh Huang","Yaozu Wu","Yankai Chen","Chunyu Miao","Hoang Nguyen","Yue Zhou","Weizhi Zhang","Liancheng Fang","Langzhou He","Yangning Li","Dongyuan Li","Renhe Jiang","Xue Liu","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2505.00753v4.pdf","comment":"Paper lists and resources are available at\n  https://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems"},{"id":"http://arxiv.org/abs/2503.08829v2","updated":"2025-06-26T12:48:11Z","published":"2025-03-11T19:08:31Z","title":"Seal Your Backdoor with Variational Defense","summary":"  We propose VIBE, a model-agnostic framework that trains classifiers resilient\nto backdoor attacks. The key concept behind our approach is to treat malicious\ninputs and corrupted labels from the training dataset as observed random\nvariables, while the actual clean labels are latent. VIBE then recovers the\ncorresponding latent clean label posterior through variational inference. The\nresulting training procedure follows the expectation-maximization (EM)\nalgorithm. The E-step infers the clean pseudolabels by solving an\nentropy-regularized optimal transport problem, while the M-step updates the\nclassifier parameters via gradient descent. Being modular, VIBE can seamlessly\nintegrate with recent advancements in self-supervised representation learning,\nwhich enhance its ability to resist backdoor attacks. We experimentally\nvalidate the method effectiveness against contemporary backdoor attacks on\nstandard datasets, a large-scale setup with 1$k$ classes, and a dataset\npoisoned with multiple attacks. VIBE consistently outperforms previous defenses\nacross all tested scenarios.\n","authors":["Ivan Sabolić","Matej Grcić","Siniša Šegvić"],"pdf_url":"https://arxiv.org/pdf/2503.08829v2.pdf","comment":"Accepted to ICCV 2025"},{"id":"http://arxiv.org/abs/2506.21186v1","updated":"2025-06-26T12:44:50Z","published":"2025-06-26T12:44:50Z","title":"Artificial Delegates Resolve Fairness Issues in Perpetual Voting with\n  Partial Turnout","summary":"  Perpetual voting addresses fairness in sequential collective decision-making\nby evaluating representational equity over time. However, existing perpetual\nvoting rules rely on full participation and complete approval information,\nassumptions that rarely hold in practice, where partial turnout is the norm. In\nthis work, we study the integration of Artificial Delegates,\npreference-learning agents trained to represent absent voters, into perpetual\nvoting systems. We examine how absenteeism affects fairness and\nrepresentativeness under various voting methods and evaluate the extent to\nwhich Artificial Delegates can compensate for missing participation. Our\nfindings indicate that while absenteeism significantly affects fairness,\nArtificial Delegates reliably mitigate these effects and enhance robustness\nacross diverse scenarios.\n","authors":["Apurva Shah","Axel Abels","Ann Nowé","Tom Lenaerts"],"pdf_url":"https://arxiv.org/pdf/2506.21186v1.pdf","comment":"The paper has been accepted at the ACM Collective Intelligence\n  Conference (CI 2025), August 4 to 6, 2025, San Diego, CA, USA"},{"id":"http://arxiv.org/abs/2504.16320v2","updated":"2025-06-26T12:42:10Z","published":"2025-04-22T23:37:05Z","title":"PCF-Grasp: Converting Point Completion to Geometry Feature to Enhance\n  6-DoF Grasp","summary":"  The 6-Degree of Freedom (DoF) grasp method based on point clouds has shown\nsignificant potential in enabling robots to grasp target objects. However, most\nexisting methods are based on the point clouds (2.5D points) generated from\nsingle-view depth images. These point clouds only have one surface side of the\nobject providing incomplete geometry information, which mislead the grasping\nalgorithm to judge the shape of the target object, resulting in low grasping\naccuracy. Humans can accurately grasp objects from a single view by leveraging\ntheir geometry experience to estimate object shapes. Inspired by humans, we\npropose a novel 6-DoF grasping framework that converts the point completion\nresults as object shape features to train the 6-DoF grasp network. Here, point\ncompletion can generate approximate complete points from the 2.5D points\nsimilar to the human geometry experience, and converting it as shape features\nis the way to utilize it to improve grasp efficiency. Furthermore, due to the\ngap between the network generation and actual execution, we integrate a score\nfilter into our framework to select more executable grasp proposals for the\nreal robot. This enables our method to maintain a high grasp quality in any\ncamera viewpoint. Extensive experiments demonstrate that utilizing complete\npoint features enables the generation of significantly more accurate grasp\nproposals and the inclusion of a score filter greatly enhances the credibility\nof real-world robot grasping. Our method achieves a 17.8\\% success rate higher\nthan the state-of-the-art method in real-world experiments.\n","authors":["Yaofeng Cheng","Fusheng Zha","Wei Guo","Pengfei Wang","Chao Zeng","Lining Sun","Chenguang Yang"],"pdf_url":"https://arxiv.org/pdf/2504.16320v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21174v1","updated":"2025-06-26T12:27:52Z","published":"2025-06-26T12:27:52Z","title":"Performance improvement of spatial semantic segmentation with enriched\n  audio features and agent-based error correction for DCASE 2025 Challenge Task\n  4","summary":"  This technical report presents submission systems for Task 4 of the DCASE\n2025 Challenge. This model incorporates additional audio features (spectral\nroll-off and chroma features) into the embedding feature extracted from the\nmel-spectral feature to im-prove the classification capabilities of an\naudio-tagging model in the spatial semantic segmentation of sound scenes (S5)\nsystem. This approach is motivated by the fact that mixed audio often contains\nsubtle cues that are difficult to capture with mel-spectrograms alone. Thus,\nthese additional features offer alterna-tive perspectives for the model.\nSecond, an agent-based label correction system is applied to the outputs\nprocessed by the S5 system. This system reduces false positives, improving the\nfinal class-aware signal-to-distortion ratio improvement (CA-SDRi) metric.\nFinally, we refine the training dataset to enhance the classi-fication accuracy\nof low-performing classes by removing irrele-vant samples and incorporating\nexternal data. That is, audio mix-tures are generated from a limited number of\ndata points; thus, even a small number of out-of-class data points could\ndegrade model performance. The experiments demonstrate that the submit-ted\nsystems employing these approaches relatively improve CA-SDRi by up to 14.7%\ncompared to the baseline of DCASE 2025 Challenge Task 4.\n","authors":["Jongyeon Park","Joonhee Lee","Do-Hyeon Lim","Hong Kook Kim","Hyeongcheol Geum","Jeong Eun Lim"],"pdf_url":"https://arxiv.org/pdf/2506.21174v1.pdf","comment":"DCASE 2025 challenge Task4, 5 pages"},{"id":"http://arxiv.org/abs/2506.07413v2","updated":"2025-06-26T12:27:25Z","published":"2025-06-09T04:19:12Z","title":"Variational Supervised Contrastive Learning","summary":"  Contrastive learning has proven to be highly efficient and adaptable in\nshaping representation spaces across diverse modalities by pulling similar\nsamples together and pushing dissimilar ones apart. However, two key\nlimitations persist: (1) Without explicit regulation of the embedding\ndistribution, semantically related instances can inadvertently be pushed apart\nunless complementary signals guide pair selection, and (2) excessive reliance\non large in-batch negatives and tailored augmentations hinders generalization.\nTo address these limitations, we propose Variational Supervised Contrastive\nLearning (VarCon), which reformulates supervised contrastive learning as\nvariational inference over latent class variables and maximizes a\nposterior-weighted evidence lower bound (ELBO) that replaces exhaustive\npair-wise comparisons for efficient class-aware matching and grants\nfine-grained control over intra-class dispersion in the embedding space.\nTrained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,\nImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art\nperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy\non ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while\nconverging in just 200 epochs; (2) yields substantially clearer decision\nboundaries and semantic organization in the embedding space, as evidenced by\nKNN classification, hierarchical clustering results, and transfer-learning\nassessments; and (3) demonstrates superior performance in few-shot learning\nthan supervised baseline and superior robustness across various augmentation\nstrategies.\n","authors":["Ziwen Wang","Jiajun Fan","Thao Nguyen","Heng Ji","Ge Liu"],"pdf_url":"https://arxiv.org/pdf/2506.07413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07229v2","updated":"2025-06-26T12:06:00Z","published":"2024-12-10T06:41:18Z","title":"Moderating the Generalization of Score-based Generative Model","summary":"  Score-based Generative Models (SGMs) have demonstrated remarkable\ngeneralization abilities, e.g. generating unseen, but natural data. However,\nthe greater the generalization power, the more likely the unintended\ngeneralization, and the more dangerous the abuse. Research on moderated\ngeneralization in SGMs remains limited. To fill this gap, we first examine the\ncurrent 'gold standard' in Machine Unlearning (MU), i.e., re-training the model\nafter removing the undesirable training data, and find it does not work in\nSGMs. Further analysis of score functions reveals that the MU 'gold standard'\ndoes not alter the original score function, which explains its ineffectiveness.\nBased on this insight, we propose the first Moderated Score-based Generative\nModel (MSGM), which introduces a novel score adjustment strategy that redirects\nthe score function away from undesirable data during the continuous-time\nstochastic differential equation process. Extensive experimental results\ndemonstrate that MSGM significantly reduces the likelihood of generating\nundesirable content while preserving high visual quality for normal image\ngeneration. Albeit designed for SGMs, MSGM is a general and flexible MU\nframework that is compatible with diverse diffusion architectures (SGM and\nDDPM) and training strategies (re-training and fine-tuning), and enables\nzero-shot transfer of the pre-trained models to downstream tasks, e.g. image\ninpainting and reconstruction. The code will be shared upon acceptance.\n","authors":["Wan Jiang","He Wang","Xin Zhang","Dan Guo","Zhaoxin Fan","Yunfeng Diao","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2412.07229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13056v2","updated":"2025-06-26T11:45:11Z","published":"2025-06-16T02:56:13Z","title":"Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model\n  Learning","summary":"  Recent advancements in large language models (LLMs) have witnessed a surge in\nthe development of advanced reasoning paradigms, which are now being integrated\ninto multimodal large language models (MLLMs). However, existing approaches\noften fall short: methods solely employing reinforcement learning (RL) can\nstruggle with sample inefficiency and activating entirely absent reasoning\ncapabilities, while conventional pipelines that initiate with a cold-start\nsupervised fine-tuning (SFT) phase before RL may restrict the model's\nexploratory capacity and face suboptimal convergence. In this work, we\nintroduce \\textbf{Metis-RISE} (\\textbf{R}L \\textbf{I}ncentivizes and\n\\textbf{S}FT \\textbf{E}nhances) for multimodal reasoning model learning. Unlike\nconventional approaches, Metis-RISE distinctively omits an initial SFT stage,\nbeginning instead with an RL phase (e.g., using a Group Relative Policy\nOptimization variant) to incentivize and activate the model's latent reasoning\ncapacity. Subsequently, the targeted SFT stage addresses two key challenges\nidentified during RL: (1) \\textit{inefficient trajectory sampling} for tasks\nwhere the model possesses but inconsistently applies correct reasoning, which\nwe tackle using self-distilled reasoning trajectories from the RL model itself;\nand (2) \\textit{fundamental capability absence}, which we address by injecting\nexpert-augmented knowledge for prompts where the model entirely fails. This\nstrategic application of RL for incentivization followed by SFT for enhancement\nforms the core of Metis-RISE, leading to two versions of our MLLMs (7B and 72B\nparameters). Evaluations on the OpenCompass Multimodal Reasoning Leaderboard\ndemonstrate that both models achieve state-of-the-art performance among\nsimilar-sized models, with the 72B version ranking fourth overall. Please refer\nto our project page for open-source information.\n","authors":["Haibo Qiu","Xiaohan Lan","Fanfan Liu","Xiaohu Sun","Delian Ruan","Peng Shi","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2506.13056v2.pdf","comment":"Project Page: https://github.com/MM-Thinking/Metis-RISE"},{"id":"http://arxiv.org/abs/2403.14684v2","updated":"2025-06-26T11:35:57Z","published":"2024-03-13T13:51:12Z","title":"Self-Regulated Neurogenesis for Online Data-Incremental Learning","summary":"  Neural networks often struggle with catastrophic forgetting when learning\nsequences of tasks or data streams, unlike humans who can continuously learn\nand consolidate new concepts even in the absence of explicit cues. Online\ndata-incremental learning seeks to emulate this capability by processing each\nsample only once, without having access to task or stream cues at any point in\ntime since this is more realistic compared to offline setups, where all data\nfrom novel class(es) is assumed to be readily available. However, existing\nmethods typically rely on storing the subsets of data in memory or expanding\nthe initial model architecture, resulting in significant computational\noverhead. Drawing inspiration from 'self-regulated neurogenesis'-brain's\nmechanism for creating specialized regions or circuits for distinct\nfunctions-we propose a novel approach SERENA which encodes each concept in a\nspecialized network path called 'concept cell', integrated into a single\nover-parameterized network. Once a concept is learned, its corresponding\nconcept cell is frozen, effectively preventing the forgetting of previously\nacquired information. Furthermore, we introduce two new continual learning\nscenarios that more closely reflect real-world conditions, characterized by\ngradually changing sample sizes. Experimental results show that our method not\nonly establishes new state-of-the-art results across ten benchmarks but also\nremarkably surpasses offline supervised batch learning performance. The code is\navailable at https://github.com/muratonuryildirim/serena.\n","authors":["Murat Onur Yildirim","Elif Ceren Gok Yildirim","Decebal Constantin Mocanu","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2403.14684v2.pdf","comment":"Published at Conference on Lifelong Learning Agents (CoLLAs) 2025"},{"id":"http://arxiv.org/abs/2506.21158v1","updated":"2025-06-26T11:31:30Z","published":"2025-06-26T11:31:30Z","title":"Diverse Mini-Batch Selection in Reinforcement Learning for Efficient\n  Chemical Exploration in de novo Drug Design","summary":"  In many real-world applications, evaluating the goodness of instances is\noften costly and time-consuming, e.g., human feedback and physics simulations,\nin contrast to proposing new instances. In particular, this is even more\ncritical in reinforcement learning, as new interactions with the environment\n(i.e., new instances) need to be evaluated to provide a reward signal to learn\nfrom. As sufficient exploration is crucial, learning from a diverse mini-batch\ncan have a large impact and help mitigate mode collapse. In this paper, we\nintroduce diverse mini-batch selection for reinforcement learning and propose\nto use determinantal point processes for this task. We study this framework in\nthe context of a real-world problem, namely drug discovery. We experimentally\nstudy how our proposed framework can improve the effectiveness of chemical\nexploration in de novo drug design, where finding diverse and high-quality\nsolutions is essential. We conduct a comprehensive evaluation with three\nwell-established molecular generation oracles over numerous generative steps.\nOur experiments conclude that our diverse mini-batch selection framework can\nsubstantially improve the diversity of the solutions, while still obtaining\nsolutions of high quality. In drug discovery, such outcome can potentially lead\nto fulfilling unmet medication needs faster.\n","authors":["Hampus Gummesson Svensson","Ola Engkvist","Jon Paul Janet","Christian Tyrchan","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2506.21158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21154v1","updated":"2025-06-26T11:24:46Z","published":"2025-06-26T11:24:46Z","title":"Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation","summary":"  The real world naturally has dimensions of time and space. Therefore,\nestimating the counterfactual outcomes with spatial-temporal attributes is a\ncrucial problem. However, previous methods are based on classical statistical\nmodels, which still have limitations in performance and generalization. This\npaper proposes a novel framework for estimating counterfactual outcomes with\nspatial-temporal attributes using the Transformer, exhibiting stronger\nestimation ability. Under mild assumptions, the proposed estimator within this\nframework is consistent and asymptotically normal. To validate the\neffectiveness of our approach, we conduct simulation experiments and real data\nexperiments. Simulation experiments show that our estimator has a stronger\nestimation capability than baseline methods. Real data experiments provide a\nvaluable conclusion to the causal effect of conflicts on forest loss in\nColombia. The source code is available at\nhttps://github.com/lihe-maxsize/DeppSTCI_Release_Version-master.\n","authors":["He Li","Haoang Chi","Mingyu Liu","Wanrong Huang","Liyang Xu","Wenjing Yang"],"pdf_url":"https://arxiv.org/pdf/2506.21154v1.pdf","comment":"24 pages, accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2312.04135v3","updated":"2025-06-26T11:21:32Z","published":"2023-12-07T08:50:25Z","title":"A Novel Federated Learning-Based IDS for Enhancing UAVs Privacy and\n  Security","summary":"  Unmanned aerial vehicles (UAVs) operating within Flying Ad-hoc Networks\n(FANETs) encounter security challenges due to the dynamic and distributed\nnature of these networks. Previous studies focused predominantly on centralized\nintrusion detection, assuming a central entity responsible for storing and\nanalyzing data from all devices. However, these approaches face challenges\nincluding computation and storage costs, along with a single point of failure\nrisk, threatening data privacy and availability. The widespread dispersion of\ndata across interconnected devices underscores the need for decentralized\napproaches. This paper introduces the Federated Learning-based Intrusion\nDetection System (FL-IDS), addressing challenges encountered by centralized\nsystems in FANETs. FL-IDS reduces computation and storage costs for both\nclients and the central server, which is crucial for resource-constrained UAVs.\nOperating in a decentralized manner, FL-IDS enables UAVs to collaboratively\ntrain a global intrusion detection model without sharing raw data, thus\navoiding delay in decisions based on collected data, as is often the case with\ntraditional methods. Experimental results demonstrate FL-IDS's competitive\nperformance with Central IDS (C-IDS) while mitigating privacy concerns, with\nthe Bias Towards Specific Clients (BTSC) method further enhancing FL-IDS\nperformance even at lower attacker ratios. Comparative analysis with\ntraditional intrusion detection methods, including Local IDS (L-IDS), sheds\nlight on the strengths of FL-IDS. This study significantly contributes to UAV\nsecurity by introducing a privacy-aware, decentralized intrusion detection\napproach tailored to UAV networks. Moreover, by introducing a realistic dataset\nfor FANETs and federated learning, our approach differs from others lacking\nhigh dynamism and 3D node movements or accurate federated data federations.\n","authors":["Ozlem Ceviz","Pinar Sadioglu","Sevil Sen","Vassilios G. Vassilakis"],"pdf_url":"https://arxiv.org/pdf/2312.04135v3.pdf","comment":"Published in Internet of Things, Volume 25, 2025, Article 101592"},{"id":"http://arxiv.org/abs/2506.21146v1","updated":"2025-06-26T11:04:12Z","published":"2025-06-26T11:04:12Z","title":"Linearity-based neural network compression","summary":"  In neural network compression, most current methods reduce unnecessary\nparameters by measuring importance and redundancy. To augment already highly\noptimized existing solutions, we propose linearity-based compression as a novel\nway to reduce weights in a neural network. It is based on the intuition that\nwith ReLU-like activation functions, neurons that are almost always activated\nbehave linearly, allowing for merging of subsequent layers. We introduce the\ntheory underlying this compression and evaluate our approach experimentally.\nOur novel method achieves a lossless compression down to 1/4 of the original\nmodel size in over the majority of tested models. Applying our method on\nalready importance-based pruned models shows very little interference between\ndifferent types of compression, demonstrating the option of successful\ncombination of techniques. Overall, our work lays the foundation for a new type\nof compression method that enables smaller and ultimately more efficient neural\nnetwork models.\n","authors":["Silas Dobler","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2506.21146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21144v1","updated":"2025-06-26T10:59:14Z","published":"2025-06-26T10:59:14Z","title":"Personalized Federated Learning via Dual-Prompt Optimization and Cross\n  Fusion","summary":"  Federated learning (FL) enables collaborative model training across\ndecentralized clients without sharing local data, but is challenged by\nheterogeneity in data, computation, and communication. Pretrained\nvision-language models (VLMs), with their strong generalization and lightweight\ntuning via prompts, offer a promising solution. However, existing federated\nprompt-learning methods rely only on text prompts and overlook joint\nlabel-domain distribution shifts. In this paper, we propose a personalized FL\nframework based on dual-prompt learning and cross fusion, termed pFedDC.\nSpecifically, each client maintains both global and local prompts across vision\nand language modalities: global prompts capture common knowledge shared across\nthe federation, while local prompts encode client-specific semantics and domain\ncharacteristics. Meanwhile, a cross-fusion module is designed to adaptively\nintegrate prompts from different levels, enabling the model to generate\npersonalized representations aligned with each client's unique data\ndistribution. Extensive experiments across nine datasets with various types of\nheterogeneity show that pFedDC consistently outperforms state-of-the-art\nmethods.\n","authors":["Yuguang Zhang","Kuangpu Guo","Zhihe Lu","Yunbo Wang","Jian Liang"],"pdf_url":"https://arxiv.org/pdf/2506.21144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21142v1","updated":"2025-06-26T10:56:34Z","published":"2025-06-26T10:56:34Z","title":"Generative Adversarial Evasion and Out-of-Distribution Detection for UAV\n  Cyber-Attacks","summary":"  The growing integration of UAVs into civilian airspace underscores the need\nfor resilient and intelligent intrusion detection systems (IDS), as traditional\nanomaly detection methods often fail to identify novel threats. A common\napproach treats unfamiliar attacks as out-of-distribution (OOD) samples;\nhowever, this leaves systems vulnerable when mitigation is inadequate.\nMoreover, conventional OOD detectors struggle to distinguish stealthy\nadversarial attacks from genuine OOD events. This paper introduces a\nconditional generative adversarial network (cGAN)-based framework for crafting\nstealthy adversarial attacks that evade IDS mechanisms. We first design a\nrobust multi-class IDS classifier trained on benign UAV telemetry and known\ncyber-attacks, including Denial of Service (DoS), false data injection (FDI),\nman-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN\nperturbs known attacks to generate adversarial samples that misclassify as\nbenign while retaining statistical resemblance to OOD distributions. These\nadversarial samples are iteratively refined to achieve high stealth and success\nrates. To detect such perturbations, we implement a conditional variational\nautoencoder (CVAE), leveraging negative log-likelihood to separate adversarial\ninputs from authentic OOD samples. Comparative evaluation shows that CVAE-based\nregret scores significantly outperform traditional Mahalanobis distance-based\ndetectors in identifying stealthy adversarial threats. Our findings emphasize\nthe importance of advanced probabilistic modeling to strengthen IDS\ncapabilities against adaptive, generative-model-based cyber intrusions.\n","authors":["Deepak Kumar Panda","Weisi Guo"],"pdf_url":"https://arxiv.org/pdf/2506.21142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.01431v2","updated":"2025-06-26T10:53:38Z","published":"2025-04-02T07:33:54Z","title":"Multi-convex Programming for Discrete Latent Factor Models Prototyping","summary":"  Discrete latent factor models (DLFMs) are widely used in various domains such\nas machine learning, economics, neuroscience, psychology, etc. Currently,\nfitting a DLFM to some dataset relies on a customized solver for individual\nmodels, which requires lots of effort to implement and is limited to the\ntargeted specific instance of DLFMs. In this paper, we propose a generic\nframework based on CVXPY, which allows users to specify and solve the fitting\nproblem of a wide range of DLFMs, including both regression and classification\nmodels, within a very short script. Our framework is flexible and inherently\nsupports the integration of regularization terms and constraints on the DLFM\nparameters and latent factors, such that the users can easily prototype the\nDLFM structure according to their dataset and application scenario. We\nintroduce our open-source Python implementation and illustrate the framework in\nseveral examples.\n","authors":["Hao Zhu","Shengchao Yan","Jasper Hoffmann","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2504.01431v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21140v1","updated":"2025-06-26T10:53:24Z","published":"2025-06-26T10:53:24Z","title":"DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding","summary":"  Electroencephalography (EEG)-based brain-computer interfaces (BCIs) transform\nspontaneous/evoked neural activity into control commands for external\ncommunication. While convolutional neural networks (CNNs) remain the mainstream\nbackbone for EEG decoding, their inherently short receptive field makes it\ndifficult to capture long-range temporal dependencies and global inter-channel\nrelationships. Recent CNN-Transformer (Conformers) hybrids partially address\nthis issue, but most adopt a serial design, resulting in suboptimal integration\nof local and global features, and often overlook explicit channel-wise\nmodeling. To address these limitations, we propose DBConformer, a dual-branch\nconvolutional Transformer network tailored for EEG decoding. It integrates a\ntemporal Conformer to model long-range temporal dependencies and a spatial\nConformer to extract inter-channel interactions, capturing both temporal\ndynamics and spatial patterns in EEG signals. A lightweight channel attention\nmodule further refines spatial representations by assigning data-driven\nimportance to EEG channels. Extensive experiments on five motor imagery (MI)\ndatasets and two seizure detection datasets under three evaluation settings\ndemonstrate that DBConformer consistently outperforms 10 competitive baseline\nmodels, with over eight times fewer parameters than the high-capacity EEG\nConformer baseline. Further, the visualization results confirm that the\nfeatures extracted by DBConformer are physiologically interpretable and aligned\nwith sensorimotor priors in MI. The superior performance and interpretability\nof DBConformer make it reliable for robust and explainable EEG decoding. Code\nis publicized at https://github.com/wzwvv/DBConformer.\n","authors":["Ziwei Wang","Hongbin Wang","Tianwang Jia","Xingyi He","Siyang Li","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2506.21140v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.18945v3","updated":"2025-06-26T10:49:32Z","published":"2025-01-31T08:08:32Z","title":"Solving Inverse Problem for Multi-armed Bandits via Convex Optimization","summary":"  We consider the inverse problem of multi-armed bandits (IMAB) that are widely\nused in neuroscience and psychology research for behavior modelling. We first\nshow that the IMAB problem is not convex in general, but can be relaxed to a\nconvex problem via variable transformation. Based on this result, we propose a\ntwo-step sequential heuristic for (approximately) solving the IMAB problem. We\ndiscuss a condition where our method provides global solution to the IMAB\nproblem with certificate, as well as approximations to further save computing\ntime. Numerical experiments indicate that our heuristic method is more robust\nthan directly solving the IMAB problem via repeated local optimization, and can\nachieve the performance of Monte Carlo methods within a significantly decreased\nrunning time. We provide the implementation of our method based on CVXPY, which\nallows straightforward application by users not well versed in convex\noptimization.\n","authors":["Hao Zhu","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2501.18945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21137v1","updated":"2025-06-26T10:47:39Z","published":"2025-06-26T10:47:39Z","title":"NaLaFormer: Norm-Aware Linear Attention for Transformer Models","summary":"  Linear attention has emerged as a viable alternative to softmax attention by\nreducing complexity from quadratic to linear in sequence length. To preserve\ntwo fundamental properties of softmax, non-negativity and entropy reduction,\ncurrent works employ various linearly separatable kernel functions with $L1$\nnormalization instead of softmax operator. However, query norms are neglected\nby the normalization operation in linear attention, such degradation heavily\nleads to an entropy gap. Meanwhile, existing works inhibit negative values of\nquery and key vectors resulting in a missing inner-product interactions after\nbeing mapped. To address these dual challenges, we propose a novel Norm-Aware\nLinear Attention mechanism serving to restore norm-guided dynamic spikiness and\nrecover kernel-perturbed norm distributions. Specifically, we first decouple\nquery and key matrices into two components: norm and direction, to achieve\nnorm-aware spikiness control and norm consistency, respectively. We\nmathematically reveal that the extent of entropy reduction varies with the\nquery norm in softmax normalization, motivating a query-norm aware kernel\nfunction for dynamic control over entropy reduction. Furthermore, to ensure\nnorm consistency and enforce non-negativity constraints, we employ a\nnorm-preserving mapping to project all elements of the angular matrix into\npositive values, leveraging cosine similarity to inhibit dimensions with\nopposite directions. We conduct extensive experiments demonstrating that the\nNaLaFormer improves performance on vision and language tasks, enhancing both\nexpressiveness and efficiency by up to 4.2\\%.\n","authors":["Weikang Meng","Yadan Luo","Liangyu Huo","Yaowei Wang","Xin Li","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.21137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15957v2","updated":"2025-06-26T10:46:25Z","published":"2025-01-27T11:03:18Z","title":"Inverse Reinforcement Learning via Convex Optimization","summary":"  We consider the inverse reinforcement learning (IRL) problem, where an\nunknown reward function of some Markov decision process is estimated based on\nobserved expert demonstrations. In most existing approaches, IRL is formulated\nand solved as a nonconvex optimization problem, posing challenges in scenarios\nwhere robustness and reproducibility are critical. We discuss a convex\nformulation of the IRL problem (CIRL) initially proposed by Ng and Russel, and\nreformulate the problem such that the domain-specific language CVXPY can be\napplied directly to specify and solve the convex problem. We also extend the\nCIRL problem to scenarios where the expert policy is not given analytically but\nby trajectory as state-action pairs, which can be strongly inconsistent with\noptimality, by augmenting some of the constraints. Theoretical analysis and\npractical implementation for hyperparameter auto-selection are introduced. This\nnote helps the users to easily apply CIRL for their problems, without\nbackground knowledge on convex optimization.\n","authors":["Hao Zhu","Yuan Zhang","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2501.15957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21129v1","updated":"2025-06-26T10:10:41Z","published":"2025-06-26T10:10:41Z","title":"Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV\n  Deconfliction under Observation-Space Attacks","summary":"  Reinforcement learning (RL) policies deployed in safety-critical systems,\nsuch as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are\nvulnerable to out-ofdistribution (OOD) adversarial attacks in the observation\nspace. These attacks induce distributional shifts that significantly degrade\nvalue estimation, leading to unsafe or suboptimal decision making rendering the\nexisting policy fragile. To address this vulnerability, we propose an\nantifragile RL framework designed to adapt against curriculum of incremental\nadversarial perturbations. The framework introduces a simulated attacker which\nincrementally increases the strength of observation-space perturbations which\nenables the RL agent to adapt and generalize across a wider range of OOD\nobservations and anticipate previously unseen attacks. We begin with a\ntheoretical characterization of fragility, formally defining catastrophic\nforgetting as a monotonic divergence in value function distributions with\nincreasing perturbation strength. Building on this, we define antifragility as\nthe boundedness of such value shifts and derive adaptation conditions under\nwhich forgetting is stabilized. Our method enforces these bounds through\niterative expert-guided critic alignment using Wasserstein distance\nminimization across incrementally perturbed observations. We empirically\nevaluate the approach in a UAV deconfliction scenario involving dynamic 3D\nobstacles. Results show that the antifragile policy consistently outperforms\nstandard and robust RL baselines when subjected to both projected gradient\ndescent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative\nreward and over 30% fewer conflict events. These findings demonstrate the\npractical and theoretical viability of antifragile reinforcement learning for\nsecure and resilient decision-making in environments with evolving threat\nscenarios.\n","authors":["Deepak Kumar Panda","Adolfo Perrusquia","Weisi Guo"],"pdf_url":"https://arxiv.org/pdf/2506.21129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21127v1","updated":"2025-06-26T10:06:29Z","published":"2025-06-26T10:06:29Z","title":"Robust Policy Switching for Antifragile Reinforcement Learning for UAV\n  Deconfliction in Adversarial Environments","summary":"  The increasing automation of navigation for unmanned aerial vehicles (UAVs)\nhas exposed them to adversarial attacks that exploit vulnerabilities in\nreinforcement learning (RL) through sensor manipulation. Although existing\nrobust RL methods aim to mitigate such threats, their effectiveness has limited\ngeneralization to out-of-distribution shifts from the optimal value\ndistribution, as they are primarily designed to handle fixed perturbation. To\naddress this limitation, this paper introduces an antifragile RL framework that\nenhances adaptability to broader distributional shifts by incorporating a\nswitching mechanism based on discounted Thompson sampling (DTS). This mechanism\ndynamically selects among multiple robust policies to minimize adversarially\ninduced state-action-value distribution shifts. The proposed approach first\nderives a diverse ensemble of action robust policies by accounting for a range\nof perturbations in the policy space. These policies are then modeled as a\nmultiarmed bandit (MAB) problem, where DTS optimally selects policies in\nresponse to nonstationary Bernoulli rewards, effectively adapting to evolving\nadversarial strategies. Theoretical framework has also been provided where by\noptimizing the DTS to minimize the overall regrets due to distributional shift,\nresults in effective adaptation against unseen adversarial attacks thus\ninducing antifragility. Extensive numerical simulations validate the\neffectiveness of the proposed framework in complex navigation environments with\nmultiple dynamic three-dimensional obstacles and with stronger projected\ngradient descent (PGD) and spoofing attacks. Compared to conventional robust,\nnon-adaptive RL methods, the antifragile approach achieves superior\nperformance, demonstrating shorter navigation path lengths and a higher rate of\nconflict-free navigation trajectories compared to existing robust RL techniques\n","authors":["Deepak Kumar Panda","Weisi Guo"],"pdf_url":"https://arxiv.org/pdf/2506.21127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21109v1","updated":"2025-06-26T09:06:52Z","published":"2025-06-26T09:06:52Z","title":"Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing\n  Change Detection","summary":"  Remote sensing change detection is essential for monitoring urban expansion,\ndisaster assessment, and resource management, offering timely, accurate, and\nlarge-scale insights into dynamic landscape transformations. While deep\nlearning has revolutionized change detection, the increasing complexity and\ncomputational demands of modern models have not necessarily translated into\nsignificant accuracy gains. Instead of following this trend, this study\nexplores a more efficient approach, focusing on lightweight models that\nmaintain high accuracy while minimizing resource consumption, which is an\nessential requirement for on-satellite processing. To this end, we propose\nFlickCD, which means quick flick then get great results, pushing the boundaries\nof the performance-resource trade-off. FlickCD introduces an Enhanced\nDifference Module (EDM) to amplify critical feature differences between\ntemporal phases while suppressing irrelevant variations such as lighting and\nweather changes, thereby reducing computational costs in the subsequent change\ndecoder. Additionally, the FlickCD decoder incorporates Local-Global Fusion\nBlocks, leveraging Shifted Window Self-Attention (SWSA) and Enhanced Global\nSelf-Attention (EGSA) to efficiently capture semantic information at multiple\nscales, preserving both coarse- and fine-grained changes. Extensive experiments\non four benchmark datasets demonstrate that FlickCD reduces computational and\nstorage overheads by more than an order of magnitude while achieving\nstate-of-the-art (SOTA) performance or incurring only a minor (<1\\% F1)\naccuracy trade-off. The implementation code is publicly available at\nhttps://github.com/xulsh8/FlickCD.\n","authors":["Luosheng Xu","Dalin Zhang","Zhaohui Song"],"pdf_url":"https://arxiv.org/pdf/2506.21109v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2506.21107v1","updated":"2025-06-26T09:05:38Z","published":"2025-06-26T09:05:38Z","title":"Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual\n  Conditional Diffusion Implicit Bridges","summary":"  Estimating single-cell responses across various perturbations facilitates the\nidentification of key genes and enhances drug screening, significantly boosting\nexperimental efficiency. However, single-cell sequencing is a destructive\nprocess, making it impossible to capture the same cell's phenotype before and\nafter perturbation. Consequently, data collected under perturbed and\nunperturbed conditions are inherently unpaired. Existing methods either attempt\nto forcibly pair unpaired data using random sampling, or neglect the inherent\nrelationship between unperturbed and perturbed cells during the modeling. In\nthis work, we propose a framework based on Dual Diffusion Implicit Bridges\n(DDIB) to learn the mapping between different data distributions, effectively\naddressing the challenge of unpaired data. We further interpret this framework\nas a form of data augmentation. We integrate gene regulatory network (GRN)\ninformation to propagate perturbation signals in a biologically meaningful way,\nand further incorporate a masking mechanism to predict silent genes, improving\nthe quality of generated profiles. Moreover, gene expression under the same\nperturbation often varies significantly across cells, frequently exhibiting a\nbimodal distribution that reflects intrinsic heterogeneity. To capture this, we\nintroduce a more suitable evaluation metric. We propose Unlasting, dual\nconditional diffusion models that overcome the problem of unpaired single-cell\nperturbation data and strengthen the model's insight into perturbations under\nthe guidance of the GRN, with a dedicated mask model designed to improve\ngeneration quality by predicting silent genes. In addition, we introduce a\nbiologically grounded evaluation metric that better reflects the inherent\nheterogeneity in single-cell responses.\n","authors":["Changxi Chi","Jun Xia","Yufei Huang","Jingbo Zhou","Siyuan Li","Yunfan Liu","Chang Yu","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2506.21107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21103v1","updated":"2025-06-26T09:01:19Z","published":"2025-06-26T09:01:19Z","title":"Learning to Skip the Middle Layers of Transformers","summary":"  Conditional computation is a popular strategy to make Transformers more\nefficient. Existing methods often target individual modules (e.g.,\nmixture-of-experts layers) or skip layers independently of one another.\nHowever, interpretability research has demonstrated that the middle layers of\nTransformers exhibit greater redundancy, and that early layers aggregate\ninformation into token positions. Guided by these insights, we propose a novel\narchitecture that dynamically skips a variable number of layers from the middle\noutward. In particular, a learned gating mechanism determines whether to bypass\na symmetric span of central blocks based on the input, and a gated attention\nmechanism prevents subsequent tokens from attending to skipped token positions.\nResidual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and\ngate sparsity with an adaptive regularization loss. We had aimed to reduce\ncompute requirements for 'simpler' tokens and potentially foster an emergent\nmulti-level representational hierarchy but, at the scales investigated, our\napproach does not achieve improvements in the trade-off between validation\ncross-entropy and estimated FLOPs compared to dense baselines with fewer\nlayers. We release our code at https://github.com/tim-lawson/skip-middle.\n","authors":["Tim Lawson","Laurence Aitchison"],"pdf_url":"https://arxiv.org/pdf/2506.21103v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2506.21102v1","updated":"2025-06-26T08:56:55Z","published":"2025-06-26T08:56:55Z","title":"Interpretable Hierarchical Concept Reasoning through Attention-Guided\n  Graph Learning","summary":"  Concept-Based Models (CBMs) are a class of deep learning models that provide\ninterpretability by explaining predictions through high-level concepts. These\nmodels first predict concepts and then use them to perform a downstream task.\nHowever, current CBMs offer interpretability only for the final task\nprediction, while the concept predictions themselves are typically made via\nblack-box neural networks. To address this limitation, we propose Hierarchical\nConcept Memory Reasoner (H-CMR), a new CBM that provides interpretability for\nboth concept and task predictions. H-CMR models relationships between concepts\nusing a learned directed acyclic graph, where edges represent logic rules that\ndefine concepts in terms of other concepts. During inference, H-CMR employs a\nneural attention mechanism to select a subset of these rules, which are then\napplied hierarchically to predict all concepts and the final task. Experimental\nresults demonstrate that H-CMR matches state-of-the-art performance while\nenabling strong human interaction through concept and model interventions. The\nformer can significantly improve accuracy at inference time, while the latter\ncan enhance data efficiency during training when background knowledge is\navailable.\n","authors":["David Debot","Pietro Barbiero","Gabriele Dominici","Giuseppe Marra"],"pdf_url":"https://arxiv.org/pdf/2506.21102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21095v1","updated":"2025-06-26T08:43:12Z","published":"2025-06-26T08:43:12Z","title":"FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation","summary":"  Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing clients' private data. However, fairness remains a key\nconcern, as biases in local clients' datasets can impact the entire federated\nsystem. Heterogeneous data distributions across clients may lead to models that\nare fairer for some clients than others. Although several fairness-enhancing\nsolutions are present in the literature, most focus on mitigating bias for a\nsingle sensitive attribute, typically binary, overlooking the diverse and\nsometimes conflicting fairness needs of different clients. This limited\nperspective can limit the effectiveness of fairness interventions for the\ndifferent clients. To support more robust and reproducible fairness research in\nFL, we aim to enable a consistent benchmarking of fairness-aware FL methods at\nboth the global and client levels. In this paper, we contribute in three ways:\n(1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to\nevaluating fair FL methods under heterogeneous client bias; (2) we release four\nbias-heterogeneous datasets and corresponding benchmarks to compare fairness\nmitigation methods in a controlled environment; (3) we provide ready-to-use\nfunctions for evaluating fairness outcomes for these datasets.\n","authors":["Xenia Heilmann","Luca Corbucci","Mattia Cerrato","Anna Monreale"],"pdf_url":"https://arxiv.org/pdf/2506.21095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21093v1","updated":"2025-06-26T08:41:45Z","published":"2025-06-26T08:41:45Z","title":"Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol\n  Detection","summary":"  Transformers have shown potential in solving wireless communication problems,\nparticularly via in-context learning (ICL), where models adapt to new tasks\nthrough prompts without requiring model updates. However, prior ICL-based\nTransformer models rely on deep architectures with many layers to achieve\nsatisfactory performance, resulting in substantial storage and computational\ncosts. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a\nCoT-enhanced shallow Transformer framework for wireless symbol detection. By\nintroducing autoregressive latent reasoning steps within the hidden space,\nCHOOSE significantly improves the reasoning capacity of shallow models (1-2\nlayers) without increasing model depth. This design enables lightweight\nTransformers to achieve detection performance comparable to much deeper models,\nmaking them well-suited for deployment on resource-constrained mobile devices.\nExperimental results demonstrate that our approach outperforms conventional\nshallow Transformers and achieves performance comparable to that of deep\nTransformers, while maintaining storage and computational efficiency. This\nrepresents a promising direction for implementing Transformer-based algorithms\nin wireless receivers with limited computational resources.\n","authors":["Li Fan","Peng Wang","Jing Yang","Cong Shen"],"pdf_url":"https://arxiv.org/pdf/2506.21093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21085v1","updated":"2025-06-26T08:28:07Z","published":"2025-06-26T08:28:07Z","title":"CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and\n  Solutions","summary":"  Molecular docking plays a crucial role in predicting the binding mode of\nligands to target proteins, and covalent interactions, which involve the\nformation of a covalent bond between the ligand and the target, are\nparticularly valuable due to their strong, enduring binding nature. However,\nmost existing docking methods and deep learning approaches hardly account for\nthe formation of covalent bonds and the associated structural changes. To\naddress this gap, we introduce a comprehensive benchmark for covalent docking,\nCovDocker, which is designed to better capture the complexities of covalent\nbinding. We decompose the covalent docking process into three main tasks:\nreactive location prediction, covalent reaction prediction, and covalent\ndocking. By adapting state-of-the-art models, such as Uni-Mol and Chemformer,\nwe establish baseline performances and demonstrate the effectiveness of the\nbenchmark in accurately predicting interaction sites and modeling the molecular\ntransformations involved in covalent binding. These results confirm the role of\nthe benchmark as a rigorous framework for advancing research in covalent drug\ndesign. It underscores the potential of data-driven approaches to accelerate\nthe discovery of selective covalent inhibitors and addresses critical\nchallenges in therapeutic development.\n","authors":["Yangzhe Peng","Kaiyuan Gao","Liang He","Yuheng Cong","Haiguang Liu","Kun He","Lijun Wu"],"pdf_url":"https://arxiv.org/pdf/2506.21085v1.pdf","comment":"Accepted to KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2506.21080v1","updated":"2025-06-26T08:09:16Z","published":"2025-06-26T08:09:16Z","title":"EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for\n  Efficient Egocentric Perception","summary":"  Modern perception models, particularly those designed for multisensory\negocentric tasks, have achieved remarkable performance but often come with\nsubstantial computational costs. These high demands pose challenges for\nreal-world deployment, especially in resource-constrained environments. In this\npaper, we introduce EgoAdapt, a framework that adaptively performs cross-modal\ndistillation and policy learning to enable efficient inference across different\negocentric perception tasks, including egocentric action recognition, active\nspeaker localization, and behavior anticipation. Our proposed policy module is\nadaptable to task-specific action spaces, making it broadly applicable.\nExperimental results on three challenging egocentric datasets EPIC-Kitchens,\nEasyCom, and Aria Everyday Activities demonstrate that our method significantly\nenhances efficiency, reducing GMACs by up to 89.09%, parameters up to 82.02%,\nand energy up to 9.6x, while still on-par and in many cases outperforming, the\nperformance of corresponding state-of-the-art models.\n","authors":["Sanjoy Chowdhury","Subrata Biswas","Sayan Nag","Tushar Nagarajan","Calvin Murdock","Ishwarya Ananthabhotla","Yijun Qian","Vamsi Krishna Ithapu","Dinesh Manocha","Ruohan Gao"],"pdf_url":"https://arxiv.org/pdf/2506.21080v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2506.21079v1","updated":"2025-06-26T08:08:49Z","published":"2025-06-26T08:08:49Z","title":"Homogenization of Multi-agent Learning Dynamics in Finite-state Markov\n  Games","summary":"  This paper introduces a new approach for approximating the learning dynamics\nof multiple reinforcement learning (RL) agents interacting in a finite-state\nMarkov game. The idea is to rescale the learning process by simultaneously\nreducing the learning rate and increasing the update frequency, effectively\ntreating the agent's parameters as a slow-evolving variable influenced by the\nfast-mixing game state. Under mild assumptions-ergodicity of the state process\nand continuity of the updates-we prove the convergence of this rescaled process\nto an ordinary differential equation (ODE). This ODE provides a tractable,\ndeterministic approximation of the agent's learning dynamics. An implementation\nof the framework is available at\\,:\nhttps://github.com/yannKerzreho/MarkovGameApproximation\n","authors":["Yann Kerzreho"],"pdf_url":"https://arxiv.org/pdf/2506.21079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21071v1","updated":"2025-06-26T07:45:15Z","published":"2025-06-26T07:45:15Z","title":"Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge\n  Graph","summary":"  Teaching large language models (LLMs) to use tools is crucial for improving\ntheir problem-solving abilities and expanding their applications. However,\neffectively using tools is challenging because it requires a deep understanding\nof tool functionalities and user intentions. Previous methods relied mainly on\nLLMs to generate instruction data, but the quality of these data was often\ninsufficient. In this paper, we propose a new method that uses knowledge graphs\nto generate high-quality instruction data for LLMs. Knowledge graphs are\nmanually curated datasets rich in semantic information. We begin by extracting\nvarious query pathways from a given knowledge graph, which are transformed into\na broad spectrum of user queries. We then translate the relationships between\nentities into actionable tools and parse the pathways of each query into\ndetailed solution steps, thereby creating high-quality instruction data. Our\nexperiments show that fine-tuning on just a small sample of this synthetic data\ncan significantly improve the tool utilization and overall capabilities of\nLLMs.\n","authors":["Jingwei Wang","Zai Zhang","Hao Qian","Chunjing Gan","Binbin Hu","Ziqi Liu","Zhiqiang Zhang","Jun Zhou","Bin Shi","Bo Dong"],"pdf_url":"https://arxiv.org/pdf/2506.21071v1.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2502.02472v3","updated":"2025-06-26T07:38:35Z","published":"2025-02-04T16:47:49Z","title":"SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic\n  Differential Equations","summary":"  The Latent Stochastic Differential Equation (SDE) is a powerful tool for time\nseries and sequence modeling. However, training Latent SDEs typically relies on\nadjoint sensitivity methods, which depend on simulation and backpropagation\nthrough approximate SDE solutions, which limit scalability. In this work, we\npropose SDE Matching, a new simulation-free method for training Latent SDEs.\nInspired by modern Score- and Flow Matching algorithms for learning generative\ndynamics, we extend these ideas to the domain of stochastic dynamics for time\nseries and sequence modeling, eliminating the need for costly numerical\nsimulations. Our results demonstrate that SDE Matching achieves performance\ncomparable to adjoint sensitivity methods while drastically reducing\ncomputational complexity.\n","authors":["Grigory Bartosh","Dmitry Vetrov","Christian A. Naesseth"],"pdf_url":"https://arxiv.org/pdf/2502.02472v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21054v1","updated":"2025-06-26T07:09:08Z","published":"2025-06-26T07:09:08Z","title":"FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in\n  Federated Learning","summary":"  In federated learning (FL), the data distribution of each client may change\nover time, introducing both temporal and spatial data heterogeneity, known as\nconcept drift. Data heterogeneity arises from three drift sources: real drift\n(a shift in the conditional distribution P(y|x)), virtual drift (a shift in the\ninput distribution P(x)), and label drift (a shift in the label distribution\nP(y)). However, most existing FL methods addressing concept drift primarily\nfocus on real drift. When clients experience virtual or label drift, these\nmethods often fail to selectively retain useful historical knowledge, leading\nto catastrophic forgetting. A key challenge lies in distinguishing different\nsources of drift, as they require distinct adaptation strategies: real drift\ncalls for discarding outdated data, while virtual or label drift benefits from\nretaining historical data. Without explicitly identifying the drift sources, a\ngeneral adaptation strategy is suboptimal and may harm generalization. To\naddress this challenge, we propose FedDAA, a dynamic clustered FL framework\ndesigned to adapt to multi-source concept drift while preserving valuable\nhistorical knowledge. Specifically, FedDAA integrates three modules: a cluster\nnumber determination module to find the optimal number of clusters; a real\ndrift detection module to distinguish real drift from virtual/label drift; and\na concept drift adaptation module to adapt to new data while retaining useful\nhistorical information. We provide theoretical convergence guarantees, and\nexperiments show that FedDAA achieves 7.84% to 8.52% accuracy improvements over\nstate-of-the-art methods on Fashion-MNIST, CIFAR-10, and CIFAR-100.\n","authors":["Fu Peng","Ming Tang"],"pdf_url":"https://arxiv.org/pdf/2506.21054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.16713v2","updated":"2025-06-26T06:57:11Z","published":"2025-05-22T14:14:50Z","title":"Sharp concentration of uniform generalization errors in binary linear\n  classification","summary":"  We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.\n","authors":["Shogo Nakakita"],"pdf_url":"https://arxiv.org/pdf/2505.16713v2.pdf","comment":"26 pages, 1 figure; minor edits to improve readability"},{"id":"http://arxiv.org/abs/2506.21045v1","updated":"2025-06-26T06:46:03Z","published":"2025-06-26T06:46:03Z","title":"Improving Diffusion-Based Image Editing Faithfulness via Guidance and\n  Scheduling","summary":"  Text-guided diffusion models have become essential for high-quality image\nsynthesis, enabling dynamic image editing. In image editing, two crucial\naspects are editability, which determines the extent of modification, and\nfaithfulness, which reflects how well unaltered elements are preserved.\nHowever, achieving optimal results is challenging because of the inherent\ntrade-off between editability and faithfulness. To address this, we propose\nFaithfulness Guidance and Scheduling (FGS), which enhances faithfulness with\nminimal impact on editability. FGS incorporates faithfulness guidance to\nstrengthen the preservation of input image information and introduces a\nscheduling strategy to resolve misalignment between editability and\nfaithfulness. Experimental results demonstrate that FGS achieves superior\nfaithfulness while maintaining editability. Moreover, its compatibility with\nvarious editing methods enables precise, high-quality image edits across\ndiverse tasks.\n","authors":["Hansam Cho","Seoung Bum Kim"],"pdf_url":"https://arxiv.org/pdf/2506.21045v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2506.21044v1","updated":"2025-06-26T06:45:59Z","published":"2025-06-26T06:45:59Z","title":"Efficient Skill Discovery via Regret-Aware Optimization","summary":"  Unsupervised skill discovery aims to learn diverse and distinguishable\nbehaviors in open-ended reinforcement learning. For existing methods, they\nfocus on improving diversity through pure exploration, mutual information\noptimization, and learning temporal representation. Despite that they perform\nwell on exploration, they remain limited in terms of efficiency, especially for\nthe high-dimensional situations. In this work, we frame skill discovery as a\nmin-max game of skill generation and policy learning, proposing a regret-aware\nmethod on top of temporal representation learning that expands the discovered\nskill space along the direction of upgradable policy strength. The key insight\nbehind the proposed method is that the skill discovery is adversarial to the\npolicy learning, i.e., skills with weak strength should be further explored\nwhile less exploration for the skills with converged strength. As an\nimplementation, we score the degree of strength convergence with regret, and\nguide the skill discovery with a learnable skill generator. To avoid\ndegeneration, skill generation comes from an up-gradable population of skill\ngenerators. We conduct experiments on environments with varying complexities\nand dimension sizes. Empirical results show that our method outperforms\nbaselines in both efficiency and diversity. Moreover, our method achieves a 15%\nzero shot improvement in high-dimensional environments, compared to existing\nmethods.\n","authors":["He Zhang","Ming Zhou","Shaopeng Zhai","Ying Sun","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2506.21044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21039v1","updated":"2025-06-26T06:35:42Z","published":"2025-06-26T06:35:42Z","title":"Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical\n  Reinforcement Learning","summary":"  Long-horizon goal-conditioned tasks pose fundamental challenges for\nreinforcement learning (RL), particularly when goals are distant and rewards\nare sparse. While hierarchical and graph-based methods offer partial solutions,\nthey often suffer from subgoal infeasibility and inefficient planning. We\nintroduce Strict Subgoal Execution (SSE), a graph-based hierarchical RL\nframework that enforces single-step subgoal reachability by structurally\nconstraining high-level decision-making. To enhance exploration, SSE employs a\ndecoupled exploration policy that systematically traverses underexplored\nregions of the goal space. Furthermore, a failure-aware path refinement, which\nrefines graph-based planning by dynamically adjusting edge costs according to\nobserved low-level success rates, thereby improving subgoal reliability.\nExperimental results across diverse long-horizon benchmarks demonstrate that\nSSE consistently outperforms existing goal-conditioned RL and hierarchical RL\napproaches in both efficiency and success rate.\n","authors":["Jaebak Hwang","Sanghyeon Lee","Jeongmo Kim","Seungyul Han"],"pdf_url":"https://arxiv.org/pdf/2506.21039v1.pdf","comment":"9 technical page followed by references and appendix"},{"id":"http://arxiv.org/abs/2506.21037v1","updated":"2025-06-26T06:28:56Z","published":"2025-06-26T06:28:56Z","title":"RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy\n  Assessment","summary":"  Modern deep architectures often rely on large-scale datasets, but training on\nthese datasets incurs high computational and storage overhead. Real-world\ndatasets often contain substantial redundancies, prompting the need for more\ndata-efficient training paradigms. Data selection has shown promise to mitigate\nredundancy by identifying the most representative samples, thereby reducing\ntraining costs without compromising performance. Existing methods typically\nrely on static scoring metrics or pretrained models, overlooking the combined\neffect of selected samples and their evolving dynamics during training. We\nintroduce the concept of epsilon-sample cover, which quantifies sample\nredundancy based on inter-sample relationships, capturing the intrinsic\nstructure of the dataset. Based on this, we reformulate data selection as a\nreinforcement learning (RL) process and propose RL-Selector, where a\nlightweight RL agent optimizes the selection policy by leveraging\nepsilon-sample cover derived from evolving dataset distribution as a reward\nsignal. Extensive experiments across benchmark datasets and diverse\narchitectures demonstrate that our method consistently outperforms existing\nstate-of-the-art baselines. Models trained with our selected datasets show\nenhanced generalization performance with improved training efficiency.\n","authors":["Suorong Yang","Peijia Li","Furao Shen","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.21037v1.pdf","comment":"ICCV 2025"},{"id":"http://arxiv.org/abs/2506.21036v1","updated":"2025-06-26T06:25:15Z","published":"2025-06-26T06:25:15Z","title":"An Information-Theoretic Analysis for Federated Learning under Concept\n  Drift","summary":"  Recent studies in federated learning (FL) commonly train models on static\ndatasets. However, real-world data often arrives as streams with shifting\ndistributions, causing performance degradation known as concept drift. This\npaper analyzes FL performance under concept drift using information theory and\nproposes an algorithm to mitigate the performance degradation. We model concept\ndrift as a Markov chain and introduce the \\emph{Stationary Generalization\nError} to assess a model's capability to capture characteristics of future\nunseen data. Its upper bound is derived using KL divergence and mutual\ninformation. We study three drift patterns (periodic, gradual, and random) and\ntheir impact on FL performance. Inspired by this, we propose an algorithm that\nregularizes the empirical risk minimization approach with KL divergence and\nmutual information, thereby enhancing long-term performance. We also explore\nthe performance-cost tradeoff by identifying a Pareto front. To validate our\napproach, we build an FL testbed using Raspberry Pi4 devices. Experimental\nresults corroborate with theoretical findings, confirming that drift patterns\nsignificantly affect performance. Our method consistently outperforms existing\napproaches for these three patterns, demonstrating its effectiveness in\nadapting concept drift in FL.\n","authors":["Fu Peng","Meng Zhang","Ming Tang"],"pdf_url":"https://arxiv.org/pdf/2506.21036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21909v3","updated":"2025-06-26T06:24:08Z","published":"2024-10-29T10:01:40Z","title":"SceneGenAgent: Precise Industrial Scene Generation with Coding Agent","summary":"  The modeling of industrial scenes is essential for simulations in industrial\nmanufacturing. While large language models (LLMs) have shown significant\nprogress in generating general 3D scenes from textual descriptions, generating\nindustrial scenes with LLMs poses a unique challenge due to their demand for\nprecise measurements and positioning, requiring complex planning over spatial\narrangement. To address this challenge, we introduce SceneGenAgent, an\nLLM-based agent for generating industrial scenes through C# code. SceneGenAgent\nensures precise layout planning through a structured and calculable format,\nlayout verification, and iterative refinement to meet the quantitative\nrequirements of industrial scenarios. Experiment results demonstrate that LLMs\npowered by SceneGenAgent exceed their original performance, reaching up to\n81.0% success rate in real-world industrial scene generation tasks and\neffectively meeting most scene generation requirements. To further enhance\naccessibility, we construct SceneInstruct, a dataset designed for fine-tuning\nopen-source LLMs to integrate into SceneGenAgent. Experiments show that\nfine-tuning open-source LLMs on SceneInstruct yields significant performance\nimprovements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our\ncode and data are available at https://github.com/THUDM/SceneGenAgent .\n","authors":["Xiao Xia","Dan Zhang","Zibo Liao","Zhenyu Hou","Tianrui Sun","Jing Li","Ling Fu","Yuxiao Dong"],"pdf_url":"https://arxiv.org/pdf/2410.21909v3.pdf","comment":"Accepted to ACL 2025"},{"id":"http://arxiv.org/abs/2506.21035v1","updated":"2025-06-26T06:19:05Z","published":"2025-06-26T06:19:05Z","title":"Little By Little: Continual Learning via Self-Activated Sparse\n  Mixture-of-Rank Adaptive Learning","summary":"  Continual learning (CL) with large pre-trained models is challenged by\ncatastrophic forgetting and task interference. Existing LoRA-based\nMixture-of-Experts (MoE) approaches mitigate forgetting by assigning and\nfreezing task-specific adapters, but suffer from interference, redundancy, and\nambiguous routing due to coarse adapter-level selection. However, this design\nintroduces three key challenges: 1) Interference: Activating full LoRA experts\nper input leads to subspace interference and prevents selective reuse of useful\ncomponents across tasks. 2) Redundancy: Newly added experts often duplicate or\ncontradict existing knowledge due to unnecessary activation of unrelated ranks\nand insufficient reuse of relevant ones. 3) Ambiguity: Overlapping features\nacross tasks confuse the router, resulting in unstable expert assignments. As\nmore experts accumulate, earlier task routing degrades, accelerating\nforgetting. We propose MoRA, a Mixture-of-Rank Adaptive learning approach with\nself-activated and sparse rank activation for CL. Unlike mixing multiple\nlow-rank matrices, MoRA decomposes each rank-r update into r rank-1 components,\neach treated as an independent expert, enabling fine-grained mixture of rank-1\nexpert utilization while mitigating interference and redundancy. To avoid\nambiguous routing, we propose that each rank-1 expert can infer its own\nrelevance via intermediate activations. Coupled with our proposed rank pruning\nand activation budgets, MoRA adaptively selects a sparse mixture of ranks per\ninput. We validate MoRA on continual learning tasks with CLIP and large\nlanguage models (LLMs), analyzing both in-domain learning and out-of-domain\nforgetting/generalization during fine-tuning. MoRA shows significant\neffectiveness on enhancing CL with PTMs, and improving generalization while\nmitigating forgetting.\n","authors":["Haodong Lu","Chongyang Zhao","Jason Xue","Lina Yao","Kristen Moore","Dong Gong"],"pdf_url":"https://arxiv.org/pdf/2506.21035v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.05432v2","updated":"2025-06-26T06:17:49Z","published":"2025-06-05T08:58:58Z","title":"PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar\n  Coordinate Decoupling","summary":"  Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.\n","authors":["Yuxuan Yue","Zukang Xu","Zhihang Yuan","Dawei Yang","Jianlong Wu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2506.05432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21028v1","updated":"2025-06-26T06:09:47Z","published":"2025-06-26T06:09:47Z","title":"TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic\n  Annotations and Local Correspondence","summary":"  Molecular property prediction aims to learn representations that map chemical\nstructures to functional properties. While multimodal learning has emerged as a\npowerful paradigm to learn molecular representations, prior works have largely\noverlooked textual and taxonomic information of molecules for representation\nlearning. We introduce TRIDENT, a novel framework that integrates molecular\nSMILES, textual descriptions, and taxonomic functional annotations to learn\nrich molecular representations. To achieve this, we curate a comprehensive\ndataset of molecule-text pairs with structured, multi-level functional\nannotations. Instead of relying on conventional contrastive loss, TRIDENT\nemploys a volume-based alignment objective to jointly align tri-modal features\nat the global level, enabling soft, geometry-aware alignment across modalities.\nAdditionally, TRIDENT introduces a novel local alignment objective that\ncaptures detailed relationships between molecular substructures and their\ncorresponding sub-textual descriptions. A momentum-based mechanism dynamically\nbalances global and local alignment, enabling the model to learn both broad\nfunctional semantics and fine-grained structure-function mappings. TRIDENT\nachieves state-of-the-art performance on 11 downstream tasks, demonstrating the\nvalue of combining SMILES, textual, and taxonomic functional annotations for\nmolecular property prediction.\n","authors":["Feng Jiang","Mangal Prakash","Hehuan Ma","Jianyuan Deng","Yuzhi Guo","Amina Mollaysa","Tommaso Mansi","Rui Liao","Junzhou Huang"],"pdf_url":"https://arxiv.org/pdf/2506.21028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20183v2","updated":"2025-06-26T05:57:03Z","published":"2025-02-27T15:19:28Z","title":"Mixture of Experts-augmented Deep Unfolding for Activity Detection in\n  IRS-aided Systems","summary":"  In the realm of activity detection for massive machine-type communications,\nintelligent reflecting surfaces (IRS) have shown significant potential in\nenhancing coverage for devices lacking direct connections to the base station\n(BS). However, traditional activity detection methods are typically designed\nfor a single type of channel model, which does not reflect the complexities of\nreal-world scenarios, particularly in systems incorporating IRS. To address\nthis challenge, this paper introduces a novel approach that combines\nmodel-driven deep unfolding with a mixture of experts (MoE) framework. By\nautomatically selecting one of three expert designs and applying it to the\nunfolded projected gradient method, our approach eliminates the need for prior\nknowledge of channel types between devices and the BS. Simulation results\ndemonstrate that the proposed MoE-augmented deep unfolding method surpasses the\ntraditional covariance-based method and black-box neural network design,\ndelivering superior detection performance under mixed channel fading\nconditions.\n","authors":["Zeyi Ren","Qingfeng Lin","Jingreng Lei","Yang Li","Yik-Chung Wu"],"pdf_url":"https://arxiv.org/pdf/2502.20183v2.pdf","comment":"5 pages, 5 figures, Accepted in IEEE Wireless Communications Letters"},{"id":"http://arxiv.org/abs/2506.21015v1","updated":"2025-06-26T05:14:45Z","published":"2025-06-26T05:14:45Z","title":"HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for\n  Skin Disease Image Generation","summary":"  Machine learning-assisted diagnosis is gaining traction in skin disease\ndetection, but training effective models requires large amounts of high-quality\ndata. Skin disease datasets often suffer from class imbalance, privacy\nconcerns, and object bias, making data augmentation essential. While classical\ngenerative models are widely used, they demand extensive computational\nresources and lengthy training time. Quantum computing offers a promising\nalternative, but existing quantum-based image generation methods can only yield\ngrayscale low-quality images. Through a novel classical-quantum latent space\nfusion technique, our work overcomes this limitation and introduces the first\nclassical-quantum generative adversarial network (GAN) capable of generating\ncolor medical images. Our model outperforms classical deep convolutional GANs\nand existing hybrid classical-quantum GANs in both image generation quality and\nclassification performance boost when used as data augmentation. Moreover, the\nperformance boost is comparable with that achieved using state-of-the-art\nclassical generative models, yet with over 25 times fewer parameters and 10\ntimes fewer training epochs. Such results suggest a promising future for\nquantum image generation as quantum hardware advances. Finally, we demonstrate\nthe robust performance of our model on real IBM quantum machine with hardware\nnoise.\n","authors":["Qingyue Jiao","Kangyu Zheng","Yiyu Shi","Zhiding Liang"],"pdf_url":"https://arxiv.org/pdf/2506.21015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05770v3","updated":"2025-06-26T05:07:48Z","published":"2022-11-10T18:55:48Z","title":"Efficient Image Generation with Variadic Attention Heads","summary":"  While the integration of transformers in vision models have yielded\nsignificant improvements on vision tasks they still require significant amounts\nof computation for both training and inference. Restricted attention mechanisms\nsignificantly reduce these computational burdens but come at the cost of losing\neither global or local coherence. We propose a simple, yet powerful method to\nreduce these trade-offs: allow the attention heads of a single transformer to\nattend to multiple receptive fields.\n  We demonstrate our method utilizing Neighborhood Attention (NA) and integrate\nit into a StyleGAN based architecture for image generation. With this work,\ndubbed StyleNAT, we are able to achieve a FID of 2.05 on FFHQ, a 6% improvement\nover StyleGAN-XL, while utilizing 28% fewer parameters and with 4$\\times$ the\nthroughput capacity. StyleNAT achieves the Pareto Frontier on FFHQ-256 and\ndemonstrates powerful and efficient image generation on other datasets. Our\ncode and model checkpoints are publicly available at:\nhttps://github.com/SHI-Labs/StyleNAT\n","authors":["Steven Walton","Ali Hassani","Xingqian Xu","Zhangyang Wang","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2211.05770v3.pdf","comment":"Published in eLVM @ CVPR\n  (https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Walton_Efficient_Image_Generation_with_Variadic_Attention_Heads_CVPRW_2025_paper)\n  | Formerly named StyleNAT: Giving Each Head a New Perspective |"},{"id":"http://arxiv.org/abs/2407.04591v3","updated":"2025-06-26T05:01:47Z","published":"2024-07-05T15:40:15Z","title":"Proximal Point Method for Online Saddle Point Problem","summary":"  This paper focuses on the online saddle point problem, which involves a\nsequence of two-player time-varying convex-concave games. Considering the\nnonstationarity of the environment, we adopt the duality gap and the dynamic\nNash equilibrium regret as performance metrics for algorithm design. We present\nthree variants of the proximal point method: the Online Proximal Point Method\n(OPPM), the Optimistic OPPM (OptOPPM), and the OptOPPM with multiple\npredictors. Each algorithm guarantees upper bounds for both the duality gap and\ndynamic Nash equilibrium regret, achieving near-optimality when measured\nagainst the duality gap. Specifically, in certain benign environments, such as\nsequences of stationary payoff functions, these algorithms maintain a nearly\nconstant metric bound. Experimental results further validate the effectiveness\nof these algorithms. Lastly, this paper discusses potential reliability\nconcerns associated with using dynamic Nash equilibrium regret as a performance\nmetric. The technical appendix and code can be found at\nhttps://github.com/qingxin6174/PPM-for-OSP.\n","authors":["Qing-xin Meng","Jian-wei Liu"],"pdf_url":"https://arxiv.org/pdf/2407.04591v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09394v2","updated":"2025-06-26T04:44:25Z","published":"2022-10-17T19:54:38Z","title":"Review learning: Real world validation of privacy preserving continual\n  learning across medical institutions","summary":"  When a deep learning model is trained sequentially on different datasets, it\noften forgets the knowledge learned from previous data, a problem known as\ncatastrophic forgetting. This damages the model's performance on diverse\ndatasets, which is critical in privacy-preserving deep learning (PPDL)\napplications based on transfer learning (TL). To overcome this, we introduce\n\"review learning\" (RevL), a low cost continual learning algorithm for diagnosis\nprediction using electronic health records (EHR) within a PPDL framework. RevL\ngenerates data samples from the model which are used to review knowledge from\nprevious datasets. Six simulated institutional experiments and one real-world\nexperiment involving three medical institutions were conducted to validate\nRevL, using three binary classification EHR data. In the real-world experiment\nwith data from 106,508 patients, the mean global area under the receiver\noperating curve was 0.710 for RevL and 0.655 for TL. These results demonstrate\nRevL's ability to retain previously learned knowledge and its effectiveness in\nreal-world PPDL scenarios. Our work establishes a realistic pipeline for PPDL\nresearch based on model transfers across institutions and highlights the\npracticality of continual learning in real-world medical settings using private\nEHR data.\n","authors":["Jaesung Yoo","Sunghyuk Choi","Ye Seul Yang","Suhyeon Kim","Jieun Choi","Dongkyeong Lim","Yaeji Lim","Hyung Joon Joo","Dae Jung Kim","Rae Woong Park","Hyeong-Jin Yoon","Kwangsoo Kim"],"pdf_url":"https://arxiv.org/pdf/2210.09394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21003v1","updated":"2025-06-26T04:34:28Z","published":"2025-06-26T04:34:28Z","title":"Distilling Normalizing Flows","summary":"  Explicit density learners are becoming an increasingly popular technique for\ngenerative models because of their ability to better model probability\ndistributions. They have advantages over Generative Adversarial Networks due to\ntheir ability to perform density estimation and having exact latent-variable\ninference. This has many advantages, including: being able to simply\ninterpolate, calculate sample likelihood, and analyze the probability\ndistribution. The downside of these models is that they are often more\ndifficult to train and have lower sampling quality.\n  Normalizing flows are explicit density models, that use composable bijective\nfunctions to turn an intractable probability function into a tractable one. In\nthis work, we present novel knowledge distillation techniques to increase\nsampling quality and density estimation of smaller student normalizing flows.\nWe seek to study the capacity of knowledge distillation in Compositional\nNormalizing Flows to understand the benefits and weaknesses provided by these\narchitectures. Normalizing flows have unique properties that allow for a\nnon-traditional forms of knowledge transfer, where we can transfer that\nknowledge within intermediate layers. We find that through this distillation,\nwe can make students significantly smaller while making substantial performance\ngains over a non-distilled student. With smaller models there is a\nproportionally increased throughput as this is dependent upon the number of\nbijectors, and thus parameters, in the network.\n","authors":["Steven Walton","Valeriy Klyukin","Maksim Artemev","Denis Derkach","Nikita Orlov","Humphrey Shi"],"pdf_url":"https://arxiv.org/pdf/2506.21003v1.pdf","comment":"Published in eLVM @ CVPR\n  (https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Walton_Distilling_Normalizing_Flows_CVPRW_2025_paper)"},{"id":"http://arxiv.org/abs/2501.18184v3","updated":"2025-06-26T04:26:22Z","published":"2025-01-30T07:35:43Z","title":"Genetic Algorithm with Innovative Chromosome Patterns in the Breeding\n  Process","summary":"  This paper proposes Genetic Algorithm with Border Trades (GAB), a novel\nmodification of the standard genetic algorithm that enhances exploration by\nincorporating new chromosome patterns in the breeding process. This approach\nsignificantly mitigates premature convergence and improves search diversity.\nEmpirically, GAB achieves up to 8x higher fitness and 10x faster convergence on\ncomplex job scheduling problems compared to standard Genetic Algorithms,\nreaching average fitness scores of 888 versus 106 in under 20 seconds. On the\nclassic Flip-Flop problem, GAB consistently finds optimal or near-optimal\nsolutions in fewer generations, even as input sizes scale to thousands of bits.\nThese results highlight GAB as a highly effective and computationally efficient\nalternative for solving large-scale combinatorial optimization problems.\n","authors":["Qingchuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2501.18184v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01787v3","updated":"2025-06-26T04:26:18Z","published":"2024-11-29T08:24:49Z","title":"Pretrained Reversible Generation as Unsupervised Visual Representation\n  Learning","summary":"  Recent generative models based on score matching and flow matching have\nsignificantly advanced generation tasks, but their potential in discriminative\ntasks remains underexplored. Previous approaches, such as generative\nclassifiers, have not fully leveraged the capabilities of these models for\ndiscriminative tasks due to their intricate designs. We propose Pretrained\nReversible Generation (PRG), which extracts unsupervised representations by\nreversing the generative process of a pretrained continuous generation model.\nPRG effectively reuses unsupervised generative models, leveraging their high\ncapacity to serve as robust and generalizable feature extractors for downstream\ntasks. This framework enables the flexible selection of feature hierarchies\ntailored to specific downstream tasks. Our method consistently outperforms\nprior approaches across multiple benchmarks, achieving state-of-the-art\nperformance among generative model based methods, including 78% top-1 accuracy\non ImageNet at a resolution of 64*64. Extensive ablation studies, including\nout-of-distribution evaluations, further validate the effectiveness of our\napproach. Code is available at https://github.com/opendilab/PRG.\n","authors":["Rongkun Xue","Jinouwen Zhang","Yazhe Niu","Dazhong Shen","Bingqi Ma","Yu Liu","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2412.01787v3.pdf","comment":"Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2506.20995v1","updated":"2025-06-26T04:20:08Z","published":"2025-06-26T04:20:08Z","title":"Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance","summary":"  We propose a novel step-by-step video-to-audio generation method that\nsequentially produces individual audio tracks, each corresponding to a specific\nsound event in the video. Our approach mirrors traditional Foley workflows,\naiming to capture all sound events induced by a given video comprehensively.\nEach generation step is formulated as a guided video-to-audio synthesis task,\nconditioned on a target text prompt and previously generated audio tracks. This\ndesign is inspired by the idea of concept negation from prior compositional\ngeneration frameworks. To enable this guided generation, we introduce a\ntraining framework that leverages pre-trained video-to-audio models and\neliminates the need for specialized paired datasets, allowing training on more\naccessible data. Experimental results demonstrate that our method generates\nmultiple semantically distinct audio tracks for a single input video, leading\nto higher-quality composite audio synthesis than existing baselines.\n","authors":["Akio Hayakawa","Masato Ishii","Takashi Shibuya","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2506.20995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12335v4","updated":"2025-06-26T04:08:57Z","published":"2024-09-18T22:05:07Z","title":"Bridging the Gap Between Approximation and Learning via Optimal\n  Approximation by ReLU MLPs of Maximal Regularity","summary":"  The foundations of deep learning are supported by the seemingly opposing\nperspectives of approximation or learning theory. The former advocates for\nlarge/expressive models that need not generalize, while the latter considers\nclasses that generalize but may be too small/constrained to be universal\napproximators. Motivated by real-world deep learning implementations that are\nboth expressive and statistically reliable, we ask: \"Is there a class of neural\nnetworks that is both large enough to be universal but structured enough to\ngeneralize?\" This paper constructively provides a positive answer to this\nquestion by identifying a highly structured class of ReLU multilayer\nperceptions (MLPs), which are optimal function approximators and are\nstatistically well-behaved. We show that any $(L,\\alpha)$-H\\\"{o}lder function\nfrom $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $\\mathcal{O}(1/n)$\nerror on $[0,1]^d$ with a sparsely connected ReLU MLP with the same H\\\"{o}lder\nexponent $\\alpha$ and coefficient $L$, of width $\\mathcal{O}(dn^{d/\\alpha})$,\ndepth $\\mathcal{O}(\\log(d))$, with $\\mathcal{O}(dn^{d/\\alpha})$ nonzero\nparameters, and whose weights and biases take values in $\\{0,\\pm 1/2\\}$ except\nin the first and last layers which instead have magnitude at-most $n$. Further,\nour class of MLPs achieves a near-optimal sample complexity of\n$\\mathcal{O}(\\log(N)/\\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian\ntraining samples. We achieve this through a new construction that perfectly\nfits together linear pieces using Kuhn triangulations, along with a new proof\ntechnique which shows that our construction preserves the regularity of not\nonly the H\\\"{o}lder functions, but also any uniformly continuous function. Our\nresults imply that neural networks can solve the McShane extension problem on\nsuitable finite sets.\n","authors":["Ruiyang Hong","Anastasis Kratsios"],"pdf_url":"https://arxiv.org/pdf/2409.12335v4.pdf","comment":"16 pages main body, 40 pages proofs, 10 figures, 1 table"},{"id":"http://arxiv.org/abs/2506.20990v1","updated":"2025-06-26T04:07:14Z","published":"2025-06-26T04:07:14Z","title":"SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via\n  Forward-Only Passes","summary":"  Fine-tuning vision language models (VLMs) has achieved remarkable performance\nacross various downstream tasks; yet, it requires access to model gradients\nthrough backpropagation (BP), making them unsuitable for memory-constrained,\ninference-only edge devices. To address this limitation, previous work has\nexplored various BP-free fine-tuning methods. However, these approaches often\nrely on high-variance evolutionary strategies (ES) or zeroth-order (ZO)\noptimization, and often fail to achieve satisfactory performance. In this\npaper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO)\napproach, specifically designed to enhance the performance of ZO VLM\nfine-tuning via a sharpness-aware warm-up training. SharpZO features a\ntwo-stage optimization process: a sharpness-aware ES stage that globally\nexplores and smooths the loss landscape to construct a strong initialization,\nfollowed by a fine-grained local search via sparse ZO optimization. The entire\noptimization relies solely on forward passes. Detailed theoretical analysis and\nextensive experiments on CLIP models demonstrate that SharpZO significantly\nimproves accuracy and convergence speed, achieving up to 7% average gain over\nstate-of-the-art forward-only methods.\n","authors":["Yifan Yang","Zhen Zhang","Rupak Vignesh Swaminathan","Jing Liu","Nathan Susanj","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20989v1","updated":"2025-06-26T04:06:20Z","published":"2025-06-26T04:06:20Z","title":"Can Gradient Descent Simulate Prompting?","summary":"  There are two primary ways of incorporating new information into a language\nmodel (LM): changing its prompt or changing its parameters, e.g. via\nfine-tuning. Parameter updates incur no long-term storage cost for model\nchanges. However, for many model updates, prompting is significantly more\neffective: prompted models can generalize robustly from single examples and\ndraw logical inferences that do not occur under standard fine-tuning. Can\nmodels be modified so that fine-tuning does emulate prompting? This paper\ndescribes a method for meta-training LMs such that gradient updates emulate the\neffects of conditioning on new information. Our approach uses tools from\ngradient-based meta-learning but uses an LM's own prompted predictions as\ntargets, eliminating the need for ground-truth labels. Subsequent gradient\ndescent training recovers some (and occasionally all) of prompted model\nperformance -- showing improvement on the ``reversal curse'' tasks, and\nanswering questions about text passages after a single gradient update. These\nresults suggest that, with appropriate initialization, gradient descent can be\nsurprisingly expressive. Our results suggest new avenues for long-context\nmodeling and offer insight into the generalization capabilities of\ngradient-based learning.\n","authors":["Eric Zhang","Leshem Choshen","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2506.20989v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2501.15131v2","updated":"2025-06-26T03:45:17Z","published":"2025-01-25T08:37:17Z","title":"Split-Merge: A Difference-based Approach for Dominant Eigenvalue Problem","summary":"  The computation of the dominant eigenvector of symmetric positive\nsemidefinite matrices is a cornerstone operation in numerous\noptimization-driven applications. Traditional methods, typically based on the\n\\textit{Quotient} formulation, often suffer from challenges related to\ncomputational efficiency and reliance on prior spectral knowledge. In this\nwork, we leverage the alternative \\textit{Difference} formulation to\nreinterpret the classical power method as a first-order optimization algorithm.\nThis perspective allows for a novel convergence analysis and facilitates the\ndevelopment of accelerated variants with larger step-sizes, achieving faster\nconvergence without additional computational cost. Building on this insight, we\nintroduce a generalized family of Difference-based methods, with the power\nmethod as a special case. Within this family, we propose Split-Merge, an\nalgorithm that attains accelerated convergence without requiring spectral\nknowledge and operates solely via matrix-vector products. Extensive experiments\non both synthetic and real-world datasets demonstrate that Split-Merge\nconsistently outperforms state-of-the-art methods in both efficiency and\nscalability. In particular, it achieves more than a $\\boldsymbol{10\\times}$\nspeedup over the classical power method, underscoring its practical\neffectiveness for large-scale problems.\n","authors":["Xiaozhi Liu","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2501.15131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.00851v2","updated":"2025-06-26T03:12:59Z","published":"2025-04-01T14:36:45Z","title":"Generalized Tensor-based Parameter-Efficient Fine-Tuning via Lie Group\n  Transformations","summary":"  Adapting pre-trained foundation models for diverse downstream tasks is a core\npractice in artificial intelligence. However, the wide range of tasks and high\ncomputational costs make full fine-tuning impractical. To overcome this,\nparameter-efficient fine-tuning (PEFT) methods like LoRA have emerged and are\nbecoming a growing research focus. Despite the success of these methods, they\nare primarily designed for linear layers, focusing on two-dimensional matrices\nwhile largely ignoring higher-dimensional parameter spaces like convolutional\nkernels. Moreover, directly applying these methods to higher-dimensional\nparameter spaces often disrupts their structural relationships. Given the rapid\nadvancements in matrix-based PEFT methods, rather than designing a specialized\nstrategy, we propose a generalization that extends matrix-based PEFT methods to\nhigher-dimensional parameter spaces without compromising their structural\nproperties. Specifically, we treat parameters as elements of a Lie group, with\nupdates modeled as perturbations in the corresponding Lie algebra. These\nperturbations are mapped back to the Lie group through the exponential map,\nensuring smooth, consistent updates that preserve the inherent structure of the\nparameter space. Extensive experiments on computer vision and natural language\nprocessing validate the effectiveness and versatility of our approach,\ndemonstrating clear improvements over existing methods.\n","authors":["Chongjie Si","Zhiyi Shi","Xuehui Wang","Yichen Xiao","Xiaokang Yang","Wei Shen"],"pdf_url":"https://arxiv.org/pdf/2504.00851v2.pdf","comment":"2025 ICCV"},{"id":"http://arxiv.org/abs/2307.03334v5","updated":"2025-06-26T03:12:31Z","published":"2023-07-07T00:30:16Z","title":"Explainable quantum regression algorithm with encoded data structure","summary":"  Hybrid variational quantum algorithms (VQAs) are promising for solving\npractical problems such as combinatorial optimization, quantum chemistry\nsimulation, quantum machine learning, and quantum error correction on noisy\nquantum computers. However, with typical random ansatz or quantum alternating\noperator ansatz, derived variational quantum algorithms become a black box that\ncannot be trusted for model interpretation, not to mention deploying as\napplications in informing critical decisions: the results of these variational\nparameters are just rotational angles for the quantum gates and have nothing to\ndo with interpretable values that a model can provide directly. In this paper,\nwe construct the first interpretable quantum regression algorithm, in which the\nquantum state exactly encodes the classical data table and the variational\nparameters correspond directly to the regression coefficients, which are real\nnumbers by construction, providing a high degree of model interpretability and\nminimal cost to optimize due to the right expressiveness. We also take\nadvantage of the encoded data structure to reduce the time complexity of\ncomputing the regression map. To shorten the circuit depth for nonlinear\nregression, our algorithm can be extended by building nonlinear features by\nclassical preprocessing as the independent encoded column vectors. Even though\nthe realization of compressed encoding in superconducting qubits has been\nachieved by the less noisy compressed encoding recently by the authors, we\nenvision potential quantum utilities with multi-qubit gates implemented in\nneutral cold atoms and ions.\n","authors":["C. -C. Joseph Wang","F. Perkkola","I. Salmenperä","A. Meijer-van de Griend","J. K. Nurminen","R. S. Bennink"],"pdf_url":"https://arxiv.org/pdf/2307.03334v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20963v1","updated":"2025-06-26T03:01:33Z","published":"2025-06-26T03:01:33Z","title":"EraRAG: Efficient and Incremental Retrieval Augmented Generation for\n  Growing Corpora","summary":"  Graph-based Retrieval-Augmented Generation (Graph-RAG) enhances large\nlanguage models (LLMs) by structuring retrieval over an external corpus.\nHowever, existing approaches typically assume a static corpus, requiring\nexpensive full-graph reconstruction whenever new documents arrive, limiting\ntheir scalability in dynamic, evolving environments. To address these\nlimitations, we introduce EraRAG, a novel multi-layered Graph-RAG framework\nthat supports efficient and scalable dynamic updates. Our method leverages\nhyperplane-based Locality-Sensitive Hashing (LSH) to partition and organize the\noriginal corpus into hierarchical graph structures, enabling efficient and\nlocalized insertions of new data without disrupting the existing topology. The\ndesign eliminates the need for retraining or costly recomputation while\npreserving high retrieval accuracy and low latency. Experiments on large-scale\nbenchmarks demonstrate that EraRag achieves up to an order of magnitude\nreduction in update time and token consumption compared to existing Graph-RAG\nsystems, while providing superior accuracy performance. This work offers a\npractical path forward for RAG systems that must operate over continually\ngrowing corpora, bridging the gap between retrieval efficiency and\nadaptability. Our code and data are available at\nhttps://github.com/EverM0re/EraRAG-Official.\n","authors":["Fangyuan Zhang","Zhengjun Huang","Yingli Zhou","Qintian Guo","Zhixun Li","Wensheng Luo","Di Jiang","Yixiang Fang","Xiaofang Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.20963v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2506.20957v1","updated":"2025-06-26T02:45:38Z","published":"2025-06-26T02:45:38Z","title":"Antibody Design and Optimization with Multi-scale Equivariant Graph\n  Diffusion Models for Accurate Complex Antigen Binding","summary":"  Antibody design remains a critical challenge in therapeutic and diagnostic\ndevelopment, particularly for complex antigens with diverse binding interfaces.\nCurrent computational methods face two main limitations: (1) capturing\ngeometric features while preserving symmetries, and (2) generalizing novel\nantigen interfaces. Despite recent advancements, these methods often fail to\naccurately capture molecular interactions and maintain structural integrity. To\naddress these challenges, we propose \\textbf{AbMEGD}, an end-to-end framework\nintegrating \\textbf{M}ulti-scale \\textbf{E}quivariant \\textbf{G}raph\n\\textbf{D}iffusion for antibody sequence and structure co-design. Leveraging\nadvanced geometric deep learning, AbMEGD combines atomic-level geometric\nfeatures with residue-level embeddings, capturing local atomic details and\nglobal sequence-structure interactions. Its E(3)-equivariant diffusion method\nensures geometric precision, computational efficiency, and robust\ngeneralizability for complex antigens. Furthermore, experiments using the\nSAbDab database demonstrate a 10.13\\% increase in amino acid recovery, 3.32\\%\nrise in improvement percentage, and a 0.062~\\AA\\ reduction in root mean square\ndeviation within the critical CDR-H3 region compared to DiffAb, a leading\nantibody design model. These results highlight AbMEGD's ability to balance\nstructural integrity with improved functionality, establishing a new benchmark\nfor sequence-structure co-design and affinity optimization. The code is\navailable at: https://github.com/Patrick221215/AbMEGD.\n","authors":["Jiameng Chen","Xiantao Cai","Jia Wu","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2506.20957v1.pdf","comment":"9 pages, 4 figures, accepted at IJCAI 2025"},{"id":"http://arxiv.org/abs/2506.20941v1","updated":"2025-06-26T02:16:16Z","published":"2025-06-26T02:16:16Z","title":"Model State Arithmetic for Machine Unlearning","summary":"  Large language models are trained on massive corpora of web data, which may\ninclude private data, copyrighted material, factually inaccurate data, or data\nthat degrades model performance. Eliminating the influence of such problematic\ndatapoints through complete retraining -- by repeatedly pretraining the model\non datasets that exclude these specific instances -- is computationally\nprohibitive. For this reason, unlearning algorithms have emerged that aim to\neliminate the influence of particular datapoints, while otherwise preserving\nthe model -- at a low computational cost. However, precisely estimating and\nundoing the influence of individual datapoints has proved to be challenging. In\nthis work, we propose a new algorithm, MSA, for estimating and undoing the\ninfluence of datapoints -- by leveraging model checkpoints i.e. artifacts\ncapturing model states at different stages of pretraining. Our experimental\nresults demonstrate that MSA consistently outperforms existing machine\nunlearning algorithms across multiple benchmarks, models, and evaluation\nmetrics, suggesting that MSA could be an effective approach towards more\nflexible large language models that are capable of data erasure.\n","authors":["Keivan Rezaei","Mehrdad Saberi","Abhilasha Ravichander","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2506.20941v1.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2506.20935v1","updated":"2025-06-26T01:53:25Z","published":"2025-06-26T01:53:25Z","title":"Forecasting Geopolitical Events with a Sparse Temporal Fusion\n  Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and\n  U.S. Conflict Dynamics","summary":"  Forecasting geopolitical conflict from data sources like the Global Database\nof Events, Language, and Tone (GDELT) is a critical challenge for national\nsecurity. The inherent sparsity, burstiness, and overdispersion of such data\ncause standard deep learning models, including the Temporal Fusion Transformer\n(TFT), to produce unreliable long-horizon predictions. We introduce STFT-VNNGP,\na hybrid architecture that won the 2023 Algorithms for Threat Detection (ATD)\ncompetition by overcoming these limitations. Designed to bridge this gap, our\nmodel employs a two-stage process: first, a TFT captures complex temporal\ndynamics to generate multi-quantile forecasts. These quantiles then serve as\ninformed inputs for a Variational Nearest Neighbor Gaussian Process (VNNGP),\nwhich performs principled spatiotemporal smoothing and uncertainty\nquantification. In a case study forecasting conflict dynamics in the Middle\nEast and the U.S., STFT-VNNGP consistently outperforms a standalone TFT,\nshowing a superior ability to predict the timing and magnitude of bursty event\nperiods, particularly at long-range horizons. This work offers a robust\nframework for generating more reliable and actionable intelligence from\nchallenging event data, with all code and workflows made publicly available to\nensure reproducibility.\n","authors":["Hsin-Hsiung Huang","Hayden Hampton"],"pdf_url":"https://arxiv.org/pdf/2506.20935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20933v1","updated":"2025-06-26T01:44:23Z","published":"2025-06-26T01:44:23Z","title":"Lower Bounds on the Size of Markov Equivalence Classes","summary":"  Causal discovery algorithms typically recover causal graphs only up to their\nMarkov equivalence classes unless additional parametric assumptions are made.\nThe sizes of these equivalence classes reflect the limits of what can be\nlearned about the underlying causal graph from purely observational data. Under\nthe assumptions of acyclicity, causal sufficiency, and a uniform model prior,\nMarkov equivalence classes are known to be small on average. In this paper, we\nshow that this is no longer the case when any of these assumptions is relaxed.\nSpecifically, we prove exponentially large lower bounds for the expected size\nof Markov equivalence classes in three settings: sparse random directed acyclic\ngraphs, uniformly random acyclic directed mixed graphs, and uniformly random\ndirected cyclic graphs.\n","authors":["Erik Jahn","Frederick Eberhardt","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2506.20933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.08483v7","updated":"2025-06-26T01:33:13Z","published":"2021-10-16T06:06:36Z","title":"Extremely Simple Streaming Forest","summary":"  Decision forests, including random forests and gradient boosting trees,\nremain the leading machine learning methods for many real-world data problems,\nespecially on tabular data. However, most of the current implementations only\noperate in batch mode, and therefore cannot incrementally update when more data\narrive. Several previous works developed streaming trees and ensembles to\novercome this limitation. Nonetheless, we found that those state-of-the-art\nalgorithms suffer from a number of drawbacks, including low accuracy on some\nproblems and high memory usage on others. We therefore developed an extremely\nsimple extension of decision trees: given new data, simply update existing\ntrees by continuing to grow them, and replace some old trees with new ones to\ncontrol the total number of trees. In a benchmark suite containing 72\nclassification problems (the OpenML-CC18 data suite), we illustrate that our\napproach, $\\textit{Extremely Simple Streaming Forest}$ (XForest), does not\nsuffer from either of the aforementioned limitations. On those datasets, we\nalso demonstrate that our approach often performs as well as, and sometimes\neven better than, conventional batch decision forest algorithms. With a\n$\\textit{zero-added-node}$ approach, XForest-Zero, we also further extend\nexisting splits to new tasks, and this very efficient method only requires\ninference time. Thus, XForests establish a simple standard for streaming trees\nand forests that could readily be applied to many real-world problems.\n","authors":["Haoyin Xu","Jayanta Dey","Sambit Panda","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2110.08483v7.pdf","comment":"Accepted at The Fourth Conference on Lifelong Learning Agents -\n  CoLLAs 2025"},{"id":"http://arxiv.org/abs/2506.20930v1","updated":"2025-06-26T01:29:19Z","published":"2025-06-26T01:29:19Z","title":"Quantum Reinforcement Learning Trading Agent for Sector Rotation in the\n  Taiwan Stock Market","summary":"  We propose a hybrid quantum-classical reinforcement learning framework for\nsector rotation in the Taiwan stock market. Our system employs Proximal Policy\nOptimization (PPO) as the backbone algorithm and integrates both classical\narchitectures (LSTM, Transformer) and quantum-enhanced models (QNN, QRWKV,\nQASA) as policy and value networks. An automated feature engineering pipeline\nextracts financial indicators from capital share data to ensure consistent\nmodel input across all configurations. Empirical backtesting reveals a key\nfinding: although quantum-enhanced models consistently achieve higher training\nrewards, they underperform classical models in real-world investment metrics\nsuch as cumulative return and Sharpe ratio. This discrepancy highlights a core\nchallenge in applying reinforcement learning to financial domains -- namely,\nthe mismatch between proxy reward signals and true investment objectives. Our\nanalysis suggests that current reward designs may incentivize overfitting to\nshort-term volatility rather than optimizing risk-adjusted returns. This issue\nis compounded by the inherent expressiveness and optimization instability of\nquantum circuits under Noisy Intermediate-Scale Quantum (NISQ) constraints. We\ndiscuss the implications of this reward-performance gap and propose directions\nfor future improvement, including reward shaping, model regularization, and\nvalidation-based early stopping. Our work offers a reproducible benchmark and\ncritical insights into the practical challenges of deploying quantum\nreinforcement learning in real-world finance.\n","authors":["Chi-Sheng Chen","Xinyu Zhang","Ya-Chuan Chen"],"pdf_url":"https://arxiv.org/pdf/2506.20930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20928v1","updated":"2025-06-26T01:25:39Z","published":"2025-06-26T01:25:39Z","title":"Active Learning for Manifold Gaussian Process Regression","summary":"  This paper introduces an active learning framework for manifold Gaussian\nProcess (GP) regression, combining manifold learning with strategic data\nselection to improve accuracy in high-dimensional spaces. Our method jointly\noptimizes a neural network for dimensionality reduction and a Gaussian process\nregressor in the latent space, supervised by an active learning criterion that\nminimizes global prediction error. Experiments on synthetic data demonstrate\nsuperior performance over randomly sequential learning. The framework\nefficiently handles complex, discontinuous functions while preserving\ncomputational tractability, offering practical value for scientific and\nengineering applications. Future work will focus on scalability and\nuncertainty-aware manifold learning.\n","authors":["Yuanxing Cheng","Lulu Kang","Yiwei Wang","Chun Liu"],"pdf_url":"https://arxiv.org/pdf/2506.20928v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.20927v1","updated":"2025-06-26T01:24:08Z","published":"2025-06-26T01:24:08Z","title":"Interpretable Representation Learning for Additive Rule Ensembles","summary":"  Small additive ensembles of symbolic rules offer interpretable prediction\nmodels. Traditionally, these ensembles use rule conditions based on\nconjunctions of simple threshold propositions $x \\geq t$ on a single input\nvariable $x$ and threshold $t$, resulting geometrically in axis-parallel\npolytopes as decision regions. While this form ensures a high degree of\ninterpretability for individual rules and can be learned efficiently using the\ngradient boosting approach, it relies on having access to a curated set of\nexpressive and ideally independent input features so that a small ensemble of\naxis-parallel regions can describe the target variable well. Absent such\nfeatures, reaching sufficient accuracy requires increasing the number and\ncomplexity of individual rules, which diminishes the interpretability of the\nmodel. Here, we extend classical rule ensembles by introducing logical\npropositions with learnable sparse linear transformations of input variables,\ni.e., propositions of the form $\\mathbf{x}^\\mathrm{T}\\mathbf{w} \\geq t$, where\n$\\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as\ngeneral polytopes with oblique faces. We propose a learning method using\nsequential greedy optimization based on an iteratively reweighted formulation\nof logistic regression. Experimental results demonstrate that the proposed\nmethod efficiently constructs rule ensembles with the same test risk as\nstate-of-the-art methods while significantly reducing model complexity across\nten benchmark datasets.\n","authors":["Shahrzad Behzadimanesh","Pierre Le Bodic","Geoffrey I. Webb","Mario Boley"],"pdf_url":"https://arxiv.org/pdf/2506.20927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20921v1","updated":"2025-06-26T01:03:44Z","published":"2025-06-26T01:03:44Z","title":"LLM-guided Chemical Process Optimization with a Multi-Agent Approach","summary":"  Chemical process optimization is crucial to maximize production efficiency\nand economic performance. Traditional methods, including gradient-based\nsolvers, evolutionary algorithms, and parameter grid searches, become\nimpractical when operating constraints are ill-defined or unavailable,\nrequiring engineers to rely on subjective heuristics to estimate feasible\nparameter ranges. To address this constraint definition bottleneck, we present\na multi-agent framework of large language model (LLM) agents that autonomously\ninfer operating constraints from minimal process descriptions, then\ncollaboratively guide optimization using the inferred constraints. Our\nAutoGen-based agentic framework employs OpenAI's o3 model, with specialized\nagents for constraint generation, parameter validation, simulation execution,\nand optimization guidance. Through two phases - autonomous constraint\ngeneration using embedded domain knowledge, followed by iterative multi-agent\noptimization - the framework eliminates the need for predefined operational\nbounds. Validated on the hydrodealkylation process across cost, yield, and\nyield-to-cost ratio metrics, the framework demonstrated competitive performance\nwith conventional optimization methods while achieving better computational\nefficiency, requiring fewer iterations to converge. Our approach converged in\nunder 20 minutes, achieving a 31-fold speedup over grid search. Beyond\ncomputational efficiency, the framework's reasoning-guided search demonstrates\nsophisticated process understanding, correctly identifying utility trade-offs,\nand applying domain-informed heuristics. This approach shows significant\npotential for optimization scenarios where operational constraints are poorly\ncharacterized or unavailable, particularly for emerging processes and retrofit\napplications.\n","authors":["Tong Zeng","Srivathsan Badrinarayanan","Janghoon Ock","Cheng-Kai Lai","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2506.20921v1.pdf","comment":"16 pages (main manuscript without references), 2 figures"},{"id":"http://arxiv.org/abs/2501.18637v2","updated":"2025-06-26T01:03:29Z","published":"2025-01-28T17:06:47Z","title":"Machine learning of microstructure--property relationships in materials\n  leveraging microstructure representation from foundational vision\n  transformers","summary":"  Machine learning of microstructure--property relationships from data is an\nemerging approach in computational materials science. Most existing machine\nlearning efforts focus on the development of task-specific models for each\nmicrostructure--property relationship. We propose utilizing pre-trained\nfoundational vision transformers for the extraction of task-agnostic\nmicrostructure features and subsequent light-weight machine learning of a\nmicrostructure-dependent property. We demonstrate our approach with pre-trained\nstate-of-the-art vision transformers (CLIP, DINOv2, SAM) in two case studies on\nmachine-learning: (i) elastic modulus of two-phase microstructures based on\nsimulations data; and (ii) Vicker's hardness of Ni-base and Co-base superalloys\nbased on experimental data published in literature. Our results show the\npotential of foundational vision transformers for robust microstructure\nrepresentation and efficient machine learning of microstructure--property\nrelationships without the need for expensive task-specific training or\nfine-tuning of bespoke deep learning models.\n","authors":["Sheila E. Whitman","Marat I. Latypov"],"pdf_url":"https://arxiv.org/pdf/2501.18637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20916v1","updated":"2025-06-26T00:49:25Z","published":"2025-06-26T00:49:25Z","title":"Explainable AI for Radar Resource Management: Modified LIME in Deep\n  Reinforcement Learning","summary":"  Deep reinforcement learning has been extensively studied in decision-making\nprocesses and has demonstrated superior performance over conventional\napproaches in various fields, including radar resource management (RRM).\nHowever, a notable limitation of neural networks is their ``black box\" nature\nand recent research work has increasingly focused on explainable AI (XAI)\ntechniques to describe the rationale behind neural network decisions. One\npromising XAI method is local interpretable model-agnostic explanations (LIME).\nHowever, the sampling process in LIME ignores the correlations between\nfeatures. In this paper, we propose a modified LIME approach that integrates\ndeep learning (DL) into the sampling process, which we refer to as DL-LIME. We\nemploy DL-LIME within deep reinforcement learning for radar resource\nmanagement. Numerical results show that DL-LIME outperforms conventional LIME\nin terms of both fidelity and task performance, demonstrating superior\nperformance with both metrics. DL-LIME also provides insights on which factors\nare more important in decision making for radar resource management.\n","authors":["Ziyang Lu","M. Cenk Gursoy","Chilukuri K. Mohan","Pramod K. Varshney"],"pdf_url":"https://arxiv.org/pdf/2506.20916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20915v1","updated":"2025-06-26T00:49:02Z","published":"2025-06-26T00:49:02Z","title":"ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large\n  Language Models","summary":"  As the deployment of large language models (LLMs) grows in sensitive domains,\nensuring the integrity of their computational provenance becomes a critical\nchallenge, particularly in regulated sectors such as healthcare, where strict\nrequirements are applied in dataset usage. We introduce ZKPROV, a novel\ncryptographic framework that enables zero-knowledge proofs of LLM provenance.\nIt allows users to verify that a model is trained on a reliable dataset without\nrevealing sensitive information about it or its parameters. Unlike prior\napproaches that focus on complete verification of the training process\n(incurring significant computational cost) or depend on trusted execution\nenvironments, ZKPROV offers a distinct balance. Our method cryptographically\nbinds a trained model to its authorized training dataset(s) through\nzero-knowledge proofs while avoiding proof of every training step. By\nleveraging dataset-signed metadata and compact model parameter commitments,\nZKPROV provides sound and privacy-preserving assurances that the result of the\nLLM is derived from a model trained on the claimed authorized and relevant\ndataset. Experimental results demonstrate the efficiency and scalability of the\nZKPROV in generating this proof and verifying it, achieving a practical\nsolution for real-world deployments. We also provide formal security\nguarantees, proving that our approach preserves dataset confidentiality while\nensuring trustworthy dataset provenance.\n","authors":["Mina Namazi","Alexander Nemecek","Erman Ayday"],"pdf_url":"https://arxiv.org/pdf/2506.20915v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2506.20910v1","updated":"2025-06-26T00:31:21Z","published":"2025-06-26T00:31:21Z","title":"Faster Fixed-Point Methods for Multichain MDPs","summary":"  We study value-iteration (VI) algorithms for solving general (a.k.a.\nmultichain) Markov decision processes (MDPs) under the average-reward\ncriterion, a fundamental but theoretically challenging setting. Beyond the\ndifficulties inherent to all average-reward problems posed by the lack of\ncontractivity and non-uniqueness of solutions to the Bellman operator, in the\nmultichain setting an optimal policy must solve the navigation subproblem of\nsteering towards the best connected component, in addition to optimizing\nlong-run performance within each component. We develop algorithms which better\nsolve this navigational subproblem in order to achieve faster convergence for\nmultichain MDPs, obtaining improved rates of convergence and sharper measures\nof complexity relative to prior work. Many key components of our results are of\npotential independent interest, including novel connections between\naverage-reward and discounted problems, optimal fixed-point methods for\ndiscounted VI which extend to general Banach spaces, new sublinear convergence\nrates for the discounted value error, and refined suboptimality decompositions\nfor multichain MDPs. Overall our results yield faster convergence rates for\ndiscounted and average-reward problems and expand the theoretical foundations\nof VI approaches.\n","authors":["Matthew Zurek","Yudong Chen"],"pdf_url":"https://arxiv.org/pdf/2506.20910v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20904v1","updated":"2025-06-26T00:22:39Z","published":"2025-06-26T00:22:39Z","title":"Optimal Single-Policy Sample Complexity and Transient Coverage for\n  Average-Reward Offline RL","summary":"  We study offline reinforcement learning in average-reward MDPs, which\npresents increased challenges from the perspectives of distribution shift and\nnon-uniform coverage, and has been relatively underexamined from a theoretical\nperspective. While previous work obtains performance guarantees under\nsingle-policy data coverage assumptions, such guarantees utilize additional\ncomplexity measures which are uniform over all policies, such as the uniform\nmixing time. We develop sharp guarantees depending only on the target policy,\nspecifically the bias span and a novel policy hitting radius, yielding the\nfirst fully single-policy sample complexity bound for average-reward offline\nRL. We are also the first to handle general weakly communicating MDPs,\ncontrasting restrictive structural assumptions made in prior work. To achieve\nthis, we introduce an algorithm based on pessimistic discounted value iteration\nenhanced by a novel quantile clipping technique, which enables the use of a\nsharper empirical-span-based penalty function. Our algorithm also does not\nrequire any prior parameter knowledge for its implementation. Remarkably, we\nshow via hard examples that learning under our conditions requires coverage\nassumptions beyond the stationary distribution of the target policy,\ndistinguishing single-policy complexity measures from previously examined\ncases. We also develop lower bounds nearly matching our main result.\n","authors":["Matthew Zurek","Guy Zamir","Yudong Chen"],"pdf_url":"https://arxiv.org/pdf/2506.20904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20898v1","updated":"2025-06-26T00:06:11Z","published":"2025-06-26T00:06:11Z","title":"Graph-Structured Feedback Multimodel Ensemble Online Conformal\n  Prediction","summary":"  Online conformal prediction has demonstrated its capability to construct a\nprediction set for each incoming data point that covers the true label with a\npredetermined probability. To cope with potential distribution shift,\nmulti-model online conformal prediction has been introduced to select and\nleverage different models from a preselected candidate set. Along with the\nimproved flexibility, the choice of the preselected set also brings challenges.\nA candidate set that includes a large number of models may increase the\ncomputational complexity. In addition, the inclusion of irrelevant models with\npoor performance may negatively impact the performance and lead to\nunnecessarily large prediction sets. To address these challenges, we propose a\nnovel multi-model online conformal prediction algorithm that identifies a\nsubset of effective models at each time step by collecting feedback from a\nbipartite graph, which is refined upon receiving new data. A model is then\nselected from this subset to construct the prediction set, resulting in reduced\ncomputational complexity and smaller prediction sets. Additionally, we\ndemonstrate that using prediction set size as feedback, alongside model loss,\ncan significantly improve efficiency by constructing smaller prediction sets\nwhile still satisfying the required coverage guarantee. The proposed algorithms\nare proven to ensure valid coverage and achieve sublinear regret. Experiments\non real and synthetic datasets validate that the proposed methods construct\nsmaller prediction sets and outperform existing multi-model online conformal\nprediction approaches.\n","authors":["Erfan Hajihashemi","Yanning Shen"],"pdf_url":"https://arxiv.org/pdf/2506.20898v1.pdf","comment":null}]},"2025-06-25T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.20869v1","updated":"2025-06-25T22:40:00Z","published":"2025-06-25T22:40:00Z","title":"Engineering RAG Systems for Real-World Applications: Design,\n  Development, and Evaluation","summary":"  Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.\n","authors":["Md Toufique Hasan","Muhammad Waseem","Kai-Kristian Kemell","Ayman Asad Khan","Mika Saari","Pekka Abrahamsson"],"pdf_url":"https://arxiv.org/pdf/2506.20869v1.pdf","comment":"Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version"},{"id":"http://arxiv.org/abs/2504.08738v3","updated":"2025-06-25T22:12:21Z","published":"2025-03-20T18:56:22Z","title":"AI-Driven Sentiment Analytics: Unlocking Business Value in the\n  E-Commerce Landscape","summary":"  The rapid growth of e-commerce has led to an overwhelming volume of customer\nfeedback, from product reviews to service interactions. Extracting meaningful\ninsights from this data is crucial for businesses aiming to improve customer\nsatisfaction and optimize decision-making. This paper presents an AI-driven\nsentiment analysis system designed specifically for e-commerce applications,\nbalancing accuracy with interpretability. Our approach integrates traditional\nmachine learning techniques with modern deep learning models, allowing for a\nmore nuanced understanding of customer sentiment while ensuring transparency in\ndecision-making. Experimental results show that our system outperforms standard\nsentiment analysis methods, achieving an accuracy of 89.7% on diverse,\nlarge-scale datasets. Beyond technical performance, real-world implementation\nacross multiple e-commerce platforms demonstrates tangible improvements in\ncustomer engagement and operational efficiency. This study highlights both the\npotential and the challenges of applying AI to sentiment analysis in a\ncommercial setting, offering insights into practical deployment strategies and\nareas for future refinement.\n","authors":["Qianye Wu","Chengxuan Xia","Sixuan Tian"],"pdf_url":"https://arxiv.org/pdf/2504.08738v3.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2506.20854v1","updated":"2025-06-25T22:00:12Z","published":"2025-06-25T22:00:12Z","title":"Towards Two-Stage Counterfactual Learning to Rank","summary":"  Counterfactual learning to rank (CLTR) aims to learn a ranking policy from\nuser interactions while correcting for the inherent biases in interaction data,\nsuch as position bias. Existing CLTR methods assume a single ranking policy\nthat selects top-K ranking from the entire document candidate set. In\nreal-world applications, the candidate document set is on the order of\nmillions, making a single-stage ranking policy impractical. In order to scale\nto millions of documents, real-world ranking systems are designed in a\ntwo-stage fashion, with a candidate generator followed by a ranker. The\nexisting CLTR method for a two-stage offline ranking system only considers the\ntop-1 ranking set-up and only focuses on training the candidate generator, with\nthe ranker fixed. A CLTR method for training both the ranker and candidate\ngenerator jointly is missing from the existing literature. In this paper, we\npropose a two-stage CLTR estimator that considers the interaction between the\ntwo stages and estimates the joint value of the two policies offline. In\naddition, we propose a novel joint optimization method to train the candidate\nand ranker policies, respectively. To the best of our knowledge, we are the\nfirst to propose a CLTR estimator and learning method for two-stage ranking.\nExperimental results on a semi-synthetic benchmark demonstrate the\neffectiveness of the proposed joint CLTR method over baselines.\n","authors":["Shashank Gupta","Yiming Liao","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2506.20854v1.pdf","comment":"Accepted at ICTIR 2025 (co-located with SIGIR 2025)"},{"id":"http://arxiv.org/abs/2411.09852v3","updated":"2025-06-25T21:48:04Z","published":"2024-11-15T00:20:36Z","title":"InterFormer: Effective Heterogeneous Interaction Learning for\n  Click-Through Rate Prediction","summary":"  Click-through rate (CTR) prediction, which predicts the probability of a user\nclicking an ad, is a fundamental task in recommender systems. The emergence of\nheterogeneous information, such as user profile and behavior sequences, depicts\nuser interests from different aspects. A mutually beneficial integration of\nheterogeneous information is the cornerstone towards the success of CTR\nprediction. However, most of the existing methods suffer from two fundamental\nlimitations, including (1) insufficient inter-mode interaction due to the\nunidirectional information flow between modes, and (2) aggressive information\naggregation caused by early summarization, resulting in excessive information\nloss. To address the above limitations, we propose a novel module named\nInterFormer to learn heterogeneous information interaction in an interleaving\nstyle. To achieve better interaction learning, InterFormer enables\nbidirectional information flow for mutually beneficial learning across\ndifferent modes. To avoid aggressive information aggregation, we retain\ncomplete information in each data mode and use a separate bridging arch for\neffective information selection and summarization. Our proposed InterFormer\nachieves state-of-the-art performance on three public datasets and a\nlarge-scale industrial dataset.\n","authors":["Zhichen Zeng","Xiaolong Liu","Mengyue Hang","Xiaoyi Liu","Qinghai Zhou","Chaofei Yang","Yiqun Liu","Yichen Ruan","Laming Chen","Yuxin Chen","Yujia Hao","Jiaqi Xu","Jade Nie","Xi Liu","Buyun Zhang","Wei Wen","Siyang Yuan","Hang Yin","Xin Zhang","Kai Wang","Wen-Yen Chen","Yiping Han","Huayu Li","Chunzhi Yang","Bo Long","Philip S. Yu","Hanghang Tong","Jiyan Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09852v3.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.20844v1","updated":"2025-06-25T21:29:33Z","published":"2025-06-25T21:29:33Z","title":"The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval\n  from Complex Structured Academic Papers","summary":"  Scientific fact-checking aims to determine the veracity of scientific claims\nby retrieving and analysing evidence from research literature. The problem is\ninherently more complex than general fact-checking since it must accommodate\nthe evolving nature of scientific knowledge, the structural complexity of\nacademic literature and the challenges posed by long-form, multimodal\nscientific expression. However, existing approaches focus on simplified\nversions of the problem based on small-scale datasets consisting of abstracts\nrather than full papers, thereby avoiding the distinct challenges associated\nwith processing complete documents. This paper examines the limitations of\ncurrent scientific fact-checking systems and reveals the many potential\nfeatures and resources that could be exploited to advance their performance. It\nidentifies key research challenges within evidence retrieval, including (1)\nevidence-driven retrieval that addresses semantic limitations and topic\nimbalance (2) time-aware evidence retrieval with citation tracking to mitigate\noutdated information, (3) structured document parsing to leverage long-range\ncontext, (4) handling complex scientific expressions, including tables,\nfigures, and domain-specific terminology and (5) assessing the credibility of\nscientific literature. Preliminary experiments were conducted to substantiate\nthese challenges and identify potential solutions. This perspective paper aims\nto advance scientific fact-checking with a specialised IR system tailored for\nreal-world applications.\n","authors":["Xingyu Deng","Xi Wang","Mark Stevenson"],"pdf_url":"https://arxiv.org/pdf/2506.20844v1.pdf","comment":"Accepted for ACM SIGIR Conference on Innovative Concepts and Theories\n  in Information Retrieval (ICTIR'25)"},{"id":"http://arxiv.org/abs/2506.20817v1","updated":"2025-06-25T20:32:12Z","published":"2025-06-25T20:32:12Z","title":"RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced\n  Retrieval-Augmented Generation in Recommendation","summary":"  This paper addresses the challenge of developing multimodal recommender\nsystems for the movie domain, where limited metadata (e.g., title, genre) often\nhinders the generation of robust recommendations. We introduce a resource that\ncombines LLM-generated plot descriptions with trailer-derived visual embeddings\nin a unified pipeline supporting both Retrieval-Augmented Generation (RAG) and\ncollaborative filtering. Central to our approach is a data augmentation step\nthat transforms sparse metadata into richer textual signals, alongside fusion\nstrategies (e.g., PCA, CCA) that integrate visual cues. Experimental\nevaluations demonstrate that CCA-based fusion significantly boosts recall\ncompared to unimodal baselines, while an LLM-driven re-ranking step further\nimproves NDCG, particularly in scenarios with limited textual data. By\nreleasing this framework, we invite further exploration of multi-modal\nrecommendation techniques tailored to cold-start, novelty-focused, and\ndomain-specific settings. All code, data, and detailed documentation are\npublicly available at: https://github.com/RecSys-lab/RAG-VisualRec\n","authors":["Ali Tourani","Fatemeh Nazary","Yashar Deldjoo"],"pdf_url":"https://arxiv.org/pdf/2506.20817v1.pdf","comment":"20 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2506.20501v1","updated":"2025-06-25T14:47:43Z","published":"2025-06-25T14:47:43Z","title":"Unidentified and Confounded? Understanding Two-Tower Models for Unbiased\n  Learning to Rank","summary":"  Additive two-tower models are popular learning-to-rank methods for handling\nbiased user feedback in industry settings. Recent studies, however, report a\nconcerning phenomenon: training two-tower models on clicks collected by\nwell-performing production systems leads to decreased ranking performance. This\npaper investigates two recent explanations for this observation: confounding\neffects from logging policies and model identifiability issues. We\ntheoretically analyze the identifiability conditions of two-tower models,\nshowing that either document swaps across positions or overlapping feature\ndistributions are required to recover model parameters from clicks. We also\ninvestigate the effect of logging policies on two-tower models, finding that\nthey introduce no bias when models perfectly capture user behavior. However,\nlogging policies can amplify biases when models imperfectly capture user\nbehavior, particularly when prediction errors correlate with document placement\nacross positions. We propose a sample weighting technique to mitigate these\neffects and provide actionable insights for researchers and practitioners using\ntwo-tower models.\n","authors":["Philipp Hager","Onno Zoeter","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2506.20501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20495v1","updated":"2025-06-25T14:41:13Z","published":"2025-06-25T14:41:13Z","title":"ReCode: Updating Code API Knowledge with Reinforcement Learning","summary":"  Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.\n","authors":["Haoze Wu","Yunzhi Yao","Wenhao Yu","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20495v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.20476v1","updated":"2025-06-25T14:23:21Z","published":"2025-06-25T14:23:21Z","title":"Knowledge-Aware Diverse Reranking for Cross-Source Question Answering","summary":"  This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG\ncompetition. The competition's evaluation set, automatically generated by\nDataMorgana from internet corpora, encompassed a wide range of target topics,\nquestion types, question formulations, audience types, and knowledge\norganization methods. It offered a fair evaluation of retrieving\nquestion-relevant supporting documents from a 15M documents subset of the\nFineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline\nachieved first place in the competition.\n","authors":["Tong Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.20476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11727v2","updated":"2025-06-25T14:06:24Z","published":"2025-06-13T12:39:59Z","title":"Forgetful by Design? A Critical Audit of YouTube's Search API for\n  Academic Research","summary":"  This paper critically audits the search endpoint of YouTube's Data API (v3),\na common tool for academic research. Through systematic weekly searches over\nsix months using eleven queries, we identify major limitations regarding\ncompleteness, representativeness, consistency, and bias. Our findings reveal\nsubstantial differences between ranking parameters like relevance and date in\nterms of video recall and precision, with relevance often retrieving numerous\noff-topic videos. We also find severe temporal decay, as the number of findable\nvideos for a specific period dramatically decreases after just 20-60 days from\nthe publication date, potentially hampering many different research designs.\nFurthermore, search results lack consistency, with identical queries yielding\ndifferent video sets over time, compromising replicability. A case study on the\nEuropean Parliament elections highlights how these issues impact research\noutcomes. While the paper offers several mitigation strategies, it concludes\nthat the API's search function, potentially prioritizing \"freshness\" over\ncomprehensive retrieval, is not adequate for robust academic research,\nespecially concerning Digital Services Act requirements.\n","authors":["Bernhard Rieder","Adrian Padilla","Oscar Coromina"],"pdf_url":"https://arxiv.org/pdf/2506.11727v2.pdf","comment":"15 pages, 2 tables and 4 figures"},{"id":"http://arxiv.org/abs/2304.04971v3","updated":"2025-06-25T13:38:45Z","published":"2023-04-11T04:31:00Z","title":"Diffusion Recommender Model","summary":"  Generative models such as Generative Adversarial Networks (GANs) and\nVariational Auto-Encoders (VAEs) are widely utilized to model the generative\nprocess of user interactions. However, these generative models suffer from\nintrinsic limitations such as the instability of GANs and the restricted\nrepresentation ability of VAEs. Such limitations hinder the accurate modeling\nof the complex user interaction generation procedure, such as noisy\ninteractions caused by various interference factors. In light of the impressive\nadvantages of Diffusion Models (DMs) over traditional generative models in\nimage synthesis, we propose a novel Diffusion Recommender Model (named DiffRec)\nto learn the generative process in a denoising manner. To retain personalized\ninformation in user interactions, DiffRec reduces the added noises and avoids\ncorrupting users' interactions into pure noises like in image synthesis. In\naddition, we extend traditional DMs to tackle the unique challenges in\npractical recommender systems: high resource costs for large-scale item\nprediction and temporal shifts of user preference. To this end, we propose two\nextensions of DiffRec: L-DiffRec clusters items for dimension compression and\nconducts the diffusion processes in the latent space; and T-DiffRec reweights\nuser interactions based on the interaction timestamps to encode temporal\ninformation. We conduct extensive experiments on three datasets under multiple\nsettings (e.g. clean training, noisy training, and temporal training). The\nempirical results and in-depth analysis validate the superiority of DiffRec\nwith two extensions over competitive baselines.\n","authors":["Wenjie Wang","Yiyan Xu","Fuli Feng","Xinyu Lin","Xiangnan He","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2304.04971v3.pdf","comment":"10 pages, 7 figures, accepted for publication in SIGIR'23"},{"id":"http://arxiv.org/abs/2506.20330v1","updated":"2025-06-25T11:28:04Z","published":"2025-06-25T11:28:04Z","title":"Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce\n  Search","summary":"  Semantic retrieval, which retrieves semantically matched items given a\ntextual query, has been an essential component to enhance system effectiveness\nin e-commerce search. In this paper, we study the multimodal retrieval problem,\nwhere the visual information (e.g, image) of item is leveraged as supplementary\nof textual information to enrich item representation and further improve\nretrieval performance. Though learning from cross-modality data has been\nstudied extensively in tasks such as visual question answering or media\nsummarization, multimodal retrieval remains a non-trivial and unsolved problem\nespecially in the asymmetric scenario where the query is unimodal while the\nitem is multimodal. In this paper, we propose a novel model named SMAR, which\nstands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the\nproblem of modality fusion and alignment in this kind of asymmetric scenario.\nExtensive experimental results on an industrial dataset show that the proposed\nmodel outperforms baseline models significantly in retrieval accuracy. We have\nopen sourced our industrial dataset for the sake of reproducibility and future\nresearch works.\n","authors":["Zhigong Zhou","Ning Ding","Xiaochuan Fan","Yue Shang","Yiming Qiu","Jingwei Zhuo","Zhiwei Ge","Songlin Wang","Lin Liu","Sulong Xu","Han Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20330v1.pdf","comment":"published in sigir2023"},{"id":"http://arxiv.org/abs/2506.20329v1","updated":"2025-06-25T11:24:52Z","published":"2025-06-25T11:24:52Z","title":"Producer-Fairness in Sequential Bundle Recommendation","summary":"  We address fairness in the context of sequential bundle recommendation, where\nusers are served in turn with sets of relevant and compatible items. Motivated\nby real-world scenarios, we formalize producer-fairness, that seeks to achieve\ndesired exposure of different item groups across users in a recommendation\nsession. Our formulation combines naturally with building high quality bundles.\nOur problem is solved in real time as users arrive. We propose an exact\nsolution that caters to small instances of our problem. We then examine two\nheuristics, quality-first and fairness-first, and an adaptive variant that\ndetermines on-the-fly the right balance between bundle fairness and quality.\nOur experiments on three real-world datasets underscore the strengths and\nlimitations of each solution and demonstrate their efficacy in providing fair\nbundle recommendations without compromising bundle quality.\n","authors":["Alexandre Rio","Marta Soare","Sihem Amer-Yahia"],"pdf_url":"https://arxiv.org/pdf/2506.20329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20291v1","updated":"2025-06-25T09:53:35Z","published":"2025-06-25T09:53:35Z","title":"A Literature Review on Simulation in Conversational Recommender Systems","summary":"  Conversational Recommender Systems (CRSs) have garnered attention as a novel\napproach to delivering personalized recommendations through multi-turn\ndialogues. This review developed a taxonomy framework to systematically\ncategorize relevant publications into four groups: dataset construction,\nalgorithm design, system evaluation, and empirical studies, providing a\ncomprehensive analysis of simulation methods in CRSs research. Our analysis\nreveals that simulation methods play a key role in tackling CRSs' main\nchallenges. For example, LLM-based simulation methods have been used to create\nconversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.\nDespite several challenges, such as dataset bias, the limited output\nflexibility of LLM-based simulations, and the gap between text semantic space\nand behavioral semantics, persist due to the complexity in Human-Computer\nInteraction (HCI) of CRSs, simulation methods hold significant potential for\nadvancing CRS research. This review offers a thorough summary of the current\nresearch landscape in this domain and identifies promising directions for\nfuture inquiry.\n","authors":["Haoran Zhang","Xin Zhao","Jinze Chen","Junpeng Guo"],"pdf_url":"https://arxiv.org/pdf/2506.20291v1.pdf","comment":"6 pages, 1 figures, accepted as a poster for CSWIM 2025"},{"id":"http://arxiv.org/abs/2403.11624v5","updated":"2025-06-25T08:38:27Z","published":"2024-03-18T09:56:00Z","title":"Dual-Channel Multiplex Graph Neural Networks for Recommendation","summary":"  Effective recommender systems play a crucial role in accurately capturing\nuser and item attributes that mirror individual preferences. Some existing\nrecommendation techniques have started to shift their focus towards modeling\nvarious types of interactive relations between users and items in real-world\nrecommendation scenarios, such as clicks, marking favorites, and purchases on\nonline shopping platforms. Nevertheless, these approaches still grapple with\ntwo significant challenges: (1) Insufficient modeling and exploitation of the\nimpact of various behavior patterns formed by multiplex relations between users\nand items on representation learning, and (2) ignoring the effect of different\nrelations within behavior patterns on the target relation in recommender system\nscenarios. In this work, we introduce a novel recommendation framework,\nDual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the\naforementioned challenges. It incorporates an explicit behavior pattern\nrepresentation learner to capture the behavior patterns composed of multiplex\nuser-item interactive relations, and includes a relation chain representation\nlearner and a relation chain-aware encoder to discover the impact of various\nauxiliary relations on the target relation, the dependencies between different\nrelations, and mine the appropriate order of relations in a behavior pattern.\nExtensive experiments on three real-world datasets demonstrate that our DCMGNN\nsurpasses various state-of-the-art recommendation methods. It outperforms the\nbest baselines by 10.06% and 12.15% on average across all datasets in terms of\nRecall@10 and NDCG@10, respectively.\n","authors":["Xiang Li","Chaofan Fu","Zhongying Zhao","Guanjie Zheng","Chao Huang","Yanwei Yu","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2403.11624v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20156v1","updated":"2025-06-25T06:23:39Z","published":"2025-06-25T06:23:39Z","title":"Irec: A Metacognitive Scaffolding for Self-Regulated Learning through\n  Just-in-Time Insight Recall: A Conceptual Framework and System Prototype","summary":"  The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.\n","authors":["Xuefei Hou","Xizhao Tan"],"pdf_url":"https://arxiv.org/pdf/2506.20156v1.pdf","comment":"Version 1 of a work in progress. Finalized system flowcharts, a\n  public GitHub repository with the source code, and a full reproducibility\n  package detailing the prompts, models, and testing guidelines will be\n  provided in v2"},{"id":"http://arxiv.org/abs/2506.17508v2","updated":"2025-06-25T06:22:45Z","published":"2025-06-20T23:17:11Z","title":"Mapping the Evolution of Research Contributions using KnoVo","summary":"  This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.\n","authors":["Sajratul Y. Rubaiat","Syed N. Sakib","Hasan M. Jamil"],"pdf_url":"https://arxiv.org/pdf/2506.17508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20141v1","updated":"2025-06-25T05:23:44Z","published":"2025-06-25T05:23:44Z","title":"Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections\n  over 11 Years of ICLR Data","summary":"  The explosive growth of AI research has driven paper submissions at flagship\nAI conferences to unprecedented levels, necessitating many venues in 2025\n(e.g., CVPR, ICCV, KDD, AAAI, IJCAI, WSDM) to enforce strict per-author\nsubmission limits and to desk-reject any excess papers by simple ID order.\nWhile this policy helps reduce reviewer workload, it may unintentionally\ndiscard valuable papers and penalize authors' efforts. In this paper, we ask an\nessential research question on whether it is possible to follow submission\nlimits while minimizing needless rejections. We first formalize the current\ndesk-rejection policies as an optimization problem, and then develop a\npractical algorithm based on linear programming relaxation and a rounding\nscheme. Under extensive evaluation on 11 years of real-world ICLR\n(International Conference on Learning Representations) data, our method\npreserves up to $19.23\\%$ more papers without violating any author limits.\nMoreover, our algorithm is highly efficient in practice, with all results on\nICLR data computed within at most 53.64 seconds. Our work provides a simple and\npractical desk-rejection strategy that significantly reduces unnecessary\nrejections, demonstrating strong potential to improve current CS conference\nsubmission policies.\n","authors":["Xiaoyu Li","Zhao Song","Jiahao Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20070v1","updated":"2025-06-25T00:25:08Z","published":"2025-06-25T00:25:08Z","title":"Multimodal Information Retrieval for Open World with Edit Distance Weak\n  Supervision","summary":"  Existing multi-media retrieval models either rely on creating a common\nsubspace with modality-specific representation models or require schema mapping\namong modalities to measure similarities among multi-media data. Our goal is to\navoid the annotation overhead incurred from considering retrieval as a\nsupervised classification task and re-use the pretrained encoders in large\nlanguage models and vision tasks. We propose \"FemmIR\", a framework to retrieve\nmultimodal results relevant to information needs expressed with multimodal\nqueries by example without any similarity label. Such identification is\nnecessary for real-world applications where data annotations are scarce and\nsatisfactory performance is required without fine-tuning with a common\nframework across applications. We curate a new dataset called MuQNOL for\nbenchmarking progress on this task. Our technique is based on weak supervision\nintroduced through edit distance between samples: graph edit distance can be\nmodified to consider the cost of replacing a data sample in terms of its\nproperties, and relevance can be measured through the implicit signal from the\namount of edit cost among the objects. Unlike metric learning or encoding\nnetworks, FemmIR re-uses the high-level properties and maintains the property\nvalue and relationship constraints with a multi-level interaction score between\ndata samples and the query example provided by the user. We empirically\nevaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs\ncomparably to similar retrieval systems in delivering on-demand retrieval\nresults with exact and approximate similarities while using the existing\nproperty identifiers in the system.\n","authors":["KMA Solaiman","Bharat Bhargava"],"pdf_url":"https://arxiv.org/pdf/2506.20070v1.pdf","comment":"Submitted to ICDE'24. An earlier version of this paper appeared on\n  TechRxiv: https://www.techrxiv.org/doi/full/10.36227/techrxiv.21990284.v1,\n  uploaded on February 05, 2023"}],"Databases":[{"id":"http://arxiv.org/abs/2506.20851v1","updated":"2025-06-25T21:48:21Z","published":"2025-06-25T21:48:21Z","title":"Generating Reliable Adverse event Profiles for Health through Automated\n  Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach","summary":"  As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.\n","authors":["Srikar Reddy Gadusu","Larry Callahan","Samir Lababidi","Arunasri Nishtala","Sophia Healey","Hande McGinty"],"pdf_url":"https://arxiv.org/pdf/2506.20851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01685v2","updated":"2025-06-25T21:36:23Z","published":"2024-11-03T21:01:40Z","title":"Reducing Biases in Record Matching Through Scores Calibration","summary":"  Record matching is the task of identifying records that refer to the same\nreal-world entity across datasets. While most existing models optimize for\naccuracy, fairness has become an important concern due to the potential for\nunequal outcomes across demographic groups. Prior work typically focuses on\nbinary outcomes evaluated at fixed decision thresholds. However, such\nevaluations can miss biases in matching scores--biases that persist across\nthresholds and affect downstream tasks. We propose a threshold-independent\nframework for measuring and reducing score bias, defined as disparities in the\ndistribution of matching scores across groups. We show that several\nstate-of-the-art matching methods exhibit substantial score bias, even when\nappearing fair under standard threshold-based metrics. To address this, we\nintroduce two post-processing score calibration algorithms. The first, calib,\naligns group-wise score distributions using the Wasserstein barycenter,\ntargeting demographic parity. The second, ccalib, conditions on predicted\nlabels to further reduce label-dependent biases, such as equal opportunity.\nBoth methods are model-agnostic and require no access to model training data.\ncalib also offers theoretical guarantees, ensuring reduced bias with minimal\ndeviation from original scores. Experiments across real-world datasets and\nmatching models confirm that calib and ccalib substantially reduce score bias\nwhile minimally impacting model accuracy.\n","authors":["Mohammad Hossein Moslemi","Mostafa Milani"],"pdf_url":"https://arxiv.org/pdf/2411.01685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20828v1","updated":"2025-06-25T20:54:07Z","published":"2025-06-25T20:54:07Z","title":"Practical and Accurate Local Edge Differentially Private Graph\n  Algorithms","summary":"  The rise of massive networks across diverse domains necessitates\nsophisticated graph analytics, often involving sensitive data and raising\nprivacy concerns. This paper addresses these challenges using local\ndifferential privacy (LDP), which enforces privacy at the individual level,\nwhere no third-party entity is trusted, unlike centralized models that assume a\ntrusted curator. We introduce novel LDP algorithms for two fundamental graph\nstatistics: k-core decomposition and triangle counting. Our approach leverages\ninput-dependent private graph properties, specifically the degeneracy and\nmaximum degree of the graph, to improve theoretical utility. Unlike prior\nmethods, our error bounds are determined by the maximum degree rather than the\ntotal number of edges, resulting in significantly tighter guarantees. For\ntriangle counting, we improve upon the work of Imola, Murakami, and\nChaudhury~\\cite{IMC21locally, IMC21communication}, which bounds error in terms\nof edge count. Instead, our algorithm achieves bounds based on graph degeneracy\nby leveraging a private out-degree orientation, a refined variant of Eden et\nal.'s randomized response technique~\\cite{ELRS23, and a novel analysis,\nyielding stronger guarantees than prior work. Beyond theoretical gains, we are\nthe first to evaluate local DP algorithms in a distributed simulation, unlike\nprior work tested on a single processor. Experiments on real-world graphs show\nsubstantial accuracy gains: our k-core decomposition achieves errors within 3x\nof exact values, far outperforming the 131x error in the baseline of Dhulipala\net al.~\\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative\napproximation errors by up to six orders of magnitude, while maintaining\ncompetitive runtime.\n","authors":["Pranay Mundra","Charalampos Papamanthou","Julian Shun","Quanquan C. Liu"],"pdf_url":"https://arxiv.org/pdf/2506.20828v1.pdf","comment":"To appear in VLDB 2025"},{"id":"http://arxiv.org/abs/2505.24758v2","updated":"2025-06-25T17:57:06Z","published":"2025-05-30T16:18:58Z","title":"Survey: Graph Databases","summary":"  Graph databases have become essential tools for managing complex and\ninterconnected data, which is common in areas like social networks,\nbioinformatics, and recommendation systems. Unlike traditional relational\ndatabases, graph databases offer a more natural way to model and query\nintricate relationships, making them particularly effective for applications\nthat demand flexibility and efficiency in handling interconnected data.\n  Despite their increasing use, graph databases face notable challenges. One\nsignificant issue is the irregular nature of graph data, often marked by\nstructural sparsity, such as in its adjacency matrix representation, which can\nlead to inefficiencies in data read and write operations. Other obstacles\ninclude the high computational demands of traversal-based queries, especially\nwithin large-scale networks, and complexities in managing transactions in\ndistributed graph environments. Additionally, the reliance on traditional\ncentralized architectures limits the scalability of Online Transaction\nProcessing (OLTP), creating bottlenecks due to contention, CPU overhead, and\nnetwork bandwidth constraints.\n  This paper presents a thorough survey of graph databases. It begins by\nexamining property models, query languages, and storage architectures,\noutlining the foundational aspects that users and developers typically engage\nwith. Following this, it provides a detailed analysis of recent advancements in\ngraph database technologies, evaluating these in the context of key aspects\nsuch as architecture, deployment, usage, and development, which collectively\ndefine the capabilities of graph database solutions.\n","authors":["Miguel E. Coimbra","Lucie Svitáková","Alexandre P. Francisco","Luís Veiga"],"pdf_url":"https://arxiv.org/pdf/2505.24758v2.pdf","comment":"47 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2506.20326v1","updated":"2025-06-25T11:14:04Z","published":"2025-06-25T11:14:04Z","title":"From Codicology to Code: A Comparative Study of Transformer and\n  YOLO-based Detectors for Layout Analysis in Historical Documents","summary":"  Robust Document Layout Analysis (DLA) is critical for the automated\nprocessing and understanding of historical documents with complex page\norganizations. This paper benchmarks five state-of-the-art object detection\narchitectures on three annotated datasets representing a spectrum of\ncodicological complexity: The e-NDP, a corpus of Parisian medieval registers\n(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval\nand modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated\nbooks of hours (ca.13th-16th centuries). We evaluate two Transformer-based\nmodels (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and\nYOLO-World). Our findings reveal significant performance variations dependent\non model architecture, data set characteristics, and bounding box\nrepresentation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results\n(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on\nthe more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB\nsignificantly outperforms all other models (0.564 and 0.568, respectively).\nThis study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)\nis not a minor refinement but a fundamental requirement for accurately modeling\nthe non-Cartesian nature of historical manuscripts. We conclude that a key\ntrade-off exists between the global context awareness of Transformers, ideal\nfor structured layouts, and the superior generalization of CNN-OBB models for\nvisually diverse and complex documents.\n","authors":["Sergio Torres Aguilar"],"pdf_url":"https://arxiv.org/pdf/2506.20326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17508v2","updated":"2025-06-25T06:22:45Z","published":"2025-06-20T23:17:11Z","title":"Mapping the Evolution of Research Contributions using KnoVo","summary":"  This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.\n","authors":["Sajratul Y. Rubaiat","Syed N. Sakib","Hasan M. Jamil"],"pdf_url":"https://arxiv.org/pdf/2506.17508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20139v1","updated":"2025-06-25T05:20:54Z","published":"2025-06-25T05:20:54Z","title":"Piecewise Linear Approximation in Learned Index Structures: Theoretical\n  and Empirical Analysis","summary":"  A growing trend in the database and system communities is to augment\nconventional index structures, such as B+-trees, with machine learning (ML)\nmodels. Among these, error-bounded Piecewise Linear Approximation\n($\\epsilon$-PLA) has emerged as a popular choice due to its simplicity and\neffectiveness. Despite its central role in many learned indexes, the design and\nanalysis of $\\epsilon$-PLA fitting algorithms remain underexplored. In this\npaper, we revisit $\\epsilon$-PLA from both theoretical and empirical\nperspectives, with a focus on its application in learned index structures. We\nfirst establish a fundamentally improved lower bound of $\\Omega(\\kappa \\cdot\n\\epsilon^2)$ on the expected segment coverage for existing $\\epsilon$-PLA\nfitting algorithms, where $\\kappa$ is a data-dependent constant. We then\npresent a comprehensive benchmark of state-of-the-art $\\epsilon$-PLA algorithms\nwhen used in different learned data structures. Our results highlight key\ntrade-offs among model accuracy, model size, and query performance, providing\nactionable guidelines for the principled design of future learned data\nstructures.\n","authors":["Jiayong Qin","Xianyu Zhu","Qiyu Liu","Guangyi Zhang","Zhigang Cai","Jianwei Liao","Sha Hu","Jingshu Peng","Yingxia Shao","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2506.20139v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2506.15928v2","updated":"2025-06-25T23:42:18Z","published":"2025-06-19T00:14:56Z","title":"Exploring Big Five Personality and AI Capability Effects in\n  LLM-Simulated Negotiation Dialogues","summary":"  This paper presents an evaluation framework for agentic AI systems in\nmission-critical negotiation contexts, addressing the need for AI agents that\ncan adapt to diverse human operators and stakeholders. Using Sotopia as a\nsimulation testbed, we present two experiments that systematically evaluated\nhow personality traits and AI agent characteristics influence LLM-simulated\nsocial negotiation outcomes--a capability essential for a variety of\napplications involving cross-team coordination and civil-military interactions.\nExperiment 1 employs causal discovery methods to measure how personality traits\nimpact price bargaining negotiations, through which we found that Agreeableness\nand Extraversion significantly affect believability, goal achievement, and\nknowledge acquisition outcomes. Sociocognitive lexical measures extracted from\nteam communications detected fine-grained differences in agents' empathic\ncommunication, moral foundations, and opinion patterns, providing actionable\ninsights for agentic AI systems that must operate reliably in high-stakes\noperational scenarios. Experiment 2 evaluates human-AI job negotiations by\nmanipulating both simulated human personality and AI system characteristics,\nspecifically transparency, competence, adaptability, demonstrating how AI agent\ntrustworthiness impact mission effectiveness. These findings establish a\nrepeatable evaluation methodology for experimenting with AI agent reliability\nacross diverse operator personalities and human-agent team dynamics, directly\nsupporting operational requirements for reliable AI systems. Our work advances\nthe evaluation of agentic AI workflows by moving beyond standard performance\nmetrics to incorporate social dynamics essential for mission success in complex\noperations.\n","authors":["Myke C. Cohen","Zhe Su","Hsien-Te Kao","Daniel Nguyen","Spencer Lynch","Maarten Sap","Svitlana Volkova"],"pdf_url":"https://arxiv.org/pdf/2506.15928v2.pdf","comment":"Under review for KDD 2025 Workshop on Evaluation and Trustworthiness\n  of Agentic and Generative AI Models"},{"id":"http://arxiv.org/abs/2504.15457v3","updated":"2025-06-25T23:40:16Z","published":"2025-04-21T21:53:00Z","title":"Improving Human-AI Coordination through Online Adversarial Training and\n  Generative Models","summary":"  Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is a promising method\nthat allows dynamic data generation and ensures that agents are robust. It\ncreates a feedback loop where the agent's performance influences the generation\nof new adversarial data, which can be used immediately to train the agent.\nHowever, adversarial training is difficult to apply in a cooperative task; how\ncan we train an adversarial cooperator? We propose a novel strategy that\ncombines a pretrained generative model to simulate valid cooperative agent\npolicies with adversarial training to maximize regret. We call our method GOAT:\nGenerative Online Adversarial Training. In this framework, the GOAT dynamically\nsearches the latent space of the generative model for coordination strategies\nwhere the learning policy, the Cooperator agent, underperforms. GOAT enables\nbetter generalization by exposing the Cooperator to various challenging\ninteraction scenarios. We maintain realistic coordination strategies by keeping\nthe generative model frozen, thus avoiding adversarial exploitation. We\nevaluate GOAT with real human partners, and the results demonstrate state of\nthe art performance on the Overcooked benchmark, highlighting its effectiveness\nin generalizing to diverse human behaviors.\n","authors":["Paresh Chaudhary","Yancheng Liang","Daphne Chen","Simon S. Du","Natasha Jaques"],"pdf_url":"https://arxiv.org/pdf/2504.15457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20886v1","updated":"2025-06-25T23:36:44Z","published":"2025-06-25T23:36:44Z","title":"Omniwise: Predicting GPU Kernels Performance with LLMs","summary":"  In recent years, the rapid advancement of deep neural networks (DNNs) has\nrevolutionized artificial intelligence, enabling models with unprecedented\ncapabilities in understanding, generating, and processing complex data. These\npowerful architectures have transformed a wide range of downstream\napplications, tackling tasks beyond human reach. In this paper, we introduce\nOmniwise, the first end-to-end, self-supervised fine-tuning pipeline that\napplies large language models (LLMs) to GPU kernel performance prediction--a\nnovel use case in performance profiling. Omniwise is model-agnostic and\nlightweight, achieving strong results even with a small 3B-parameter model. It\ncan predict key performance metrics, including memory bandwidth, cache hit\nrates, GFLOPs, and arithmetic intensity, directly from kernel code without the\nneed for code execution or profiling tools. Our approach achieves over 90% of\npredictions within 10% relative error on GPU kernels executed on AMD MI250 and\nMI300X architectures. In addition to the pipeline, we develop an online\ninference server and a Visual Studio Code plugin that seamlessly integrate\nLLM-based performance prediction into developers' workflows.\n","authors":["Zixian Wang","Cole Ramos","Muhammad A. Awad","Keith Lowery"],"pdf_url":"https://arxiv.org/pdf/2506.20886v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20883v1","updated":"2025-06-25T23:10:12Z","published":"2025-06-25T23:10:12Z","title":"Complex Model Transformations by Reinforcement Learning with Uncertain\n  Human Guidance","summary":"  Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.\n","authors":["Kyanna Dagenais","Istvan David"],"pdf_url":"https://arxiv.org/pdf/2506.20883v1.pdf","comment":"Accepted for ACM/IEEE MODELS'25"},{"id":"http://arxiv.org/abs/2505.12942v3","updated":"2025-06-25T23:03:54Z","published":"2025-05-19T10:29:32Z","title":"A3 : an Analytical Low-Rank Approximation Framework for Attention","summary":"  Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.\n","authors":["Jeffrey T. H. Wong","Cheng Zhang","Xinye Cao","Pedro Gimenes","George A. Constantinides","Wayne Luk","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2505.12942v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20877v1","updated":"2025-06-25T22:59:40Z","published":"2025-06-25T22:59:40Z","title":"THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired\n  Multi-Stage Fusion","summary":"  Monocular depth estimation methods traditionally train deep models to infer\ndepth directly from RGB pixels. This implicit learning often overlooks explicit\nmonocular cues that the human visual system relies on, such as occlusion\nboundaries, shading, and perspective. Rather than expecting a network to\ndiscover these cues unaided, we present ThirdEye, a cue-aware pipeline that\ndeliberately supplies each cue through specialised, pre-trained, and frozen\nnetworks. These cues are fused in a three-stage cortical hierarchy (V1->V2->V3)\nequipped with a key-value working-memory module that weights them by\nreliability. An adaptive-bins transformer head then produces a high-resolution\ndisparity map. Because the cue experts are frozen, ThirdEye inherits large\namounts of external supervision while requiring only modest fine-tuning. This\nextended version provides additional architectural detail, neuroscientific\nmotivation, and an expanded experimental protocol; quantitative results will\nappear in a future revision.\n","authors":["Calin Teodor Ioan"],"pdf_url":"https://arxiv.org/pdf/2506.20877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20869v1","updated":"2025-06-25T22:40:00Z","published":"2025-06-25T22:40:00Z","title":"Engineering RAG Systems for Real-World Applications: Design,\n  Development, and Evaluation","summary":"  Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.\n","authors":["Md Toufique Hasan","Muhammad Waseem","Kai-Kristian Kemell","Ayman Asad Khan","Mika Saari","Pekka Abrahamsson"],"pdf_url":"https://arxiv.org/pdf/2506.20869v1.pdf","comment":"Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version"},{"id":"http://arxiv.org/abs/2504.08738v3","updated":"2025-06-25T22:12:21Z","published":"2025-03-20T18:56:22Z","title":"AI-Driven Sentiment Analytics: Unlocking Business Value in the\n  E-Commerce Landscape","summary":"  The rapid growth of e-commerce has led to an overwhelming volume of customer\nfeedback, from product reviews to service interactions. Extracting meaningful\ninsights from this data is crucial for businesses aiming to improve customer\nsatisfaction and optimize decision-making. This paper presents an AI-driven\nsentiment analysis system designed specifically for e-commerce applications,\nbalancing accuracy with interpretability. Our approach integrates traditional\nmachine learning techniques with modern deep learning models, allowing for a\nmore nuanced understanding of customer sentiment while ensuring transparency in\ndecision-making. Experimental results show that our system outperforms standard\nsentiment analysis methods, achieving an accuracy of 89.7% on diverse,\nlarge-scale datasets. Beyond technical performance, real-world implementation\nacross multiple e-commerce platforms demonstrates tangible improvements in\ncustomer engagement and operational efficiency. This study highlights both the\npotential and the challenges of applying AI to sentiment analysis in a\ncommercial setting, offering insights into practical deployment strategies and\nareas for future refinement.\n","authors":["Qianye Wu","Chengxuan Xia","Sixuan Tian"],"pdf_url":"https://arxiv.org/pdf/2504.08738v3.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2506.06285v3","updated":"2025-06-25T22:00:25Z","published":"2025-04-28T20:18:46Z","title":"NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy\n  Forecasting","summary":"  Deep learning models, despite their popularity, face challenges such as long\ntraining times and a lack of interpretability. In contrast, fuzzy inference\nsystems offer a balance of accuracy and transparency. This paper addresses the\nlimitations of traditional Takagi-Sugeno-Kang fuzzy models by extending the\nrecently proposed New Takagi-Sugeno-Kang model to a new Mamdani-based\nregressor. These models are data-driven, allowing users to define the number of\nrules to balance accuracy and interpretability. To handle the complexity of\nlarge datasets, this research integrates wrapper and ensemble techniques. A\nGenetic Algorithm is used as a wrapper for feature selection, creating genetic\nversions of the models. Furthermore, ensemble models, including the Random New\nMamdani Regressor, Random New Takagi-Sugeno-Kang, and Random Forest New\nTakagi-Sugeno-Kang, are introduced to improve robustness. The proposed models\nare validated on photovoltaic energy forecasting datasets, a critical\napplication due to the intermittent nature of solar power. Results demonstrate\nthat the genetic and ensemble fuzzy models, particularly the Genetic New\nTakagi-Sugeno-Kang and Random Forest New Takagi-Sugeno-Kang, achieve superior\nperformance. They often outperform both traditional machine learning and deep\nlearning models while providing a simpler and more interpretable rule-based\nstructure. The models are available online in a library called nfisis\n(https://pypi.org/project/nfisis/).\n","authors":["Kaike Sa Teles Rocha Alves","Eduardo Pestana de Aguiar"],"pdf_url":"https://arxiv.org/pdf/2506.06285v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20851v1","updated":"2025-06-25T21:48:21Z","published":"2025-06-25T21:48:21Z","title":"Generating Reliable Adverse event Profiles for Health through Automated\n  Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach","summary":"  As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.\n","authors":["Srikar Reddy Gadusu","Larry Callahan","Samir Lababidi","Arunasri Nishtala","Sophia Healey","Hande McGinty"],"pdf_url":"https://arxiv.org/pdf/2506.20851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09852v3","updated":"2025-06-25T21:48:04Z","published":"2024-11-15T00:20:36Z","title":"InterFormer: Effective Heterogeneous Interaction Learning for\n  Click-Through Rate Prediction","summary":"  Click-through rate (CTR) prediction, which predicts the probability of a user\nclicking an ad, is a fundamental task in recommender systems. The emergence of\nheterogeneous information, such as user profile and behavior sequences, depicts\nuser interests from different aspects. A mutually beneficial integration of\nheterogeneous information is the cornerstone towards the success of CTR\nprediction. However, most of the existing methods suffer from two fundamental\nlimitations, including (1) insufficient inter-mode interaction due to the\nunidirectional information flow between modes, and (2) aggressive information\naggregation caused by early summarization, resulting in excessive information\nloss. To address the above limitations, we propose a novel module named\nInterFormer to learn heterogeneous information interaction in an interleaving\nstyle. To achieve better interaction learning, InterFormer enables\nbidirectional information flow for mutually beneficial learning across\ndifferent modes. To avoid aggressive information aggregation, we retain\ncomplete information in each data mode and use a separate bridging arch for\neffective information selection and summarization. Our proposed InterFormer\nachieves state-of-the-art performance on three public datasets and a\nlarge-scale industrial dataset.\n","authors":["Zhichen Zeng","Xiaolong Liu","Mengyue Hang","Xiaoyi Liu","Qinghai Zhou","Chaofei Yang","Yiqun Liu","Yichen Ruan","Laming Chen","Yuxin Chen","Yujia Hao","Jiaqi Xu","Jade Nie","Xi Liu","Buyun Zhang","Wei Wen","Siyang Yuan","Hang Yin","Xin Zhang","Kai Wang","Wen-Yen Chen","Yiping Han","Huayu Li","Chunzhi Yang","Bo Long","Philip S. Yu","Hanghang Tong","Jiyan Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09852v3.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.04292v3","updated":"2025-06-25T21:47:50Z","published":"2024-12-05T16:12:25Z","title":"SIDA: Social Media Image Deepfake Detection, Localization and\n  Explanation with Large Multimodal Model","summary":"  The rapid advancement of generative models in creating highly realistic\nimages poses substantial risks for misinformation dissemination. For instance,\na synthetic image, when shared on social media, can mislead extensive audiences\nand erode trust in digital content, resulting in severe repercussions. Despite\nsome progress, academia has not yet created a large and diversified deepfake\ndetection dataset for social media, nor has it devised an effective solution to\naddress this issue. In this paper, we introduce the Social media Image\nDetection dataSet (SID-Set), which offers three key advantages: (1) extensive\nvolume, featuring 300K AI-generated/tampered and authentic images with\ncomprehensive annotations, (2) broad diversity, encompassing fully synthetic\nand tampered images across various classes, and (3) elevated realism, with\nimages that are predominantly indistinguishable from genuine ones through mere\nvisual inspection. Furthermore, leveraging the exceptional capabilities of\nlarge multimodal models, we propose a new image deepfake detection,\nlocalization, and explanation framework, named SIDA (Social media Image\nDetection, localization, and explanation Assistant). SIDA not only discerns the\nauthenticity of images, but also delineates tampered regions through mask\nprediction and provides textual explanations of the model's judgment criteria.\nCompared with state-of-the-art deepfake detection models on SID-Set and other\nbenchmarks, extensive experiments demonstrate that SIDA achieves superior\nperformance among diversified settings. The code, model, and dataset will be\nreleased.\n","authors":["Zhenglin Huang","Jinwei Hu","Xiangtai Li","Yiwei He","Xingyu Zhao","Bei Peng","Baoyuan Wu","Xiaowei Huang","Guangliang Cheng"],"pdf_url":"https://arxiv.org/pdf/2412.04292v3.pdf","comment":"This version revises and corrects the metric calculations in the\n  tables"},{"id":"http://arxiv.org/abs/2503.11175v2","updated":"2025-06-25T21:45:14Z","published":"2025-03-14T08:22:26Z","title":"Zero-TIG: Temporal Consistency-Aware Zero-Shot Illumination-Guided\n  Low-light Video Enhancement","summary":"  Low-light and underwater videos suffer from poor visibility, low contrast,\nand high noise, necessitating enhancements in visual quality. However, existing\napproaches typically rely on paired ground truth, which limits their\npracticality and often fails to maintain temporal consistency. To overcome\nthese obstacles, this paper introduces a novel zero-shot learning approach\nnamed Zero-TIG, leveraging the Retinex theory and optical flow techniques. The\nproposed network consists of an enhancement module and a temporal feedback\nmodule. The enhancement module comprises three subnetworks: low-light image\ndenoising, illumination estimation, and reflection denoising. The temporal\nenhancement module ensures temporal consistency by incorporating histogram\nequalization, optical flow computation, and image warping to align the enhanced\nprevious frame with the current frame, thereby maintaining continuity.\nAdditionally, we address color distortion in underwater data by adaptively\nbalancing RGB channels. The experimental results demonstrate that our method\nachieves low-light video enhancement without the need for paired training data,\nmaking it a promising and applicable method for real-world scenario\nenhancement.\n","authors":["Yini Li","Nantheera Anantrasirichai"],"pdf_url":"https://arxiv.org/pdf/2503.11175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20841v1","updated":"2025-06-25T21:25:05Z","published":"2025-06-25T21:25:05Z","title":"FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain\n  Generalization","summary":"  Semi-supervised domain generalization (SSDG) aims to solve the problem of\ngeneralizing to out-of-distribution data when only a few labels are available.\nDue to label scarcity, applying domain generalization methods often\nunderperform. Consequently, existing SSDG methods combine semi-supervised\nlearning methods with various regularization terms. However, these methods do\nnot explicitly regularize to learn domains invariant representations across all\ndomains, which is a key goal for domain generalization. To address this, we\nintroduce FixCLR. Inspired by success in self-supervised learning, we change\ntwo crucial components to adapt contrastive learning for explicit domain\ninvariance regularization: utilization of class information from pseudo-labels\nand using only a repelling term. FixCLR can also be added on top of most\nexisting SSDG and semi-supervised methods for complementary performance\nimprovements. Our research includes extensive experiments that have not been\npreviously explored in SSDG studies. These experiments include benchmarking\ndifferent improvements to semi-supervised methods, evaluating the performance\nof pretrained versus non-pretrained models, and testing on datasets with many\ndomains. Overall, FixCLR proves to be an effective SSDG method, especially when\ncombined with other semi-supervised methods.\n","authors":["Ha Min Son","Shahbaz Rezaei","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2506.20841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.23062v2","updated":"2025-06-25T21:09:46Z","published":"2025-05-29T04:09:19Z","title":"Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics\n  Data","summary":"  Incorporating pre-collected offline data from a source environment can\nsignificantly improve the sample efficiency of reinforcement learning (RL), but\nthis benefit is often challenged by discrepancies between the transition\ndynamics of the source and target environments. Existing methods typically\naddress this issue by penalizing or filtering out source transitions in high\ndynamics-gap regions. However, their estimation of the dynamics gap often\nrelies on KL divergence or mutual information, which can be ill-defined when\nthe source and target dynamics have disjoint support. To overcome these\nlimitations, we propose CompFlow, a method grounded in the theoretical\nconnection between flow matching and optimal transport. Specifically, we model\nthe target dynamics as a conditional flow built upon the output distribution of\nthe source-domain flow, rather than learning it directly from a Gaussian prior.\nThis composite structure offers two key advantages: (1) improved generalization\nfor learning target dynamics, and (2) a principled estimation of the dynamics\ngap via the Wasserstein distance between source and target transitions.\nLeveraging our principled estimation of the dynamics gap, we further introduce\nan optimistic active data collection strategy that prioritizes exploration in\nregions of high dynamics gap, and theoretically prove that it reduces the\nperformance disparity with the optimal policy. Empirically, CompFlow\noutperforms strong baselines across several RL benchmarks with shifted\ndynamics.\n","authors":["Lingkai Kong","Haichuan Wang","Tonghan Wang","Guojun Xiong","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2505.23062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01923v2","updated":"2025-06-25T21:02:25Z","published":"2025-06-02T17:43:55Z","title":"TaxaDiffusion: Progressively Trained Diffusion Model for Fine-Grained\n  Species Generation","summary":"  We propose TaxaDiffusion, a taxonomy-informed training framework for\ndiffusion models to generate fine-grained animal images with high morphological\nand identity accuracy. Unlike standard approaches that treat each species as an\nindependent category, TaxaDiffusion incorporates domain knowledge that many\nspecies exhibit strong visual similarities, with distinctions often residing in\nsubtle variations of shape, pattern, and color. To exploit these relationships,\nTaxaDiffusion progressively trains conditioned diffusion models across\ndifferent taxonomic levels -- starting from broad classifications such as Class\nand Order, refining through Family and Genus, and ultimately distinguishing at\nthe Species level. This hierarchical learning strategy first captures\ncoarse-grained morphological traits shared by species with common ancestors,\nfacilitating knowledge transfer before refining fine-grained differences for\nspecies-level distinction. As a result, TaxaDiffusion enables accurate\ngeneration even with limited training samples per species. Extensive\nexperiments on three fine-grained animal datasets demonstrate that outperforms\nexisting approaches, achieving superior fidelity in fine-grained animal image\ngeneration. Project page: https://amink8.github.io/TaxaDiffusion/\n","authors":["Amin Karimi Monsefi","Mridul Khurana","Rajiv Ramnath","Anuj Karpatne","Wei-Lun Chao","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.01923v2.pdf","comment":"Accepted to ICCV 2025"},{"id":"http://arxiv.org/abs/2506.20832v1","updated":"2025-06-25T21:00:44Z","published":"2025-06-25T21:00:44Z","title":"Leveraging Vision-Language Models to Select Trustworthy Super-Resolution\n  Samples Generated by Diffusion Models","summary":"  Super-resolution (SR) is an ill-posed inverse problem with many feasible\nsolutions consistent with a given low-resolution image. On one hand, regressive\nSR models aim to balance fidelity and perceptual quality to yield a single\nsolution, but this trade-off often introduces artifacts that create ambiguity\nin information-critical applications such as recognizing digits or letters. On\nthe other hand, diffusion models generate a diverse set of SR images, but\nselecting the most trustworthy solution from this set remains a challenge. This\npaper introduces a robust, automated framework for identifying the most\ntrustworthy SR sample from a diffusion-generated set by leveraging the semantic\nreasoning capabilities of vision-language models (VLMs). Specifically, VLMs\nsuch as BLIP-2, GPT-4o, and their variants are prompted with structured queries\nto assess semantic correctness, visual quality, and artifact presence. The\ntop-ranked SR candidates are then ensembled to yield a single trustworthy\noutput in a cost-effective manner. To rigorously assess the validity of\nVLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid\nmetric that quantifies SR reliability based on three complementary components:\nsemantic similarity via CLIP embeddings, structural integrity using SSIM on\nedge maps, and artifact sensitivity through multi-level wavelet decomposition.\nWe empirically show that TWS correlates strongly with human preference in both\nambiguous and natural images, and that VLM-guided selections consistently yield\nhigh TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail\nto reflect information fidelity, our approach offers a principled, scalable,\nand generalizable solution for navigating the uncertainty of the diffusion SR\nspace. By aligning outputs with human expectations and semantic correctness,\nthis work sets a new benchmark for trustworthiness in generative SR.\n","authors":["Cansu Korkmaz","Ahmet Murat Tekalp","Zafer Dogan"],"pdf_url":"https://arxiv.org/pdf/2506.20832v1.pdf","comment":"14 pages, 9 figures, 5 tables, accepted to IEEE Transactions on\n  Circuits and Systems for Video Technology"},{"id":"http://arxiv.org/abs/2411.02136v3","updated":"2025-06-25T20:45:19Z","published":"2024-11-04T14:49:01Z","title":"Advanced computer vision for extracting georeferenced vehicle\n  trajectories from drone imagery","summary":"  This paper presents a framework for extracting georeferenced vehicle\ntrajectories from high-altitude drone imagery, addressing key challenges in\nurban traffic monitoring and the limitations of traditional ground-based\nsystems. Our approach integrates several novel contributions, including a\ntailored object detector optimized for high-altitude bird's-eye view\nperspectives, a unique track stabilization method that uses detected vehicle\nbounding boxes as exclusion masks during image registration, and an orthophoto\nand master frame-based georeferencing strategy that enhances consistent\nalignment across multiple drone viewpoints. Additionally, our framework\nfeatures robust vehicle dimension estimation and detailed road segmentation,\nenabling comprehensive traffic analysis. Conducted in the Songdo International\nBusiness District, South Korea, the study utilized a multi-drone experiment\ncovering 20 intersections, capturing approximately 12TB of 4K video data over\nfour days. The framework produced two high-quality datasets: the Songdo Traffic\ndataset, comprising approximately 700,000 unique vehicle trajectories, and the\nSongdo Vision dataset, containing over 5,000 human-annotated images with about\n300,000 vehicle instances in four classes. Comparisons with high-precision\nsensor data from an instrumented probe vehicle highlight the accuracy and\nconsistency of our extraction pipeline in dense urban environments. The public\nrelease of Songdo Traffic and Songdo Vision, and the complete source code for\nthe extraction pipeline, establishes new benchmarks in data quality,\nreproducibility, and scalability in traffic research. Results demonstrate the\npotential of integrating drone technology with advanced computer vision for\nprecise and cost-effective urban traffic monitoring, providing valuable\nresources for developing intelligent transportation systems and enhancing\ntraffic management strategies.\n","authors":["Robert Fonod","Haechan Cho","Hwasoo Yeo","Nikolas Geroliminis"],"pdf_url":"https://arxiv.org/pdf/2411.02136v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20822v1","updated":"2025-06-25T20:43:04Z","published":"2025-06-25T20:43:04Z","title":"Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via\n  Behavioral Vignettes","summary":"  Large language models (LLMs) are increasingly proposed for detecting and\nresponding to violent content online, yet their ability to reason about morally\nambiguous, real-world scenarios remains underexamined. We present the first\nstudy to evaluate LLMs using a validated social science instrument designed to\nmeasure human response to everyday conflict, namely the Violent Behavior\nVignette Questionnaire (VBVQ). To assess potential bias, we introduce\npersona-based prompting that varies race, age, and geographic identity within\nthe United States. Six LLMs developed across different geopolitical and\norganizational contexts are evaluated under a unified zero-shot setting. Our\nstudy reveals two key findings: (1) LLMs surface-level text generation often\ndiverges from their internal preference for violent responses; (2) their\nviolent tendencies vary across demographics, frequently contradicting\nestablished findings in criminology, social science, and psychology.\n","authors":["Quintin Myers","Yanjun Gao"],"pdf_url":"https://arxiv.org/pdf/2506.20822v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2506.20821v1","updated":"2025-06-25T20:37:20Z","published":"2025-06-25T20:37:20Z","title":"MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation\n  (RAG) Framework for Financial Question Answering","summary":"  Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span\nhundreds of pages and combine diverse modalities, including dense narrative\ntext, structured tables, and complex figures. Answering questions over such\ncontent often requires joint reasoning across modalities, which strains\ntraditional large language models (LLMs) and retrieval-augmented generation\n(RAG) pipelines due to token limitations, layout loss, and fragmented\ncross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation\nframework purpose-built for financial QA. MultiFinRAG first performs multimodal\nextraction by grouping table and figure images into batches and sending them to\na lightweight, quantized open-source multimodal LLM, which produces both\nstructured JSON outputs and concise textual summaries. These outputs, along\nwith narrative text, are embedded and indexed with modality-aware similarity\nthresholds for precise retrieval. A tiered fallback strategy then dynamically\nescalates from text-only to text+table+image contexts when necessary, enabling\ncross-modal reasoning while reducing irrelevant context. Despite running on\ncommodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy\nthan ChatGPT-4o (free-tier) on complex financial QA tasks involving text,\ntables, images, and combined multimodal reasoning.\n","authors":["Chinmay Gondhalekar","Urjitkumar Patel","Fang-Chun Yeh"],"pdf_url":"https://arxiv.org/pdf/2506.20821v1.pdf","comment":"Preprint Copy"},{"id":"http://arxiv.org/abs/2506.20815v1","updated":"2025-06-25T20:29:46Z","published":"2025-06-25T20:29:46Z","title":"Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI\n  Applications","summary":"  LLM-powered applications are highly susceptible to the quality of user\nprompts, and crafting high-quality prompts can often be challenging especially\nfor domain-specific applications. This paper presents a novel dynamic\ncontext-aware prompt recommendation system for domain-specific AI applications.\nOur solution combines contextual query analysis, retrieval-augmented knowledge\ngrounding, hierarchical skill organization, and adaptive skill ranking to\ngenerate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical\nreasoning process to dynamically select and rank relevant skills, and\nsynthesizes prompts using both predefined and adaptive templates enhanced with\nfew-shot learning. Experiments on real-world datasets demonstrate that our\napproach achieves high usefulness and relevance, as validated by both automated\nand expert evaluations.\n","authors":["Xinye Tang","Haijun Zhai","Chaitanya Belwal","Vineeth Thayanithi","Philip Baumann","Yogesh K Roy"],"pdf_url":"https://arxiv.org/pdf/2506.20815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20810v1","updated":"2025-06-25T20:07:46Z","published":"2025-06-25T20:07:46Z","title":"FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated\n  LSTMs","summary":"  Recurrent neural networks (RNNs), particularly LSTMs, are effective for\ntime-series tasks like sentiment analysis and short-term stock prediction.\nHowever, their computational complexity poses challenges for real-time\ndeployment in resource constrained environments. While FPGAs offer a promising\nplatform for energy-efficient AI acceleration, existing tools mainly target\nfeed-forward networks, and LSTM acceleration typically requires full custom\nimplementation. In this paper, we address this gap by leveraging the\nopen-source and extensible FINN framework to enable the generalized deployment\nof LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open\nNeural Network Exchange (ONNX) specification to model the recurrent nature of\nLSTM computations, enabling support for mixed quantisation within them and\nfunctional verification of LSTM-based models. Furthermore, we introduce custom\ntransformations within the FINN compiler to map the quantised ONNX computation\ngraph to hardware blocks from the HLS kernel library of the FINN compiler and\nVitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM\nmodel for a mid-price stock prediction task using the widely used dataset and\ngenerating a corresponding hardware IP of the model using our flow, targeting\nthe XCZU7EV device. We show that the generated quantised ConvLSTM accelerator\nthrough our flow achieves a balance between performance (latency) and resource\nconsumption, while matching (or bettering) inference accuracy of\nstate-of-the-art models with reduced precision. We believe that the\ngeneralisable nature of the proposed flow will pave the way for\nresource-efficient RNN accelerator designs on FPGAs.\n","authors":["Shashwat Khandelwal","Jakoba Petri-Koenig","Thomas B. Preußer","Michaela Blott","Shreejith Shanker"],"pdf_url":"https://arxiv.org/pdf/2506.20810v1.pdf","comment":"9 pages, 6 figures, 5 tables, Accepted for publication in IEEE\n  FPL-2025 (https://2025.fpl.org/)"},{"id":"http://arxiv.org/abs/2506.20807v1","updated":"2025-06-25T19:59:34Z","published":"2025-06-25T19:59:34Z","title":"GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel\n  Optimization","summary":"  Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.\n","authors":["Martin Andrews","Sam Witteveen"],"pdf_url":"https://arxiv.org/pdf/2506.20807v1.pdf","comment":"4 page paper plus Appendices. Accepted to the ES-FoMo \"Efficient\n  Systems for Foundation Models\" workshop at ICML 2025"},{"id":"http://arxiv.org/abs/2506.20806v1","updated":"2025-06-25T19:49:55Z","published":"2025-06-25T19:49:55Z","title":"Poster: Enhancing GNN Robustness for Network Intrusion Detection via\n  Agent-based Analysis","summary":"  Graph Neural Networks (GNNs) show great promise for Network Intrusion\nDetection Systems (NIDS), particularly in IoT environments, but suffer\nperformance degradation due to distribution drift and lack robustness against\nrealistic adversarial attacks. Current robustness evaluations often rely on\nunrealistic synthetic perturbations and lack demonstrations on systematic\nanalysis of different kinds of adversarial attack, which encompass both\nblack-box and white-box scenarios. This work proposes a novel approach to\nenhance GNN robustness and generalization by employing Large Language Models\n(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These\nagents scrutinize graph structures derived from network flow data, identifying\nand potentially mitigating suspicious or adversarially perturbed elements\nbefore GNN processing. Our experiments, using a framework designed for\nrealistic evaluation and testing with a variety of adversarial attacks\nincluding a dataset collected from physical testbed experiments, demonstrate\nthat integrating LLM analysis can significantly improve the resilience of\nGNN-based NIDS against challenges, showcasing the potential of LLM agent as a\ncomplementary layer in intrusion detection architectures.\n","authors":["Zhonghao Zhan","Huichi Zhou","Hamed Haddadi"],"pdf_url":"https://arxiv.org/pdf/2506.20806v1.pdf","comment":"Poster accepted at the 10th IEEE European Symposium on Security and\n  Privacy (Euro S&P 2025)"},{"id":"http://arxiv.org/abs/2506.20803v1","updated":"2025-06-25T19:47:23Z","published":"2025-06-25T19:47:23Z","title":"The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus\n  Human Research Ideas","summary":"  Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.\n","authors":["Chenglei Si","Tatsunori Hashimoto","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2506.20803v1.pdf","comment":"main paper is 14 pages"},{"id":"http://arxiv.org/abs/2506.20790v1","updated":"2025-06-25T19:26:31Z","published":"2025-06-25T19:26:31Z","title":"Stochastic Parameter Decomposition","summary":"  A key step in reverse engineering neural networks is to decompose them into\nsimpler parts that can be studied in relative isolation. Linear parameter\ndecomposition -- a framework that has been proposed to resolve several issues\nwith current decomposition methods -- decomposes neural network parameters into\na sum of sparsely used vectors in parameter space. However, the current main\nmethod in this framework, Attribution-based Parameter Decomposition (APD), is\nimpractical on account of its computational cost and sensitivity to\nhyperparameters. In this work, we introduce \\textit{Stochastic Parameter\nDecomposition} (SPD), a method that is more scalable and robust to\nhyperparameters than APD, which we demonstrate by decomposing models that are\nslightly larger and more complex than was possible to decompose with APD. We\nalso show that SPD avoids other issues, such as shrinkage of the learned\nparameters, and better identifies ground truth mechanisms in toy models. By\nbridging causal mediation analysis and network decomposition methods, this\ndemonstration opens up new research possibilities in mechanistic\ninterpretability by removing barriers to scaling linear parameter decomposition\nmethods to larger models. We release a library for running SPD and reproducing\nour experiments at https://github.com/goodfire-ai/spd.\n","authors":["Lucius Bushnaq","Dan Braun","Lee Sharkey"],"pdf_url":"https://arxiv.org/pdf/2506.20790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.14333v2","updated":"2025-06-25T19:04:21Z","published":"2025-03-18T15:08:19Z","title":"Revealing higher-order neural representations of uncertainty with the\n  Noise Estimation through Reinforcement-based Diffusion (NERD) model","summary":"  Studies often aim to reveal ``first-order\" representations (FORs), which\nencode aspects of an observer's environment, such as contents or structure. A\nless-common target is ``higher-order\" representations (HORs), which are\n``about\" FORs -- e.g., their strength or uncertainty -- and which may\ncontribute to learning. HORs about uncertainty are unlikely to be direct\n``read-outs\" of FOR characteristics, instead reflecting noisy estimation\nprocesses incorporating prior expectations about uncertainty, but how the brain\nrepresents such expected uncertainty distributions remains largely unexplored.\nHere, we study ``noise expectation\" HORs using neural data from a task which\nmay require the brain to learn about its own noise: decoded neurofeedback,\nwherein human subjects learn to volitionally produce target neural patterns. We\ndevelop and apply a Noise Estimation through Reinforcement-based Diffusion\n(NERD) model to characterize how brains may undertake this process, and show\nthat NERD offers high explanatory power for human behavior.\n","authors":["Hojjat Azimi Asrari","Megan A. K. Peters"],"pdf_url":"https://arxiv.org/pdf/2503.14333v2.pdf","comment":"27 pages, 7 figures, 12 equations"},{"id":"http://arxiv.org/abs/2411.14133v2","updated":"2025-06-25T19:01:33Z","published":"2024-11-21T14:00:01Z","title":"GASP: Efficient Black-Box Generation of Adversarial Suffixes for\n  Jailbreaking LLMs","summary":"  LLMs have shown impressive capabilities across various natural language\nprocessing tasks, yet remain vulnerable to input prompts, known as jailbreak\nattacks, carefully designed to bypass safety guardrails and elicit harmful\nresponses. Traditional methods rely on manual heuristics but suffer from\nlimited generalizability. Despite being automatic, optimization-based attacks\noften produce unnatural prompts that can be easily detected by safety filters\nor require high computational costs due to discrete token optimization. In this\npaper, we introduce Generative Adversarial Suffix Prompter (GASP), a novel\nautomated framework that can efficiently generate human-readable jailbreak\nprompts in a fully black-box setting. In particular, GASP leverages latent\nBayesian optimization to craft adversarial suffixes by efficiently exploring\ncontinuous latent embedding spaces, gradually optimizing the suffix prompter to\nimprove attack efficacy while balancing prompt coherence via a targeted\niterative refinement procedure. Through comprehensive experiments, we show that\nGASP can produce natural adversarial prompts, significantly improving jailbreak\nsuccess over baselines, reducing training times, and accelerating inference\nspeed, thus making it an efficient and scalable solution for red-teaming LLMs.\n","authors":["Advik Raj Basani","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.14133v2.pdf","comment":"38 pages, 8 tables, 18 figures"},{"id":"http://arxiv.org/abs/2506.20759v1","updated":"2025-06-25T18:47:08Z","published":"2025-06-25T18:47:08Z","title":"Agile Management for Machine Learning: A Systematic Mapping Study","summary":"  [Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.\n","authors":["Lucas Romao","Hugo Villamizar","Romeu Oliveira","Silvio Alonso","Marcos Kalinowski"],"pdf_url":"https://arxiv.org/pdf/2506.20759v1.pdf","comment":"Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025"},{"id":"http://arxiv.org/abs/2506.20748v1","updated":"2025-06-25T18:16:14Z","published":"2025-06-25T18:16:14Z","title":"Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on\n  Human Prosocial Behavior Toward Chatbots","summary":"  Chatbots are increasingly integrated into people's lives and are widely used\nto help people. Recently, there has also been growing interest in the reverse\ndirection-humans help chatbots-due to a wide range of benefits including better\nchatbot performance, human well-being, and collaborative outcomes. However,\nlittle research has explored the factors that motivate people to help chatbots.\nTo address this gap, we draw on the Computers Are Social Actors (CASA)\nframework to examine how chatbot anthropomorphism-including human-like\nidentity, emotional expression, and non-verbal expression-influences human\nempathy toward chatbots and their subsequent prosocial behaviors and\nintentions. We also explore people's own interpretations of their prosocial\nbehaviors toward chatbots. We conducted an online experiment (N = 244) in which\nchatbots made mistakes in a collaborative image labeling task and explained the\nreasons to participants. We then measured participants' prosocial behaviors and\nintentions toward the chatbots. Our findings revealed that human identity and\nemotional expression of chatbots increased participants' prosocial behavior and\nintention toward chatbots, with empathy mediating these effects. Qualitative\nanalysis further identified two motivations for participants' prosocial\nbehaviors: empathy for the chatbot and perceiving the chatbot as human-like. We\ndiscuss the implications of these results for understanding and promoting human\nprosocial behaviors toward chatbots.\n","authors":["Jingshu Li","Zicheng Zhu","Renwen Zhang","Yi-Chieh Lee"],"pdf_url":"https://arxiv.org/pdf/2506.20748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08597v2","updated":"2025-06-25T18:09:48Z","published":"2025-02-12T17:34:04Z","title":"Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs.\n  No-Regret Learners","summary":"  We analyze the performance of heterogeneous learning agents in asset markets\nwith stochastic payoffs. Our main focus is on comparing Bayesian learners and\nno-regret learners who compete in markets and identifying the conditions under\nwhich each approach is more effective. Surprisingly, we find that low regret is\nnot sufficient for survival: an agent can have regret as low as $O(\\log T)$ but\nstill vanish when competing against a Bayesian with a finite prior and any\npositive prior probability on the correct model. On the other hand, we show\nthat Bayesian learning is fragile, while no-regret learning requires less\nknowledge of the environment and is therefore more robust. Motivated by the\nstrengths and weaknesses of both approaches, we propose a balanced strategy for\nutilizing Bayesian updates that improves robustness and adaptability to\ndistribution shifts, providing a step toward a best-of-both-worlds learning\napproach. The method is general, efficient, and easy to implement. Finally, we\nformally establish the relationship between the notions of survival and market\ndominance studied in economics and the framework of regret minimization, thus\nbridging these theories. More broadly, our work contributes to the\nunderstanding of dynamics with heterogeneous types of learning agents and their\nimpact on markets.\n","authors":["David Easley","Yoav Kolumbus","Eva Tardos"],"pdf_url":"https://arxiv.org/pdf/2502.08597v2.pdf","comment":"Learning in Markets, Heterogeneous Agents, Regret and Survival,\n  Bayesian Learning, No-Regret Learning, Portfolio Optimization, Kelly Rule,\n  Distribution Shifts, Robust Bayesian Updates"},{"id":"http://arxiv.org/abs/2506.20737v1","updated":"2025-06-25T18:04:25Z","published":"2025-06-25T18:04:25Z","title":"MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation","summary":"  The proliferation of LLM-based agents has led to increasing deployment of\ninter-agent collaboration for tasks like scheduling, negotiation, resource\nallocation etc. In such systems, privacy is critical, as agents often access\nproprietary tools and domain-specific databases requiring strict\nconfidentiality. This paper examines whether LLM-based agents demonstrate an\nunderstanding of contextual privacy. And, if instructed, do these systems\npreserve inference time user privacy in non-adversarial multi-turn\nconversation. Existing benchmarks to evaluate contextual privacy in LLM-agents\nprimarily assess single-turn, low-complexity tasks where private information\ncan be easily excluded. We first present a benchmark - MAGPIE comprising 158\nreal-life high-stakes scenarios across 15 domains. These scenarios are designed\nsuch that complete exclusion of private data impedes task completion yet\nunrestricted information sharing could lead to substantial losses. We then\nevaluate the current state-of-the-art LLMs on (a) their understanding of\ncontextually private data and (b) their ability to collaborate without\nviolating user privacy. Empirical experiments demonstrate that current models,\nincluding GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual\nprivacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the\ntime. In multi-turn conversations, these models disclose private information in\n59.9\\% and 50.5\\% of cases even under explicit privacy instructions.\nFurthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios.\nThese results underscore that current models are not aligned towards both\ncontextual privacy preservation and collaborative task-solving.\n","authors":["Gurusha Juneja","Alon Albalak","Wenyue Hua","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2506.20737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20729v1","updated":"2025-06-25T18:00:18Z","published":"2025-06-25T18:00:18Z","title":"Test-time Scaling Techniques in Theoretical Physics -- A Comparison of\n  Methods on the TPBench Dataset","summary":"  Large language models (LLMs) have shown strong capabilities in complex\nreasoning, and test-time scaling techniques can enhance their performance with\ncomparably low cost. Many of these methods have been developed and evaluated on\nmathematical reasoning benchmarks such as AIME. This paper investigates whether\nthe lessons learned from these benchmarks generalize to the domain of advanced\ntheoretical physics. We evaluate a range of common test-time scaling methods on\nthe TPBench physics dataset and compare their effectiveness with results on\nAIME. To better leverage the structure of physics problems, we develop a novel,\nsymbolic weak-verifier framework to improve parallel scaling results. Our\nempirical results demonstrate that this method significantly outperforms\nexisting test-time scaling approaches on TPBench. We also evaluate our method\non AIME, confirming its effectiveness in solving advanced mathematical\nproblems. Our findings highlight the power of step-wise symbolic verification\nfor tackling complex scientific problems.\n","authors":["Zhiqi Gao","Tianyi Li","Yurii Kvasiuk","Sai Chaitanya Tadepalli","Maja Rudolph","Daniel J. H. Chung","Frederic Sala","Moritz Münchmeyer"],"pdf_url":"https://arxiv.org/pdf/2506.20729v1.pdf","comment":"23 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.20705v1","updated":"2025-06-25T18:00:00Z","published":"2025-06-25T18:00:00Z","title":"On Convolutions, Intrinsic Dimension, and Diffusion Models","summary":"  The manifold hypothesis asserts that data of interest in high-dimensional\nambient spaces, such as image data, lies on unknown low-dimensional\nsubmanifolds. Diffusion models (DMs) -- which operate by convolving data with\nprogressively larger amounts of Gaussian noise and then learning to revert this\nprocess -- have risen to prominence as the most performant generative models,\nand are known to be able to learn distributions with low-dimensional support.\nFor a given datum in one of these submanifolds, we should thus intuitively\nexpect DMs to have implicitly learned its corresponding local intrinsic\ndimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari\net al. (2024b) recently showed that this is indeed the case by linking this LID\nto the rate of change of the log marginal densities of the DM with respect to\nthe amount of added noise, resulting in an LID estimator known as FLIPD. LID\nestimators such as FLIPD have a plethora of uses, among others they quantify\nthe complexity of a given datum, and can be used to detect outliers,\nadversarial examples and AI-generated text. FLIPD achieves state-of-the-art\nperformance at LID estimation, yet its theoretical underpinnings are incomplete\nsince Kamkari et al. (2024b) only proved its correctness under the highly\nunrealistic assumption of affine submanifolds. In this work we bridge this gap\nby formally proving the correctness of FLIPD under realistic assumptions.\nAdditionally, we show that an analogous result holds when Gaussian convolutions\nare replaced with uniform ones, and discuss the relevance of this result.\n","authors":["Kin Kwan Leung","Rasa Hosseinzadeh","Gabriel Loaiza-Ganem"],"pdf_url":"https://arxiv.org/pdf/2506.20705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20702v1","updated":"2025-06-25T17:59:50Z","published":"2025-06-25T17:59:50Z","title":"The Singapore Consensus on Global AI Safety Research Priorities","summary":"  Rapidly improving AI capabilities and autonomy hold significant promise of\ntransformation, but are also driving vigorous debate on how to ensure that AI\nis safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem\nis therefore essential -- it helps people embrace AI with confidence and gives\nmaximal space for innovation while avoiding backlash.\n  The \"2025 Singapore Conference on AI (SCAI): International Scientific\nExchange on AI Safety\" aimed to support research in this space by bringing\ntogether AI scientists across geographies to identify and synthesise research\npriorities in AI safety. This resulting report builds on the International AI\nSafety Report chaired by Yoshua Bengio and backed by 33 governments. By\nadopting a defence-in-depth model, this report organises AI safety research\ndomains into three types: challenges with creating trustworthy AI systems\n(Development), challenges with evaluating their risks (Assessment), and\nchallenges with monitoring and intervening after deployment (Control).\n","authors":["Yoshua Bengio","Tegan Maharaj","Luke Ong","Stuart Russell","Dawn Song","Max Tegmark","Lan Xue","Ya-Qin Zhang","Stephen Casper","Wan Sie Lee","Sören Mindermann","Vanessa Wilfred","Vidhisha Balachandran","Fazl Barez","Michael Belinsky","Imane Bello","Malo Bourgon","Mark Brakel","Siméon Campos","Duncan Cass-Beggs","Jiahao Chen","Rumman Chowdhury","Kuan Chua Seah","Jeff Clune","Juntao Dai","Agnes Delaborde","Nouha Dziri","Francisco Eiras","Joshua Engels","Jinyu Fan","Adam Gleave","Noah Goodman","Fynn Heide","Dan Hendrycks","Cyrus Hodes","Bryan Low Kian Hsiang","Minlie Huang","Sami Jawhar","Wang Jingyu","Adam Tauman Kalai","Meindert Kamphuis","Mohan Kankanhalli","Subhash Kantamneni","Mathias Bonde Kirk","Thomas Kwa","Jeffrey Ladish","Kwok-Yan Lam","Wan Lee Sie","Taewhi Lee","Xiaojian Li","Jiajun Liu","Chaochao Lu","Yifan Mai","Richard Mallah","Julian Michael","Nick Moës","Simon Möller","Kihyuk Nam","Kwan Yee Ng","Mark Nitzberg","Besmira Nushi","Seán O hÉigeartaigh","Alejandro Ortega","Pierre Peigné","James Petrie","Benjamin Prud'Homme","Reihaneh Rabbany","Nayat Sanchez-Pi","Sarah Schwettmann","Buck Shlegeris","Saad Siddiqui","Aradhana Sinha","Martín Soto","Cheston Tan","Dong Ting","Robert Trager","Brian Tse","Anthony Tung K. H.","Vanessa Wilfred","John Willes","Denise Wong","Wei Xu","Rongwu Xu","Yi Zeng","HongJiang Zhang","Djordje Žikelić"],"pdf_url":"https://arxiv.org/pdf/2506.20702v1.pdf","comment":"Final report from the \"2025 Singapore Conference on AI (SCAI)\" held\n  April 26: https://www.scai.gov.sg/2025/scai2025-report"},{"id":"http://arxiv.org/abs/2506.20701v1","updated":"2025-06-25T17:59:10Z","published":"2025-06-25T17:59:10Z","title":"Diffusion Tree Sampling: Scalable inference-time alignment of diffusion\n  models","summary":"  Adapting a pretrained diffusion model to new objectives at inference time\nremains an open problem in generative modeling. Existing steering methods\nsuffer from inaccurate value estimation, especially at high noise levels, which\nbiases guidance. Moreover, information from past runs is not reused to improve\nsample quality, resulting in inefficient use of compute. Inspired by the\nsuccess of Monte Carlo Tree Search, we address these limitations by casting\ninference-time alignment as a search problem that reuses past computations. We\nintroduce a tree-based approach that samples from the reward-aligned target\ndensity by propagating terminal rewards back through the diffusion chain and\niteratively refining value estimates with each additional generation. Our\nproposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact\nsamples from the target distribution in the limit of infinite rollouts, and its\ngreedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search\nfor high reward samples. On MNIST and CIFAR-10 class-conditional generation,\nDTS matches the FID of the best-performing baseline with up to $10\\times$ less\ncompute. In text-to-image generation and language completion tasks, DTS$^\\star$\neffectively searches for high reward samples that match best-of-N with up to\n$5\\times$ less compute. By reusing information from previous generations, we\nget an anytime algorithm that turns additional compute into steadily better\nsamples, providing a scalable approach for inference-time alignment of\ndiffusion models.\n","authors":["Vineet Jain","Kusha Sareen","Mohammad Pedramfar","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2506.20701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20666v1","updated":"2025-06-25T17:58:12Z","published":"2025-06-25T17:58:12Z","title":"Inside you are many wolves: Using cognitive models to interpret value\n  trade-offs in LLMs","summary":"  Navigating everyday social situations often requires juggling conflicting\ngoals, such as conveying a harsh truth, maintaining trust, all while still\nbeing mindful of another person's feelings. These value trade-offs are an\nintegral part of human decision-making and language use, however, current tools\nfor interpreting such dynamic and multi-faceted notions of values in LLMs are\nlimited. In cognitive science, so-called \"cognitive models\" provide formal\naccounts of these trade-offs in humans, by modeling the weighting of a\nspeaker's competing utility functions in choosing an action or utterance. In\nthis work, we use a leading cognitive model of polite speech to interpret the\nextent to which LLMs represent human-like trade-offs. We apply this lens to\nsystematically evaluate value trade-offs in two encompassing model settings:\ndegrees of reasoning \"effort\" in frontier black-box models, and RL\npost-training dynamics of open-source models. Our results highlight patterns of\nhigher informational utility than social utility in reasoning models, and in\nopen-source models shown to be stronger in mathematical reasoning. Our findings\nfrom LLMs' training dynamics suggest large shifts in utility values early on in\ntraining with persistent effects of the choice of base model and pretraining\ndata, compared to feedback dataset or alignment method. We show that our method\nis responsive to diverse aspects of the rapidly evolving LLM landscape, with\ninsights for forming hypotheses about other high-level behaviors, shaping\ntraining regimes for reasoning models, and better controlling trade-offs\nbetween values during model training.\n","authors":["Sonia K. Murthy","Rosie Zhao","Jennifer Hu","Sham Kakade","Markus Wulfmeier","Peng Qian","Tomer Ullman"],"pdf_url":"https://arxiv.org/pdf/2506.20666v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.20664v1","updated":"2025-06-25T17:55:27Z","published":"2025-06-25T17:55:27Z","title":"The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind","summary":"  As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.\n","authors":["Andrei Lupu","Timon Willi","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2506.20664v1.pdf","comment":"41 pages, 19 figures"},{"id":"http://arxiv.org/abs/2506.18871v2","updated":"2025-06-25T17:54:25Z","published":"2025-06-23T17:38:54Z","title":"OmniGen2: Exploration to Advanced Multimodal Generation","summary":"  In this work, we introduce OmniGen2, a versatile and open-source generative\nmodel designed to provide a unified solution for diverse generation tasks,\nincluding text-to-image, image editing, and in-context generation. Unlike\nOmniGen v1, OmniGen2 features two distinct decoding pathways for text and image\nmodalities, utilizing unshared parameters and a decoupled image tokenizer. This\ndesign enables OmniGen2 to build upon existing multimodal understanding models\nwithout the need to re-adapt VAE inputs, thereby preserving the original text\ngeneration capabilities. To facilitate the training of OmniGen2, we developed\ncomprehensive data construction pipelines, encompassing image editing and\nin-context generation data. Additionally, we introduce a reflection mechanism\ntailored for image generation tasks and curate a dedicated reflection dataset\nbased on OmniGen2. Despite its relatively modest parameter size, OmniGen2\nachieves competitive results on multiple task benchmarks, including\ntext-to-image and image editing. To further evaluate in-context generation,\nalso referred to as subject-driven tasks, we introduce a new benchmark named\nOmniContext. OmniGen2 achieves state-of-the-art performance among open-source\nmodels in terms of consistency. We will release our models, training code,\ndatasets, and data construction pipeline to support future research in this\nfield. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:\nhttps://github.com/VectorSpaceLab/OmniGen2\n","authors":["Chenyuan Wu","Pengfei Zheng","Ruiran Yan","Shitao Xiao","Xin Luo","Yueze Wang","Wanli Li","Xiyan Jiang","Yexin Liu","Junjie Zhou","Ze Liu","Ziyi Xia","Chaofan Li","Haoge Deng","Jiahao Wang","Kun Luo","Bo Zhang","Defu Lian","Xinlong Wang","Zhongyuan Wang","Tiejun Huang","Zheng Liu"],"pdf_url":"https://arxiv.org/pdf/2506.18871v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20649v1","updated":"2025-06-25T17:44:37Z","published":"2025-06-25T17:44:37Z","title":"Disentangled representations of microscopy images","summary":"  Microscopy image analysis is fundamental for different applications, from\ndiagnosis to synthetic engineering and environmental monitoring. Modern\nacquisition systems have granted the possibility to acquire an escalating\namount of images, requiring a consequent development of a large collection of\ndeep learning-based automatic image analysis methods. Although deep neural\nnetworks have demonstrated great performance in this field, interpretability,\nan essential requirement for microscopy image analysis, remains an open\nchallenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology\nto enhance model interpretability for microscopy image classification.\nExploiting benchmark datasets from three different microscopic image domains\n(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based\non transferring a representation learnt from synthetic data, can provide a good\ntrade-off between accuracy and interpretability in this domain.\n","authors":["Jacopo Dapueto","Vito Paolo Pastore","Nicoletta Noceti","Francesca Odone"],"pdf_url":"https://arxiv.org/pdf/2506.20649v1.pdf","comment":"Published in: International Joint Conference on Neural Networks\n  (IJCNN 2025). Project page:\n  https://github.com/JacopoDapueto/disentangled_microscopy"},{"id":"http://arxiv.org/abs/2506.20640v1","updated":"2025-06-25T17:36:02Z","published":"2025-06-25T17:36:02Z","title":"Towards Community-Driven Agents for Machine Learning Engineering","summary":"  Large language model-based machine learning (ML) agents have shown great\npromise in automating ML research. However, existing agents typically operate\nin isolation on a given research problem, without engaging with the broader\nresearch community, where human researchers often gain insights and contribute\nby sharing knowledge. To bridge this gap, we introduce MLE-Live, a live\nevaluation framework designed to assess an agent's ability to communicate with\nand leverage collective knowledge from a simulated Kaggle research community.\nBuilding on this framework, we propose CoMind, a novel agent that excels at\nexchanging insights and developing novel solutions within a community context.\nCoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%\nhuman competitors on average across four ongoing Kaggle competitions. Our code\nis released at https://github.com/comind-ml/CoMind.\n","authors":["Sijie Li","Weiwei Sun","Shanda Li","Ameet Talwalkar","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2506.20640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08914v2","updated":"2025-06-25T17:32:22Z","published":"2025-02-13T03:05:42Z","title":"Diffusion Models Through a Global Lens: Are They Culturally Inclusive?","summary":"  Text-to-image diffusion models have recently enabled the creation of visually\ncompelling, detailed images from textual prompts. However, their ability to\naccurately represent various cultural nuances remains an open question. In our\nwork, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion\nmodels whether they can generate culturally specific images spanning ten\ncountries. We show that these models often fail to generate cultural artifacts\nin architecture, clothing, and food, especially for underrepresented country\nregions, by conducting a fine-grained analysis of different similarity aspects,\nrevealing significant disparities in cultural relevance, description fidelity,\nand realism compared to real-world reference images. With the collected human\nevaluations, we develop a neural-based image-image similarity metric, namely,\nCultDiff-S, to predict human judgment on real and generated images with\ncultural artifacts. Our work highlights the need for more inclusive generative\nAI systems and equitable dataset representation over a wide range of cultures.\n","authors":["Zahra Bayramli","Ayhan Suleymanzade","Na Min An","Huzama Ahmad","Eunsu Kim","Junyeong Park","James Thorne","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2502.08914v2.pdf","comment":"17 pages, 17 figures, 3 tables"},{"id":"http://arxiv.org/abs/2506.04689v2","updated":"2025-06-25T17:12:12Z","published":"2025-06-05T07:12:12Z","title":"Recycling the Web: A Method to Enhance Pre-training Data Quality and\n  Quantity for Language Models","summary":"  Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.\n","authors":["Thao Nguyen","Yang Li","Olga Golovneva","Luke Zettlemoyer","Sewoong Oh","Ludwig Schmidt","Xian Li"],"pdf_url":"https://arxiv.org/pdf/2506.04689v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20621v1","updated":"2025-06-25T17:11:26Z","published":"2025-06-25T17:11:26Z","title":"Define-ML: An Approach to Ideate Machine Learning-Enabled Systems","summary":"  [Context] The increasing adoption of machine learning (ML) in software\nsystems demands specialized ideation approaches that address ML-specific\nchallenges, including data dependencies, technical feasibility, and alignment\nbetween business objectives and probabilistic system behavior. Traditional\nideation methods like Lean Inception lack structured support for these ML\nconsiderations, which can result in misaligned product visions and unrealistic\nexpectations. [Goal] This paper presents Define-ML, a framework that extends\nLean Inception with tailored activities - Data Source Mapping, Feature-to-Data\nSource Mapping, and ML Mapping - to systematically integrate data and technical\nconstraints into early-stage ML product ideation. [Method] We developed and\nvalidated Define-ML following the Technology Transfer Model, conducting both\nstatic validation (with a toy problem) and dynamic validation (in a real-world\nindustrial case study). The analysis combined quantitative surveys with\nqualitative feedback, assessing utility, ease of use, and intent of adoption.\n[Results] Participants found Define-ML effective for clarifying data concerns,\naligning ML capabilities with business goals, and fostering cross-functional\ncollaboration. The approach's structured activities reduced ideation ambiguity,\nthough some noted a learning curve for ML-specific components, which can be\nmitigated by expert facilitation. All participants expressed the intention to\nadopt Define-ML. [Conclusion] Define-ML provides an openly available, validated\napproach for ML product ideation, building on Lean Inception's agility while\naligning features with available data and increasing awareness of technical\nfeasibility.\n","authors":["Silvio Alonso","Antonio Pedro Santos Alves","Lucas Romao","Hélio Lopes","Marcos Kalinowski"],"pdf_url":"https://arxiv.org/pdf/2506.20621v1.pdf","comment":"Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025"},{"id":"http://arxiv.org/abs/2401.01259v5","updated":"2025-06-25T17:10:45Z","published":"2024-01-02T16:05:23Z","title":"Do Concept Bottleneck Models Respect Localities?","summary":"  Concept-based explainability methods use human-understandable intermediaries\nto produce explanations for machine learning models. These methods assume\nconcept predictions can help understand a model's internal reasoning. In this\nwork, we assess the degree to which such an assumption is true by analyzing\nwhether concept predictors leverage \"relevant\" features to make predictions, a\nterm we call locality. Concept-based models that fail to respect localities\nalso fail to be explainable because concept predictions are based on spurious\nfeatures, making the interpretation of the concept predictions vacuous. To\nassess whether concept-based models respect localities, we construct and use\nthree metrics to characterize when models respect localities, complementing our\nanalysis with theoretical results. Each of our metrics captures a different\nnotion of perturbation and assess whether perturbing \"irrelevant\" features\nimpacts the predictions made by a concept predictors. We find that many\nconcept-based models used in practice fail to respect localities because\nconcept predictors cannot always clearly distinguish distinct concepts. Based\non these findings, we propose suggestions for alleviating this issue.\n","authors":["Naveen Raman","Mateo Espinosa Zarlenga","Juyeon Heo","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2401.01259v5.pdf","comment":"Published at TMLR"},{"id":"http://arxiv.org/abs/2503.07294v2","updated":"2025-06-25T17:08:53Z","published":"2025-03-10T13:16:48Z","title":"From $\\mathcal{O}(n^{2})$ to $\\mathcal{O}(n)$ Parameters: Quantum\n  Self-Attention in Vision Transformers for Biomedical Image Classification","summary":"  We demonstrate that quantum vision transformers (QViTs), vision transformers\n(ViTs) with self-attention (SA) mechanisms replaced by quantum self-attention\n(QSA) mechanisms, can match state-of-the-art (SOTA) biomedical image\nclassifiers while using 99.99% fewer parameters. QSAs are produced by replacing\nlinear SA layers with parameterised quantum neural networks (QNNs), producing a\nQSA mechanism and reducing parameter scaling from $\\mathcal{O}(n^2)$ to\n$\\mathcal{O}(n)$. On RetinaMNIST, our ultra parameter-efficient QViT\noutperforms 13/14 SOTA methods including CNNs and ViTs, achieving 56.5%\naccuracy, just 0.88% below the top MedMamba model while using 99.99% fewer\nparameters (1K vs 14.5M) and 89% fewer GFLOPs. We present the first\ninvestigation of knowledge distillation (KD) from classical to quantum vision\ntransformers in biomedical image classification, showing that QViTs maintain\ncomparable performance to classical ViTs across eight diverse datasets spanning\nmultiple modalities, with improved QSA parameter-efficiency. Our higher-qubit\narchitecture benefitted more from KD pre-training, suggesting a scaling\nrelationship between QSA parameters and KD effectiveness. These findings\nestablish QSA as a practical architectural choice toward parameter-efficient\nbiomedical image analysis.\n","authors":["Thomas Boucher","John Whittle","Evangelos B. Mazomenos"],"pdf_url":"https://arxiv.org/pdf/2503.07294v2.pdf","comment":"Submitted for EMA4MICCAI 2025"},{"id":"http://arxiv.org/abs/2506.20614v1","updated":"2025-06-25T17:04:00Z","published":"2025-06-25T17:04:00Z","title":"Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI\n  segmentation","summary":"  In recent decades, the use of 4D Flow MRI images has enabled the\nquantification of velocity fields within a volume of interest and along the\ncardiac cycle. However, the lack of resolution and the presence of noise in\nthese biomarkers are significant issues. As indicated by recent studies, it\nappears that biomarkers such as wall shear stress are particularly impacted by\nthe poor resolution of vessel segmentation. The Phase Contrast Magnetic\nResonance Angiography (PC-MRA) is the state-of-the-art method to facilitate\nsegmentation. The objective of this work is to introduce a new handcraft\nfeature that provides a novel visualisation of 4D Flow MRI images, which is\nuseful in the segmentation task. This feature, termed Weighted Mean Frequencies\n(WMF), is capable of revealing the region in three dimensions where a voxel has\nbeen passed by pulsatile flow. Indeed, this feature is representative of the\nhull of all pulsatile velocity voxels. The value of the feature under\ndiscussion is illustrated by two experiments. The experiments involved\nsegmenting 4D Flow MRI images using optimal thresholding and deep learning\nmethods. The results obtained demonstrate a substantial enhancement in terms of\nIoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with\nthe PC-MRA feature, as evidenced by the deep learning task. This feature has\nthe potential to yield valuable insights that could inform future segmentation\nprocesses in other vascular regions, such as the heart or the brain.\n","authors":["Simon Perrin","Sébastien Levilly","Huajun Sun","Harold Mouchère","Jean-Michel Serfaty"],"pdf_url":"https://arxiv.org/pdf/2506.20614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20609v1","updated":"2025-06-25T17:00:21Z","published":"2025-06-25T17:00:21Z","title":"Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot\n  Recordings","summary":"  The escalating rates of gun-related violence and mass shootings represent a\nsignificant threat to public safety. Timely and accurate information for law\nenforcement agencies is crucial in mitigating these incidents. Current\ncommercial gunshot detection systems, while effective, often come with\nprohibitive costs. This research explores a cost-effective alternative by\nleveraging acoustic analysis of gunshot recordings, potentially obtainable from\nubiquitous devices like cell phones, to not only detect gunshots but also\nclassify the type of firearm used. This paper details a study on deciphering\ngun type hierarchies using a curated dataset of 3459 recordings. We investigate\nthe fundamental acoustic characteristics of gunshots, including muzzle blasts\nand shockwaves, which vary based on firearm type, ammunition, and shooting\ndirection. We propose and evaluate machine learning frameworks, including\nSupport Vector Machines (SVMs) as a baseline and a more advanced Convolutional\nNeural Network (CNN) architecture for joint gunshot detection and gun type\nclassification. Results indicate that our deep learning approach achieves a\nmean average precision (mAP) of 0.58 on clean labeled data, outperforming the\nSVM baseline (mAP 0.39). Challenges related to data quality, environmental\nnoise, and the generalization capabilities when using noisy web-sourced data\n(mAP 0.35) are also discussed. The long-term vision is to develop a highly\naccurate, real-time system deployable on common recording devices,\nsignificantly reducing detection costs and providing critical intelligence to\nfirst responders.\n","authors":["Ankit Shah","Rita Singh","Bhiksha Raj","Alexander Hauptmann"],"pdf_url":"https://arxiv.org/pdf/2506.20609v1.pdf","comment":"4 pages + 1 References"},{"id":"http://arxiv.org/abs/2506.20608v1","updated":"2025-06-25T17:00:05Z","published":"2025-06-25T17:00:05Z","title":"AI Assistants to Enhance and Exploit the PETSc Knowledge Base","summary":"  Generative AI, especially through large language models (LLMs), is\ntransforming how technical knowledge can be accessed, reused, and extended.\nPETSc, a widely used numerical library for high-performance scientific\ncomputing, has accumulated a rich but fragmented knowledge base over its three\ndecades of development, spanning source code, documentation, mailing lists,\nGitLab issues, Discord conversations, technical papers, and more. Much of this\nknowledge remains informal and inaccessible to users and new developers. To\nactivate and utilize this knowledge base more effectively, the PETSc team has\nbegun building an LLM-powered system that combines PETSc content with custom\nLLM tools -- including retrieval-augmented generation (RAG), reranking\nalgorithms, and chatbots -- to assist users, support developers, and propose\nupdates to formal documentation. This paper presents initial experiences\ndesigning and evaluating these tools, focusing on system architecture, using\nRAG and reranking for PETSc-specific information, evaluation methodologies for\nvarious LLMs and embedding models, and user interface design. Leveraging the\nArgonne Leadership Computing Facility resources, we analyze how LLM responses\ncan enhance the development and use of numerical software, with an initial\nfocus on scalable Krylov solvers. Our goal is to establish an extensible\nframework for knowledge-centered AI in scientific software, enabling scalable\nsupport, enriched documentation, and enhanced workflows for research and\ndevelopment. We conclude by outlining directions for expanding this system into\na robust, evolving platform that advances software ecosystems to accelerate\nscientific discovery.\n","authors":["Barry Smith","Junchao Zhang","Hong Zhang","Lois Curfman McInnes","Murat Keceli","Archit Vasan","Satish Balay","Toby Isaac","Le Chen","Venkatram Vishwanath"],"pdf_url":"https://arxiv.org/pdf/2506.20608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08059v3","updated":"2025-06-25T16:40:39Z","published":"2024-03-12T20:11:38Z","title":"FluoroSAM: A Language-promptable Foundation Model for Flexible X-ray\n  Image Segmentation","summary":"  Language promptable X-ray image segmentation would enable greater flexibility\nfor human-in-the-loop workflows in diagnostic and interventional precision\nmedicine. Prior efforts have contributed task-specific models capable of\nsolving problems within a narrow scope, but expanding to broader use requires\nadditional data, annotations, and training time. Recently, language-aligned\nfoundation models (LFMs) -- machine learning models trained on large amounts of\nhighly variable image and text data thus enabling broad applicability -- have\nemerged as promising tools for automated image analysis. Existing foundation\nmodels for medical image analysis focus on scenarios and modalities where\nlarge, richly annotated datasets are available. However, the X-ray imaging\nmodality features highly variable image appearance and applications, from\ndiagnostic chest X-rays to interventional fluoroscopy, with varying\navailability of data. To pave the way toward an LFM for comprehensive and\nlanguage-aligned analysis of arbitrary medical X-ray images, we introduce\nFluoroSAM, a language-promptable variant of the Segment Anything Model, trained\nfrom scratch on 3M synthetic X-ray images from a wide variety of human\nanatomies, imaging geometries, and viewing angles. These include pseudo-ground\ntruth masks for 128 organ types and 464 tools with associated text\ndescriptions. FluoroSAM is capable of segmenting myriad anatomical structures\nand tools based on natural language prompts, thanks to the novel incorporation\nof vector quantization (VQ) of text embeddings in the training process. We\ndemonstrate FluoroSAM's performance quantitatively on real X-ray images and\nshowcase on several applications how FluoroSAM is a key enabler for rich\nhuman-machine interaction in the X-ray image acquisition and analysis context.\nCode is available at https://github.com/arcadelab/fluorosam.\n","authors":["Benjamin D. Killeen","Liam J. Wang","Blanca Inigo","Han Zhang","Mehran Armand","Russell H. Taylor","Greg Osgood","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2403.08059v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20600v1","updated":"2025-06-25T16:39:05Z","published":"2025-06-25T16:39:05Z","title":"CogGen: A Learner-Centered Generative AI Architecture for Intelligent\n  Tutoring with Programming Video","summary":"  We introduce CogGen, a learner-centered AI architecture that transforms\nprogramming videos into interactive, adaptive learning experiences by\nintegrating student modeling with generative AI tutoring based on the Cognitive\nApprenticeship framework. The architecture consists of three components: (1)\nvideo segmentation by learning goals, (2) a conversational tutoring engine\napplying Cognitive Apprenticeship strategies, and (3) a student model using\nBayesian Knowledge Tracing to adapt instruction. Our technical evaluation\ndemonstrates effective video segmentation accuracy and strong pedagogical\nalignment across knowledge, method, action, and interaction layers. Ablation\nstudies confirm the necessity of each component in generating effective\nguidance. This work advances AI-powered tutoring by bridging structured student\nmodeling with interactive AI conversations, offering a scalable approach to\nenhancing video-based programming education.\n","authors":["Wengxi Li","Roy Pea","Nick Haber","Hari Subramonyam"],"pdf_url":"https://arxiv.org/pdf/2506.20600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20598v1","updated":"2025-06-25T16:37:46Z","published":"2025-06-25T16:37:46Z","title":"Fine-Tuning and Prompt Engineering of LLMs, for the Creation of\n  Multi-Agent AI for Addressing Sustainable Protein Production Challenges","summary":"  The global demand for sustainable protein sources has accelerated the need\nfor intelligent tools that can rapidly process and synthesise domain-specific\nscientific knowledge. In this study, we present a proof-of-concept multi-agent\nArtificial Intelligence (AI) framework designed to support sustainable protein\nproduction research, with an initial focus on microbial protein sources. Our\nRetrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based\nLLM agents: (1) a literature search agent that retrieves relevant scientific\nliterature on microbial protein production for a specified microbial strain,\nand (2) an information extraction agent that processes the retrieved content to\nextract relevant biological and chemical information. Two parallel\nmethodologies, fine-tuning and prompt engineering, were explored for agent\noptimisation. Both methods demonstrated effectiveness at improving the\nperformance of the information extraction agent in terms of transformer-based\ncosine similarity scores between obtained and ideal outputs. Mean cosine\nsimilarity scores were increased by up to 25%, while universally reaching mean\nscores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved\nthe mean scores to a greater extent (consistently of $\\geq 0.94$) compared to\nprompt engineering, although lower statistical uncertainties were observed with\nthe latter approach. A user interface was developed and published for enabling\nthe use of the multi-agent AI system, alongside preliminary exploration of\nadditional chemical safety-based search capabilities\n","authors":["Alexander D. Kalian","Jaewook Lee","Stefan P. Johannesson","Lennart Otte","Christer Hogstrand","Miao Guo"],"pdf_url":"https://arxiv.org/pdf/2506.20598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20595v1","updated":"2025-06-25T16:34:09Z","published":"2025-06-25T16:34:09Z","title":"AI in the Writing Process: How Purposeful AI Support Fosters Student\n  Writing","summary":"  The ubiquity of technologies like ChatGPT has raised concerns about their\nimpact on student writing, particularly regarding reduced learner agency and\nsuperficial engagement with content. While standalone chat-based LLMs often\nproduce suboptimal writing outcomes, evidence suggests that purposefully\ndesigned AI writing support tools can enhance the writing process. This paper\ninvestigates how different AI support approaches affect writers' sense of\nagency and depth of knowledge transformation. Through a randomized control\ntrial with 90 undergraduate students, we compare three conditions: (1) a\nchat-based LLM writing assistant, (2) an integrated AI writing tool to support\ndiverse subprocesses, and (3) a standard writing interface (control). Our\nfindings demonstrate that, among AI-supported conditions, students using the\nintegrated AI writing tool exhibited greater agency over their writing process\nand engaged in deeper knowledge transformation overall. These results suggest\nthat thoughtfully designed AI writing support targeting specific aspects of the\nwriting process can help students maintain ownership of their work while\nfacilitating improved engagement with content.\n","authors":["Momin N. Siddiqui","Roy Pea","Hari Subramonyam"],"pdf_url":"https://arxiv.org/pdf/2506.20595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.19195v2","updated":"2025-06-25T16:24:12Z","published":"2025-01-31T15:03:54Z","title":"Rethinking Early Stopping: Refine, Then Calibrate","summary":"  Machine learning classifiers often produce probabilistic predictions that are\ncritical for accurate and interpretable decision-making in various domains. The\nquality of these predictions is generally evaluated with proper losses, such as\ncross-entropy, which decompose into two components: calibration error assesses\ngeneral under/overconfidence, while refinement error measures the ability to\ndistinguish different classes. In this paper, we present a novel variational\nformulation of the calibration-refinement decomposition that sheds new light on\npost-hoc calibration, and enables rapid estimation of the different terms.\nEquipped with this new perspective, we provide theoretical and empirical\nevidence that calibration and refinement errors are not minimized\nsimultaneously during training. Selecting the best epoch based on validation\nloss thus leads to a compromise point that is suboptimal for both terms. To\naddress this, we propose minimizing refinement error only during training\n(Refine,...), before minimizing calibration error post hoc, using standard\ntechniques (...then Calibrate). Our method integrates seamlessly with any\nclassifier and consistently improves performance across diverse classification\ntasks.\n","authors":["Eugène Berta","David Holzmüller","Michael I. Jordan","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2501.19195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20583v1","updated":"2025-06-25T16:23:43Z","published":"2025-06-25T16:23:43Z","title":"Dense Video Captioning using Graph-based Sentence Summarization","summary":"  Recently, dense video captioning has made attractive progress in detecting\nand captioning all events in a long untrimmed video. Despite promising results\nwere achieved, most existing methods do not sufficiently explore the scene\nevolution within an event temporal proposal for captioning, and therefore\nperform less satisfactorily when the scenes and objects change over a\nrelatively long proposal. To address this problem, we propose a graph-based\npartition-and-summarization (GPaS) framework for dense video captioning within\ntwo stages. For the ``partition\" stage, a whole event proposal is split into\nshort video segments for captioning at a finer level. For the ``summarization\"\nstage, the generated sentences carrying rich description information for each\nsegment are summarized into one sentence to describe the whole event. We\nparticularly focus on the ``summarization\" stage, and propose a framework that\neffectively exploits the relationship between semantic words for summarization.\nWe achieve this goal by treating semantic words as nodes in a graph and\nlearning their interactions by coupling Graph Convolutional Network (GCN) and\nLong Short Term Memory (LSTM), with the aid of visual cues. Two schemes of\nGCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN\nand LSTM. The effectiveness of our approach is demonstrated via an extensive\ncomparison with the state-of-the-arts methods on the two benchmarks ActivityNet\nCaptions dataset and YouCook II dataset.\n","authors":["Zhiwang Zhang","Dong Xu","Wanli Ouyang","Luping Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.20583v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2412.03905v3","updated":"2025-06-25T16:21:54Z","published":"2024-12-05T06:21:31Z","title":"Integrating Various Software Artifacts for Better LLM-based Bug\n  Localization and Program Repair","summary":"  LLMs have garnered considerable attention for their potential to streamline\nAutomated Program Repair (APR). LLM-based approaches can either insert the\ncorrect code or directly generate patches when provided with buggy methods.\nHowever, most of LLM-based APR methods rely on a single type of software\ninformation, without fully leveraging different software artifacts. Despite\nthis, many LLM-based approaches do not explore which specific types of\ninformation best assist in APR. Addressing this gap is crucial for advancing\nLLM-based APR techniques. We propose DEVLoRe to use issue content (description\nand message) and stack error traces to localize buggy methods, then rely on\ndebug information in buggy methods and issue content and stack error to\nlocalize buggy lines and generate plausible patches which can pass all unit\ntests. The results show that while issue content is particularly effective in\nassisting LLMs with fault localization and program repair, different types of\nsoftware artifacts complement each other. By incorporating different artifacts,\nDEVLoRe successfully locates 49.3% and 47.6% of single and non-single buggy\nmethods and generates 56.0% and 14.5% plausible patches for the Defects4J v2.0\ndataset, respectively. This outperforms current state-of-the-art APR methods.\nFurthermore, we re-implemented and evaluated our framework, demonstrating its\neffectiveness in its effectiveness in resolving 9 unique issues compared to\nother state-of-the-art frameworks using the same or more advanced models on\nSWE-bench Lite.We also discussed whether a leading framework for Python code\ncan be directly applied to Java code, or vice versa. The source code and\nexperimental results of this work for replication are available at\nhttps://github.com/XYZboom/DEVLoRe.\n","authors":["Qiong Feng","Xiaotian Ma","Jiayi Sheng","Ziyuan Feng","Wei Song","Peng Liang"],"pdf_url":"https://arxiv.org/pdf/2412.03905v3.pdf","comment":"25 pages, 12 images, 10 tables, Manuscript revision submitted to a\n  journal (2025)"},{"id":"http://arxiv.org/abs/2501.06256v2","updated":"2025-06-25T16:21:31Z","published":"2025-01-09T09:45:05Z","title":"Unlocking In-Context Learning for Natural Datasets Beyond Language\n  Modelling","summary":"  Large Language Models (LLMs) exhibit In-Context Learning (ICL), which enables\nthe model to perform new tasks conditioning only on the examples provided in\nthe context without updating the model's weights. While ICL offers fast\nadaptation across natural language tasks and domains, its emergence is less\nstraightforward for modalities beyond text. In this work, we systematically\nuncover properties present in LLMs that support the emergence of ICL for\nautoregressive models and various modalities by promoting the learning of the\nneeded mechanisms for ICL. We identify exact token repetitions in the training\ndata sequences as an important factor for ICL. Such repetitions further improve\nstability and reduce transiency in ICL performance. Moreover, we emphasise the\nsignificance of training task difficulty for the emergence of ICL. Finally, by\napplying our novel insights on ICL emergence, we unlock ICL capabilities for\nvarious visual datasets and a more challenging EEG classification task in a\nfew-shot learning regime.\n","authors":["Jelena Bratulić","Sudhanshu Mittal","David T. Hoffmann","Samuel Böhm","Robin Tibor Schirrmeister","Tonio Ball","Christian Rupprecht","Thomas Brox"],"pdf_url":"https://arxiv.org/pdf/2501.06256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20582v1","updated":"2025-06-25T16:17:36Z","published":"2025-06-25T16:17:36Z","title":"Causal Representation Learning with Observational Grouping for CXR\n  Classification","summary":"  Identifiable causal representation learning seeks to uncover the true causal\nrelationships underlying a data generation process. In medical imaging, this\npresents opportunities to improve the generalisability and robustness of\ntask-specific latent features. This work introduces the concept of grouping\nobservations to learn identifiable representations for disease classification\nin chest X-rays via an end-to-end framework. Our experiments demonstrate that\nthese causal representations improve generalisability and robustness across\nmultiple classification tasks when grouping is used to enforce invariance w.r.t\nrace, sex, and imaging views.\n","authors":["Rajat Rasal","Avinash Kori","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2506.20582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16791v2","updated":"2025-06-25T16:14:44Z","published":"2025-06-20T07:14:48Z","title":"TabArena: A Living Benchmark for Machine Learning on Tabular Data","summary":"  With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning and investigate the contributions of individual models. We launch\nTabArena with a public leaderboard, reproducible code, and maintenance\nprotocols to create a living benchmark available at https://tabarena.ai.\n","authors":["Nick Erickson","Lennart Purucker","Andrej Tschalzev","David Holzmüller","Prateek Mutalik Desai","David Salinas","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2506.16791v2.pdf","comment":"v2: fixed author list. 51 pages. Code available at\n  https://tabarena.ai/code; examples at https://tabarena.ai/code-examples;\n  dataset curation at https://tabarena.ai/data-tabular-ml-iid-study and\n  https://tabarena.ai/dataset-curation"},{"id":"http://arxiv.org/abs/2506.20576v1","updated":"2025-06-25T16:10:20Z","published":"2025-06-25T16:10:20Z","title":"Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks\n  on NIDS","summary":"  Adversarial attacks, wherein slight inputs are carefully crafted to mislead\nintelligent models, have attracted increasing attention. However, a critical\ngap persists between theoretical advancements and practical application,\nparticularly in structured data like network traffic, where interdependent\nfeatures complicate effective adversarial manipulations. Moreover, ambiguity in\ncurrent approaches restricts reproducibility and limits progress in this field.\nHence, existing defenses often fail to handle evolving adversarial attacks.\nThis paper proposes a novel approach for black-box adversarial attacks, that\naddresses these limitations. Unlike prior work, which often assumes system\naccess or relies on repeated probing, our method strictly respect black-box\nconstraints, reducing interaction to avoid detection and better reflect\nreal-world scenarios. We present an adaptive feature selection strategy using\nchange-point detection and causality analysis to identify and target sensitive\nfeatures to perturbations. This lightweight design ensures low computational\ncost and high deployability. Our comprehensive experiments show the attack's\neffectiveness in evading detection with minimal interaction, enhancing its\nadaptability and applicability in real-world scenarios. By advancing the\nunderstanding of adversarial attacks in network traffic, this work lays a\nfoundation for developing robust defenses.\n","authors":["Sabrine Ennaji","Elhadj Benkhelifa","Luigi V. Mancini"],"pdf_url":"https://arxiv.org/pdf/2506.20576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20567v1","updated":"2025-06-25T16:02:04Z","published":"2025-06-25T16:02:04Z","title":"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided\n  Sentence Summarization","summary":"  In this work, we propose a division-and-summarization (DaS) framework for\ndense video captioning. After partitioning each untrimmed long video as\nmultiple event proposals, where each event proposal consists of a set of short\nvideo segments, we extract visual feature (e.g., C3D feature) from each segment\nand use the existing image/video captioning approach to generate one sentence\ndescription for this segment. Considering that the generated sentences contain\nrich semantic descriptions about the whole event proposal, we formulate the\ndense video captioning task as a visual cue aided sentence summarization\nproblem and propose a new two stage Long Short Term Memory (LSTM) approach\nequipped with a new hierarchical attention mechanism to summarize all generated\nsentences as one descriptive sentence with the aid of visual features.\nSpecifically, the first-stage LSTM network takes all semantic words from the\ngenerated sentences and the visual features from all segments within one event\nproposal as the input, and acts as the encoder to effectively summarize both\nsemantic and visual information related to this event proposal. The\nsecond-stage LSTM network takes the output from the first-stage LSTM network\nand the visual features from all video segments within one event proposal as\nthe input, and acts as the decoder to generate one descriptive sentence for\nthis event proposal. Our comprehensive experiments on the ActivityNet Captions\ndataset demonstrate the effectiveness of our newly proposed DaS framework for\ndense video captioning.\n","authors":["Zhiwang Zhang","Dong Xu","Wanli Ouyang","Chuanqi Tan"],"pdf_url":"https://arxiv.org/pdf/2506.20567v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2506.20555v1","updated":"2025-06-25T15:53:18Z","published":"2025-06-25T15:53:18Z","title":"DeepQuark: deep-neural-network approach to multiquark bound states","summary":"  For the first time, we implement the deep-neural-network-based variational\nMonte Carlo approach for the multiquark bound states, whose complexity\nsurpasses that of electron or nucleon systems due to strong SU(3) color\ninteractions. We design a novel and high-efficiency architecture, DeepQuark, to\naddress the unique challenges in multiquark systems such as stronger\ncorrelations, extra discrete quantum numbers, and intractable confinement\ninteraction. Our method demonstrates competitive performance with\nstate-of-the-art approaches, including diffusion Monte Carlo and Gaussian\nexpansion method, in the nucleon, doubly heavy tetraquark, and fully heavy\ntetraquark systems. Notably, it outperforms existing calculations for\npentaquarks, exemplified by the triply heavy pentaquark. For the nucleon, we\nsuccessfully incorporate three-body flux-tube confinement interactions without\nadditional computational costs. In tetraquark systems, we consistently describe\nhadronic molecule $T_{cc}$ and compact tetraquark $T_{bb}$ with an unbiased\nform of wave function ansatz. In the pentaquark sector, we obtain weakly bound\n$\\bar D^*\\Xi_{cc}^*$ molecule $P_{cc\\bar c}(5715)$ with $S=\\frac{5}{2}$ and its\nbottom partner $P_{bb\\bar b}(15569)$. They can be viewed as the analogs of the\nmolecular $T_{cc}$. We recommend experimental search of $P_{cc\\bar c}(5715)$ in\nthe D-wave $J/\\psi \\Lambda_c$ channel. DeepQuark holds great promise for\nextension to larger multiquark systems, overcoming the computational barriers\nin conventional methods. It also serves as a powerful framework for exploring\nconfining mechanism beyond two-body interactions in multiquark states, which\nmay offer valuable insights into nonperturbative QCD and general many-body\nphysics.\n","authors":["Wei-Lin Wu","Lu Meng","Shi-Lin Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.20555v1.pdf","comment":"10 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2506.20551v1","updated":"2025-06-25T15:50:34Z","published":"2025-06-25T15:50:34Z","title":"Large Language Model-Driven Code Compliance Checking in Building\n  Information Modeling","summary":"  This research addresses the time-consuming and error-prone nature of manual\ncode compliance checking in Building Information Modeling (BIM) by introducing\na Large Language Model (LLM)-driven approach to semi-automate this critical\nprocess. The developed system integrates LLMs such as GPT, Claude, Gemini, and\nLlama, with Revit software to interpret building codes, generate Python\nscripts, and perform semi-automated compliance checks within the BIM\nenvironment. Case studies on a single-family residential project and an office\nbuilding project demonstrated the system's ability to reduce the time and\neffort required for compliance checks while improving accuracy. It streamlined\nthe identification of violations, such as non-compliant room dimensions,\nmaterial usage, and object placements, by automatically assessing relationships\nand generating actionable reports. Compared to manual methods, the system\neliminated repetitive tasks, simplified complex regulations, and ensured\nreliable adherence to standards. By offering a comprehensive, adaptable, and\ncost-effective solution, this proposed approach offers a promising advancement\nin BIM-based compliance checking, with potential applications across diverse\nregulatory documents in construction projects.\n","authors":["Soumya Madireddy","Lu Gao","Zia Din","Kinam Kim","Ahmed Senouci","Zhe Han","Yunpeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20548v1","updated":"2025-06-25T15:46:41Z","published":"2025-06-25T15:46:41Z","title":"Pay Less Attention to Deceptive Artifacts: Robust Detection of\n  Compressed Deepfakes on Online Social Networks","summary":"  With the rapid advancement of deep learning, particularly through generative\nadversarial networks (GANs) and diffusion models (DMs), AI-generated images, or\n``deepfakes\", have become nearly indistinguishable from real ones. These images\nare widely shared across Online Social Networks (OSNs), raising concerns about\ntheir misuse. Existing deepfake detection methods overlook the ``block effects\"\nintroduced by compression in OSNs, which obscure deepfake artifacts, and\nprimarily focus on raw images, rarely encountered in real-world scenarios. To\naddress these challenges, we propose PLADA (Pay Less Attention to Deceptive\nArtifacts), a novel framework designed to tackle the lack of paired data and\nthe ineffective use of compressed images. PLADA consists of two core modules:\nBlock Effect Eraser (B2E), which uses a dual-stage attention mechanism to\nhandle block effects, and Open Data Aggregation (ODA), which processes both\npaired and unpaired data to improve detection. Extensive experiments across 26\ndatasets demonstrate that PLADA achieves a remarkable balance in deepfake\ndetection, outperforming SoTA methods in detecting deepfakes on OSNs, even with\nlimited paired data and compression. More importantly, this work introduces the\n``block effect\" as a critical factor in deepfake detection, providing a robust\nsolution for open-world scenarios. Our code is available at\nhttps://github.com/ManyiLee/PLADA.\n","authors":["Manyi Li","Renshuai Tao","Yufan Liu","Chuangchuang Tan","Haotong Qin","Bing Li","Yunchao Wei","Yao Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.20548v1.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2506.20544v1","updated":"2025-06-25T15:37:53Z","published":"2025-06-25T15:37:53Z","title":"When Life Gives You Samples: The Benefits of Scaling up Inference\n  Compute for Multilingual LLMs","summary":"  Recent advancements in large language models (LLMs) have shifted focus toward\nscaling inference-time compute, improving performance without retraining the\nmodel. A common approach is to sample multiple outputs in parallel, and select\none of these as the final output. However, work to date has focused on English\nand a handful of domains such as math and code. In contrast, we are most\ninterested in techniques that generalize across open-ended tasks, formally\nverifiable tasks, and across languages. In this work, we study how to robustly\nscale inference-time compute for open-ended generative tasks in a multilingual,\nmulti-task setting.\n  Our findings show that both sampling strategy based on temperature variation\nand selection strategy must be adapted to account for diverse domains and\nvaried language settings. We evaluate existing selection methods, revealing\nthat strategies effective in English often fail to generalize across languages.\nWe propose novel sampling and selection strategies specifically adapted for\nmultilingual and multi-task inference scenarios, and show they yield notable\ngains across languages and tasks. In particular, our combined sampling and\nselection methods lead to an average +6.8 jump in win-rates for our 8B models\non m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At\nlarger scale, Command-A (111B model) equipped with our methods, shows +9.0\nimprovement in win-rates on the same benchmark with just five samples against\nsingle-sample decoding, a substantial increase at minimal cost. Our results\nunderscore the need for language- and task-aware approaches to inference-time\ncompute, aiming to democratize performance improvements in underrepresented\nlanguages.\n","authors":["Ammar Khairi","Daniel D'souza","Ye Shen","Julia Kreutzer","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2506.20544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01633v2","updated":"2025-06-25T15:31:17Z","published":"2025-02-03T18:59:01Z","title":"Adversarial Reasoning at Jailbreaking Time","summary":"  As large language models (LLMs) are becoming more capable and widespread, the\nstudy of their failure cases is becoming increasingly important. Recent\nadvances in standardizing, measuring, and scaling test-time compute suggest new\nmethodologies for optimizing models to achieve high performance on hard tasks.\nIn this paper, we apply these advances to the task of model jailbreaking:\neliciting harmful responses from aligned LLMs. We develop an adversarial\nreasoning approach to automatic jailbreaking that leverages a loss signal to\nguide the test-time compute, achieving SOTA attack success rates against many\naligned LLMs, even those that aim to trade inference-time compute for\nadversarial robustness. Our approach introduces a new paradigm in understanding\nLLM vulnerabilities, laying the foundation for the development of more robust\nand trustworthy AI systems.\n","authors":["Mahdi Sabbaghi","Paul Kassianik","George Pappas","Yaron Singer","Amin Karbasi","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2502.01633v2.pdf","comment":"Accepted to the 42nd International Conference on Machine Learning\n  (ICML 2025)"},{"id":"http://arxiv.org/abs/2506.20535v1","updated":"2025-06-25T15:24:45Z","published":"2025-06-25T15:24:45Z","title":"WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon\n  Footprint of AI Workloads","summary":"  The rapid advancement of AI, particularly large language models (LLMs), has\nraised significant concerns about the energy use and carbon emissions\nassociated with model training and inference. However, existing tools for\nmeasuring and reporting such impacts are often fragmented, lacking systematic\nmetric integration and offering limited support for correlation analysis among\nthem. This paper presents WattsOnAI, a comprehensive software toolkit for the\nmeasurement, analysis, and visualization of energy use, power draw, hardware\nperformance, and carbon emissions across AI workloads. By seamlessly\nintegrating with existing AI frameworks, WattsOnAI offers standardized reports\nand exports fine-grained time-series data to support benchmarking and\nreproducibility in a lightweight manner. It further enables in-depth\ncorrelation analysis between hardware metrics and model performance and thus\nfacilitates bottleneck identification and performance enhancement. By\naddressing critical limitations in existing tools, WattsOnAI encourages the\nresearch community to weigh environmental impact alongside raw performance of\nAI workloads and advances the shift toward more sustainable \"Green AI\"\npractices. The code is available at https://github.com/SusCom-Lab/WattsOnAI.\n","authors":["Hongzhen Huang","Kunming Zhang","Hanlong Liao","Kui Wu","Guoming Tang"],"pdf_url":"https://arxiv.org/pdf/2506.20535v1.pdf","comment":"11 pages, 7 figures and 5 tables"},{"id":"http://arxiv.org/abs/2506.20531v1","updated":"2025-06-25T15:19:25Z","published":"2025-06-25T15:19:25Z","title":"Case-based Reasoning Augmented Large Language Model Framework for\n  Decision Making in Realistic Safety-Critical Driving Scenarios","summary":"  Driving in safety-critical scenarios requires quick, context-aware\ndecision-making grounded in both situational understanding and experiential\nreasoning. Large Language Models (LLMs), with their powerful general-purpose\nreasoning capabilities, offer a promising foundation for such decision-making.\nHowever, their direct application to autonomous driving remains limited due to\nchallenges in domain adaptation, contextual grounding, and the lack of\nexperiential knowledge needed to make reliable and interpretable decisions in\ndynamic, high-risk environments. To address this gap, this paper presents a\nCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for\nevasive maneuver decision-making in complex risk scenarios. Our approach\nintegrates semantic scene understanding from dashcam video inputs with the\nretrieval of relevant past driving cases, enabling LLMs to generate maneuver\nrecommendations that are both context-sensitive and human-aligned. Experiments\nacross multiple open-source LLMs show that our framework improves decision\naccuracy, justification quality, and alignment with human expert behavior.\nRisk-aware prompting strategies further enhance performance across diverse risk\ntypes, while similarity-based case retrieval consistently outperforms random\nsampling in guiding in-context learning. Case studies further demonstrate the\nframework's robustness in challenging real-world conditions, underscoring its\npotential as an adaptive and trustworthy decision-support tool for intelligent\ndriving systems.\n","authors":["Wenbin Gan","Minh-Son Dao","Koji Zettsu"],"pdf_url":"https://arxiv.org/pdf/2506.20531v1.pdf","comment":"12 pages, 10 figures, under-review conference"},{"id":"http://arxiv.org/abs/2411.08745v4","updated":"2025-06-25T15:16:54Z","published":"2024-11-13T16:26:19Z","title":"Separating Tongue from Thought: Activation Patching Reveals\n  Language-Agnostic Concept Representations in Transformers","summary":"  A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word-translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean\nrepresentation of a concept across different languages does not affect the\nmodels' ability to translate it, but instead improves it. Finally, we\ngeneralize to multi-token generation and demonstrate that the model can\ngenerate natural language description of those mean representations. Our\nresults provide evidence for the existence of language-agnostic concept\nrepresentations within the investigated models.\n","authors":["Clément Dumas","Chris Wendler","Veniamin Veselovsky","Giovanni Monea","Robert West"],"pdf_url":"https://arxiv.org/pdf/2411.08745v4.pdf","comment":"20 pages, 14 figures, previous version published under the title \"How\n  Do Llamas Process Multilingual Text? A Latent Exploration through Activation\n  Patching\" at the ICML 2024 mechanistic interpretability workshop at\n  https://openreview.net/forum?id=0ku2hIm4BS"},{"id":"http://arxiv.org/abs/2412.02863v2","updated":"2025-06-25T15:15:12Z","published":"2024-12-03T21:57:04Z","title":"Proximal Control of UAVs with Federated Learning for Human-Robot\n  Collaborative Domains","summary":"  The human-robot interaction (HRI) is a growing area of research. In HRI,\ncomplex command (action) classification is still an open problem that usually\nprevents the real applicability of such a technique. The literature presents\nsome works that use neural networks to detect these actions. However, occlusion\nis still a major issue in HRI, especially when using uncrewed aerial vehicles\n(UAVs), since, during the robot's movement, the human operator is often out of\nthe robot's field of view. Furthermore, in multi-robot scenarios, distributed\ntraining is also an open problem. In this sense, this work proposes an action\nrecognition and control approach based on Long Short-Term Memory (LSTM) Deep\nNeural Networks with two layers in association with three densely connected\nlayers and Federated Learning (FL) embedded in multiple drones. The FL enabled\nour approach to be trained in a distributed fashion, i.e., access to data\nwithout the need for cloud or other repositories, which facilitates the\nmulti-robot system's learning. Furthermore, our multi-robot approach results\nalso prevented occlusion situations, with experiments with real robots\nachieving an accuracy greater than 96%.\n","authors":["Lucas Nogueira Nobrega","Ewerton de Oliveira","Martin Saska","Tiago Nascimento"],"pdf_url":"https://arxiv.org/pdf/2412.02863v2.pdf","comment":"version 2"},{"id":"http://arxiv.org/abs/2506.20525v1","updated":"2025-06-25T15:10:43Z","published":"2025-06-25T15:10:43Z","title":"Industrial Energy Disaggregation with Digital Twin-generated Dataset and\n  Efficient Data Augmentation","summary":"  Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of\nhigh-quality datasets and the complex variability of industrial energy\nconsumption patterns. To address data scarcity and privacy issues, we introduce\nthe Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an\nopen-source dataset generated using Digital Twin simulations. SIDED includes\nthree types of industrial facilities across three different geographic\nlocations, capturing diverse appliance behaviors, weather conditions, and load\nprofiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)\nmethod, a computationally efficient technique that enhances NILM model\ngeneralization by intelligently scaling appliance power contributions based on\ntheir relative impact. We show in experiments that NILM models trained with\nAMDA-augmented data significantly improve the disaggregation of energy\nconsumption of complex industrial appliances like combined heat and power\nsystems. Specifically, in our out-of-sample scenarios, models trained with AMDA\nachieved a Normalized Disaggregation Error of 0.093, outperforming models\ntrained without data augmentation (0.451) and those trained with random data\naugmentation (0.290). Data distribution analyses confirm that AMDA effectively\naligns training and test data distributions, enhancing model generalization.\n","authors":["Christian Internò","Andrea Castellani","Sebastian Schmitt","Fabio Stella","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2506.20525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16014v3","updated":"2025-06-25T15:06:17Z","published":"2025-06-19T04:21:23Z","title":"VRAIL: Vectorized Reward-based Attribution for Interpretable Learning","summary":"  We propose VRAIL (Vectorized Reward-based Attribution for Interpretable\nLearning), a bi-level framework for value-based reinforcement learning (RL)\nthat learns interpretable weight representations from state features. VRAIL\nconsists of two stages: a deep learning (DL) stage that fits an estimated value\nfunction using state features, and an RL stage that uses this to shape learning\nvia potential-based reward transformations. The estimator is modeled in either\nlinear or quadratic form, allowing attribution of importance to individual\nfeatures and their interactions. Empirical results on the Taxi-v3 environment\ndemonstrate that VRAIL improves training stability and convergence compared to\nstandard DQN, without requiring environment modifications. Further analysis\nshows that VRAIL uncovers semantically meaningful subgoals, such as passenger\npossession, highlighting its ability to produce human-interpretable behavior.\nOur findings suggest that VRAIL serves as a general, model-agnostic framework\nfor reward shaping that enhances both learning and interpretability.\n","authors":["Jina Kim","Youjin Jang","Jeongjin Han"],"pdf_url":"https://arxiv.org/pdf/2506.16014v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20512v1","updated":"2025-06-25T14:58:13Z","published":"2025-06-25T14:58:13Z","title":"OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling","summary":"  Different base language model families, such as Llama and Qwen, exhibit\ndivergent behaviors during post-training with reinforcement learning (RL),\nespecially on reasoning-intensive tasks. What makes a base language model\nsuitable for reinforcement learning? Gaining deeper insight into this question\nis essential for developing RL-scalable foundation models of the next\ngeneration. In this work, we investigate how mid-training strategies shape RL\ndynamics, focusing on two representative model families: Qwen and Llama. Our\nstudy reveals that (1) high-quality mathematical corpora, such as\nMegaMath-Web-Pro, significantly improve both base model and RL performance,\nwhile existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further\nadding QA-style data, particularly long chain-of-thought (CoT) reasoning\nexamples, enhances RL outcomes, and instruction data further unlocks this\neffect; (3) while long-CoT improves reasoning depth, it can also induce\nverbosity of model responses and unstability of RL training, underscoring the\nimportance of data formatting; (4) scaling mid-training consistently leads to\nstronger downstream RL performance. Building on these insights, we introduce a\ntwo-stage mid-training strategy, Stable-then-Decay, in which base models are\nfirst trained on 200B tokens with a constant learning rate, followed by 20B\ntokens across three CoT-focused branches with learning rate decay. This yields\nOctoThinker, a family of models demonstrating strong RL compatibility and\nclosing the performance gap with more RL-friendly model families, i.e., Qwen.\nWe hope our work will help shape pre-training strategies for foundation models\nin the RL era. To support further research, we release our open-source models\nalong with a curated math reasoning-intensive corpus of over 70 billion tokens\n(i.e., MegaMath-Web-Pro-Max).\n","authors":["Zengzhi Wang","Fan Zhou","Xuefeng Li","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2506.20512v1.pdf","comment":"26 pages; The first three authors contribute to this work equally"},{"id":"http://arxiv.org/abs/2506.20504v1","updated":"2025-06-25T14:49:50Z","published":"2025-06-25T14:49:50Z","title":"Engineering Sentience","summary":"  We spell out a definition of sentience that may be useful for designing and\nbuilding it in machines. We propose that for sentience to be meaningful for AI,\nit must be fleshed out in functional, computational terms, in enough detail to\nallow for implementation. Yet, this notion of sentience must also reflect\nsomething essentially 'subjective', beyond just having the general capacity to\nencode perceptual content. For this specific functional notion of sentience to\noccur, we propose that certain sensory signals need to be both assertoric\n(persistent) and qualitative. To illustrate the definition in more concrete\nterms, we sketch out some ways for potential implementation, given current\ntechnology. Understanding what it takes for artificial agents to be\nfunctionally sentient can also help us avoid creating them inadvertently, or at\nleast, realize that we have created them in a timely manner.\n","authors":["Konstantin Demin","Taylor Webb","Eric Elmoznino","Hakwan Lau"],"pdf_url":"https://arxiv.org/pdf/2506.20504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08727v3","updated":"2025-06-25T14:45:56Z","published":"2025-03-11T01:07:57Z","title":"Training Plug-n-Play Knowledge Modules with Deep Context Distillation","summary":"  Dynamically integrating new or rapidly evolving information after (Large)\nLanguage Model pre-training remains challenging, particularly in low-data\nscenarios or when dealing with private and specialized documents. In-context\nlearning and retrieval-augmented generation (RAG) face limitations, including\ntheir high inference costs and their inability to capture global document\ninformation. In this paper, we propose a way of modularizing knowledge by\ntraining document-level Knowledge Modules (KMs). KMs are lightweight components\nimplemented as parameter-efficient LoRA modules, which are trained to store\ninformation about new documents and can be easily plugged into models on\ndemand. We show that next-token prediction performs poorly as the training\nobjective for KMs. We instead propose Deep Context Distillation: we learn KMs\nparameters such as to simulate hidden states and logits of a teacher that takes\nthe document in context. Our method outperforms standard next-token prediction\nand pre-instruction training techniques, across two datasets. Finally, we\nhighlight synergies between KMs and RAG.\n","authors":["Lucas Caccia","Alan Ansell","Edoardo Ponti","Ivan Vulić","Alessandro Sordoni"],"pdf_url":"https://arxiv.org/pdf/2503.08727v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.04030v2","updated":"2025-06-25T14:44:30Z","published":"2025-02-06T12:47:25Z","title":"Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated\n  Model Merging","summary":"  Reasoning capabilities represent a critical frontier for large language\nmodels (LLMs), but developing them requires extensive proprietary datasets and\ncomputational resources. One way to efficiently supplement capabilities with is\nby model merging, which offers a promising alternative by combining multiple\nmodels without retraining. However, current merging approaches rely on\nmanually-designed strategies for merging hyperparameters, limiting the\nexploration of potential model combinations and requiring significant human\neffort. We propose an Automated Model Merging Framework that enables\nfine-grained exploration of merging strategies while reducing costs through\nmulti-fidelity approximations. We support both single and multi-objective\noptimization and introduce two novel search spaces: layerwise fusion (LFS) and\ndepth-wise integration (DIS). Evaluating across a number of benchmarks, we find\nthat the search autonomously finds 1) Merges that further boost\nsingle-objective performance, even on tasks the model has already been\nfinetuned on, and 2) Merges that optimize multi-objective frontiers across\ntasks. Effective merges are found with limited compute, e.g. within less than\n500 search steps.\n","authors":["Guinan Su","Jonas Geiping"],"pdf_url":"https://arxiv.org/pdf/2502.04030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20495v1","updated":"2025-06-25T14:41:13Z","published":"2025-06-25T14:41:13Z","title":"ReCode: Updating Code API Knowledge with Reinforcement Learning","summary":"  Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.\n","authors":["Haoze Wu","Yunzhi Yao","Wenhao Yu","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20495v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.18165v2","updated":"2025-06-25T14:39:40Z","published":"2025-06-22T20:41:31Z","title":"Non-equilibrium Annealed Adjoint Sampler","summary":"  Recently, there has been significant progress in learning-based diffusion\nsamplers, which aim to sample from a given unnormalized density. These methods\ntypically follow one of two paradigms: (i) formulating sampling as an unbiased\nstochastic optimal control (SOC) problem using a canonical reference process,\nor (ii) refining annealed path measures through importance-weighted sampling.\nAlthough annealing approaches have advantages in guiding samples toward\nhigh-density regions, reliance on importance sampling leads to high variance\nand limited scalability in practice. In this paper, we introduce the\n\\textbf{Non-equilibrium Annealed Adjoint Sampler (NAAS)}, a novel SOC-based\ndiffusion sampler that leverages annealed reference dynamics without resorting\nto importance sampling. NAAS employs a lean adjoint system inspired by adjoint\nmatching, enabling efficient and scalable training. We demonstrate the\neffectiveness of our approach across a range of tasks, including sampling from\nclassical energy landscapes and molecular Boltzmann distribution.\n","authors":["Jaemoo Choi","Yongxin Chen","Molei Tao","Guan-Horng Liu"],"pdf_url":"https://arxiv.org/pdf/2506.18165v2.pdf","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2506.15549v2","updated":"2025-06-25T14:37:57Z","published":"2025-06-18T15:21:34Z","title":"CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse\n  Myocardial Scar Synthesis and Segmentation","summary":"  Deep learning-based myocardial scar segmentation from late gadolinium\nenhancement (LGE) cardiac MRI has shown great potential for accurate and timely\ndiagnosis and treatment planning for structural cardiac diseases. However, the\nlimited availability and variability of LGE images with high-quality scar\nlabels restrict the development of robust segmentation models. To address this,\nwe introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE\n\\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial\nScar Synthesis and Segmentation framework, a framework for anatomically\ngrounded scar generation and segmentation. At its core is the SMILE module\n(Scar Mask generation guided by cLinical knowledgE), which conditions a\ndiffusion-based generator on the clinically adopted AHA 17-segment model to\nsynthesize images with anatomically consistent and spatially diverse scar\npatterns. In addition, CLAIM employs a joint training strategy in which the\nscar segmentation network is optimized alongside the generator, aiming to\nenhance both the realism of synthesized scars and the accuracy of the scar\nsegmentation performance. Experimental results show that CLAIM produces\nanatomically coherent scar patterns and achieves higher Dice similarity with\nreal scar distributions compared to baseline models. Our approach enables\ncontrollable and realistic myocardial scar synthesis and has demonstrated\nutility for downstream medical imaging task. Code is available at\nhttps://github.com/farheenjabeen/CLAIM-Scar-Synthesis.\n","authors":["Farheen Ramzan","Yusuf Kiberu","Nikesh Jathanna","Shahnaz Jamil-Copley","Richard H. Clayton","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2506.15549v2.pdf","comment":"14 Pages"},{"id":"http://arxiv.org/abs/2506.20486v1","updated":"2025-06-25T14:33:35Z","published":"2025-06-25T14:33:35Z","title":"Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth\n  Modelling and Self-Organization","summary":"  Neural Cellular Automata (NCAs) are a promising new approach to model\nself-organizing processes, with potential applications in life science.\nHowever, their deterministic nature limits their ability to capture the\nstochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework\nincorporating the idea of mixture models into the NCA paradigm. By combining\nprobabilistic rule assignments with intrinsic noise, MNCAs can model diverse\nlocal behaviors and reproduce the stochastic dynamics observed in biological\nprocesses.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic\nsimulations of tissue growth and differentiation, (2) image morphogenesis\nrobustness, and (3) microscopy image segmentation. Results show that MNCAs\nachieve superior robustness to perturbations, better recapitulate real\nbiological growth patterns, and provide interpretable rule segmentation. These\nfindings position MNCAs as a promising tool for modeling stochastic dynamical\nsystems and studying self-growth processes.\n","authors":["Salvatore Milite","Giulio Caravagna","Andrea Sottoriva"],"pdf_url":"https://arxiv.org/pdf/2506.20486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20481v1","updated":"2025-06-25T14:25:11Z","published":"2025-06-25T14:25:11Z","title":"Counterfactual Influence as a Distributional Quantity","summary":"  Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.\n","authors":["Matthieu Meeus","Igor Shilov","Georgios Kaissis","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2506.20481v1.pdf","comment":"Workshop on The Impact of Memorization on Trustworthy Foundation\n  Models (MemFM) @ ICML 2025"},{"id":"http://arxiv.org/abs/2505.07089v3","updated":"2025-06-25T14:14:56Z","published":"2025-05-11T18:38:00Z","title":"RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing\n  Framework Based on Large Language Models","summary":"  Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\ninherent knowledge of LLMs. However, existing LLM-based AutoPT frameworks often\nunderperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sightedness in\nthe planning process, and hallucinations during command generation. Moreover,\nthe trial-and-error nature of the PT process is constrained by existing\nframeworks lacking mechanisms to learn from previous failures, restricting\nadaptive improvement of PT strategies. To address these limitations, we propose\na knowledge-informed, self-reflective PT framework powered by LLMs, called\nRefPentester. This AutoPT framework is designed to assist human operators in\nidentifying the current stage of the PT process, selecting appropriate tactics\nand techniques for each stage, choosing suggested actions, providing\nstep-by-step operational guidance, and reflecting on and learning from previous\nfailed operations. We also modeled the PT process as a seven-state Stage\nMachine to integrate the proposed framework effectively. The evaluation shows\nthat RefPentester can successfully reveal credentials on Hack The Box's Sau\nmachine, outperforming the baseline GPT-4o model by 16.7%. Across PT stages,\nRefPentester also demonstrates superior success rates on PT stage transitions.\n","authors":["Hanzheng Dai","Yuanliang Li","Jun Yan","Zhibo Zhang"],"pdf_url":"https://arxiv.org/pdf/2505.07089v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10521v3","updated":"2025-06-25T14:13:38Z","published":"2025-06-12T09:29:16Z","title":"Scientists' First Exam: Probing Cognitive Abilities of MLLM via\n  Perception, Understanding, and Reasoning","summary":"  Scientific discoveries increasingly rely on complex multimodal reasoning\nbased on information-intensive scientific data and domain-specific expertise.\nEmpowered by expert-level scientific benchmarks, scientific Multimodal Large\nLanguage Models (MLLMs) hold the potential to significantly enhance this\ndiscovery process in realistic workflows. However, current scientific\nbenchmarks mostly focus on evaluating the knowledge understanding capabilities\nof MLLMs, leading to an inadequate assessment of their perception and reasoning\nabilities. To address this gap, we present the Scientists' First Exam (SFE)\nbenchmark, designed to evaluate the scientific cognitive capacities of MLLMs\nthrough three interconnected levels: scientific signal perception, scientific\nattribute understanding, scientific comparative reasoning. Specifically, SFE\ncomprises 830 expert-verified VQA pairs across three question types, spanning\n66 multimodal tasks across five high-value disciplines. Extensive experiments\nreveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%\nand 26.52% on SFE, highlighting significant room for MLLMs to improve in\nscientific realms. We hope the insights obtained in SFE will facilitate further\ndevelopments in AI-enhanced scientific discoveries.\n","authors":["Yuhao Zhou","Yiheng Wang","Xuming He","Ruoyao Xiao","Zhiwei Li","Qiantai Feng","Zijie Guo","Yuejin Yang","Hao Wu","Wenxuan Huang","Jiaqi Wei","Dan Si","Xiuqi Yao","Jia Bu","Haiwen Huang","Tianfan Fu","Shixiang Tang","Ben Fei","Dongzhan Zhou","Fenghua Ling","Yan Lu","Siqi Sun","Chenhui Li","Guanjie Zheng","Jiancheng Lv","Wenlong Zhang","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2506.10521v3.pdf","comment":"82 pages"},{"id":"http://arxiv.org/abs/2407.02508v3","updated":"2025-06-25T14:06:21Z","published":"2024-06-18T14:27:14Z","title":"Physics-informed Imitative Reinforcement Learning for Real-world Driving","summary":"  Recent advances in imitative reinforcement learning (IRL) have considerably\nenhanced the ability of autonomous agents to assimilate expert demonstrations,\nleading to rapid skill acquisition in a range of demanding tasks. However, such\nlearning-based agents face significant challenges when transferring knowledge\nto highly dynamic closed-loop environments. Their performance is significantly\nimpacted by the conflicting optimization objectives of imitation learning (IL)\nand reinforcement learning (RL), sample inefficiency, and the complexity of\nuncovering the hidden world model and physics. To address this challenge, we\npropose a physics-informed IRL that is entirely data-driven. It leverages both\nexpert demonstration data and exploratory data with a joint optimization\nobjective, allowing the underlying physical principles of vehicle dynamics to\nemerge naturally from the training process. The performance is evaluated\nthrough empirical experiments and results exceed popular IL, RL and IRL\nalgorithms in closed-loop settings on Waymax benchmark. Our approach exhibits\n37.8% reduction in collision rate and 22.2% reduction in off-road rate compared\nto the baseline method.\n","authors":["Hang Zhou","Yihao Qin","Dan Xu","Yiding Ji"],"pdf_url":"https://arxiv.org/pdf/2407.02508v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20767v4","updated":"2025-06-25T14:02:19Z","published":"2025-05-27T06:16:27Z","title":"CogniBench: A Legal-inspired Framework and Dataset for Assessing\n  Cognitive Faithfulness of Large Language Models","summary":"  Faithfulness hallucinations are claims generated by a Large Language Model\n(LLM) not supported by contexts provided to the LLM. Lacking assessment\nstandards, existing benchmarks focus on \"factual statements\" that rephrase\nsource materials while overlooking \"cognitive statements\" that involve making\ninferences from the given context. Consequently, evaluating and detecting the\nhallucination of cognitive statements remains challenging. Inspired by how\nevidence is assessed in the legal domain, we design a rigorous framework to\nassess different levels of faithfulness of cognitive statements and introduce\nthe CogniBench dataset where we reveal insightful statistics. To keep pace with\nrapidly evolving LLMs, we further develop an automatic annotation pipeline that\nscales easily across different models. This results in a large-scale\nCogniBench-L dataset, which facilitates training accurate detectors for both\nfactual and cognitive hallucinations. We release our model and datasets at:\nhttps://github.com/FUTUREEEEEE/CogniBench\n","authors":["Xiaqiang Tang","Jian Li","Keyu Hu","Du Nan","Xiaolong Li","Xi Zhang","Weigao Sun","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2505.20767v4.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2506.20451v1","updated":"2025-06-25T13:57:54Z","published":"2025-06-25T13:57:54Z","title":"Automatic Demonstration Selection for LLM-based Tabular Data\n  Classification","summary":"  A fundamental question in applying In-Context Learning (ICL) for tabular data\nclassification is how to determine the ideal number of demonstrations in the\nprompt. This work addresses this challenge by presenting an algorithm to\nautomatically select a reasonable number of required demonstrations. Our method\ndistinguishes itself by integrating not only the tabular data's distribution\nbut also the user's selected prompt template and the specific Large Language\nModel (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed\nalgorithm defines a novel metric to quantify the similarities between different\ndemonstrations. We then construct a similarity graph and analyze the\neigenvalues of its Laplacian to derive the minimum number of demonstrations\ncapable of representing the data within the LLM's intrinsic representation\nspace. We validate the efficacy of our approach through experiments comparing\nits performance against conventional random selection algorithms on diverse\ndatasets and LLMs.\n","authors":["Shuchu Han","Wolfgang Bruckner"],"pdf_url":"https://arxiv.org/pdf/2506.20451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20430v1","updated":"2025-06-25T13:42:26Z","published":"2025-06-25T13:42:26Z","title":"An Agentic System for Rare Disease Diagnosis with Traceable Reasoning","summary":"  Rare diseases collectively affect over 300 million individuals worldwide, yet\ntimely and accurate diagnosis remains a pervasive challenge. This is largely\ndue to their clinical heterogeneity, low individual prevalence, and the limited\nfamiliarity most clinicians have with rare conditions. Here, we introduce\nDeepRare, the first rare disease diagnosis agentic system powered by a large\nlanguage model (LLM), capable of processing heterogeneous clinical inputs. The\nsystem generates ranked diagnostic hypotheses for rare diseases, each\naccompanied by a transparent chain of reasoning that links intermediate\nanalytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term\nmemory module; specialized agent servers responsible for domain-specific\nanalytical tasks integrating over 40 specialized tools and web-scale,\nup-to-date medical knowledge sources, ensuring access to the most current\nclinical information. This modular and scalable design enables complex\ndiagnostic reasoning while maintaining traceability and adaptability. We\nevaluate DeepRare on eight datasets. The system demonstrates exceptional\ndiagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013\ndiseases. In HPO-based evaluations, DeepRare significantly outperforms other 15\nmethods, like traditional bioinformatics diagnostic tools, LLMs, and other\nagentic systems, achieving an average Recall@1 score of 57.18% and surpassing\nthe second-best method (Reasoning LLM) by a substantial margin of 23.79\npercentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at\nRecall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of\nreasoning chains by clinical experts achieves 95.40% agreements. Furthermore,\nthe DeepRare system has been implemented as a user-friendly web application\nhttp://raredx.cn/doctor.\n","authors":["Weike Zhao","Chaoyi Wu","Yanjie Fan","Xiaoman Zhang","Pengcheng Qiu","Yuze Sun","Xiao Zhou","Yanfeng Wang","Ya Zhang","Yongguo Yu","Kun Sun","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2506.20430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20417v1","updated":"2025-06-25T13:31:46Z","published":"2025-06-25T13:31:46Z","title":"Off-Policy Evaluation and Learning for the Future under Non-Stationarity","summary":"  We study the novel problem of future off-policy evaluation (F-OPE) and\nlearning (F-OPL) for estimating and optimizing the future value of policies in\nnon-stationary environments, where distributions vary over time. In e-commerce\nrecommendations, for instance, our goal is often to estimate and optimize the\npolicy value for the upcoming month using data collected by an old policy in\nthe previous month. A critical challenge is that data related to the future\nenvironment is not observed in the historical data. Existing methods assume\nstationarity or depend on restrictive reward-modeling assumptions, leading to\nsignificant bias. To address these limitations, we propose a novel estimator\nnamed \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture\n\\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating\npolicy values at any future time point. The key feature of OPFV is its ability\nto leverage the useful structure within time-series data. While future data\nmight not be present in the historical log, we can leverage, for example,\nseasonal, weekly, or holiday effects that are consistent in both the historical\nand future data. Our estimator is the first to exploit these time-related\nstructures via a new type of importance weighting, enabling effective F-OPE.\nTheoretical analysis identifies the conditions under which OPFV becomes\nlow-bias. In addition, we extend our estimator to develop a new policy-gradient\nmethod to proactively learn a good future policy using only historical data.\nEmpirical results show that our methods substantially outperform existing\nmethods in estimating and optimizing the future policy value under\nnon-stationarity for various experimental setups.\n","authors":["Tatsuhiro Shimizu","Kazuki Kawamura","Takanori Muroi","Yusuke Narita","Kei Tateno","Takuma Udagawa","Yuta Saito"],"pdf_url":"https://arxiv.org/pdf/2506.20417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20415v1","updated":"2025-06-25T13:31:13Z","published":"2025-06-25T13:31:13Z","title":"SV-LLM: An Agentic Approach for SoC Security Verification using Large\n  Language Models","summary":"  Ensuring the security of complex system-on-chips (SoCs) designs is a critical\nimperative, yet traditional verification techniques struggle to keep pace due\nto significant challenges in automation, scalability, comprehensiveness, and\nadaptability. The advent of large language models (LLMs), with their remarkable\ncapabilities in natural language understanding, code generation, and advanced\nreasoning, presents a new paradigm for tackling these issues. Moving beyond\nmonolithic models, an agentic approach allows for the creation of multi-agent\nsystems where specialized LLMs collaborate to solve complex problems more\neffectively. Recognizing this opportunity, we introduce SV-LLM, a novel\nmulti-agent assistant system designed to automate and enhance SoC security\nverification. By integrating specialized agents for tasks like verification\nquestion answering, security asset identification, threat modeling, test plan\nand property generation, vulnerability detection, and simulation-based bug\nvalidation, SV-LLM streamlines the workflow. To optimize their performance in\nthese diverse tasks, agents leverage different learning paradigms, such as\nin-context learning, fine-tuning, and retrieval-augmented generation (RAG). The\nsystem aims to reduce manual intervention, improve accuracy, and accelerate\nsecurity analysis, supporting proactive identification and mitigation of risks\nearly in the design cycle. We demonstrate its potential to transform hardware\nsecurity practices through illustrative case studies and experiments that\nshowcase its applicability and efficacy.\n","authors":["Dipayan Saha","Shams Tarek","Hasan Al Shaikh","Khan Thamid Hasan","Pavan Sai Nalluri","Md. Ajoad Hasan","Nashmin Alam","Jingbo Zhou","Sujan Kumar Saha","Mark Tehranipoor","Farimah Farahmandi"],"pdf_url":"https://arxiv.org/pdf/2506.20415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17219v2","updated":"2025-06-25T13:27:49Z","published":"2025-06-20T17:59:52Z","title":"No Free Lunch: Rethinking Internal Feedback for LLM Reasoning","summary":"  Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.\n","authors":["Yanzhi Zhang","Zhaoxi Zhang","Haoxiang Guan","Yilin Cheng","Yitong Duan","Chen Wang","Yue Wang","Shuxin Zheng","Jiyan He"],"pdf_url":"https://arxiv.org/pdf/2506.17219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20413v1","updated":"2025-06-25T13:27:36Z","published":"2025-06-25T13:27:36Z","title":"Client Clustering Meets Knowledge Sharing: Enhancing Privacy and\n  Robustness in Personalized Peer-to-Peer Learning","summary":"  The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.\n","authors":["Mohammad Mahdi Maheri","Denys Herasymuk","Hamed Haddadi"],"pdf_url":"https://arxiv.org/pdf/2506.20413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20404v1","updated":"2025-06-25T13:19:42Z","published":"2025-06-25T13:19:42Z","title":"GymPN: A Library for Decision-Making in Process Management Systems","summary":"  Process management systems support key decisions about the way work is\nallocated in organizations. This includes decisions on which task to perform\nnext, when to execute the task, and who to assign the task to. Suitable\nsoftware tools are required to support these decisions in a way that is optimal\nfor the organization. This paper presents a software library, called GymPN,\nthat supports optimal decision-making in business processes using Deep\nReinforcement Learning. GymPN builds on previous work that supports task\nassignment in business processes, introducing two key novelties: support for\npartial process observability and the ability to model multiple decisions in a\nbusiness process. These novel elements address fundamental limitations of\nprevious work and thus enable the representation of more realistic process\ndecisions. We evaluate the library on eight typical business process\ndecision-making problem patterns, showing that GymPN allows for easy modeling\nof the desired problems, as well as learning optimal decision policies.\n","authors":["Riccardo Lo Bianco","Willem van Jaarsveld","Remco Dijkman"],"pdf_url":"https://arxiv.org/pdf/2506.20404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20384v1","updated":"2025-06-25T12:50:28Z","published":"2025-06-25T12:50:28Z","title":"Paladin-mini: A Compact and Efficient Grounding Model Excelling in\n  Real-World Scenarios","summary":"  This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.\n","authors":["Dror Ivry","Oran Nahum"],"pdf_url":"https://arxiv.org/pdf/2506.20384v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2502.06485v3","updated":"2025-06-25T12:45:51Z","published":"2025-02-10T14:04:23Z","title":"WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry","summary":"  Crystalline materials often exhibit a high level of symmetry. However, most\ngenerative models do not account for symmetry, but rather model each atom\nwithout any constraints on its position or element. We propose a generative\nmodel, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based\ndescriptions of crystals. This is enabled by considering a crystal structure\nrepresentation that encodes all symmetry, and we design a novel neural network\narchitecture which enables using this representation inside a discrete\ngenerative model framework. In addition to respecting symmetry by construction,\nthe discrete nature of our model enables fast generation. We additionally\npresent a new metric, Fr\\'echet Wrenformer Distance, which captures the\nsymmetry aspects of the materials generated, and we benchmark WyckoffDiff\nagainst recently proposed generative models for crystal generation. As a\nproof-of-concept study, we use WyckoffDiff to find new materials below the\nconvex hull of thermodynamical stability.\n","authors":["Filip Ekström Kelvinius","Oskar B. Andersson","Abhijith S. Parackal","Dong Qian","Rickard Armiento","Fredrik Lindsten"],"pdf_url":"https://arxiv.org/pdf/2502.06485v3.pdf","comment":"Accepted to ICML 2025, to appear in PMLR 267. Code is available\n  online at https://github.com/httk/wyckoffdiff"},{"id":"http://arxiv.org/abs/2502.19119v2","updated":"2025-06-25T12:45:28Z","published":"2025-02-26T13:13:24Z","title":"Chemical knowledge-informed framework for privacy-aware retrosynthesis\n  learning","summary":"  Chemical reaction data is a pivotal asset, driving advances in competitive\nfields such as pharmaceuticals, materials science, and industrial chemistry.\nIts proprietary nature renders it sensitive, as it often includes confidential\ninsights and competitive advantages organizations strive to protect. However,\nin contrast to this need for confidentiality, the current standard training\nparadigm for machine learning-based retrosynthesis gathers reaction data from\nmultiple sources into one single edge to train prediction models. This paradigm\nposes considerable privacy risks as it necessitates broad data availability\nacross organizational boundaries and frequent data transmission between\nentities, potentially exposing proprietary information to unauthorized access\nor interception during storage and transfer. In the present study, we introduce\nthe chemical knowledge-informed framework (CKIF), a privacy-preserving approach\nfor learning retrosynthesis models. CKIF enables distributed training across\nmultiple chemical organizations without compromising the confidentiality of\nproprietary reaction data. Instead of gathering raw reaction data, CKIF learns\nretrosynthesis models through iterative, chemical knowledge-informed\naggregation of model parameters. In particular, the chemical properties of\npredicted reactants are leveraged to quantitatively assess the observable\nbehaviors of individual models, which in turn determines the adaptive weights\nused for model aggregation. On a variety of reaction datasets, CKIF outperforms\nseveral strong baselines by a clear margin.\n","authors":["Guikun Chen","Xu Zhang","Xiaolin Hu","Yong Liu","Yi Yang","Wenguan Wang"],"pdf_url":"https://arxiv.org/pdf/2502.19119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06406v2","updated":"2025-06-25T12:36:55Z","published":"2025-06-06T12:47:29Z","title":"SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal\n  Large Language Models Preserving Language Capabilities","summary":"  Mixture of Experts (MoE) architectures have become a key approach for scaling\nlarge language models, with growing interest in extending them to multimodal\ntasks. Existing methods to build multimodal MoE models either incur high\ntraining costs or suffer from degraded language capabilities when adapting\npretrained models. To address this, we propose Soft ModalityAware Routing\n(SMAR), a novel regularization technique that uses Kullback Leibler divergence\nto control routing probability distributions across modalities, encouraging\nexpert specialization without modifying model architecture or heavily relying\non textual data. Experiments on visual instruction tuning show that SMAR\npreserves language ability at 86.6% retention with only 2.5% pure text,\noutperforming baselines while maintaining strong multimodal performance. Our\napproach offers a practical and efficient solution to balance modality\ndifferentiation and language capabilities in multimodal MoE models.\n","authors":["Guoyang Xia","Yifeng Ding","Fengfa Li","Lei Ren","Wei Chen","Fangxiang Feng","Xiaojie Wang"],"pdf_url":"https://arxiv.org/pdf/2506.06406v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20373v1","updated":"2025-06-25T12:36:49Z","published":"2025-06-25T12:36:49Z","title":"CARMA: Context-Aware Situational Grounding of Human-Robot Group\n  Interactions by Combining Vision-Language Models with Object and Action\n  Recognition","summary":"  We introduce CARMA, a system for situational grounding in human-robot group\ninteractions. Effective collaboration in such group settings requires\nsituational awareness based on a consistent representation of present persons\nand objects coupled with an episodic abstraction of events regarding actors and\nmanipulated objects. This calls for a clear and consistent assignment of\ninstances, ensuring that robots correctly recognize and track actors, objects,\nand their interactions over time. To achieve this, CARMA uniquely identifies\nphysical instances of such entities in the real world and organizes them into\ngrounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple\nhumans and a robot interact: collaborative pouring, handovers, and sorting.\nThese scenarios allow the assessment of the system's capabilities as to role\ndistinction, multi-actor awareness, and consistent instance identification. Our\nexperiments demonstrate that the system can reliably generate accurate\nactor-action-object triplets, providing a structured and robust foundation for\napplications requiring spatiotemporal reasoning and situated decision-making in\ncollaborative settings.\n","authors":["Joerg Deigmoeller","Stephan Hasler","Nakul Agarwal","Daniel Tanneberg","Anna Belardinelli","Reza Ghoddoosian","Chao Wang","Felix Ocker","Fan Zhang","Behzad Dariush","Michael Gienger"],"pdf_url":"https://arxiv.org/pdf/2506.20373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06665v5","updated":"2025-06-25T12:31:31Z","published":"2022-11-12T13:52:06Z","title":"A Survey on Explainable Reinforcement Learning: Concepts, Algorithms,\n  Challenges","summary":"  Reinforcement Learning (RL) is a popular machine learning paradigm where\nintelligent agents interact with the environment to fulfill a long-term goal.\nDriven by the resurgence of deep learning, Deep RL (DRL) has witnessed great\nsuccess over a wide spectrum of complex control tasks. Despite the encouraging\nresults achieved, the deep neural network-based backbone is widely deemed as a\nblack box that impedes practitioners to trust and employ trained agents in\nrealistic scenarios where high security and reliability are essential. To\nalleviate this issue, a large volume of literature devoted to shedding light on\nthe inner workings of the intelligent agents has been proposed, by constructing\nintrinsic interpretability or post-hoc explainability. In this survey, we\nprovide a comprehensive review of existing works on eXplainable RL (XRL) and\nintroduce a new taxonomy where prior works are clearly categorized into\nmodel-explaining, reward-explaining, state-explaining, and task-explaining\nmethods. We also review and highlight RL methods that conversely leverage human\nknowledge to promote learning efficiency and performance of agents while this\nkind of method is often ignored in XRL field. Some challenges and opportunities\nin XRL are discussed. This survey intends to provide a high-level summarization\nof XRL and to motivate future research on more effective XRL solutions.\nCorresponding open source codes are collected and categorized at\nhttps://github.com/Plankson/awesome-explainable-reinforcement-learning.\n","authors":["Yunpeng Qing","Shunyu Liu","Jie Song","Huiqiong Wang","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2211.06665v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20362v1","updated":"2025-06-25T12:23:23Z","published":"2025-06-25T12:23:23Z","title":"Self-Supervised Graph Learning via Spectral Bootstrapping and\n  Laplacian-Based Augmentations","summary":"  We present LaplaceGNN, a novel self-supervised graph learning framework that\nbypasses the need for negative sampling by leveraging spectral bootstrapping\ntechniques. Our method integrates Laplacian-based signals into the learning\nprocess, allowing the model to effectively capture rich structural\nrepresentations without relying on contrastive objectives or handcrafted\naugmentations. By focusing on positive alignment, LaplaceGNN achieves linear\nscaling while offering a simpler, more efficient, self-supervised alternative\nfor graph neural networks, applicable across diverse domains. Our contributions\nare twofold: we precompute spectral augmentations through max-min\ncentrality-guided optimization, enabling rich structural supervision without\nrelying on handcrafted augmentations, then we integrate an adversarial\nbootstrapped training scheme that further strengthens feature learning and\nrobustness. Our extensive experiments on different benchmark datasets show that\nLaplaceGNN achieves superior performance compared to state-of-the-art\nself-supervised graph methods, offering a promising direction for efficiently\nlearning expressive graph representations.\n","authors":["Lorenzo Bini","Stephane Marchand-Maillet"],"pdf_url":"https://arxiv.org/pdf/2506.20362v1.pdf","comment":"LaplaceGNN is a novel graph learning framework that employs a\n  bootstrapped teacher-student architecture. Its precomputed spectral\n  augmentations and adversarial training enable robust performance,\n  outperforming SOTA methods while scaling linearly"},{"id":"http://arxiv.org/abs/2506.20357v1","updated":"2025-06-25T12:18:34Z","published":"2025-06-25T12:18:34Z","title":"Tabular Feature Discovery With Reasoning Type Exploration","summary":"  Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.\n","authors":["Sungwon Han","Sungkyu Park","Seungeon Lee"],"pdf_url":"https://arxiv.org/pdf/2506.20357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20354v1","updated":"2025-06-25T12:07:10Z","published":"2025-06-25T12:07:10Z","title":"A foundation model with multi-variate parallel attention to generate\n  neuronal activity","summary":"  Learning from multi-variate time-series with heterogeneous channel\nconfigurations remains a fundamental challenge for deep neural networks (DNNs),\nparticularly in clinical domains such as intracranial electroencephalography\n(iEEG), where channel setups vary widely across subjects. In this work, we\nintroduce multi-variate parallel attention (MVPA), a novel self-attention\nmechanism that disentangles content, temporal, and spatial attention, enabling\nflexible, generalizable, and efficient modeling of time-series data with\nvarying channel counts and configurations. We use MVPA to build MVPFormer, a\ngenerative foundation model for human electrophysiology, trained to predict the\nevolution of iEEG signals across diverse subjects. To support this and future\neffort by the community, we release the SWEC iEEG dataset, the largest publicly\navailable iEEG dataset to date, comprising nearly 10,000 hours of recordings\nfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong\ngeneralization across subjects, demonstrating expert-level performance in\nseizure detection and outperforming state-of-the-art Transformer baselines on\nour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard\ntime-series forecasting and classification tasks, where it matches or exceeds\nexisting attention-based models. Together, our contributions establish MVPA as\na general-purpose attention mechanism for heterogeneous time-series and\nMVPFormer as the first open-source, open-weights, and open-data iEEG foundation\nmodel with state-of-the-art clinical performance. The code is available at\nhttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\ndataset is available at\nhttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.\n","authors":["Francesco Carzaniga","Michael Hersche","Abu Sebastian","Kaspar Schindler","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2506.20354v1.pdf","comment":"The code is available at\n  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\n  dataset is available at\n  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg"},{"id":"http://arxiv.org/abs/2506.20353v1","updated":"2025-06-25T12:04:53Z","published":"2025-06-25T12:04:53Z","title":"DipSVD: Dual-importance Protected SVD for Efficient LLM Compression","summary":"  The ever-increasing computational demands and deployment costs of large\nlanguage models (LLMs) have spurred numerous compressing methods. Compared to\nquantization and unstructured pruning, SVD compression offers superior hardware\ncompatibility and theoretical guarantees. However, existing SVD-based methods\nfocus on the overall discrepancy between the original and compressed matrices\nwhile overlooking the protection of critical components within the matrix,\nwhich leads to inferior performance in the compressed models. This paper\nproposes a dual-level importance protection mechanism to enhance SVD-based\ncompression methods: (1) local importance protection: preserving the most\ncritical singular vectors within each weight matrix through channel-weighted\ndata whitening; and (2) global importance protection: enabling less important\nlayers to bear a greater portion of the compression burden through either a\nheuristic or optimization-based approach, thereby minimizing the impact of\ncompression on critical layers. Extensive experiments demonstrate that DipSVD\noutperforms existing SVD-based compression approaches across multiple\nbenchmarks, achieving superior model performance especially at high model\ncompression ratios.\n","authors":["Xuan Ding","Rui Sun","Yunjian Zhang","Xiu Yan","Yueqi Zhou","Kaihao Huang","Suzhong Fu","Chuanlong Xie","Yao Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.20353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20342v1","updated":"2025-06-25T11:50:23Z","published":"2025-06-25T11:50:23Z","title":"Feature Hallucination for Self-supervised Action Recognition","summary":"  Understanding human actions in videos requires more than raw pixel analysis;\nit relies on high-level semantic reasoning and effective integration of\nmultimodal features. We propose a deep translational action recognition\nframework that enhances recognition accuracy by jointly predicting action\nconcepts and auxiliary features from RGB video frames. At test time,\nhallucination streams infer missing cues, enriching feature representations\nwithout increasing computational overhead. To focus on action-relevant regions\nbeyond raw pixels, we introduce two novel domain-specific descriptors. Object\nDetection Features (ODF) aggregate outputs from multiple object detectors to\ncapture contextual cues, while Saliency Detection Features (SDF) highlight\nspatial and intensity patterns crucial for action recognition. Our framework\nseamlessly integrates these descriptors with auxiliary modalities such as\noptical flow, Improved Dense Trajectories, skeleton data, and audio cues. It\nremains compatible with state-of-the-art architectures, including I3D,\nAssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE\nV2 and InternVideo2. To handle uncertainty in auxiliary features, we\nincorporate aleatoric uncertainty modeling in the hallucination step and\nintroduce a robust loss function to mitigate feature noise. Our multimodal\nself-supervised action recognition framework achieves state-of-the-art\nperformance on multiple benchmarks, including Kinetics-400, Kinetics-600, and\nSomething-Something V2, demonstrating its effectiveness in capturing\nfine-grained action dynamics.\n","authors":["Lei Wang","Piotr Koniusz"],"pdf_url":"https://arxiv.org/pdf/2506.20342v1.pdf","comment":"Accepted for publication in International Journal of Computer Vision\n  (IJCV)"},{"id":"http://arxiv.org/abs/2506.20696v1","updated":"2025-06-25T11:37:34Z","published":"2025-06-25T11:37:34Z","title":"IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left\n  Ventricular Finite Element Modeling with Image Motion Consistency and\n  Biomechanical Parameter Estimation","summary":"  Elucidating the biomechanical behavior of the myocardium is crucial for\nunderstanding cardiac physiology, but cannot be directly inferred from clinical\nimaging and typically requires finite element (FE) simulations. However,\nconventional FE methods are computationally expensive and often fail to\nreproduce observed cardiac motions. We propose IMC-PINN-FE, a physics-informed\nneural network (PINN) framework that integrates imaged motion consistency (IMC)\nwith FE modeling for patient-specific left ventricular (LV) biomechanics.\nCardiac motion is first estimated from MRI or echocardiography using either a\npre-trained attention-based network or an unsupervised cyclic-regularized\nnetwork, followed by extraction of motion modes. IMC-PINN-FE then rapidly\nestimates myocardial stiffness and active tension by fitting clinical pressure\nmeasurements, accelerating computation from hours to seconds compared to\ntraditional inverse FE. Based on these parameters, it performs FE modeling\nacross the cardiac cycle at 75x speedup. Through motion constraints, it matches\nimaged displacements more accurately, improving average Dice from 0.849 to\n0.927, while preserving realistic pressure-volume behavior. IMC-PINN-FE\nadvances previous PINN-FE models by introducing back-computation of material\nproperties and better motion fidelity. Using motion from a single subject to\nreconstruct shape modes also avoids the need for large datasets and improves\npatient specificity. IMC-PINN-FE offers a robust and efficient approach for\nrapid, personalized, and image-consistent cardiac biomechanical modeling.\n","authors":["Siyu Mu","Wei Xuan Chan","Choon Hwai Yap"],"pdf_url":"https://arxiv.org/pdf/2506.20696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20332v1","updated":"2025-06-25T11:34:43Z","published":"2025-06-25T11:34:43Z","title":"Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based\n  Mobile Agent via Task-Level Rewards","summary":"  Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.\n","authors":["Jihao Gu","Qihang Ai","Yingyao Wang","Pi Bu","Jingxuan Xing","Zekun Zhu","Wei Jiang","Ziming Wang","Yingxiu Zhao","Ming-Liang Zhang","Jun Song","Yuning Jiang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.20332v1.pdf","comment":"14 pages, 12 figures"},{"id":"http://arxiv.org/abs/2506.20323v1","updated":"2025-06-25T11:04:33Z","published":"2025-06-25T11:04:33Z","title":"Comparative Analysis of Deep Learning Models for Crop Disease Detection:\n  A Transfer Learning Approach","summary":"  This research presents the development of an Artificial Intelligence (AI) -\ndriven crop disease detection system designed to assist farmers in rural areas\nwith limited resources. We aim to compare different deep learning models for a\ncomparative analysis, focusing on their efficacy in transfer learning. By\nleveraging deep learning models, including EfficientNet, ResNet101,\nMobileNetV2, and our custom CNN, which achieved a validation accuracy of\n95.76%, the system effectively classifies plant diseases. This research\ndemonstrates the potential of transfer learning in reshaping agricultural\npractices, improving crop health management, and supporting sustainable farming\nin rural environments.\n","authors":["Saundarya Subramaniam","Shalini Majumdar","Shantanu Nadar","Kaustubh Kulkarni"],"pdf_url":"https://arxiv.org/pdf/2506.20323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18330v2","updated":"2025-06-25T10:49:23Z","published":"2025-06-23T06:23:53Z","title":"Confucius3-Math: A Lightweight High-Performance Reasoning LLM for\n  Chinese K-12 Mathematics Learning","summary":"  We introduce Confucius3-Math, an open-source large language model with 14B\nparameters that (1) runs efficiently on a single consumer-grade GPU; (2)\nachieves SOTA performances on a range of mathematical reasoning tasks,\noutperforming many models with significantly larger sizes. In particular, as\npart of our mission to enhancing education and knowledge dissemination with AI,\nConfucius3-Math is specifically committed to mathematics learning for Chinese\nK-12 students and educators. Built via post-training with large-scale\nreinforcement learning (RL), Confucius3-Math aligns with national curriculum\nand excels at solving main-stream Chinese K-12 mathematical problems with low\ncost. In this report we share our development recipe, the challenges we\nencounter and the techniques we develop to overcome them. In particular, we\nintroduce three technical innovations: Targeted Entropy Regularization, Recent\nSample Recovery and Policy-Specific Hardness Weighting. These innovations\nencompass a new entropy regularization, a novel data scheduling policy, and an\nimproved group-relative advantage estimator. Collectively, they significantly\nstabilize the RL training, improve data efficiency, and boost performance. Our\nwork demonstrates the feasibility of building strong reasoning models in a\nparticular domain at low cost. We open-source our model and code at\nhttps://github.com/netease-youdao/Confucius3-Math.\n","authors":["Lixin Wu","Na Cai","Qiao Cheng","Jiachen Wang","Yitao Duan"],"pdf_url":"https://arxiv.org/pdf/2506.18330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20307v1","updated":"2025-06-25T10:39:32Z","published":"2025-06-25T10:39:32Z","title":"Beyond-Expert Performance with Limited Demonstrations: Efficient\n  Imitation Learning with Double Exploration","summary":"  Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.\n","authors":["Heyang Zhao","Xingrui Yu","David M. Bossens","Ivor W. Tsang","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2506.20307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18746v3","updated":"2025-06-25T10:37:25Z","published":"2025-05-24T15:25:44Z","title":"$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking","summary":"  Agents based on large language models leverage tools to modify environments,\nrevolutionizing how AI interacts with the physical world. Unlike traditional\nNLP tasks that rely solely on historical dialogue for responses, these agents\nmust consider more complex factors, such as inter-tool relationships,\nenvironmental feedback and previous decisions, when making choices. Current\nresearch typically evaluates agents via multi-turn dialogues. However, it\noverlooks the influence of these critical factors on agent behavior. To bridge\nthis gap, we present an open-source and high-quality benchmark $C^3$-Bench.\nThis benchmark integrates attack concepts and applies univariate analysis to\npinpoint key elements affecting agent robustness. In concrete, we design three\nchallenges: navigate complex tool relationships, handle critical hidden\ninformation and manage dynamic decision paths. Complementing these challenges,\nwe introduce fine-grained metrics, innovative data collection algorithms and\nreproducible evaluation methods. Extensive experiments are conducted on 49\nmainstream agents, encompassing general fast-thinking, slow-thinking and\ndomain-specific models. We observe that agents have significant shortcomings in\nhandling tool dependencies, long context information dependencies and frequent\npolicy-type switching. In essence, $C^3$-Bench aims to expose model\nvulnerabilities through these challenges and drive research into the\ninterpretability of agent performance. The benchmark is publicly available at\nhttps://github.com/yupeijei1997/C3-Bench.\n","authors":["Peijie Yu","Yifan Yang","Jinjian Li","Zelong Zhang","Haorui Wang","Xiao Feng","Feng Zhang"],"pdf_url":"https://arxiv.org/pdf/2505.18746v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07744v2","updated":"2025-06-25T10:33:47Z","published":"2025-06-09T13:26:23Z","title":"Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning","summary":"  Existing offline hierarchical reinforcement learning methods rely on\nhigh-level policy learning to generate subgoal sequences. However, their\nefficiency degrades as task horizons increase, and they lack effective\nstrategies for stitching useful state transitions across different\ntrajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that\nformulates subgoal selection as a graph search problem rather than learning an\nexplicit high-level policy. By embedding states into a Temporal Distance\nRepresentation (TDR) space, GAS clusters semantically similar states from\ndifferent trajectories into unified graph nodes, enabling efficient transition\nstitching. A shortest-path algorithm is then applied to select subgoal\nsequences within the graph, while a low-level policy learns to reach the\nsubgoals. To improve graph quality, we introduce the Temporal Efficiency (TE)\nmetric, which filters out noisy or inefficient transition states, significantly\nenhancing task performance. GAS outperforms prior offline HRL methods across\nlocomotion, navigation, and manipulation tasks. Notably, in the most\nstitching-critical task, it achieves a score of 88.3, dramatically surpassing\nthe previous state-of-the-art score of 1.0. Our source code is available at:\nhttps://github.com/qortmdgh4141/GAS.\n","authors":["Seungho Baek","Taegeon Park","Jongchan Park","Seungjun Oh","Yusung Kim"],"pdf_url":"https://arxiv.org/pdf/2506.07744v2.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2502.06379v2","updated":"2025-06-25T09:54:45Z","published":"2025-02-10T11:59:02Z","title":"Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled\n  Diffusion Sequential Monte Carlo","summary":"  A recent line of research has exploited pre-trained generative diffusion\nmodels as priors for solving Bayesian inverse problems. We contribute to this\nresearch direction by designing a sequential Monte Carlo method for\nlinear-Gaussian inverse problems which builds on \"decoupled diffusion\", where\nthe generative process is designed such that larger updates to the sample are\npossible. The method is asymptotically exact and we demonstrate the\neffectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC)\nalgorithm on both synthetic as well as protein and image data. Further, we\ndemonstrate how the approach can be extended to discrete data.\n","authors":["Filip Ekström Kelvinius","Zheng Zhao","Fredrik Lindsten"],"pdf_url":"https://arxiv.org/pdf/2502.06379v2.pdf","comment":"Accepted to ICML 2025, to appear in PMLR 267. Code available at\n  https://github.com/filipekstrm/ddsmc"},{"id":"http://arxiv.org/abs/2502.11962v3","updated":"2025-06-25T09:51:33Z","published":"2025-02-17T16:10:30Z","title":"Balancing Truthfulness and Informativeness with Uncertainty-Aware\n  Instruction Fine-Tuning","summary":"  Instruction fine-tuning (IFT) can increase the informativeness of large\nlanguage models (LLMs), but may reduce their truthfulness. This trade-off\narises because IFT steers LLMs to generate responses containing long-tail\nknowledge that was not well covered during pre-training. As a result, models\nbecome more informative but less accurate when generalizing to unseen tasks. In\nthis paper, we empirically demonstrate how unfamiliar knowledge in IFT datasets\ncan negatively affect the truthfulness of LLMs, and we introduce two new IFT\nparadigms, $UNIT_{cut}$ and $UNIT_{ref}$, to address this issue. $UNIT_{cut}$\nidentifies and removes unfamiliar knowledge from IFT datasets to mitigate its\nimpact on model truthfulness, whereas $UNIT_{ref}$ trains LLMs to recognize\ntheir uncertainty and explicitly indicate it at the end of their responses. Our\nexperiments show that $UNIT_{cut}$ substantially improves LLM truthfulness,\nwhile $UNIT_{ref}$ maintains high informativeness and reduces hallucinations by\ndistinguishing between confident and uncertain statements.\n","authors":["Tianyi Wu","Jingwei Ni","Bryan Hooi","Jiaheng Zhang","Elliott Ash","See-Kiong Ng","Mrinmaya Sachan","Markus Leippold"],"pdf_url":"https://arxiv.org/pdf/2502.11962v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20274v1","updated":"2025-06-25T09:34:25Z","published":"2025-06-25T09:34:25Z","title":"Enterprise Large Language Model Evaluation Benchmark","summary":"  Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.\n","authors":["Liya Wang","David Yi","Damien Jose","John Passarelli","James Gao","Jordan Leventis","Kang Li"],"pdf_url":"https://arxiv.org/pdf/2506.20274v1.pdf","comment":"Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index"},{"id":"http://arxiv.org/abs/2505.22843v2","updated":"2025-06-25T09:30:26Z","published":"2025-05-28T20:22:43Z","title":"Aurora: Are Android Malware Classifiers Reliable and Stable under\n  Distribution Shift?","summary":"  The performance figures of modern drift-adaptive malware classifiers appear\npromising, but does this translate to genuine operational reliability? The\nstandard evaluation paradigm primarily focuses on baseline performance metrics,\nneglecting confidence-error alignment and operational stability. While\nTESSERACT established the importance of temporal evaluation, we take a\ncomplementary direction by investigating whether malware classifiers maintain\nreliable and stable confidence estimates under distribution shifts and\nexploring the tensions between scientific advancement and practical impacts\nwhen they do not. We propose AURORA, a framework to evaluate malware\nclassifiers based on their confidence quality and operational resilience.\nAURORA subjects the confidence profile of a given model to verification to\nassess the reliability of its estimates. Unreliable confidence estimates erode\noperational trust, waste valuable annotation budget on non-informative samples\nfor active learning, and leave error-prone instances undetected in selective\nclassification. AURORA is complemented by a set of metrics designed to go\nbeyond point-in-time performance, striving towards a more holistic assessment\nof operational stability throughout temporal evaluation periods. The fragility\nin SOTA frameworks across datasets of varying drift suggests the need for a\nreturn to the whiteboard.\n","authors":["Alexander Herzog","Aliai Eusebi","Lorenzo Cavallaro"],"pdf_url":"https://arxiv.org/pdf/2505.22843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10390v2","updated":"2025-06-25T09:27:22Z","published":"2025-04-14T16:36:56Z","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"  Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.\n","authors":["Fangcheng Jin","Yuqi Wang","Peixin Ma","Guodong Yang","Pan Zhao","En Li","Zhengtao Zhang"],"pdf_url":"https://arxiv.org/pdf/2504.10390v2.pdf","comment":"8 pages, 6 figures, 6 tables, IROS 2025"},{"id":"http://arxiv.org/abs/2504.06185v2","updated":"2025-06-25T09:21:21Z","published":"2025-04-08T16:25:59Z","title":"WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and\n  Real-World Wound Care","summary":"  Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For a fair comparison,\nwe standardize training, data augmentation, and evaluation, conducting\ncross-validation to minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates and evaluate this, along with mask\nquality, for the five best architectures based on physician assessments.\nOverall, the transformer-based TransNeXt showed the highest levels of\ngeneralizability. Despite variations in inference times, all models processed\nat least one image per second on the CPU, which is deemed adequate for the\nintended application. Interpretability analysis typically revealed prominent\nactivations in wound regions, emphasizing focus on clinically relevant\nfeatures. Expert evaluation showed high mask approval for all analyzed models,\nwith VWFormer and ConvNeXtS backbone performing the best. Size retrieval\naccuracy was similar across models, and predictions closely matched expert\nannotations. Finally, we demonstrate how our AI-driven wound size estimation\nframework, WoundAmbit, is integrated into a custom telehealth system.\n","authors":["Vanessa Borst","Timo Dittus","Tassilo Dege","Astrid Schmieder","Samuel Kounev"],"pdf_url":"https://arxiv.org/pdf/2504.06185v2.pdf","comment":"Main paper: 18 pages; supplementary material: 15 pages; the paper has\n  been accepted for publication at the Applied Data Science (ADS) track of the\n  European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECML PKDD 2025)"},{"id":"http://arxiv.org/abs/2411.01969v3","updated":"2025-06-25T09:19:50Z","published":"2024-11-04T10:44:46Z","title":"Toddlers' Active Gaze Behavior Supports Self-Supervised Object Learning","summary":"  Toddlers learn to recognize objects from different viewpoints with almost no\nsupervision. During this learning, they execute frequent eye and head movements\nthat shape their visual experience. It is presently unclear if and how these\nbehaviors contribute to toddlers' emerging object recognition abilities. To\nanswer this question, we here combine head-mounted eye tracking during dyadic\nplay with unsupervised machine learning. We approximate toddlers' central\nvisual field experience by cropping image regions from a head-mounted camera\ncentered on the current gaze location estimated via eye tracking. This visual\nstream feeds an unsupervised computational model of toddlers' learning, which\nconstructs visual representations that slowly change over time. Our experiments\ndemonstrate that toddlers' gaze strategy supports the learning of invariant\nobject representations. Our analysis also shows that the limited size of the\ncentral visual field where acuity is high is crucial for this. Overall, our\nwork reveals how toddlers' gaze behavior may support their development of\nview-invariant object recognition.\n","authors":["Zhengyang Yu","Arthur Aubret","Marcel C. Raabe","Jane Yang","Chen Yu","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2411.01969v3.pdf","comment":"27 pages, 16 figures"},{"id":"http://arxiv.org/abs/2506.20260v1","updated":"2025-06-25T09:07:00Z","published":"2025-06-25T09:07:00Z","title":"Argumentative Ensembling for Robust Recourse under Model Multiplicity","summary":"  In machine learning, it is common to obtain multiple equally performing\nmodels for the same prediction task, e.g., when training neural networks with\ndifferent random seeds. Model multiplicity (MM) is the situation which arises\nwhen these competing models differ in their predictions for the same input, for\nwhich ensembling is often employed to determine an aggregation of the outputs.\nProviding recourse recommendations via counterfactual explanations (CEs) under\nMM thus becomes complex, since the CE may not be valid across all models, i.e.,\nthe CEs are not robust under MM. In this work, we formalise the problem of\nproviding recourse under MM, which we name recourse-aware ensembling (RAE). We\npropose the idea that under MM, CEs for each individual model should be\nconsidered alongside their predictions so that the aggregated prediction and\nrecourse are decided in tandem. Centred around this intuition, we introduce six\ndesirable properties for solutions to this problem. For solving RAE, we propose\na novel argumentative ensembling method which guarantees the robustness of CEs\nunder MM. Specifically, our method leverages computational argumentation to\nexplicitly represent the conflicts between models and counterfactuals regarding\nprediction results and CE validity. It then uses argumentation semantics to\nresolve the conflicts and obtain the final solution, in a manner which is\nparametric to the chosen semantics. Our method also allows for the\nspecification of preferences over the models under MM, allowing further\ncustomisation of the ensemble. In a comprehensive theoretical analysis, we\ncharacterise the behaviour of argumentative ensembling with four different\nargumentation semantics. We then empirically demonstrate the effectiveness of\nour approach in satisfying desirable properties with eight instantiations of\nour method. (Abstract is shortened for arXiv.)\n","authors":["Junqi Jiang","Antonio Rago","Francesco Leofante","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2506.20260v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2312.15097"},{"id":"http://arxiv.org/abs/2506.20259v1","updated":"2025-06-25T09:05:58Z","published":"2025-06-25T09:05:58Z","title":"Generating and Customizing Robotic Arm Trajectories using Neural\n  Networks","summary":"  We introduce a neural network approach for generating and customizing the\ntrajectory of a robotic arm, that guarantees precision and repeatability. To\nhighlight the potential of this novel method, we describe the design and\nimplementation of the technique and show its application in an experimental\nsetting of cognitive robotics. In this scenario, the NICO robot was\ncharacterized by the ability to point to specific points in space with precise\nlinear movements, increasing the predictability of the robotic action during\nits interaction with humans. To achieve this goal, the neural network computes\nthe forward kinematics of the robot arm. By integrating it with a generator of\njoint angles, another neural network was developed and trained on an artificial\ndataset created from suitable start and end poses of the robotic arm. Through\nthe computation of angular velocities, the robot was characterized by its\nability to perform the movement, and the quality of its action was evaluated in\nterms of shape and accuracy. Thanks to its broad applicability, our approach\nsuccessfully generates precise trajectories that could be customized in their\nshape and adapted to different settings.\n","authors":["Andrej Lúčny","Matilde Antonj","Carlo Mazzola","Hana Hornáčková","Igor Farkaš"],"pdf_url":"https://arxiv.org/pdf/2506.20259v1.pdf","comment":"The code is released at\n  https://github.com/andylucny/nico2/tree/main/generate"},{"id":"http://arxiv.org/abs/2506.20253v1","updated":"2025-06-25T08:54:47Z","published":"2025-06-25T08:54:47Z","title":"Time-series surrogates from energy consumers generated by machine\n  learning approaches for long-term forecasting scenarios","summary":"  Forecasting attracts a lot of research attention in the electricity value\nchain. However, most studies concentrate on short-term forecasting of\ngeneration or consumption with a focus on systems and less on individual\nconsumers. Even more neglected is the topic of long-term forecasting of\nindividual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods\nfor generating synthetic time series data tailored to energy consumption\nlong-term forecasting. High-fidelity synthetic data is crucial for a wide range\nof applications, including state estimations in energy systems or power grid\nplanning. In this study, we assess and compare the performance of multiple\nstate-of-the-art but less common techniques: a hybrid Wasserstein Generative\nAdversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),\nHidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial\nnormalizing Flows (MABF). We analyze the ability of each method to replicate\nthe temporal dynamics, long-range dependencies, and probabilistic transitions\ncharacteristic of individual energy consumption profiles. Our comparative\nevaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and\nMABF aiding in selecting the most suitable approach for state estimations and\nother energy-related tasks. Our generation and analysis framework aims to\nenhance the accuracy and reliability of synthetic power consumption data while\ngenerating data that fulfills criteria like anonymisation - preserving privacy\nconcerns mitigating risks of specific profiling of single customers. This study\nutilizes an open-source dataset from households in Germany with 15min time\nresolution. The generated synthetic power profiles can readily be used in\napplications like state estimations or consumption forecasting.\n","authors":["Ben Gerhards","Nikita Popkov","Annekatrin König","Marcel Arpogaus","Bastian Schäfermeier","Leonie Riedl","Stephan Vogt","Philip Hehlert"],"pdf_url":"https://arxiv.org/pdf/2506.20253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20251v1","updated":"2025-06-25T08:52:22Z","published":"2025-06-25T08:52:22Z","title":"Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching\n  for Quantized Large Language Models","summary":"  Quantized large language models (LLMs) have gained increasing attention and\nsignificance for enabling deployment in resource-constrained environments.\nHowever, emerging studies on a few calibration dataset-free quantization\nmethods suggest that quantization may compromise the safety capabilities of\nLLMs, underscoring the urgent need for systematic safety evaluations and\neffective mitigation strategies. In this paper, we present comprehensive safety\nevaluations across various mainstream quantization techniques and diverse\ncalibration datasets, utilizing widely accepted safety benchmarks. To address\nthe identified safety vulnerabilities, we propose a quantization-aware safety\npatching framework, Q-resafe, to efficiently restore the safety capabilities of\nquantized LLMs while minimizing any adverse impact on utility. Extensive\nexperimental results demonstrate that Q-resafe successfully re-aligns the\nsafety of quantized LLMs with their pre-quantization counterparts, even under\nchallenging evaluation scenarios. Project page is available at:\nhttps://github.com/Thecommonirin/Qresafe.\n","authors":["Kejia Chen","Jiawen Zhang","Jiacong Hu","Yu Wang","Jian Lou","Zunlei Feng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2506.20251v1.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2412.12587v2","updated":"2025-06-25T08:50:42Z","published":"2024-12-17T06:44:05Z","title":"Distributed satellite information networks: Architecture, enabling\n  technologies, and trends","summary":"  Driven by the vision of ubiquitous connectivity and wireless intelligence,\nthe evolution of ultra-dense constellation-based satellite-integrated Internet\nis underway, now taking preliminary shape. Nevertheless, the entrenched\ninstitutional silos and limited, nonrenewable heterogeneous network resources\nleave current satellite systems struggling to accommodate the escalating\ndemands of next-generation intelligent applications. In this context, the\ndistributed satellite information networks (DSIN), exemplified by the cohesive\nclustered satellites system, have emerged as an innovative architecture,\nbridging information gaps across diverse satellite systems, such as\ncommunication, navigation, and remote sensing, and establishing a unified, open\ninformation network paradigm to support resilient space information services.\nThis survey first provides a profound discussion about innovative network\narchitectures of DSIN, encompassing distributed regenerative satellite network\narchitecture, distributed satellite computing network architecture, and\nreconfigurable satellite formation flying, to enable flexible and scalable\ncommunication, computing and control. The DSIN faces challenges from network\nheterogeneity, unpredictable channel dynamics, sparse resources, and\ndecentralized collaboration frameworks. To address these issues, a series of\nenabling technologies is identified, including channel modeling and estimation,\ncloud-native distributed MIMO cooperation, grant-free massive access, network\nrouting, and the proper combination of all these diversity techniques.\nFurthermore, to heighten the overall resource efficiency, the cross-layer\noptimization techniques are further developed to meet upper-layer\ndeterministic, adaptive and secure information services requirements. In\naddition, emerging research directions and new opportunities are highlighted on\nthe way to achieving the DSIN vision.\n","authors":["Qinyu Zhang","Liang Xu","Jianhao Huang","Tao Yang","Jian Jiao","Ye Wang","Yao Shi","Chiya Zhang","Xingjian Zhang","Ke Zhang","Yupeng Gong","Na Deng","Nan Zhao","Zhen Gao","Shujun Han","Xiaodong Xu","Li You","Dongming Wang","Shan Jiang","Dixian Zhao","Nan Zhang","Liujun Hu","Xiongwen He","Yonghui Li","Xiqi Gao","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2412.12587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20249v1","updated":"2025-06-25T08:46:10Z","published":"2025-06-25T08:46:10Z","title":"Language Modeling by Language Models","summary":"  Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.\n","authors":["Junyan Cheng","Peter Clark","Kyle Richardson"],"pdf_url":"https://arxiv.org/pdf/2506.20249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20694v1","updated":"2025-06-25T08:43:37Z","published":"2025-06-25T08:43:37Z","title":"Evaluating PDE discovery methods for multiscale modeling of biological\n  signals","summary":"  Biological systems are non-linear, include unobserved variables and the\nphysical principles that govern their dynamics are partly unknown. This makes\nthe characterization of their behavior very challenging. Notably, their\nactivity occurs on multiple interdependent spatial and temporal scales that\nrequire linking mechanisms across scales. To address the challenge of bridging\ngaps between scales, we leverage partial differential equations (PDE)\ndiscovery. PDE discovery suggests meso-scale dynamics characteristics from\nmicro-scale data. In this article, we present our framework combining\nparticle-based simulations and PDE discovery and conduct preliminary\nexperiments to assess equation discovery in controlled settings. We evaluate\nfive state-of-the-art PDE discovery methods on particle-based simulations of\ncalcium diffusion in astrocytes. The performances of the methods are evaluated\non both the form of the discovered equation and the forecasted temporal\nvariations of calcium concentration. Our results show that several methods\naccurately recover the diffusion term, highlighting the potential of PDE\ndiscovery for capturing macroscopic dynamics in biological systems from\nmicroscopic data.\n","authors":["Andréa Ducos","Audrey Denizot","Thomas Guyet","Hugues Berry"],"pdf_url":"https://arxiv.org/pdf/2506.20694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20245v1","updated":"2025-06-25T08:42:10Z","published":"2025-06-25T08:42:10Z","title":"FedBKD: Distilled Federated Learning to Embrace Gerneralization and\n  Personalization on Non-IID Data","summary":"  Federated learning (FL) is a decentralized collaborative machine learning\n(ML) technique. It provides a solution to the issues of isolated data islands\nand data privacy leakage in industrial ML practices. One major challenge in FL\nis handling the non-identical and independent distributed (non-IID) data.\nCurrent solutions either focus on constructing an all-powerful global model, or\ncustomizing personalized local models. Few of them can provide both a\nwell-generalized global model and well-performed local models at the same time.\nAdditionally, many FL solutions to the non-IID problem are benefited from\nintroducing public datasets. However, this will also increase the risk of data\nleakage. To tackle the problems, we propose a novel data-free distillation\nframework, Federated Bidirectional Knowledge Distillation (FedBKD).\nSpecifically, we train Generative Adversarial Networks (GAN) for synthetic\ndata. During the GAN training, local models serve as discriminators and their\nparameters are frozen. The synthetic data is then used for bidirectional\ndistillation between global and local models to achieve knowledge interactions\nso that performances for both sides are improved. We conduct extensive\nexperiments on 4 benchmarks under different non-IID settings. The results show\nthat FedBKD achieves SOTA performances in every case.\n","authors":["Yushan Zhao","Jinyuan He","Donglai Chen","Weijie Luo","Chong Xie","Ri Zhang","Yonghong Chen","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2506.20245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20243v1","updated":"2025-06-25T08:39:22Z","published":"2025-06-25T08:39:22Z","title":"CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment","summary":"  Automatic fluency assessment (AFA) remains challenging, particularly in\ncapturing speech rhythm, pauses, and disfluencies in non-native speakers. We\nintroduce a chunk-based approach integrating self-supervised learning (SSL)\nmodels (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths\nin phonetic, prosodic, and noisy speech modeling, with a hierarchical\nCNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero\nvoice activity detection (Silero-VAD), enabling fine-grained temporal analysis\nwhile mitigating over-segmentation artifacts. SSL embeddings are fused via a\nlearnable weighted mechanism, balancing acoustic and linguistic features, and\nenriched with chunk-level fluency markers (e.g., speech rate, pause durations,\nn-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies\nacross chunks. Evaluated on Avalinguo and Speechocean762, our approach improves\nF1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines\non Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on\nAvalinguo, surpassing Pyannote.audio-based segmentation baselines. These\nfindings highlight chunk-based multi-SSL fusion for robust fluency evaluation,\nthough future work should explore generalization to dialects with irregular\nprosody.\n","authors":["Papa Séga Wade","Mihai Andries","Ioannis Kanellos","Thierry Moudenc"],"pdf_url":"https://arxiv.org/pdf/2506.20243v1.pdf","comment":"5 pages, accepted for presentation at EUSIPCO 2025"},{"id":"http://arxiv.org/abs/2506.20241v1","updated":"2025-06-25T08:36:12Z","published":"2025-06-25T08:36:12Z","title":"Enhancing Large Language Models through Structured Reasoning","summary":"  Recent Large Language Models (LLMs) have significantly advanced natural\nlanguage processing and automated decision-making. However, these models still\nencounter difficulties when performing complex reasoning tasks involving\nlogical deduction and systematic planning, primarily due to their reliance on\nimplicit statistical relationships without structured knowledge\nrepresentation.Inspired by cognitive science and neurosymbolic AI, we introduce\na novel approach to enhance LLMs through explicit structured reasoning. First,\nwe convert unstructured data into structured formats by explicitly annotating\nreasoning steps. We then employ this structured dataset to train LLMs through\nSupervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning\ncapabilities of LLMs using Group Relative Policy Optimization (GRPO),\nincorporating two innovative algorithms--MAX-Flow and Longest Common\nSubsequence (LCS)--which notably improve reasoning effectiveness and reduce\ncomputational complexity. Experimental results from fine-tuning a\nDeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust\nperformance across various scenarios, and improved compatibility with\noptimization techniques, validating the efficacy of structured reasoning\nintegration in LLMs.\n","authors":["Yubo Dong","Hehe Fan"],"pdf_url":"https://arxiv.org/pdf/2506.20241v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2506.20235v1","updated":"2025-06-25T08:25:56Z","published":"2025-06-25T08:25:56Z","title":"Directed Link Prediction using GNN with Local and Global Feature Fusion","summary":"  Link prediction is a classical problem in graph analysis with many practical\napplications. For directed graphs, recently developed deep learning approaches\ntypically analyze node similarities through contrastive learning and aggregate\nneighborhood information through graph convolutions. In this work, we propose a\nnovel graph neural network (GNN) framework to fuse feature embedding with\ncommunity information. We theoretically demonstrate that such hybrid features\ncan improve the performance of directed link prediction. To utilize such\nfeatures efficiently, we also propose an approach to transform input graphs\ninto directed line graphs so that nodes in the transformed graph can aggregate\nmore information during graph convolutions. Experiments on benchmark datasets\nshow that our approach outperforms the state-of-the-art in most cases when 30%,\n40%, 50%, and 60% of the connected links are used as training data,\nrespectively.\n","authors":["Yuyang Zhang","Xu Shen","Yu Xie","Ka-Chun Wong","Weidun Xie","Chengbin Peng"],"pdf_url":"https://arxiv.org/pdf/2506.20235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00757v3","updated":"2025-06-25T08:23:23Z","published":"2025-02-02T11:40:07Z","title":"AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds\n  via Self-Improvement","summary":"  Scaffolding Large Language Models (LLMs) into multi-agent systems often\nimproves performance on complex tasks, but the safety impact of such scaffolds\nhas not been thoroughly explored. We introduce AgentBreeder, a framework for\nmulti-objective self-improving evolutionary search over scaffolds. We evaluate\ndiscovered scaffolds on widely recognized reasoning, mathematics, and safety\nbenchmarks and compare them with popular baselines. In 'blue' mode, we see a\n79.4% average uplift in safety benchmark performance while maintaining or\nimproving capability scores. In 'red' mode, we find adversarially weak\nscaffolds emerging concurrently with capability optimization. Our work\ndemonstrates the risks of multi-agent scaffolding and provides a framework for\nmitigating them. Code is available at\nhttps://github.com/J-Rosser-UK/AgentBreeder.\n","authors":["J Rosser","Jakob Nicolaus Foerster"],"pdf_url":"https://arxiv.org/pdf/2502.00757v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01109v2","updated":"2025-06-25T08:14:50Z","published":"2025-03-03T02:33:39Z","title":"FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with\n  Sparse and Dense Map Fusion","summary":"  3D gaussian splatting has advanced simultaneous localization and mapping\n(SLAM) technology by enabling real-time positioning and the construction of\nhigh-fidelity maps. However, the uncertainty in gaussian position and\ninitialization parameters introduces challenges, often requiring extensive\niterative convergence and resulting in redundant or insufficient gaussian\nrepresentations. To address this, we introduce a novel adaptive densification\nmethod based on Fourier frequency domain analysis to establish gaussian priors\nfor rapid convergence. Additionally, we propose constructing independent and\nunified sparse and dense maps, where a sparse map supports efficient tracking\nvia Generalized Iterative Closest Point (GICP) and a dense map creates\nhigh-fidelity visual representations. This is the first SLAM system leveraging\nfrequency domain analysis to achieve high-quality gaussian mapping in\nreal-time. Experimental results demonstrate an average frame rate of 36 FPS on\nReplica and TUM RGB-D datasets, achieving competitive accuracy in both\nlocalization and mapping.\n","authors":["Yansong Xu","Junlin Li","Wei Zhang","Siyu Chen","Shengyong Zhang","Yuquan Leng","Weijia Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01109v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17253v2","updated":"2025-06-25T07:55:20Z","published":"2025-06-08T10:33:39Z","title":"MS-TVNet:A Long-Term Time Series Prediction Method Based on Multi-Scale\n  Dynamic Convolution","summary":"  Long-term time series prediction has predominantly relied on Transformer and\nMLP models, while the potential of convolutional networks in this domain\nremains underexplored. To address this gap, we introduce a novel multi-scale\ntime series reshape module, which effectively captures the relationships among\nmulti-period patches and variable dependencies. Building upon this module, we\npropose MS-TVNet, a multi-scale 3D dynamic convolutional neural network.\nThrough comprehensive evaluations on diverse datasets, MS-TVNet demonstrates\nsuperior performance compared to baseline models, achieving state-of-the-art\n(SOTA) results in long-term time series prediction. Our findings highlight the\neffectiveness of leveraging convolutional networks for capturing complex\ntemporal patterns, suggesting a promising direction for future research in this\nfield.The code is realsed on https://github.com/Curyyfaust/TVNet.\n","authors":["Chenghan Li","Mingchen Li","Yipu Liao","Ruisheng Diao"],"pdf_url":"https://arxiv.org/pdf/2506.17253v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20209v1","updated":"2025-06-25T07:53:36Z","published":"2025-06-25T07:53:36Z","title":"Perspectives in Play: A Multi-Perspective Approach for More Inclusive\n  NLP Systems","summary":"  In the realm of Natural Language Processing (NLP), common approaches for\nhandling human disagreement consist of aggregating annotators' viewpoints to\nestablish a single ground truth. However, prior studies show that disregarding\nindividual opinions can lead can lead to the side effect of underrepresenting\nminority perspectives, especially in subjective tasks, where annotators may\nsystematically disagree because of their preferences. Recognizing that labels\nreflect the diverse backgrounds, life experiences, and values of individuals,\nthis study proposes a new multi-perspective approach using soft labels to\nencourage the development of the next generation of perspective aware models,\nmore inclusive and pluralistic. We conduct an extensive analysis across diverse\nsubjective text classification tasks, including hate speech, irony, abusive\nlanguage, and stance detection, to highlight the importance of capturing human\ndisagreements, often overlooked by traditional aggregation methods. Results\nshow that the multi-perspective approach not only better approximates human\nlabel distributions, as measured by Jensen-Shannon Divergence (JSD), but also\nachieves superior classification performance (higher F1 scores), outperforming\ntraditional approaches. However, our approach exhibits lower confidence in\ntasks like irony and stance detection, likely due to the inherent subjectivity\npresent in the texts. Lastly, leveraging Explainable AI (XAI), we explore model\nuncertainty and uncover meaningful insights into model predictions.\n","authors":["Benedetta Muscato","Lucia Passaro","Gizem Gezici","Fosca Giannotti"],"pdf_url":"https://arxiv.org/pdf/2506.20209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20204v1","updated":"2025-06-25T07:48:22Z","published":"2025-06-25T07:48:22Z","title":"Affective Priming Score: A Data-Driven Method to Detect Priming in\n  Sequential Datasets","summary":"  Affective priming exemplifies the challenge of ambiguity in affective\ncomputing. While the community has largely addressed this issue from a\nlabel-based perspective, identifying data points in the sequence affected by\nthe priming effect, the impact of priming on data itself, particularly in\nphysiological signals, remains underexplored. Data affected by priming can lead\nto misclassifications when used in learning models. This study proposes the\nAffective Priming Score (APS), a data-driven method to detect data points\ninfluenced by the priming effect. The APS assigns a score to each data point,\nquantifying the extent to which it is affected by priming. To validate this\nmethod, we apply it to the SEED and SEED-VII datasets, which contain sufficient\ntransitions between emotional events to exhibit priming effects. We train\nmodels with the same configuration using both the original data and\npriming-free sequences. The misclassification rate is significantly reduced\nwhen using priming-free sequences compared to the original data. This work\ncontributes to the broader challenge of ambiguity by identifying and mitigating\npriming effects at the data level, enhancing model robustness, and offering\nvaluable insights for the design and collection of affective computing\ndatasets.\n","authors":["Eduardo Gutierrez Maestro","Hadi Banaee","Amy Loutfi"],"pdf_url":"https://arxiv.org/pdf/2506.20204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20199v1","updated":"2025-06-25T07:39:19Z","published":"2025-06-25T07:39:19Z","title":"How to Retrieve Examples in In-context Learning to Improve\n  Conversational Emotion Recognition using Large Language Models?","summary":"  Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.\n","authors":["Mengqi Wang","Tiantian Feng","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2506.20199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20197v1","updated":"2025-06-25T07:37:16Z","published":"2025-06-25T07:37:16Z","title":"Zero-Shot Attribution for Large Language Models: A Distribution Testing\n  Approach","summary":"  A growing fraction of all code is sampled from Large Language Models (LLMs).\nWe investigate the problem of attributing code generated by language models\nusing hypothesis testing to leverage established techniques and guarantees.\nGiven a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to\nassess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse\nof dimensionality, this is intractable when only samples from the LLM are\ngiven: to circumvent this, we use both samples and density estimates from the\nLLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames\nattribution as a distribution testing problem. Our experiments on a benchmark\nof code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores (\n$\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and\nStable-Code using only $\\approx 2000$ samples.\n","authors":["Clément L. Canonne","Yash Pote","Uddalok Sarkar"],"pdf_url":"https://arxiv.org/pdf/2506.20197v1.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2506.13087v3","updated":"2025-06-25T07:27:44Z","published":"2025-06-16T04:12:04Z","title":"IKDiffuser: A Generative Inverse Kinematics Solver for Multi-arm Robots\n  via Diffusion Model","summary":"  Solving Inverse Kinematics (IK) problems is fundamental to robotics, but has\nprimarily been successful with single serial manipulators. For multi-arm\nrobotic systems, IK remains challenging due to complex self-collisions, coupled\njoints, and high-dimensional redundancy. These complexities make traditional IK\nsolvers slow, prone to failure, and lacking in solution diversity. In this\npaper, we present IKDiffuser, a diffusion-based model designed for fast and\ndiverse IK solution generation for multi-arm robotic systems. IKDiffuser learns\nthe joint distribution over the configuration space, capturing complex\ndependencies and enabling seamless generalization to multi-arm robotic systems\nof different structures. In addition, IKDiffuser can incorporate additional\nobjectives during inference without retraining, offering versatility and\nadaptability for task-specific requirements. In experiments on 6 different\nmulti-arm systems, the proposed IKDiffuser achieves superior solution accuracy,\nprecision, diversity, and computational efficiency compared to existing\nsolvers. The proposed IKDiffuser framework offers a scalable, unified approach\nto solving multi-arm IK problems, facilitating the potential of multi-arm\nrobotic systems in real-time manipulation tasks.\n","authors":["Zeyu Zhang","Ziyuan Jiao"],"pdf_url":"https://arxiv.org/pdf/2506.13087v3.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2408.16767v4","updated":"2025-06-25T07:19:44Z","published":"2024-08-29T17:59:40Z","title":"ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion\n  Model","summary":"  Advancements in 3D scene reconstruction have transformed 2D images from the\nreal world into 3D models, producing realistic 3D results from hundreds of\ninput photos. Despite great success in dense-view reconstruction scenarios,\nrendering a detailed scene from insufficient captured views is still an\nill-posed optimization problem, often resulting in artifacts and distortions in\nunseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction\nparadigm that reframes the ambiguous reconstruction challenge as a temporal\ngeneration task. The key insight is to unleash the strong generative prior of\nlarge pre-trained video diffusion models for sparse-view reconstruction.\nHowever, 3D view consistency struggles to be accurately preserved in directly\ngenerated video frames from pre-trained models. To address this, given limited\ninput views, the proposed ReconX first constructs a global point cloud and\nencodes it into a contextual space as the 3D structure condition. Guided by the\ncondition, the video diffusion model then synthesizes video frames that are\nboth detail-preserved and exhibit a high degree of 3D consistency, ensuring the\ncoherence of the scene from various perspectives. Finally, we recover the 3D\nscene from the generated video through a confidence-aware 3D Gaussian Splatting\noptimization scheme. Extensive experiments on various real-world datasets show\nthe superiority of our ReconX over state-of-the-art methods in terms of quality\nand generalizability.\n","authors":["Fangfu Liu","Wenqiang Sun","Hanyang Wang","Yikai Wang","Haowen Sun","Junliang Ye","Jun Zhang","Yueqi Duan"],"pdf_url":"https://arxiv.org/pdf/2408.16767v4.pdf","comment":"Project page: https://liuff19.github.io/ReconX"},{"id":"http://arxiv.org/abs/2506.02097v2","updated":"2025-06-25T07:18:47Z","published":"2025-06-02T17:59:27Z","title":"Hybrid AI for Responsive Multi-Turn Online Conversations with Novel\n  Dynamic Routing and Feedback Adaptation","summary":"  Retrieval-Augmented Generation (RAG) systems and large language model\n(LLM)-powered chatbots have significantly advanced conversational AI by\ncombining generative capabilities with external knowledge retrieval. Despite\ntheir success, enterprise-scale deployments face critical challenges, including\ndiverse user queries, high latency, hallucinations, and difficulty integrating\nfrequently updated domain-specific knowledge. This paper introduces a novel\nhybrid framework that integrates RAG with intent-based canned responses,\nleveraging predefined high-confidence responses for efficiency while\ndynamically routing complex or ambiguous queries to the RAG pipeline. Our\nframework employs a dialogue context manager to ensure coherence in multi-turn\ninteractions and incorporates a feedback loop to refine intents, dynamically\nadjust confidence thresholds, and expand response coverage over time.\nExperimental results demonstrate that the proposed framework achieves a balance\nof high accuracy (95\\%) and low latency (180ms), outperforming RAG and\nintent-based systems across diverse query types, positioning it as a scalable\nand adaptive solution for enterprise conversational AI applications.\n","authors":["Priyaranjan Pattnayak","Amit Agarwal","Hansa Meghwani","Hitesh Laxmichand Patel","Srikant Panda"],"pdf_url":"https://arxiv.org/pdf/2506.02097v2.pdf","comment":"Proceedings of the 4th International Workshop on Knowledge Augmented\n  Methods for Natural Language Processing in NAACL 2025, pages 215 to 229,\n  Albuquerque, New Mexico, USA. Association for Computational Linguistics"},{"id":"http://arxiv.org/abs/2506.20179v1","updated":"2025-06-25T07:07:32Z","published":"2025-06-25T07:07:32Z","title":"Progressive Alignment Degradation Learning for Pansharpening","summary":"  Deep learning-based pansharpening has been shown to effectively generate\nhigh-resolution multispectral (HRMS) images. To create supervised ground-truth\nHRMS images, synthetic data generated using the Wald protocol is commonly\nemployed. This protocol assumes that networks trained on artificial\nlow-resolution data will perform equally well on high-resolution data. However,\nwell-trained models typically exhibit a trade-off in performance between\nreduced-resolution and full-resolution datasets. In this paper, we delve into\nthe Wald protocol and find that its inaccurate approximation of real-world\ndegradation patterns limits the generalization of deep pansharpening models. To\naddress this issue, we propose the Progressive Alignment Degradation Module\n(PADM), which uses mutual iteration between two sub-networks, PAlignNet and\nPDegradeNet, to adaptively learn accurate degradation processes without relying\non predefined operators. Building on this, we introduce HFreqdiff, which embeds\nhigh-frequency details into a diffusion framework and incorporates CFB and BACM\nmodules for frequency-selective detail extraction and precise reverse process\nlearning. These innovations enable effective integration of high-resolution\npanchromatic and multispectral images, significantly enhancing spatial\nsharpness and quality. Experiments and ablation studies demonstrate the\nproposed method's superior performance compared to state-of-the-art techniques.\n","authors":["Enzhe Zhao","Zhichang Guo","Yao Li","Fanghui Song","Boying Wu"],"pdf_url":"https://arxiv.org/pdf/2506.20179v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2506.20178v1","updated":"2025-06-25T07:04:49Z","published":"2025-06-25T07:04:49Z","title":"COIN: Uncertainty-Guarding Selective Question Answering for Foundation\n  Models with Provable Risk Guarantees","summary":"  Uncertainty quantification (UQ) for foundation models is essential to\nidentify and mitigate potential hallucinations in automatically generated text.\nHowever, heuristic UQ approaches lack formal guarantees for key metrics such as\nthe false discovery rate (FDR) in selective prediction. Previous work adopts\nthe split conformal prediction (SCP) framework to ensure desired coverage of\nadmissible answers by constructing prediction sets, but these sets often\ncontain incorrect candidates, limiting their practical utility. To address\nthis, we propose COIN, an uncertainty-guarding selection framework that\ncalibrates statistically valid thresholds to filter a single generated answer\nper question under user-specified FDR constraints. COIN estimates the empirical\nerror rate on a calibration set and applies confidence interval methods such as\nClopper-Pearson to establish a high-probability upper bound on the true error\nrate (i.e., FDR). This enables the selection of the largest uncertainty\nthreshold that ensures FDR control on test data while significantly increasing\nsample retention. We demonstrate COIN's robustness in risk control, strong\ntest-time power in retaining admissible answers, and predictive efficiency\nunder limited calibration data across both general and multimodal text\ngeneration tasks. Furthermore, we show that employing alternative upper bound\nconstructions and UQ strategies can further boost COIN's power performance,\nwhich underscores its extensibility and adaptability to diverse application\nscenarios.\n","authors":["Zhiyuan Wang","Jinhao Duan","Qingni Wang","Xiaofeng Zhu","Tianlong Chen","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2506.20178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20173v1","updated":"2025-06-25T06:59:55Z","published":"2025-06-25T06:59:55Z","title":"Valid Selection among Conformal Sets","summary":"  Conformal prediction offers a distribution-free framework for constructing\nprediction sets with coverage guarantees. In practice, multiple valid conformal\nprediction sets may be available, arising from different models or\nmethodologies. However, selecting the most desirable set, such as the smallest,\ncan invalidate the coverage guarantees. To address this challenge, we propose a\nstability-based approach that ensures coverage for the selected prediction set.\nWe extend our results to the online conformal setting, propose several\nrefinements in settings where additional structure is available, and\ndemonstrate its effectiveness through experiments.\n","authors":["Mahmoud Hegazy","Liviu Aolaritei","Michael I. Jordan","Aymeric Dieuleveut"],"pdf_url":"https://arxiv.org/pdf/2506.20173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20167v1","updated":"2025-06-25T06:40:14Z","published":"2025-06-25T06:40:14Z","title":"SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series\n  Prediction with LLMs","summary":"  Multivariate time series forecasting requires models to simultaneously\ncapture variable-wise structural dependencies and generalize across diverse\ntasks. While structural encoders are effective in modeling feature\ninteractions, they lack the capacity to support semantic-level reasoning or\ntask adaptation. Conversely, large language models (LLMs) possess strong\ngeneralization capabilities but remain incompatible with raw time series\ninputs. This gap limits the development of unified, transferable prediction\nsystems. Therefore, we introduce SEED, a structural encoder for\nembedding-driven decoding, which integrates four stages: a token-aware encoder\nfor patch extraction, a projection module that aligns patches with language\nmodel embeddings, a semantic reprogramming mechanism that maps patches to\ntask-aware prototypes, and a frozen language model for prediction. This modular\narchitecture decouples representation learning from inference, enabling\nefficient alignment between numerical patterns and semantic reasoning.\nEmpirical results demonstrate that the proposed method achieves consistent\nimprovements over strong baselines, and comparative studies on various datasets\nconfirm SEED's role in addressing the structural-semantic modeling gap.\n","authors":["Fengze Li","Yue Wang","Yangle Liu","Ming Huang","Dou Hong","Jieming Ma"],"pdf_url":"https://arxiv.org/pdf/2506.20167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20164v1","updated":"2025-06-25T06:38:13Z","published":"2025-06-25T06:38:13Z","title":"Do psychic cells generate consciousness?","summary":"  Technological advances in the past decades have begun to enable\nneuroscientists to address fundamental questions about consciousness in an\nunprecedented way. Here we review remarkable recent progress in our\nunderstanding of cellular-level mechanisms of conscious processing in the\nbrain. Of particular interest are the cortical pyramidal neurons -- or \"psychic\ncells\" called by Ram\\'on y Cajal more than 100 years ago -- which have an\nintriguing cellular mechanism that accounts for selective disruption of\nfeedback signaling in the brain upon anesthetic-induced loss of consciousness.\nImportantly, a particular class of metabotropic receptors distributed over the\ndendrites of pyramidal cells are highlighted as the key cellular mechanism.\nAfter all, Cajal's instinct over a century ago may turn out to be correct -- we\nmay have just begun to understand whether and how psychic cells indeed generate\nand control our consciousness.\n","authors":["Mototaka Suzuki","Jaan Aru"],"pdf_url":"https://arxiv.org/pdf/2506.20164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20159v1","updated":"2025-06-25T06:29:03Z","published":"2025-06-25T06:29:03Z","title":"AI and Agile Software Development: From Frustration to Success -- XP2025\n  Workshop Summary","summary":"  The full-day workshop on AI and Agile at XP 2025 convened a diverse group of\nresearchers and industry practitioners to address the practical challenges and\nopportunities of integrating Artificial Intelligence into Agile software\ndevelopment. Through interactive sessions, participants identified shared\nfrustrations related to integrating AI into Agile Software Development\npractices, including challenges with tooling, governance, data quality, and\ncritical skill gaps. These challenges were systematically prioritized and\nanalyzed to uncover root causes. The workshop culminated in the collaborative\ndevelopment of a research roadmap that pinpoints actionable directions for\nfuture work, including both immediate solutions and ambitious long-term goals.\nThe key outcome is a structured agenda designed to foster joint\nindustry-academic efforts to move from identified frustrations to successful\nimplementation.\n","authors":["Tomas Herda","Victoria Pichler","Zheying Zhang","Pekka Abrahamsson","Geir K. Hanssen"],"pdf_url":"https://arxiv.org/pdf/2506.20159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20156v1","updated":"2025-06-25T06:23:39Z","published":"2025-06-25T06:23:39Z","title":"Irec: A Metacognitive Scaffolding for Self-Regulated Learning through\n  Just-in-Time Insight Recall: A Conceptual Framework and System Prototype","summary":"  The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.\n","authors":["Xuefei Hou","Xizhao Tan"],"pdf_url":"https://arxiv.org/pdf/2506.20156v1.pdf","comment":"Version 1 of a work in progress. Finalized system flowcharts, a\n  public GitHub repository with the source code, and a full reproducibility\n  package detailing the prompts, models, and testing guidelines will be\n  provided in v2"},{"id":"http://arxiv.org/abs/2506.17508v2","updated":"2025-06-25T06:22:45Z","published":"2025-06-20T23:17:11Z","title":"Mapping the Evolution of Research Contributions using KnoVo","summary":"  This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.\n","authors":["Sajratul Y. Rubaiat","Syed N. Sakib","Hasan M. Jamil"],"pdf_url":"https://arxiv.org/pdf/2506.17508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20152v1","updated":"2025-06-25T06:18:46Z","published":"2025-06-25T06:18:46Z","title":"Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep\n  Neural Network Acceleration","summary":"  Structured pruning is a well-established technique for compressing neural\nnetworks, making it suitable for deployment in resource-limited edge devices.\nThis paper presents an efficient Loss-Aware Automatic Selection of Structured\nPruning Criteria (LAASP) for slimming and accelerating deep neural networks.\nThe majority of pruning methodologies employ a sequential process consisting of\nthree stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed\npruning technique adopts a pruning-while-training approach that eliminates the\nfirst stage and integrates the second and third stages into a single cycle. The\nautomatic selection of magnitude or similarity-based filter pruning criteria\nfrom a specified pool of criteria and the specific pruning layer at each\npruning iteration is guided by the network's overall loss on a small subset of\nthe training data. To mitigate the abrupt accuracy drop due to pruning, the\nnetwork is retrained briefly after each reduction of a predefined number of\nfloating-point operations (FLOPs). The optimal pruning rates for each layer in\nthe network are automatically determined, eliminating the need for manual\nallocation of fixed or variable pruning rates for each layer. Experiments on\nthe VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets\ndemonstrate the effectiveness of the proposed method. In particular, the\nResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the\ntop-1 accuracy compared to state-of-the-art methods while reducing the network\nFLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces\nFLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The\nsource code of this paper is publicly available online -\nhttps://github.com/ghimiredhikura/laasp.\n","authors":["Deepak Ghimire","Kilho Lee","Seong-heum Kim"],"pdf_url":"https://arxiv.org/pdf/2506.20152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20151v1","updated":"2025-06-25T06:15:07Z","published":"2025-06-25T06:15:07Z","title":"EAR: Erasing Concepts from Unified Autoregressive Models","summary":"  Autoregressive (AR) models have achieved unified and strong performance\nacross both visual understanding and image generation tasks. However, removing\nundesired concepts from AR models while maintaining overall generation quality\nremains an open challenge. In this paper, we propose Erasure Autoregressive\nModel (EAR), a fine-tuning method for effective and utility-preserving concept\nerasure in AR models. Specifically, we introduce Windowed Gradient Accumulation\n(WGA) strategy to align patch-level decoding with erasure objectives, and\nThresholded Loss Masking (TLM) strategy to protect content unrelated to the\ntarget concept during fine-tuning. Furthermore, we propose a novel benchmark,\nErase Concept Generator and Visual Filter (ECGVF), aim at provide a more\nrigorous and comprehensive foundation for evaluating concept erasure in AR\nmodels. Specifically, we first employ structured templates across diverse large\nlanguage models (LLMs) to pre-generate a large-scale corpus of\ntarget-replacement concept prompt pairs. Subsequently, we generate images from\nthese prompts and subject them to rigorous filtering via a visual classifier to\nensure concept fidelity and alignment. Extensive experimental results conducted\non the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR\nachieves marked improvements in both erasure effectiveness and model utility\npreservation. Code is available at: https://github.com/immc-lab/ear/\n","authors":["Haipeng Fan","Shiyuan Zhang"," Baohunesitu","Zihang Guo","Huaiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.20151v1.pdf","comment":"11 pages, 7 figures, 1 tables"},{"id":"http://arxiv.org/abs/2506.17667v2","updated":"2025-06-25T06:09:22Z","published":"2025-06-21T09:55:42Z","title":"PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for\n  Multimodal Models","summary":"  Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/.\n","authors":["Lintao Wang","Encheng Su","Jiaqi Liu","Pengze Li","Peng Xia","Jiabei Xiao","Wenlong Zhang","Xinnan Dai","Xi Chen","Yuan Meng","Mingyu Ding","Lei Bai","Wanli Ouyang","Shixiang Tang","Aoran Wang","Xinzhu Ma"],"pdf_url":"https://arxiv.org/pdf/2506.17667v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10504v2","updated":"2025-06-25T06:07:36Z","published":"2024-11-15T14:15:16Z","title":"USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction\n  and Gaussian Splatting","summary":"  Spike cameras, as an innovative neuromorphic camera that captures scenes with\nthe 0-1 bit stream at 40 kHz, are increasingly employed for the 3D\nreconstruction task via Neural Radiance Fields (NeRF) or 3D Gaussian Splatting\n(3DGS). Previous spike-based 3D reconstruction approaches often employ a\ncasecased pipeline: starting with high-quality image reconstruction from spike\nstreams based on established spike-to-image reconstruction algorithms, then\nprogressing to camera pose estimation and 3D reconstruction. However, this\ncascaded approach suffers from substantial cumulative errors, where quality\nlimitations of initial image reconstructions negatively impact pose estimation,\nultimately degrading the fidelity of the 3D reconstruction. To address these\nissues, we propose a synergistic optimization framework, \\textbf{USP-Gaussian},\nthat unifies spike-based image reconstruction, pose correction, and Gaussian\nsplatting into an end-to-end framework. Leveraging the multi-view consistency\nafforded by 3DGS and the motion capture capability of the spike camera, our\nframework enables a joint iterative optimization that seamlessly integrates\ninformation between the spike-to-image network and 3DGS. Experiments on\nsynthetic datasets with accurate poses demonstrate that our method surpasses\nprevious approaches by effectively eliminating cascading errors. Moreover, we\nintegrate pose optimization to achieve robust 3D reconstruction in real-world\nscenarios with inaccurate initial poses, outperforming alternative methods by\neffectively reducing noise and preserving fine texture details. Our code, data\nand trained models will be available at\nhttps://github.com/chenkang455/USP-Gaussian.\n","authors":["Kang Chen","Jiyuan Zhang","Zecheng Hao","Yajing Zheng","Tiejun Huang","Zhaofei Yu"],"pdf_url":"https://arxiv.org/pdf/2411.10504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00845v2","updated":"2025-06-25T06:00:08Z","published":"2025-03-02T10:39:40Z","title":"Rewarding Graph Reasoning Process makes LLMs more Generalized Reasoners","summary":"  Despite significant advancements in Large Language Models (LLMs), developing\nadvanced reasoning capabilities in LLMs remains a key challenge. Process Reward\nModels (PRMs) have demonstrated exceptional promise in enhancing reasoning by\nproviding step-wise feedback, particularly in the context of mathematical\nreasoning. However, their application to broader reasoning domains remains\nunderstudied, largely due to the high costs associated with manually creating\nstep-level supervision. In this work, we explore the potential of PRMs in graph\nreasoning problems - a domain that demands sophisticated multi-step reasoning\nand offers opportunities for automated step-level data generation using\nestablished graph algorithms. We introduce GraphSILO, the largest dataset for\ngraph reasoning problems with fine-grained step-wise labels, built using\nautomated Task-oriented Trajectories and Monte Carlo Tree Search (MCTS) to\ngenerate detailed reasoning steps with step-wise labels. Building upon this\ndataset, we train GraphPRM, the first PRM designed for graph reasoning\nproblems, and evaluate its effectiveness in two key settings: inference-time\nscaling and reinforcement learning via Direct Preference Optimization (DPO).\nExperimental results show that GraphPRM significantly improves LLM performance\nacross 13 graph reasoning tasks, delivering a 9% gain for Qwen2.5-7B and\ndemonstrating transferability to new graph reasoning datasets and new reasoning\ndomains like mathematical problem-solving. Notably, GraphPRM enhances LLM\nperformance on GSM8K and Math500, underscoring the cross-domain applicability\nof graph-based reasoning rewards. Our findings highlight the potential of PRMs\nin advancing reasoning across diverse domains, paving the way for more\nversatile and effective LLMs.\n","authors":["Miao Peng","Nuo Chen","Zongrui Suo","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2503.00845v2.pdf","comment":"Accepted to KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2506.07368v2","updated":"2025-06-25T05:23:29Z","published":"2025-06-09T02:34:19Z","title":"C3S3: Complementary Competition and Contrastive Selection for\n  Semi-Supervised Medical Image Segmentation","summary":"  For the immanent challenge of insufficiently annotated samples in the medical\nfield, semi-supervised medical image segmentation (SSMIS) offers a promising\nsolution. Despite achieving impressive results in delineating primary target\nareas, most current methodologies struggle to precisely capture the subtle\ndetails of boundaries. This deficiency often leads to significant diagnostic\ninaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised\nsegmentation model that synergistically integrates complementary competition\nand contrastive selection. This design significantly sharpens boundary\ndelineation and enhances overall precision. Specifically, we develop an\nOutcome-Driven Contrastive Learning module dedicated to refining boundary\nlocalization. Additionally, we incorporate a Dynamic Complementary Competition\nmodule that leverages two high-performing sub-networks to generate\npseudo-labels, thereby further improving segmentation quality. The proposed\nC3S3 undergoes rigorous validation on two publicly accessible datasets,\nencompassing the practices of both MRI and CT scans. The results demonstrate\nthat our method achieves superior performance compared to previous cutting-edge\ncompetitors. Especially, on the 95HD and ASD metrics, our approach achieves a\nnotable improvement of at least 6%, highlighting the significant advancements.\nThe code is available at https://github.com/Y-TARL/C3S3.\n","authors":["Jiaying He","Yitong Lin","Jiahe Chen","Honghui Xu","Jianwei Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.07368v2.pdf","comment":"Accepted to ICME 2025"},{"id":"http://arxiv.org/abs/2506.19269v2","updated":"2025-06-25T05:10:04Z","published":"2025-06-24T03:03:26Z","title":"AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic\n  Manipulation","summary":"  We present AnchorDP3, a diffusion policy framework for dual-arm robotic\nmanipulation that achieves state-of-the-art performance in highly randomized\nenvironments. AnchorDP3 integrates three key innovations: (1)\nSimulator-Supervised Semantic Segmentation, using rendered ground truth to\nexplicitly segment task-critical objects within the point cloud, which provides\nstrong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight\nmodules processing augmented point clouds per task, enabling efficient\nmulti-task learning through a shared diffusion-based action expert; (3)\nAffordance-Anchored Keypose Diffusion with Full State Supervision, replacing\ndense trajectory prediction with sparse, geometrically meaningful action\nanchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to\naffordances, drastically simplifying the prediction space; the action expert is\nforced to predict both robot joint angles and end-effector poses\nsimultaneously, which exploits geometric consistency to accelerate convergence\nand boost accuracy. Trained on large-scale, procedurally generated simulation\ndata, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark\nacross diverse tasks under extreme randomization of objects, clutter, table\nheight, lighting, and backgrounds. This framework, when integrated with the\nRoboTwin real-to-sim pipeline, has the potential to enable fully autonomous\ngeneration of deployable visuomotor policies from only scene and instruction,\ntotally eliminating human demonstrations from learning manipulation skills.\n","authors":["Ziyan Zhao","Ke Fan","He-Yang Xu","Ning Qiao","Bo Peng","Wenlong Gao","Dongjiang Li","Hui Shen"],"pdf_url":"https://arxiv.org/pdf/2506.19269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13205v3","updated":"2025-06-25T05:05:18Z","published":"2025-06-16T08:09:32Z","title":"Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments","summary":"  With the growing integration of vision-language models (VLMs), mobile agents\nare now widely used for tasks like UI automation and camera-based user\nassistance. These agents are often fine-tuned on limited user-generated\ndatasets, leaving them vulnerable to covert threats during the training\nprocess. In this work we present GHOST, the first clean-label backdoor attack\nspecifically designed for mobile agents built upon VLMs. Our method manipulates\nonly the visual inputs of a portion of the training samples - without altering\ntheir corresponding labels or instructions - thereby injecting malicious\nbehaviors into the model. Once fine-tuned with this tampered data, the agent\nwill exhibit attacker-controlled responses when a specific visual trigger is\nintroduced at inference time. The core of our approach lies in aligning the\ngradients of poisoned samples with those of a chosen target instance, embedding\nbackdoor-relevant features into the poisoned training data. To maintain stealth\nand enhance robustness, we develop three realistic visual triggers: static\nvisual patches, dynamic motion cues, and subtle low-opacity overlays. We\nevaluate our method across six real-world Android apps and three VLM\narchitectures adapted for mobile use. Results show that our attack achieves\nhigh attack success rates (up to 94.67 percent) while maintaining high\nclean-task performance (FSR up to 95.85 percent). Additionally, ablation\nstudies shed light on how various design choices affect the efficacy and\nconcealment of the attack. Overall, this work is the first to expose critical\nsecurity flaws in VLM-based mobile agents, highlighting their susceptibility to\nclean-label backdoor attacks and the urgent need for effective defense\nmechanisms in their training pipelines.\n","authors":["Xuan Wang","Siyuan Liang","Zhe Liu","Yi Yu","Yuliang Lu","Xiaochun Cao","Ee-Chien Chang","Xitong Gao"],"pdf_url":"https://arxiv.org/pdf/2506.13205v3.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2505.13033v2","updated":"2025-06-25T04:59:41Z","published":"2025-05-19T12:18:53Z","title":"TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series\n  Analysis","summary":"  The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters\n(10-100X smaller than existing SOTA models) and allow GPU-free inference,\nsetting a new standard for efficient time-series pre-trained models. The models\ncan be accessed from\nhttps://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1\n","authors":["Vijay Ekambaram","Subodh Kumar","Arindam Jati","Sumanta Mukherjee","Tomoya Sakai","Pankaj Dayama","Wesley M. Gifford","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2505.13033v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20130v1","updated":"2025-06-25T04:56:28Z","published":"2025-06-25T04:56:28Z","title":"AI Copilots for Reproducibility in Science: A Case Study","summary":"  Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.\n","authors":["Adrien Bibal","Steven N. Minton","Deborah Khider","Yolanda Gil"],"pdf_url":"https://arxiv.org/pdf/2506.20130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20128v1","updated":"2025-06-25T04:49:03Z","published":"2025-06-25T04:49:03Z","title":"CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG\n  Evaluation","summary":"  RAG systems enhance LLMs by incorporating external knowledge, which is\ncrucial for domains that demand factual accuracy and up-to-date information.\nHowever, evaluating the multifaceted quality of RAG outputs, spanning aspects\nsuch as contextual coherence, query relevance, factual correctness, and\ninformational completeness, poses significant challenges. Existing evaluation\nmethods often rely on simple lexical overlap metrics, which are inadequate for\ncapturing these nuances, or involve complex multi-stage pipelines with\nintermediate steps like claim extraction or require finetuning specialized\njudge models, hindering practical efficiency. To address these limitations, we\npropose CCRS (Contextual Coherence and Relevance Score), a novel suite of five\nmetrics that utilizes a single, powerful, pretrained LLM as a zero-shot,\nend-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance\n(QR), Information Density (ID), Answer Correctness (AC), and Information Recall\n(IR). We apply CCRS to evaluate six diverse RAG system configurations on the\nchallenging BioASQ dataset. Our analysis demonstrates that CCRS effectively\ndiscriminates between system performances, confirming, for instance, that the\nMistral-7B reader outperforms Llama variants. We provide a detailed analysis of\nCCRS metric properties, including score distributions, convergent/discriminant\nvalidity, tie rates, population statistics, and discriminative power. Compared\nto the complex RAGChecker framework, CCRS offers comparable or superior\ndiscriminative power for key aspects like recall and faithfulness, while being\nsignificantly more computationally efficient. CCRS thus provides a practical,\ncomprehensive, and efficient framework for evaluating and iteratively improving\nRAG systems.\n","authors":["Aashiq Muhamed"],"pdf_url":"https://arxiv.org/pdf/2506.20128v1.pdf","comment":"Accepted at LLM4Eval @ SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.17289v2","updated":"2025-06-25T04:27:25Z","published":"2025-06-16T01:44:26Z","title":"Evaluating Generalization and Representation Stability in Small LMs via\n  Prompting, Fine-Tuning and Out-of-Distribution Prompts","summary":"  We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings. Beyond accuracy, we analyze the internal\nrepresentations learned by each approach to assess the stability and\nabstraction of task-specific features. Our findings highlight critical\ndifferences in how small models internalize and generalize knowledge under\ndifferent adaptation strategies. This work offers practical guidance for model\nselection in low-data regimes and contributes empirical insight into the\nongoing debate over prompting versus fine-tuning. Code for the experiments is\navailable at the following\n","authors":["Rahul Raja","Arpita Vats"],"pdf_url":"https://arxiv.org/pdf/2506.17289v2.pdf","comment":"Accepted at ICML"},{"id":"http://arxiv.org/abs/2506.20689v1","updated":"2025-06-25T04:10:09Z","published":"2025-06-25T04:10:09Z","title":"U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and\n  Vision Transformer for Accurate Semantic Segmentation of CMRs","summary":"  Artificial intelligence, including deep learning models, will play a\ntransformative role in automated medical image analysis for the diagnosis of\ncardiac disorders and their management. Automated accurate delineation of\ncardiac images is the first necessary initial step for the quantification and\nautomated diagnosis of cardiac disorders. In this paper, we propose a deep\nlearning based enhanced UNet model, U-R-Veda, which integrates convolution\ntransformations, vision transformer, residual links, channel-attention, and\nspatial attention, together with edge-detection based skip-connections for an\naccurate fully-automated semantic segmentation of cardiac magnetic resonance\n(CMR) images. The model extracts local-features and their interrelationships\nusing a stack of combination convolution blocks, with embedded channel and\nspatial attention in the convolution block, and vision transformers. Deep\nembedding of channel and spatial attention in the convolution block identifies\nimportant features and their spatial localization. The combined edge\ninformation with channel and spatial attention as skip connection reduces\ninformation-loss during convolution transformations. The overall model\nsignificantly improves the semantic segmentation of CMR images necessary for\nimproved medical image analysis. An algorithm for the dual attention module\n(channel and spatial attention) has been presented. Performance results show\nthat U-R-Veda achieves an average accuracy of 95.2%, based on DSC metrics. The\nmodel outperforms the accuracy attained by other models, based on DSC and HD\nmetrics, especially for the delineation of right-ventricle and\nleft-ventricle-myocardium.\n","authors":["Racheal Mukisa","Arvind K. Bansal"],"pdf_url":"https://arxiv.org/pdf/2506.20689v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05319v2","updated":"2025-06-25T03:53:34Z","published":"2025-03-07T10:58:38Z","title":"Robust Multimodal Learning for Ophthalmic Disease Grading via\n  Disentangled Representation","summary":"  This paper discusses how ophthalmologists often rely on multimodal data to\nimprove diagnostic accuracy. However, complete multimodal data is rare in\nreal-world applications due to a lack of medical equipment and concerns about\ndata privacy. Traditional deep learning methods typically address these issues\nby learning representations in latent space. However, the paper highlights two\nkey limitations of these approaches: (i) Task-irrelevant redundant information\n(e.g., numerous slices) in complex modalities leads to significant redundancy\nin latent space representations. (ii) Overlapping multimodal representations\nmake it difficult to extract unique features for each modality. To overcome\nthese challenges, the authors propose the Essence-Point and Disentangle\nRepresentation Learning (EDRL) strategy, which integrates a self-distillation\nmechanism into an end-to-end framework to enhance feature selection and\ndisentanglement for more robust multimodal learning. Specifically, the\nEssence-Point Representation Learning module selects discriminative features\nthat improve disease grading performance. The Disentangled Representation\nLearning module separates multimodal data into modality-common and\nmodality-unique representations, reducing feature entanglement and enhancing\nboth robustness and interpretability in ophthalmic disease diagnosis.\nExperiments on multimodal ophthalmology datasets show that the proposed EDRL\nstrategy significantly outperforms current state-of-the-art methods.\n","authors":["Xinkun Wang","Yifang Wang","Senwei Liang","Feilong Tang","Chengzhi Liu","Ming Hu","Chao Hu","Junjun He","Zongyuan Ge","Imran Razzak"],"pdf_url":"https://arxiv.org/pdf/2503.05319v2.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2506.20103v1","updated":"2025-06-25T03:30:04Z","published":"2025-06-25T03:30:04Z","title":"BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization\n  in AI-Generated Videos","summary":"  Recent advances in deep generative models have led to significant progress in\nvideo generation, yet the fidelity of AI-generated videos remains limited.\nSynthesized content often exhibits visual artifacts such as temporally\ninconsistent motion, physically implausible trajectories, unnatural object\ndeformations, and local blurring that undermine realism and user trust.\nAccurate detection and spatial localization of these artifacts are crucial for\nboth automated quality control and for guiding the development of improved\ngenerative models. However, the research community currently lacks a\ncomprehensive benchmark specifically designed for artifact localization in AI\ngenerated videos. Existing datasets either restrict themselves to video or\nframe level detection or lack the fine-grained spatial annotations necessary\nfor evaluating localization methods. To address this gap, we introduce\nBrokenVideos, a benchmark dataset of 3,254 AI-generated videos with\nmeticulously annotated, pixel-level masks highlighting regions of visual\ncorruption. Each annotation is validated through detailed human inspection to\nensure high quality ground truth. Our experiments show that training state of\nthe art artifact detection models and multi modal large language models (MLLMs)\non BrokenVideos significantly improves their ability to localize corrupted\nregions. Through extensive evaluation, we demonstrate that BrokenVideos\nestablishes a critical foundation for benchmarking and advancing research on\nartifact localization in generative video models. The dataset is available at:\nhttps://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.\n","authors":["Jiahao Lin","Weixuan Peng","Bojia Zi","Yifeng Gao","Xianbiao Qi","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.20103v1.pdf","comment":"7 page,4 figures,2 tables"},{"id":"http://arxiv.org/abs/2506.18251v2","updated":"2025-06-25T03:25:37Z","published":"2025-06-23T02:43:21Z","title":"Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models","summary":"  In this paper, we present Morse, a simple dual-sampling framework for\naccelerating diffusion models losslessly. The key insight of Morse is to\nreformulate the iterative generation (from noise to data) process via taking\nadvantage of fast jump sampling and adaptive residual feedback strategies.\nSpecifically, Morse involves two models called Dash and Dot that interact with\neach other. The Dash model is just the pre-trained diffusion model of any type,\nbut operates in a jump sampling regime, creating sufficient space for sampling\nefficiency improvement. The Dot model is significantly faster than the Dash\nmodel, which is learnt to generate residual feedback conditioned on the\nobservations at the current jump sampling point on the trajectory of the Dash\nmodel, lifting the noise estimate to easily match the next-step estimate of the\nDash model without jump sampling. By chaining the outputs of the Dash and Dot\nmodels run in a time-interleaved fashion, Morse exhibits the merit of flexibly\nattaining desired image generation performance while improving overall runtime\nefficiency. With our proposed weight sharing strategy between the Dash and Dot\nmodels, Morse is efficient for training and inference. Our method shows a\nlossless speedup of 1.78X to 3.31X on average over a wide range of sampling\nstep budgets relative to 9 baseline diffusion models on 6 image generation\ntasks. Furthermore, we show that our method can be also generalized to improve\nthe Latent Consistency Model (LCM-SDXL, which is already accelerated with\nconsistency distillation technique) tailored for few-step text-to-image\nsynthesis. The code and models are available at\nhttps://github.com/deep-optimization/Morse.\n","authors":["Chao Li","Jiawei Fan","Anbang Yao"],"pdf_url":"https://arxiv.org/pdf/2506.18251v2.pdf","comment":"Fixed a prompt typo in Figure 18 of the Appendix. This work is\n  accepted to ICML 2025. The project page:\n  https://github.com/deep-optimization/Morse"},{"id":"http://arxiv.org/abs/2506.20100v1","updated":"2025-06-25T03:07:54Z","published":"2025-06-25T03:07:54Z","title":"MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in\n  Agricultural Expert-Guided Conversations","summary":"  We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io\n","authors":["Vardhan Dongre","Chi Gui","Shubham Garg","Hooshang Nayyeri","Gokhan Tur","Dilek Hakkani-Tür","Vikram S. Adve"],"pdf_url":"https://arxiv.org/pdf/2506.20100v1.pdf","comment":"66 pages, 32 figures, 23 tables"},{"id":"http://arxiv.org/abs/2506.18023v2","updated":"2025-06-25T02:40:39Z","published":"2025-06-22T13:06:13Z","title":"PP-DocBee2: Improved Baselines with Efficient Data for Multimodal\n  Document Understanding","summary":"  This report introduces PP-DocBee2, an advanced version of the PP-DocBee,\ndesigned to enhance multimodal document understanding. Built on a large\nmultimodal model architecture, PP-DocBee2 addresses the limitations of its\npredecessor through key technological improvements, including enhanced\nsynthetic data quality, improved visual feature fusion strategy, and optimized\ninference methodologies. These enhancements yield an $11.4\\%$ performance boost\non internal benchmarks for Chinese business documents, and reduce inference\nlatency by $73.0\\%$ to the vanilla version. A key innovation of our work is a\ndata quality optimization strategy for multimodal document tasks. By employing\na large-scale multimodal pre-trained model to evaluate data, we apply a novel\nstatistical criterion to filter outliers, ensuring high-quality training data.\nInspired by insights into underutilized intermediate features in multimodal\nmodels, we enhance the ViT representational capacity by decomposing it into\nlayers and applying a novel feature fusion strategy to improve complex\nreasoning. The source code and pre-trained model are available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Kui Huang","Xinrong Chen","Wenyu Lv","Jincheng Liao","Guanzhong Wang","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2506.18023v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10978v2","updated":"2025-06-25T02:37:46Z","published":"2025-06-12T17:59:51Z","title":"Fine-Grained Perturbation Guidance via Attention Head Selection","summary":"  Recent guidance methods in diffusion models steer reverse sampling by\nperturbing the model to construct an implicit weak model and guide generation\naway from it. Among these approaches, attention perturbation has demonstrated\nstrong empirical performance in unconditional scenarios where classifier-free\nguidance is not applicable. However, existing attention perturbation methods\nlack principled approaches for determining where perturbations should be\napplied, particularly in Diffusion Transformer (DiT) architectures where\nquality-relevant computations are distributed across layers. In this paper, we\ninvestigate the granularity of attention perturbations, ranging from the layer\nlevel down to individual attention heads, and discover that specific heads\ngovern distinct visual concepts such as structure, style, and texture quality.\nBuilding on this insight, we propose \"HeadHunter\", a systematic framework for\niteratively selecting attention heads that align with user-centric objectives,\nenabling fine-grained control over generation quality and visual attributes. In\naddition, we introduce SoftPAG, which linearly interpolates each selected\nhead's attention map toward an identity matrix, providing a continuous knob to\ntune perturbation strength and suppress artifacts. Our approach not only\nmitigates the oversmoothing issues of existing layer-level perturbation but\nalso enables targeted manipulation of specific visual styles through\ncompositional head selection. We validate our method on modern large-scale\nDiT-based text-to-image models including Stable Diffusion 3 and FLUX.1,\ndemonstrating superior performance in both general quality enhancement and\nstyle-specific guidance. Our work provides the first head-level analysis of\nattention perturbation in diffusion models, uncovering interpretable\nspecialization within attention layers and enabling practical design of\neffective perturbation strategies.\n","authors":["Donghoon Ahn","Jiwon Kang","Sanghyun Lee","Minjae Kim","Jaewon Min","Wooseok Jang","Saungwu Lee","Sayak Paul","Susung Hong","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2506.10978v2.pdf","comment":"Project page: https://cvlab-kaist.github.io/HeadHunter/"},{"id":"http://arxiv.org/abs/2411.14499v2","updated":"2025-06-25T02:31:33Z","published":"2024-11-21T03:58:50Z","title":"Understanding World or Predicting Future? A Comprehensive Survey of\n  World Models","summary":"  The concept of world models has garnered significant attention due to\nadvancements in multimodal large language models such as GPT-4 and video\ngeneration models such as Sora, which are central to the pursuit of artificial\ngeneral intelligence. This survey offers a comprehensive review of the\nliterature on world models. Generally, world models are regarded as tools for\neither understanding the present state of the world or predicting its future\ndynamics. This review presents a systematic categorization of world models,\nemphasizing two primary functions: (1) constructing internal representations to\nunderstand the mechanisms of the world, and (2) predicting future states to\nsimulate and guide decision-making. Initially, we examine the current progress\nin these two categories. We then explore the application of world models in key\ndomains, including autonomous driving, robotics, and social simulacra, with a\nfocus on how each domain utilizes these aspects. Finally, we outline key\nchallenges and provide insights into potential future research directions. We\nsummarize the representative papers along with their code repositories in\nhttps://github.com/tsinghua-fib-lab/World-Model.\n","authors":["Jingtao Ding","Yunke Zhang","Yu Shang","Yuheng Zhang","Zefang Zong","Jie Feng","Yuan Yuan","Hongyuan Su","Nian Li","Nicholas Sukiennik","Fengli Xu","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.14499v2.pdf","comment":"Accepted by ACM CSUR, 37 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2502.17419v6","updated":"2025-06-25T02:24:46Z","published":"2025-02-24T18:50:52Z","title":"From System 1 to System 2: A Survey of Reasoning Large Language Models","summary":"  Achieving human-level intelligence requires refining the transition from the\nfast, intuitive System 1 to the slower, more deliberate System 2 reasoning.\nWhile System 1 excels in quick, heuristic decisions, System 2 relies on logical\nreasoning for more accurate judgments and reduced biases. Foundational Large\nLanguage Models (LLMs) excel at fast decision-making but lack the depth for\ncomplex reasoning, as they have not yet fully embraced the step-by-step\nanalysis characteristic of true System 2 thinking. Recently, reasoning LLMs\nlike OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level\nperformance in fields such as mathematics and coding, closely mimicking the\ndeliberate reasoning of System 2 and showcasing human-like cognitive abilities.\nThis survey begins with a brief overview of the progress in foundational LLMs\nand the early development of System 2 technologies, exploring how their\ncombination has paved the way for reasoning LLMs. Next, we discuss how to\nconstruct reasoning LLMs, analyzing their features, the core methods enabling\nadvanced reasoning, and the evolution of various reasoning LLMs. Additionally,\nwe provide an overview of reasoning benchmarks, offering an in-depth comparison\nof the performance of representative reasoning LLMs. Finally, we explore\npromising directions for advancing reasoning LLMs and maintain a real-time\n\\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub\nRepository} to track the latest developments. We hope this survey will serve as\na valuable resource to inspire innovation and drive progress in this rapidly\nevolving field.\n","authors":["Zhong-Zhi Li","Duzhen Zhang","Ming-Liang Zhang","Jiaxin Zhang","Zengyan Liu","Yuxuan Yao","Haotian Xu","Junhao Zheng","Pei-Jie Wang","Xiuyi Chen","Yingying Zhang","Fei Yin","Jiahua Dong","Zhiwei Li","Bao-Long Bi","Ling-Rui Mei","Junfeng Fang","Xiao Liang","Zhijiang Guo","Le Song","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2502.17419v6.pdf","comment":"Slow-thinking, Large Language Models, Human-like Reasoning, Decision\n  Making in AI, AGI"},{"id":"http://arxiv.org/abs/2505.24765v5","updated":"2025-06-25T02:08:22Z","published":"2025-05-30T16:29:12Z","title":"Supervised Quantum Machine Learning: A Future Outlook from Qubits to\n  Enterprise Applications","summary":"  Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.\n","authors":["Srikanth Thudumu","Jason Fisher","Hung Du"],"pdf_url":"https://arxiv.org/pdf/2505.24765v5.pdf","comment":"Future outlook and roadmap of QML with 7 pages and 1 figure"},{"id":"http://arxiv.org/abs/2505.19550v3","updated":"2025-06-25T01:55:54Z","published":"2025-05-26T06:13:15Z","title":"Turing Test 2.0: The General Intelligence Threshold","summary":"  With the rise of artificial intelligence (A.I.) and large language models\nlike ChatGPT, a new race for achieving artificial general intelligence (A.G.I)\nhas started. While many speculate how and when A.I. will achieve A.G.I., there\nis no clear agreement on how A.G.I. can be detected in A.I. models, even when\npopular tools like the Turing test (and its modern variations) are used to\nmeasure their intelligence. In this work, we discuss why traditional methods\nlike the Turing test do not suffice for measuring or detecting A.G.I. and\nprovide a new, practical method that can be used to decide if a system\n(computer or any other) has reached or surpassed A.G.I. To achieve this, we\nmake two new contributions. First, we present a clear definition for general\nintelligence (G.I.) and set a G.I. Threshold (G.I.T.) that can be used to\ndistinguish between systems that achieve A.G.I. and systems that do not.\nSecond, we present a new framework on how to construct tests that can detect if\na system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass\nway. We call this novel framework the Turing test 2.0. We then demonstrate\nreal-life examples of applying tests that follow our Turing test 2.0 framework\non modern A.I. models.\n","authors":["Georgios Mappouras"],"pdf_url":"https://arxiv.org/pdf/2505.19550v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18213v2","updated":"2025-06-25T01:49:52Z","published":"2025-05-22T22:24:31Z","title":"AIDRIN 2.0: A Framework to Assess Data Readiness for AI","summary":"  AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve\ndata preparedness for AI applications. It addresses critical data readiness\ndimensions such as data quality, bias, fairness, and privacy. This paper\ndetails enhancements to AIDRIN by focusing on user interface improvements and\nintegration with a privacy-preserving federated learning (PPFL) framework. By\nrefining the UI and enabling smooth integration with decentralized AI\npipelines, AIDRIN becomes more accessible and practical for users with varying\ntechnical expertise. Integrating with an existing PPFL framework ensures that\ndata readiness and privacy are prioritized in federated learning environments.\nA case study involving a real-world dataset demonstrates AIDRIN's practical\nvalue in identifying data readiness issues that impact AI model performance.\n","authors":["Kaveen Hiniduma","Dylan Ryan","Suren Byna","Jean Luca Bez","Ravi Madduri"],"pdf_url":"https://arxiv.org/pdf/2505.18213v2.pdf","comment":"3 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.19028v2","updated":"2025-06-25T01:21:47Z","published":"2025-06-23T18:31:22Z","title":"Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical\n  Perspective","summary":"  Large Language Models (LLMs) often generate responses with inherent biases,\nundermining their reliability in real-world applications. Existing evaluation\nmethods often overlook biases in long-form responses and the intrinsic\nvariability of LLM outputs. To address these challenges, we propose\nFiSCo(Fine-grained Semantic Computation), a novel statistical framework to\nevaluate group-level fairness in LLMs by detecting subtle semantic differences\nin long-form responses across demographic groups. Unlike prior work focusing on\nsentiment or token-level comparisons, FiSCo goes beyond surface-level analysis\nby operating at the claim level, leveraging entailment checks to assess the\nconsistency of meaning across responses. We decompose model outputs into\nsemantically distinct claims and apply statistical hypothesis testing to\ncompare inter- and intra-group similarities, enabling robust detection of\nsubtle biases. We formalize a new group counterfactual fairness definition and\nvalidate FiSCo on both synthetic and human-annotated datasets spanning gender,\nrace, and age. Experiments show that FiSco more reliably identifies nuanced\nbiases while reducing the impact of stochastic LLM variability, outperforming\nvarious evaluation metrics.\n","authors":["Weijie Xu","Yiwen Wang","Chi Xue","Xiangkun Hu","Xi Fang","Guimin Dong","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2506.19028v2.pdf","comment":"29 pages, 9 figures, 15 tables"},{"id":"http://arxiv.org/abs/2506.18240v2","updated":"2025-06-25T01:01:03Z","published":"2025-06-23T02:12:36Z","title":"Quantum-Classical Hybrid Quantized Neural Network","summary":"  Here in this work, we present a novel Quadratic Binary Optimization (QBO)\nmodel for quantized neural network training, enabling the use of arbitrary\nactivation and loss functions through spline interpolation. We introduce\nForward Interval Propagation (FIP), a method designed to tackle the challenges\nof non-linearity and the multi-layer composite structure in neural networks by\ndiscretizing activation functions into linear subintervals. This approach\npreserves the universal approximation properties of neural networks while\nallowing complex nonlinear functions to be optimized using quantum computers,\nthus broadening their applicability in artificial intelligence. We provide\ntheoretical upper bounds on the approximation error and the number of Ising\nspins required, by deriving the sample complexity of the empirical risk\nminimization problem, from an optimization perspective. A significant challenge\nin solving the associated Quadratic Constrained Binary Optimization (QCBO)\nmodel on a large scale is the presence of numerous constraints. When employing\nthe penalty method to handle these constraints, tuning a large number of\npenalty coefficients becomes a critical hyperparameter optimization problem,\nincreasing computational complexity and potentially affecting solution quality.\nTo address this, we employ the Quantum Conditional Gradient Descent (QCGD)\nalgorithm, which leverages quantum computing to directly solve the QCBO\nproblem. We prove the convergence of QCGD under a quantum oracle with\nrandomness and bounded variance in objective value, as well as under limited\nprecision constraints in the coefficient matrix. Additionally, we provide an\nupper bound on the Time-To-Solution for the QCBO solving process. Experimental\nresults using a coherent Ising machine (CIM) demonstrate a 94.95% accuracy on\nthe Fashion MNIST classification task, with only 1.1-bit precision.\n","authors":["Wenxin Li","Chuan Wang","Hongdong Zhu","Qi Gao","Yin Ma","Hai Wei","Kai Wen"],"pdf_url":"https://arxiv.org/pdf/2506.18240v2.pdf","comment":"27 pages, 5 figures, comments are welcome"},{"id":"http://arxiv.org/abs/2506.20073v1","updated":"2025-06-25T00:55:34Z","published":"2025-06-25T00:55:34Z","title":"A Modular Multitask Reasoning Framework Integrating Spatio-temporal\n  Models and LLMs","summary":"  Spatio-temporal data mining plays a pivotal role in informed decision making\nacross diverse domains. However, existing models are often restricted to narrow\ntasks, lacking the capacity for multi-task inference and complex long-form\nreasoning that require generation of in-depth, explanatory outputs. These\nlimitations restrict their applicability to real-world, multi-faceted decision\nscenarios. In this work, we introduce STReason, a novel framework that\nintegrates the reasoning strengths of large language models (LLMs) with the\nanalytical capabilities of spatio-temporal models for multi-task inference and\nexecution. Without requiring task-specific finetuning, STReason leverages\nin-context learning to decompose complex natural language queries into modular,\ninterpretable programs, which are then systematically executed to generate both\nsolutions and detailed rationales. To facilitate rigorous evaluation, we\nconstruct a new benchmark dataset and propose a unified evaluation framework\nwith metrics specifically designed for long-form spatio-temporal reasoning.\nExperimental results show that STReason significantly outperforms advanced LLM\nbaselines across all metrics, particularly excelling in complex,\nreasoning-intensive spatio-temporal scenarios. Human evaluations further\nvalidate STReason's credibility and practical utility, demonstrating its\npotential to reduce expert workload and broaden the applicability to real-world\nspatio-temporal tasks. We believe STReason provides a promising direction for\ndeveloping more capable and generalizable spatio-temporal reasoning systems.\n","authors":["Kethmi Hirushini Hettige","Jiahao Ji","Cheng Long","Shili Xiang","Gao Cong","Jingyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2506.20073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08557v3","updated":"2025-06-25T00:47:40Z","published":"2023-11-14T21:39:15Z","title":"Low-light Pedestrian Detection in Visible and Infrared Image Feeds:\n  Issues and Challenges","summary":"  Pedestrian detection has become a cornerstone for several high-level tasks,\nincluding autonomous driving, intelligent transportation, and traffic\nsurveillance. There are several works focussed on pedestrian detection using\nvisible images, mainly in the daytime. However, this task is very intriguing\nwhen the environmental conditions change to poor lighting or nighttime.\nRecently, new ideas have been spurred to use alternative sources, such as Far\nInfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light\nconditions. This study reviews recent developments in low-light pedestrian\ndetection approaches. It systematically categorizes and analyses various\nalgorithms from region-based to non-region-based and graph-based learning\nmethodologies by highlighting their methodologies, implementation issues, and\nchallenges. It also outlines the key benchmark datasets that can be used for\nresearch and development of advanced pedestrian detection algorithms,\nparticularly in low-light situations.\n","authors":["Thangarajah Akilan","Hrishikesh Vachhani"],"pdf_url":"https://arxiv.org/pdf/2311.08557v3.pdf","comment":"29 pages, 4 tables, 21 figures"},{"id":"http://arxiv.org/abs/2503.13305v3","updated":"2025-06-25T00:26:59Z","published":"2025-03-17T15:47:37Z","title":"Computation Mechanism Behind LLM Position Generalization","summary":"  Most written natural languages are composed of sequences of words and\nsentences. Similar to humans, large language models (LLMs) exhibit flexibility\nin handling textual positions - a phenomenon we term position generalization.\nThey can understand texts with position perturbations and generalize to longer\ntexts than those encountered during training with the latest techniques. These\nphenomena suggest that LLMs handle positions tolerantly, but how LLMs\ncomputationally process positional relevance remains largely unexplored. This\nwork connects the linguistic phenomenon with LLMs' computational mechanisms. We\nshow how LLMs enforce certain computational mechanisms for the aforementioned\ntolerance in position perturbations. Despite the complex design of the\nself-attention mechanism, this work reveals that LLMs learn a counterintuitive\ndisentanglement of attention logits. Their values show a 0.959 linear\ncorrelation with an approximation of the arithmetic sum of positional relevance\nand semantic importance. Furthermore, we identify a prevalent pattern in\nintermediate features, which we prove theoretically enables this effect. The\npattern, which is different from how randomly initialized parameters would\nbehave, suggests that it is a learned behavior rather than a natural result of\nthe model architecture. Based on these findings, we provide computational\nexplanations and criteria for LLMs' position flexibilities. This work takes a\npioneering step in linking position generalization with modern LLMs' internal\nmechanisms.\n","authors":["Chi Han","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2503.13305v3.pdf","comment":"ACL 2025 Main Long Paper"},{"id":"http://arxiv.org/abs/2506.19143v2","updated":"2025-06-25T00:18:53Z","published":"2025-06-23T21:28:45Z","title":"Thought Anchors: Which LLM Reasoning Steps Matter?","summary":"  Reasoning large language models have recently achieved state-of-the-art\nperformance in many fields. However, their long-form chain-of-thought reasoning\ncreates interpretability challenges as each generated token depends on all\nprevious ones, making the computation harder to decompose. We argue that\nanalyzing reasoning traces at the sentence level is a promising approach to\nunderstanding reasoning processes. We present three complementary attribution\nmethods: (1) a black-box method measuring each sentence's counterfactual\nimportance by comparing final answers across 100 rollouts conditioned on the\nmodel generating that sentence or one with a different meaning; (2) a white-box\nmethod of aggregating attention patterns between pairs of sentences, which\nidentified \"broadcasting\" sentences that receive disproportionate attention\nfrom all future sentences via \"receiver\" attention heads; (3) a causal\nattribution method measuring logical connections between sentences by\nsuppressing attention toward one sentence and measuring the effect on each\nfuture sentence's tokens. Each method provides evidence for the existence of\nthought anchors, reasoning steps that have outsized importance and that\ndisproportionately influence the subsequent reasoning process. These thought\nanchors are typically planning or backtracking sentences. We provide an\nopen-source tool (www.thought-anchors.com) for visualizing the outputs of our\nmethods, and present a case study showing converging patterns across methods\nthat map how a model performs multi-step reasoning. The consistency across\nmethods demonstrates the potential of sentence-level analysis for a deeper\nunderstanding of reasoning models.\n","authors":["Paul C. Bogdan","Uzay Macar","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2506.19143v2.pdf","comment":"Paul C. Bogdan and Uzay Macar contributed equally to this work, and\n  their listed order was determined by coinflip. Neel Nanda and Arthur Conmy\n  contributed equally to this work as senior authors, and their listed order\n  was determined by coinflip"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2506.20893v1","updated":"2025-06-25T23:53:56Z","published":"2025-06-25T23:53:56Z","title":"On the Necessity of Output Distribution Reweighting for Effective Class\n  Unlearning","summary":"  In this work, we introduce an output-reweighting unlearning method, RWFT, a\nlightweight technique that erases an entire class from a trained classifier\nwithout full retraining. Forgetting specific classes from trained models is\nessential for enforcing user deletion rights and mitigating harmful or biased\npredictions. The full retraining is costly and existing unlearning methods fail\nto replicate the behavior of the retrained models when predicting samples from\nthe unlearned class. We prove this failure by designing a variant of membership\ninference attacks, MIA-NN that successfully reveals the unlearned class for any\nof these methods. We propose a simple redistribution of the probability mass\nfor the prediction on the samples in the forgotten class which is robust to\nMIA-NN. We also introduce a new metric based on the total variation (TV)\ndistance of the prediction probabilities to quantify residual leakage to\nprevent future methods from susceptibility to the new attack. Through extensive\nexperiments with state of the art baselines in machine unlearning, we show that\nour approach matches the results of full retraining in both metrics used for\nevaluation by prior work and the new metric we propose in this work. Compare to\nstate-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%\nin our new TV-based metric over the best existing method.\n","authors":["Yian Wang","Ali Ebrahimpour-Boroojeny","Hari Sundaram"],"pdf_url":"https://arxiv.org/pdf/2506.20893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13718v3","updated":"2025-06-25T23:53:42Z","published":"2024-05-22T15:09:41Z","title":"Next-token prediction capacity: general upper bounds and a lower bound\n  for transformers","summary":"  Given a sequence of tokens, such as words, the task of next-token prediction\nis to predict the next-token conditional probability distribution. Decoder-only\ntransformers have become effective models for this task, but their properties\nare still not fully understood. In particular, the largest number of distinct\ncontext sequences that a decoder-only transformer can interpolate next-token\ndistributions for has not been established. To fill this gap, we prove upper\nand lower bounds on this number, which are equal up to a multiplicative\nconstant. We prove these bounds in the general setting where next-token\ndistributions can be arbitrary as well as the empirical setting where they are\ncalculated from a finite number of document sequences. Our lower bounds are for\none-layer multi-head decoder-only transformers and our proofs highlight an\nimportant injectivity property satisfied by self-attention. Furthermore, we\nprovide numerical evidence that the minimal number of parameters for\nmemorization is sufficient for being able to train the model to the entropy\nlower bound.\n","authors":["Liam Madden","Curtis Fox","Christos Thrampoulidis"],"pdf_url":"https://arxiv.org/pdf/2405.13718v3.pdf","comment":"V3: added two examples, a remark, and a second experiment where only\n  the FNN layers are trained"},{"id":"http://arxiv.org/abs/2506.20886v1","updated":"2025-06-25T23:36:44Z","published":"2025-06-25T23:36:44Z","title":"Omniwise: Predicting GPU Kernels Performance with LLMs","summary":"  In recent years, the rapid advancement of deep neural networks (DNNs) has\nrevolutionized artificial intelligence, enabling models with unprecedented\ncapabilities in understanding, generating, and processing complex data. These\npowerful architectures have transformed a wide range of downstream\napplications, tackling tasks beyond human reach. In this paper, we introduce\nOmniwise, the first end-to-end, self-supervised fine-tuning pipeline that\napplies large language models (LLMs) to GPU kernel performance prediction--a\nnovel use case in performance profiling. Omniwise is model-agnostic and\nlightweight, achieving strong results even with a small 3B-parameter model. It\ncan predict key performance metrics, including memory bandwidth, cache hit\nrates, GFLOPs, and arithmetic intensity, directly from kernel code without the\nneed for code execution or profiling tools. Our approach achieves over 90% of\npredictions within 10% relative error on GPU kernels executed on AMD MI250 and\nMI300X architectures. In addition to the pipeline, we develop an online\ninference server and a Visual Studio Code plugin that seamlessly integrate\nLLM-based performance prediction into developers' workflows.\n","authors":["Zixian Wang","Cole Ramos","Muhammad A. Awad","Keith Lowery"],"pdf_url":"https://arxiv.org/pdf/2506.20886v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05090v2","updated":"2025-06-25T23:23:23Z","published":"2024-10-07T14:42:45Z","title":"HyperINF: Unleashing the HyperPower of the Schulz's Method for Data\n  Influence Estimation","summary":"  Influence functions provide a principled method to assess the contribution of\nindividual training samples to a specific target. Yet, their high computational\ncosts limit their applications on large-scale models and datasets. Existing\nmethods proposed for influence function approximation have significantly\nreduced the computational overheads. However, they mostly suffer from\ninaccurate estimation due to the lack of strong convergence guarantees from the\nalgorithm. The family of hyperpower methods are well-known for their rigorous\nconvergence guarantees on matrix inverse approximation, while the matrix\nmultiplication operation can involve intractable memory and computation costs\non large-scale models. We propose HyperINF, an efficient and accurate influence\nfunction approximation method which leverages the hyperpower method,\nspecifically Schulz's iterative algorithm. To deal with the\ncomputation-intensive matrix multiplication, we incorporate the generalized\nfisher information (GFIM) as a low-rank approximation of the Hessian matrix,\nwhich reduces the memory and computation overheads to constant costs\nindependent of ranks on LoRA-tuned models. We first demonstrate the superior\naccuracy and stability of HyperINF compared to other baselines through a\nsynthetic convergence simulation for matrix inversion. We further validate the\nefficacy of HyperINF through extensive real-world data attribution tasks,\nincluding mislabeled data detection and data selection for LLM and VLM\nfine-tuning. On LoRA-tuned models, HyperINF achieves superior downstream\nperformance with minimal memory and computational overhead, while other\nbaselines suffer from significant degradation. Our codebase is available at\nhttps://github.com/Blackzxy/HyperINF.\n","authors":["Xinyu Zhou","Simin Fan","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2410.05090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20883v1","updated":"2025-06-25T23:10:12Z","published":"2025-06-25T23:10:12Z","title":"Complex Model Transformations by Reinforcement Learning with Uncertain\n  Human Guidance","summary":"  Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.\n","authors":["Kyanna Dagenais","Istvan David"],"pdf_url":"https://arxiv.org/pdf/2506.20883v1.pdf","comment":"Accepted for ACM/IEEE MODELS'25"},{"id":"http://arxiv.org/abs/2407.11933v2","updated":"2025-06-25T23:07:40Z","published":"2024-07-16T17:23:41Z","title":"Fairly Accurate: Fairness-aware Multi-group Target Detection in Online\n  Discussion","summary":"  Target-group detection is the task of detecting which group(s) a social media\npost is ``directed at or about'', with various applications, such as\ntargeted-marketing. In this work, we focus on the fairness implications of\ntarget-group detection in the context of toxicity detection, where the\nperceived harm of a post often depends on which group(s) it targets. Because\ntoxicity is highly contextual, language that appears benign in general may be\nharmful when targeting specific demographic groups. It is thus important to\nfirst detect which group(s) are being {\\em targeted} by a post as a precursor\nto the subsequent task of determining whether the post is toxic given the\ngroup(s). Target-group detection is also challenging: a single post may\nsimultaneously target one to many groups, and we must detect groups fairly in\norder to promote equitable treatment. We show that our proposed approach to\n{\\em fairness-aware multi target-group detection} not only reduces bias across\ngroups, but also achieves competitive predictive performance, outperforming\nexisting fairness-aware baselines. To spur future research on fairness-aware\ntarget-group detection and support competitive benchmarking, we also share our\ncode.\n","authors":["Soumyajit Gupta","Maria De-Arteaga","Matthew Lease"],"pdf_url":"https://arxiv.org/pdf/2407.11933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.01996v2","updated":"2025-06-25T23:06:43Z","published":"2025-05-04T05:42:21Z","title":"Always Skip Attention","summary":"  We highlight a curious empirical result within modern Vision Transformers\n(ViTs). Specifically, self-attention catastrophically fails to train unless it\nis used in conjunction with a skip connection. This is in contrast to other\nelements of a ViT that continue to exhibit good performance (albeit suboptimal)\nwhen skip connections are removed. Further, we show that this critical\ndependence on skip connections is a relatively new phenomenon, with previous\ndeep architectures (\\eg, CNNs) exhibiting good performance in their absence. In\nthis paper, we theoretically characterize that the self-attention mechanism is\nfundamentally ill-conditioned and is, therefore, uniquely dependent on skip\nconnections for regularization. Additionally, we propose Token Graying -- a\nsimple yet effective complement (to skip connections) that further improves the\ncondition of input tokens. We validate our approach in both supervised and\nself-supervised training methods.\n","authors":["Yiping Ji","Hemanth Saratchandran","Peyman Moghadam","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2505.01996v2.pdf","comment":"This work has just been accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2505.12942v3","updated":"2025-06-25T23:03:54Z","published":"2025-05-19T10:29:32Z","title":"A3 : an Analytical Low-Rank Approximation Framework for Attention","summary":"  Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.\n","authors":["Jeffrey T. H. Wong","Cheng Zhang","Xinye Cao","Pedro Gimenes","George A. Constantinides","Wayne Luk","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2505.12942v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20872v1","updated":"2025-06-25T22:46:30Z","published":"2025-06-25T22:46:30Z","title":"Empowering Digital Agriculture: A Privacy-Preserving Framework for Data\n  Sharing and Collaborative Research","summary":"  Data-driven agriculture, which integrates technology and data into\nagricultural practices, has the potential to improve crop yield, disease\nresilience, and long-term soil health. However, privacy concerns, such as\nadverse pricing, discrimination, and resource manipulation, deter farmers from\nsharing data, as it can be used against them. To address this barrier, we\npropose a privacy-preserving framework that enables secure data sharing and\ncollaboration for research and development while mitigating privacy risks. The\nframework combines dimensionality reduction techniques (like Principal\nComponent Analysis (PCA)) and differential privacy by introducing Laplacian\nnoise to protect sensitive information. The proposed framework allows\nresearchers to identify potential collaborators for a target farmer and train\npersonalized machine learning models either on the data of identified\ncollaborators via federated learning or directly on the aggregated\nprivacy-protected data. It also allows farmers to identify potential\ncollaborators based on similarities. We have validated this on real-life\ndatasets, demonstrating robust privacy protection against adversarial attacks\nand utility performance comparable to a centralized system. We demonstrate how\nthis framework can facilitate collaboration among farmers and help researchers\npursue broader research objectives. The adoption of the framework can empower\nresearchers and policymakers to leverage agricultural data responsibly, paving\nthe way for transformative advances in data-driven agriculture. By addressing\ncritical privacy challenges, this work supports secure data integration,\nfostering innovation and sustainability in agricultural systems.\n","authors":["Osama Zafar","Rosemarie Santa González","Mina Namazi","Alfonso Morales","Erman Ayday"],"pdf_url":"https://arxiv.org/pdf/2506.20872v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2409.06069"},{"id":"http://arxiv.org/abs/2306.11017v2","updated":"2025-06-25T22:16:22Z","published":"2023-06-19T15:29:32Z","title":"High-dimensional Contextual Bandit Problem without Sparsity","summary":"  In this research, we investigate the high-dimensional linear contextual\nbandit problem where the number of features $p$ is greater than the budget $T$,\nor it may even be infinite. Differing from the majority of previous works in\nthis field, we do not impose sparsity on the regression coefficients. Instead,\nwe rely on recent findings on overparameterized models, which enables us to\nanalyze the performance of the minimum-norm interpolating estimator when data\ndistributions have small effective ranks. We propose an explore-then-commit\n(EtC) algorithm to address this problem and examine its performance. Through\nour analysis, we derive the optimal rate of the ETC algorithm in terms of $T$\nand show that this rate can be achieved by balancing exploration and\nexploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC)\nalgorithm that adaptively finds the optimal balance. We assess the performance\nof the proposed algorithms through a series of simulations.\n","authors":["Junpei Komiyama","Masaaki Imaizumi"],"pdf_url":"https://arxiv.org/pdf/2306.11017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20856v1","updated":"2025-06-25T22:01:25Z","published":"2025-06-25T22:01:25Z","title":"Leaner Training, Lower Leakage: Revisiting Memorization in LLM\n  Fine-Tuning with LoRA","summary":"  Memorization in large language models (LLMs) makes them vulnerable to data\nextraction attacks. While pre-training memorization has been extensively\nstudied, fewer works have explored its impact in fine-tuning, particularly for\nLoRA fine-tuning, a widely adopted parameter-efficient method.\n  In this work, we re-examine memorization in fine-tuning and uncover a\nsurprising divergence from prior findings across different fine-tuning\nstrategies. Factors such as model scale and data duplication, which strongly\ninfluence memorization in pre-training and full fine-tuning, do not follow the\nsame trend in LoRA fine-tuning. Using a more relaxed similarity-based\nmemorization metric, we demonstrate that LoRA significantly reduces\nmemorization risks compared to full fine-tuning, while still maintaining strong\ntask performance.\n","authors":["Fei Wang","Baochun Li"],"pdf_url":"https://arxiv.org/pdf/2506.20856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00460v2","updated":"2025-06-25T22:00:25Z","published":"2025-05-01T11:28:18Z","title":"Subspace-Distance-Enabled Active Learning for Efficient Data-Driven\n  Model Reduction of Parametric Dynamical Systems","summary":"  In situations where the solution of a high-fidelity dynamical system needs to\nbe evaluated repeatedly, over a vast pool of parametric configurations and in\nabsence of access to the underlying governing equations, data-driven model\nreduction techniques are preferable. We propose a novel active learning\napproach to build a parametric data-driven reduced-order model (ROM) by\ngreedily picking the most important parameter samples from the parameter\ndomain. As a result, during the ROM construction phase, the number of\nhigh-fidelity solutions dynamically grow in a principled fashion. The\nhigh-fidelity solution snapshots are expressed in several parameter-specific\nlinear subspaces, with the help of proper orthogonal decomposition (POD), and\nthe relative distance between these subspaces is used as a guiding mechanism to\nperform active learning. For successfully achieving this, we provide a distance\nmeasure to evaluate the similarity between pairs of linear subspaces with\ndifferent dimensions, and also show that this distance measure is a metric. The\nusability of the proposed subspace-distance-enabled active learning (SDE-AL)\nframework is demonstrated by augmenting two existing non-intrusive\nreduced-order modeling approaches, and providing their active-learning-driven\n(ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN.\nFurthermore, we report positive results for two parametric physical models,\nhighlighting the efficiency of the proposed SDE-AL approach.\n","authors":["Harshit Kapadia","Peter Benner","Lihong Feng"],"pdf_url":"https://arxiv.org/pdf/2505.00460v2.pdf","comment":"31 pages, 10 figures, 4 tables; v2: minor improvements"},{"id":"http://arxiv.org/abs/2506.20853v1","updated":"2025-06-25T21:56:30Z","published":"2025-06-25T21:56:30Z","title":"Multi-Objective Reinforcement Learning for Cognitive Radar Resource\n  Management","summary":"  The time allocation problem in multi-function cognitive radar systems focuses\non the trade-off between scanning for newly emerging targets and tracking the\npreviously detected targets. We formulate this as a multi-objective\noptimization problem and employ deep reinforcement learning to find\nPareto-optimal solutions and compare deep deterministic policy gradient (DDPG)\nand soft actor-critic (SAC) algorithms. Our results demonstrate the\neffectiveness of both algorithms in adapting to various scenarios, with SAC\nshowing improved stability and sample efficiency compared to DDPG. We further\nemploy the NSGA-II algorithm to estimate an upper bound on the Pareto front of\nthe considered problem. This work contributes to the development of more\nefficient and adaptive cognitive radar systems capable of balancing multiple\ncompeting objectives in dynamic environments.\n","authors":["Ziyang Lu","Subodh Kalia","M. Cenk Gursoy","Chilukuri K. Mohan","Pramod K. Varshney"],"pdf_url":"https://arxiv.org/pdf/2506.20853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09852v3","updated":"2025-06-25T21:48:04Z","published":"2024-11-15T00:20:36Z","title":"InterFormer: Effective Heterogeneous Interaction Learning for\n  Click-Through Rate Prediction","summary":"  Click-through rate (CTR) prediction, which predicts the probability of a user\nclicking an ad, is a fundamental task in recommender systems. The emergence of\nheterogeneous information, such as user profile and behavior sequences, depicts\nuser interests from different aspects. A mutually beneficial integration of\nheterogeneous information is the cornerstone towards the success of CTR\nprediction. However, most of the existing methods suffer from two fundamental\nlimitations, including (1) insufficient inter-mode interaction due to the\nunidirectional information flow between modes, and (2) aggressive information\naggregation caused by early summarization, resulting in excessive information\nloss. To address the above limitations, we propose a novel module named\nInterFormer to learn heterogeneous information interaction in an interleaving\nstyle. To achieve better interaction learning, InterFormer enables\nbidirectional information flow for mutually beneficial learning across\ndifferent modes. To avoid aggressive information aggregation, we retain\ncomplete information in each data mode and use a separate bridging arch for\neffective information selection and summarization. Our proposed InterFormer\nachieves state-of-the-art performance on three public datasets and a\nlarge-scale industrial dataset.\n","authors":["Zhichen Zeng","Xiaolong Liu","Mengyue Hang","Xiaoyi Liu","Qinghai Zhou","Chaofei Yang","Yiqun Liu","Yichen Ruan","Laming Chen","Yuxin Chen","Yujia Hao","Jiaqi Xu","Jade Nie","Xi Liu","Buyun Zhang","Wei Wen","Siyang Yuan","Hang Yin","Xin Zhang","Kai Wang","Wen-Yen Chen","Yiping Han","Huayu Li","Chunzhi Yang","Bo Long","Philip S. Yu","Hanghang Tong","Jiyan Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09852v3.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.20849v1","updated":"2025-06-25T21:44:07Z","published":"2025-06-25T21:44:07Z","title":"Learning-Based Resource Management in Integrated Sensing and\n  Communication Systems","summary":"  In this paper, we tackle the task of adaptive time allocation in integrated\nsensing and communication systems equipped with radar and communication units.\nThe dual-functional radar-communication system's task involves allocating dwell\ntimes for tracking multiple targets and utilizing the remaining time for data\ntransmission towards estimated target locations. We introduce a novel\nconstrained deep reinforcement learning (CDRL) approach, designed to optimize\nresource allocation between tracking and communication under time budget\nconstraints, thereby enhancing target communication quality. Our numerical\nresults demonstrate the efficiency of our proposed CDRL framework, confirming\nits ability to maximize communication quality in highly dynamic environments\nwhile adhering to time constraints.\n","authors":["Ziyang Lu","M. Cenk Gursoy","Chilukuri K. Mohan","Pramod K. Varshney"],"pdf_url":"https://arxiv.org/pdf/2506.20849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18927v2","updated":"2025-06-25T21:42:13Z","published":"2025-06-21T05:09:07Z","title":"From Tiny Machine Learning to Tiny Deep Learning: A Survey","summary":"  The rapid growth of edge devices has driven the demand for deploying\nartificial intelligence (AI) at the edge, giving rise to Tiny Machine Learning\n(TinyML) and its evolving counterpart, Tiny Deep Learning (TinyDL). While\nTinyML initially focused on enabling simple inference tasks on\nmicrocontrollers, the emergence of TinyDL marks a paradigm shift toward\ndeploying deep learning models on severely resource-constrained hardware. This\nsurvey presents a comprehensive overview of the transition from TinyML to\nTinyDL, encompassing architectural innovations, hardware platforms, model\noptimization techniques, and software toolchains. We analyze state-of-the-art\nmethods in quantization, pruning, and neural architecture search (NAS), and\nexamine hardware trends from MCUs to dedicated neural accelerators.\nFurthermore, we categorize software deployment frameworks, compilers, and\nAutoML tools enabling practical on-device learning. Applications across domains\nsuch as computer vision, audio recognition, healthcare, and industrial\nmonitoring are reviewed to illustrate the real-world impact of TinyDL. Finally,\nwe identify emerging directions including neuromorphic computing, federated\nTinyDL, edge-native foundation models, and domain-specific co-design\napproaches. This survey aims to serve as a foundational resource for\nresearchers and practitioners, offering a holistic view of the ecosystem and\nlaying the groundwork for future advancements in edge AI.\n","authors":["Shriyank Somvanshi","Md Monzurul Islam","Gaurab Chhetri","Rohit Chakraborty","Mahmuda Sultana Mimi","Sawgat Ahmed Shuvo","Kazi Sifatul Islam","Syed Aaqib Javed","Sharif Ahmed Rafat","Anandi Dutta","Subasish Das"],"pdf_url":"https://arxiv.org/pdf/2506.18927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01685v2","updated":"2025-06-25T21:36:23Z","published":"2024-11-03T21:01:40Z","title":"Reducing Biases in Record Matching Through Scores Calibration","summary":"  Record matching is the task of identifying records that refer to the same\nreal-world entity across datasets. While most existing models optimize for\naccuracy, fairness has become an important concern due to the potential for\nunequal outcomes across demographic groups. Prior work typically focuses on\nbinary outcomes evaluated at fixed decision thresholds. However, such\nevaluations can miss biases in matching scores--biases that persist across\nthresholds and affect downstream tasks. We propose a threshold-independent\nframework for measuring and reducing score bias, defined as disparities in the\ndistribution of matching scores across groups. We show that several\nstate-of-the-art matching methods exhibit substantial score bias, even when\nappearing fair under standard threshold-based metrics. To address this, we\nintroduce two post-processing score calibration algorithms. The first, calib,\naligns group-wise score distributions using the Wasserstein barycenter,\ntargeting demographic parity. The second, ccalib, conditions on predicted\nlabels to further reduce label-dependent biases, such as equal opportunity.\nBoth methods are model-agnostic and require no access to model training data.\ncalib also offers theoretical guarantees, ensuring reduced bias with minimal\ndeviation from original scores. Experiments across real-world datasets and\nmatching models confirm that calib and ccalib substantially reduce score bias\nwhile minimally impacting model accuracy.\n","authors":["Mohammad Hossein Moslemi","Mostafa Milani"],"pdf_url":"https://arxiv.org/pdf/2411.01685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20839v1","updated":"2025-06-25T21:18:14Z","published":"2025-06-25T21:18:14Z","title":"Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation\n  Plasticity and Stress-Strain Response in FCC Alloys","summary":"  Machine learning has significantly advanced the understanding and application\nof structural materials, with an increasing emphasis on integrating existing\ndata and quantifying uncertainties in predictive modeling. This study presents\na comprehensive methodology utilizing a mixed density network (MDN) model,\ntrained on extensive experimental data from literature. This approach uniquely\npredicts the distribution of dislocation density, inferred as a latent\nvariable, and the resulting stress distribution at the grain level. The\nincorporation of statistical parameters of those predicted distributions into a\ndislocation-mediated plasticity model allows for accurate stress-strain\npredictions with explicit uncertainty quantification. This strategy not only\nimproves the accuracy and reliability of mechanical property predictions but\nalso plays a vital role in optimizing alloy design, thereby facilitating the\ndevelopment of new materials in a rapidly evolving industry.\n","authors":["Jing Luo","Yejun Gu","Yanfei Wang","Xiaolong Ma","Jaafar. A El-Awady"],"pdf_url":"https://arxiv.org/pdf/2506.20839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20612v2","updated":"2025-06-25T21:11:53Z","published":"2025-02-28T00:28:25Z","title":"Discovering Global False Negatives On the Fly for Self-supervised\n  Contrastive Learning","summary":"  In self-supervised contrastive learning, negative pairs are typically\nconstructed using an anchor image and a sample drawn from the entire dataset,\nexcluding the anchor. However, this approach can result in the creation of\nnegative pairs with similar semantics, referred to as \"false negatives\",\nleading to their embeddings being falsely pushed apart. To address this issue,\nwe introduce GloFND, an optimization-based approach that automatically learns\non the fly the threshold for each anchor data to identify its false negatives\nduring training. In contrast to previous methods for false negative discovery,\nour approach globally detects false negatives across the entire dataset rather\nthan locally within the mini-batch. Moreover, its per-iteration computation\ncost remains independent of the dataset size. Experimental results on image and\nimage-text data demonstrate the effectiveness of the proposed method. Our\nimplementation is available at https://github.com/vibalcam/GloFND.\n","authors":["Vicente Balmaseda","Bokun Wang","Ching-Long Lin","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2502.20612v2.pdf","comment":"Accepted to ICML 2025"},{"id":"http://arxiv.org/abs/2505.23062v2","updated":"2025-06-25T21:09:46Z","published":"2025-05-29T04:09:19Z","title":"Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics\n  Data","summary":"  Incorporating pre-collected offline data from a source environment can\nsignificantly improve the sample efficiency of reinforcement learning (RL), but\nthis benefit is often challenged by discrepancies between the transition\ndynamics of the source and target environments. Existing methods typically\naddress this issue by penalizing or filtering out source transitions in high\ndynamics-gap regions. However, their estimation of the dynamics gap often\nrelies on KL divergence or mutual information, which can be ill-defined when\nthe source and target dynamics have disjoint support. To overcome these\nlimitations, we propose CompFlow, a method grounded in the theoretical\nconnection between flow matching and optimal transport. Specifically, we model\nthe target dynamics as a conditional flow built upon the output distribution of\nthe source-domain flow, rather than learning it directly from a Gaussian prior.\nThis composite structure offers two key advantages: (1) improved generalization\nfor learning target dynamics, and (2) a principled estimation of the dynamics\ngap via the Wasserstein distance between source and target transitions.\nLeveraging our principled estimation of the dynamics gap, we further introduce\nan optimistic active data collection strategy that prioritizes exploration in\nregions of high dynamics gap, and theoretically prove that it reduces the\nperformance disparity with the optimal policy. Empirically, CompFlow\noutperforms strong baselines across several RL benchmarks with shifted\ndynamics.\n","authors":["Lingkai Kong","Haichuan Wang","Tonghan Wang","Guojun Xiong","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2505.23062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12540v3","updated":"2025-06-25T21:04:02Z","published":"2025-05-18T20:37:07Z","title":"Harnessing the Universal Geometry of Embeddings","summary":"  We introduce the first method for translating text embeddings from one vector\nspace to another without any paired data, encoders, or predefined sets of\nmatches. Our unsupervised approach translates any embedding to and from a\nuniversal latent representation (i.e., a universal semantic structure\nconjectured by the Platonic Representation Hypothesis). Our translations\nachieve high cosine similarity across model pairs with different architectures,\nparameter counts, and training datasets.\n  The ability to translate unknown embeddings into a different space while\npreserving their geometry has serious implications for the security of vector\ndatabases. An adversary with access only to embedding vectors can extract\nsensitive information about the underlying documents, sufficient for\nclassification and attribute inference.\n","authors":["Rishi Jha","Collin Zhang","Vitaly Shmatikov","John X. Morris"],"pdf_url":"https://arxiv.org/pdf/2505.12540v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01923v2","updated":"2025-06-25T21:02:25Z","published":"2025-06-02T17:43:55Z","title":"TaxaDiffusion: Progressively Trained Diffusion Model for Fine-Grained\n  Species Generation","summary":"  We propose TaxaDiffusion, a taxonomy-informed training framework for\ndiffusion models to generate fine-grained animal images with high morphological\nand identity accuracy. Unlike standard approaches that treat each species as an\nindependent category, TaxaDiffusion incorporates domain knowledge that many\nspecies exhibit strong visual similarities, with distinctions often residing in\nsubtle variations of shape, pattern, and color. To exploit these relationships,\nTaxaDiffusion progressively trains conditioned diffusion models across\ndifferent taxonomic levels -- starting from broad classifications such as Class\nand Order, refining through Family and Genus, and ultimately distinguishing at\nthe Species level. This hierarchical learning strategy first captures\ncoarse-grained morphological traits shared by species with common ancestors,\nfacilitating knowledge transfer before refining fine-grained differences for\nspecies-level distinction. As a result, TaxaDiffusion enables accurate\ngeneration even with limited training samples per species. Extensive\nexperiments on three fine-grained animal datasets demonstrate that outperforms\nexisting approaches, achieving superior fidelity in fine-grained animal image\ngeneration. Project page: https://amink8.github.io/TaxaDiffusion/\n","authors":["Amin Karimi Monsefi","Mridul Khurana","Rajiv Ramnath","Anuj Karpatne","Wei-Lun Chao","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.01923v2.pdf","comment":"Accepted to ICCV 2025"},{"id":"http://arxiv.org/abs/2506.20831v1","updated":"2025-06-25T20:58:28Z","published":"2025-06-25T20:58:28Z","title":"Efficacy of Temporal Fusion Transformers for Runoff Simulation","summary":"  Combining attention with recurrence has shown to be valuable in sequence\nmodeling, including hydrological predictions. Here, we explore the strength of\nTemporal Fusion Transformers (TFTs) over Long Short-Term Memory (LSTM) networks\nin rainfall-runoff modeling. We train ten randomly initialized models, TFT and\nLSTM, for 531 CAMELS catchments in the US. We repeat the experiment with five\nsubsets of the Caravan dataset, each representing catchments in the US,\nAustralia, Brazil, Great Britain, and Chile. Then, the performance of the\nmodels, their variability regarding the catchment attributes, and the\ndifference according to the datasets are assessed. Our findings show that TFT\nslightly outperforms LSTM, especially in simulating the midsection and peak of\nhydrographs. Furthermore, we show the ability of TFT to handle longer sequences\nand why it can be a better candidate for higher or larger catchments. Being an\nexplainable AI technique, TFT identifies the key dynamic and static variables,\nproviding valuable scientific insights. However, both TFT and LSTM exhibit a\nconsiderable drop in performance with the Caravan dataset, indicating possible\ndata quality issues. Overall, the study highlights the potential of TFT in\nimproving hydrological modeling and understanding.\n","authors":["Sinan Rasiya Koya","Tirthankar Roy"],"pdf_url":"https://arxiv.org/pdf/2506.20831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02136v3","updated":"2025-06-25T20:45:19Z","published":"2024-11-04T14:49:01Z","title":"Advanced computer vision for extracting georeferenced vehicle\n  trajectories from drone imagery","summary":"  This paper presents a framework for extracting georeferenced vehicle\ntrajectories from high-altitude drone imagery, addressing key challenges in\nurban traffic monitoring and the limitations of traditional ground-based\nsystems. Our approach integrates several novel contributions, including a\ntailored object detector optimized for high-altitude bird's-eye view\nperspectives, a unique track stabilization method that uses detected vehicle\nbounding boxes as exclusion masks during image registration, and an orthophoto\nand master frame-based georeferencing strategy that enhances consistent\nalignment across multiple drone viewpoints. Additionally, our framework\nfeatures robust vehicle dimension estimation and detailed road segmentation,\nenabling comprehensive traffic analysis. Conducted in the Songdo International\nBusiness District, South Korea, the study utilized a multi-drone experiment\ncovering 20 intersections, capturing approximately 12TB of 4K video data over\nfour days. The framework produced two high-quality datasets: the Songdo Traffic\ndataset, comprising approximately 700,000 unique vehicle trajectories, and the\nSongdo Vision dataset, containing over 5,000 human-annotated images with about\n300,000 vehicle instances in four classes. Comparisons with high-precision\nsensor data from an instrumented probe vehicle highlight the accuracy and\nconsistency of our extraction pipeline in dense urban environments. The public\nrelease of Songdo Traffic and Songdo Vision, and the complete source code for\nthe extraction pipeline, establishes new benchmarks in data quality,\nreproducibility, and scalability in traffic research. Results demonstrate the\npotential of integrating drone technology with advanced computer vision for\nprecise and cost-effective urban traffic monitoring, providing valuable\nresources for developing intelligent transportation systems and enhancing\ntraffic management strategies.\n","authors":["Robert Fonod","Haechan Cho","Hwasoo Yeo","Nikolas Geroliminis"],"pdf_url":"https://arxiv.org/pdf/2411.02136v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20818v1","updated":"2025-06-25T20:32:23Z","published":"2025-06-25T20:32:23Z","title":"Demystifying Distributed Training of Graph Neural Networks for Link\n  Prediction","summary":"  Graph neural networks (GNNs) are powerful tools for solving graph-related\nproblems. Distributed GNN frameworks and systems enhance the scalability of\nGNNs and accelerate model training, yet most are optimized for node\nclassification. Their performance on link prediction remains underexplored.\nThis paper demystifies distributed training of GNNs for link prediction by\ninvestigating the issue of performance degradation when each worker trains a\nGNN on its assigned partitioned subgraph without having access to the entire\ngraph. We discover that the main sources of the issue come from not only the\ninformation loss caused by graph partitioning but also the ways of drawing\nnegative samples during model training. While sharing the complete graph\ninformation with each worker resolves the issue and preserves link prediction\naccuracy, it incurs a high communication cost. We propose SpLPG, which\neffectively leverages graph sparsification to mitigate the issue of performance\ndegradation at a reduced communication cost. Experiment results on several\npublic real-world datasets demonstrate the effectiveness of SpLPG, which\nreduces the communication overhead by up to about 80% while mostly preserving\nlink prediction accuracy.\n","authors":["Xin Huang","Chul-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2506.20818v1.pdf","comment":"Accepted by IEEE ICDCS 2025"},{"id":"http://arxiv.org/abs/2506.20816v1","updated":"2025-06-25T20:30:28Z","published":"2025-06-25T20:30:28Z","title":"Universal and Efficient Detection of Adversarial Data through Nonuniform\n  Impact on Network Layers","summary":"  Deep Neural Networks (DNNs) are notoriously vulnerable to adversarial input\ndesigns with limited noise budgets. While numerous successful attacks with\nsubtle modifications to original input have been proposed, defense techniques\nagainst these attacks are relatively understudied. Existing defense approaches\neither focus on improving DNN robustness by negating the effects of\nperturbations or use a secondary model to detect adversarial data. Although\nequally important, the attack detection approach, which is studied in this\nwork, provides a more practical defense compared to the robustness approach. We\nshow that the existing detection methods are either ineffective against the\nstate-of-the-art attack techniques or computationally inefficient for real-time\nprocessing. We propose a novel universal and efficient method to detect\nadversarial examples by analyzing the varying degrees of impact of attacks on\ndifferent DNN layers. {Our method trains a lightweight regression model that\npredicts deeper-layer features from early-layer features, and uses the\nprediction error to detect adversarial samples.} Through theoretical arguments\nand extensive experiments, we demonstrate that our detection method is highly\neffective, computationally efficient for real-time processing, compatible with\nany DNN architecture, and applicable across different domains, such as image,\nvideo, and audio.\n","authors":["Furkan Mumcu","Yasin Yilmaz"],"pdf_url":"https://arxiv.org/pdf/2506.20816v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.17442"},{"id":"http://arxiv.org/abs/2506.20814v1","updated":"2025-06-25T20:26:04Z","published":"2025-06-25T20:26:04Z","title":"Divide, Specialize, and Route: A New Approach to Efficient Ensemble\n  Learning","summary":"  Ensemble learning has proven effective in boosting predictive performance,\nbut traditional methods such as bagging, boosting, and dynamic ensemble\nselection (DES) suffer from high computational cost and limited adaptability to\nheterogeneous data distributions. To address these limitations, we propose\nHellsemble, a novel and interpretable ensemble framework for binary\nclassification that leverages dataset complexity during both training and\ninference. Hellsemble incrementally partitions the dataset into circles of\ndifficulty by iteratively passing misclassified instances from simpler models\nto subsequent ones, forming a committee of specialised base learners. Each\nmodel is trained on increasingly challenging subsets, while a separate router\nmodel learns to assign new instances to the most suitable base model based on\ninferred difficulty. Hellsemble achieves strong classification accuracy while\nmaintaining computational efficiency and interpretability. Experimental results\non OpenML-CC18 and Tabzilla benchmarks demonstrate that Hellsemble often\noutperforms classical ensemble methods. Our findings suggest that embracing\ninstance-level difficulty offers a promising direction for constructing\nefficient and robust ensemble systems.\n","authors":["Jakub Piwko","Jędrzej Ruciński","Dawid Płudowski","Antoni Zajko","Patryzja Żak","Mateusz Zacharecki","Anna Kozak","Katarzyna Woźnica"],"pdf_url":"https://arxiv.org/pdf/2506.20814v1.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.20810v1","updated":"2025-06-25T20:07:46Z","published":"2025-06-25T20:07:46Z","title":"FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated\n  LSTMs","summary":"  Recurrent neural networks (RNNs), particularly LSTMs, are effective for\ntime-series tasks like sentiment analysis and short-term stock prediction.\nHowever, their computational complexity poses challenges for real-time\ndeployment in resource constrained environments. While FPGAs offer a promising\nplatform for energy-efficient AI acceleration, existing tools mainly target\nfeed-forward networks, and LSTM acceleration typically requires full custom\nimplementation. In this paper, we address this gap by leveraging the\nopen-source and extensible FINN framework to enable the generalized deployment\nof LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open\nNeural Network Exchange (ONNX) specification to model the recurrent nature of\nLSTM computations, enabling support for mixed quantisation within them and\nfunctional verification of LSTM-based models. Furthermore, we introduce custom\ntransformations within the FINN compiler to map the quantised ONNX computation\ngraph to hardware blocks from the HLS kernel library of the FINN compiler and\nVitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM\nmodel for a mid-price stock prediction task using the widely used dataset and\ngenerating a corresponding hardware IP of the model using our flow, targeting\nthe XCZU7EV device. We show that the generated quantised ConvLSTM accelerator\nthrough our flow achieves a balance between performance (latency) and resource\nconsumption, while matching (or bettering) inference accuracy of\nstate-of-the-art models with reduced precision. We believe that the\ngeneralisable nature of the proposed flow will pave the way for\nresource-efficient RNN accelerator designs on FPGAs.\n","authors":["Shashwat Khandelwal","Jakoba Petri-Koenig","Thomas B. Preußer","Michaela Blott","Shreejith Shanker"],"pdf_url":"https://arxiv.org/pdf/2506.20810v1.pdf","comment":"9 pages, 6 figures, 5 tables, Accepted for publication in IEEE\n  FPL-2025 (https://2025.fpl.org/)"},{"id":"http://arxiv.org/abs/2506.20807v1","updated":"2025-06-25T19:59:34Z","published":"2025-06-25T19:59:34Z","title":"GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel\n  Optimization","summary":"  Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.\n","authors":["Martin Andrews","Sam Witteveen"],"pdf_url":"https://arxiv.org/pdf/2506.20807v1.pdf","comment":"4 page paper plus Appendices. Accepted to the ES-FoMo \"Efficient\n  Systems for Foundation Models\" workshop at ICML 2025"},{"id":"http://arxiv.org/abs/2506.20803v1","updated":"2025-06-25T19:47:23Z","published":"2025-06-25T19:47:23Z","title":"The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus\n  Human Research Ideas","summary":"  Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.\n","authors":["Chenglei Si","Tatsunori Hashimoto","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2506.20803v1.pdf","comment":"main paper is 14 pages"},{"id":"http://arxiv.org/abs/2506.20799v1","updated":"2025-06-25T19:43:23Z","published":"2025-06-25T19:43:23Z","title":"Structural System Identification via Validation and Adaptation","summary":"  Estimating the governing equation parameter values is essential for\nintegrating experimental data with scientific theory to understand, validate,\nand predict the dynamics of complex systems. In this work, we propose a new\nmethod for structural system identification (SI), uncertainty quantification,\nand validation directly from data. Inspired by generative modeling frameworks,\na neural network maps random noise to physically meaningful parameters. These\nparameters are then used in the known equation of motion to obtain fake\naccelerations, which are compared to real training data via a mean square error\nloss. To simultaneously validate the learned parameters, we use independent\nvalidation datasets. The generated accelerations from these datasets are\nevaluated by a discriminator network, which determines whether the output is\nreal or fake, and guides the parameter-generator network. Analytical and real\nexperiments show the parameter estimation accuracy and model validation for\ndifferent nonlinear structural systems.\n","authors":["Cristian López","Keegan J. Moore"],"pdf_url":"https://arxiv.org/pdf/2506.20799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20790v1","updated":"2025-06-25T19:26:31Z","published":"2025-06-25T19:26:31Z","title":"Stochastic Parameter Decomposition","summary":"  A key step in reverse engineering neural networks is to decompose them into\nsimpler parts that can be studied in relative isolation. Linear parameter\ndecomposition -- a framework that has been proposed to resolve several issues\nwith current decomposition methods -- decomposes neural network parameters into\na sum of sparsely used vectors in parameter space. However, the current main\nmethod in this framework, Attribution-based Parameter Decomposition (APD), is\nimpractical on account of its computational cost and sensitivity to\nhyperparameters. In this work, we introduce \\textit{Stochastic Parameter\nDecomposition} (SPD), a method that is more scalable and robust to\nhyperparameters than APD, which we demonstrate by decomposing models that are\nslightly larger and more complex than was possible to decompose with APD. We\nalso show that SPD avoids other issues, such as shrinkage of the learned\nparameters, and better identifies ground truth mechanisms in toy models. By\nbridging causal mediation analysis and network decomposition methods, this\ndemonstration opens up new research possibilities in mechanistic\ninterpretability by removing barriers to scaling linear parameter decomposition\nmethods to larger models. We release a library for running SPD and reproducing\nour experiments at https://github.com/goodfire-ai/spd.\n","authors":["Lucius Bushnaq","Dan Braun","Lee Sharkey"],"pdf_url":"https://arxiv.org/pdf/2506.20790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20782v1","updated":"2025-06-25T19:12:16Z","published":"2025-06-25T19:12:16Z","title":"Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A\n  Theoretical Framework for Energy-Efficient Processing","summary":"  We present the first theoretical framework for applying spiking neural\nnetworks (SNNs) to synthetic aperture radar (SAR) interferometric phase\nunwrapping. Despite extensive research in both domains, our comprehensive\nliterature review confirms that SNNs have never been applied to phase\nunwrapping, representing a significant gap in current methodologies. As Earth\nobservation data volumes continue to grow exponentially (with missions like\nNISAR expected to generate 100PB in two years) energy-efficient processing\nbecomes critical for sustainable data center operations. SNNs, with their\nevent-driven computation model, offer potential energy savings of 30-100x\ncompared to conventional approaches while maintaining comparable accuracy. We\ndevelop spike encoding schemes specifically designed for wrapped phase data,\npropose SNN architectures that leverage the spatial propagation nature of phase\nunwrapping, and provide theoretical analysis of computational complexity and\nconvergence properties. Our framework demonstrates how the temporal dynamics\ninherent in SNNs can naturally model the spatial continuity constraints\nfundamental to phase unwrapping. This work opens a new research direction at\nthe intersection of neuromorphic computing and SAR interferometry, offering a\ncomplementary approach to existing algorithms that could enable more\nsustainable large-scale InSAR processing.\n","authors":["Marc Bara"],"pdf_url":"https://arxiv.org/pdf/2506.20782v1.pdf","comment":"8 pages, 2 figures, patent pending"},{"id":"http://arxiv.org/abs/2506.20779v1","updated":"2025-06-25T19:10:03Z","published":"2025-06-25T19:10:03Z","title":"Stable Minima of ReLU Neural Networks Suffer from the Curse of\n  Dimensionality: The Neural Shattering Phenomenon","summary":"  We study the implicit bias of flatness / low (loss) curvature and its effects\non generalization in two-layer overparameterized ReLU networks with\nmultivariate inputs -- a problem well motivated by the minima stability and\nedge-of-stability phenomena in gradient-descent training. Existing work either\nrequires interpolation or focuses only on univariate inputs. This paper\npresents new and somewhat surprising theoretical results for multivariate\ninputs. On two natural settings (1) generalization gap for flat solutions, and\n(2) mean-squared error (MSE) in nonparametric function estimation by stable\nminima, we prove upper and lower bounds, which establish that while flatness\ndoes imply generalization, the resulting rates of convergence necessarily\ndeteriorate exponentially as the input dimension grows. This gives an\nexponential separation between the flat solutions vis-\\`a-vis low-norm\nsolutions (i.e., weight decay), which knowingly do not suffer from the curse of\ndimensionality. In particular, our minimax lower bound construction, based on a\nnovel packing argument with boundary-localized ReLU neurons, reveals how flat\nsolutions can exploit a kind of ''neural shattering'' where neurons rarely\nactivate, but with high weight magnitudes. This leads to poor performance in\nhigh dimensions. We corroborate these theoretical findings with extensive\nnumerical simulations. To the best of our knowledge, our analysis provides the\nfirst systematic explanation for why flat minima may fail to generalize in high\ndimensions.\n","authors":["Tongtong Liang","Dan Qiao","Yu-Xiang Wang","Rahul Parhi"],"pdf_url":"https://arxiv.org/pdf/2506.20779v1.pdf","comment":"Comments Welcome!"},{"id":"http://arxiv.org/abs/2506.15799v2","updated":"2025-06-25T19:09:52Z","published":"2025-06-18T18:35:57Z","title":"Steering Your Diffusion Policy with Latent Space Reinforcement Learning","summary":"  Robotic control policies learned from human demonstrations have achieved\nimpressive results in many real-world applications. However, in scenarios where\ninitial performance is not satisfactory, as is often the case in novel\nopen-world settings, such behavioral cloning (BC)-learned policies typically\nrequire collecting additional human demonstrations to further improve their\nbehavior -- an expensive and time-consuming process. In contrast, reinforcement\nlearning (RL) holds the promise of enabling autonomous online policy\nimprovement, but often falls short of achieving this due to the large number of\nsamples it typically requires. In this work we take steps towards enabling fast\nautonomous adaptation of BC-trained policies via efficient real-world RL.\nFocusing in particular on diffusion policies -- a state-of-the-art BC\nmethodology -- we propose diffusion steering via reinforcement learning (DSRL):\nadapting the BC policy by running RL over its latent-noise space. We show that\nDSRL is highly sample efficient, requires only black-box access to the BC\npolicy, and enables effective real-world autonomous policy improvement.\nFurthermore, DSRL avoids many of the challenges associated with finetuning\ndiffusion policies, obviating the need to modify the weights of the base policy\nat all. We demonstrate DSRL on simulated benchmarks, real-world robotic tasks,\nand for adapting pretrained generalist policies, illustrating its sample\nefficiency and effective performance at real-world policy improvement.\n","authors":["Andrew Wagenmaker","Mitsuhiko Nakamoto","Yunchu Zhang","Seohong Park","Waleed Yagoub","Anusha Nagabandi","Abhishek Gupta","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2506.15799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.14333v2","updated":"2025-06-25T19:04:21Z","published":"2025-03-18T15:08:19Z","title":"Revealing higher-order neural representations of uncertainty with the\n  Noise Estimation through Reinforcement-based Diffusion (NERD) model","summary":"  Studies often aim to reveal ``first-order\" representations (FORs), which\nencode aspects of an observer's environment, such as contents or structure. A\nless-common target is ``higher-order\" representations (HORs), which are\n``about\" FORs -- e.g., their strength or uncertainty -- and which may\ncontribute to learning. HORs about uncertainty are unlikely to be direct\n``read-outs\" of FOR characteristics, instead reflecting noisy estimation\nprocesses incorporating prior expectations about uncertainty, but how the brain\nrepresents such expected uncertainty distributions remains largely unexplored.\nHere, we study ``noise expectation\" HORs using neural data from a task which\nmay require the brain to learn about its own noise: decoded neurofeedback,\nwherein human subjects learn to volitionally produce target neural patterns. We\ndevelop and apply a Noise Estimation through Reinforcement-based Diffusion\n(NERD) model to characterize how brains may undertake this process, and show\nthat NERD offers high explanatory power for human behavior.\n","authors":["Hojjat Azimi Asrari","Megan A. K. Peters"],"pdf_url":"https://arxiv.org/pdf/2503.14333v2.pdf","comment":"27 pages, 7 figures, 12 equations"},{"id":"http://arxiv.org/abs/2506.20771v1","updated":"2025-06-25T19:04:02Z","published":"2025-06-25T19:04:02Z","title":"Stochastic and Non-local Closure Modeling for Nonlinear Dynamical\n  Systems via Latent Score-based Generative Models","summary":"  We propose a latent score-based generative AI framework for learning\nstochastic, non-local closure models and constitutive laws in nonlinear\ndynamical systems of computational mechanics. This work addresses a key\nchallenge of modeling complex multiscale dynamical systems without a clear\nscale separation, for which numerically resolving all scales is prohibitively\nexpensive, e.g., for engineering turbulent flows. While classical closure\nmodeling methods leverage domain knowledge to approximate subgrid-scale\nphenomena, their deterministic and local assumptions can be too restrictive in\nregimes lacking a clear scale separation. Recent developments of\ndiffusion-based stochastic models have shown promise in the context of closure\nmodeling, but their prohibitive computational inference cost limits practical\napplications for many real-world applications. This work addresses this\nlimitation by jointly training convolutional autoencoders with conditional\ndiffusion models in the latent spaces, significantly reducing the\ndimensionality of the sampling process while preserving essential physical\ncharacteristics. Numerical results demonstrate that the joint training approach\nhelps discover a proper latent space that not only guarantees small\nreconstruction errors but also ensures good performance of the diffusion model\nin the latent space. When integrated into numerical simulations, the proposed\nstochastic modeling framework via latent conditional diffusion models achieves\nsignificant computational acceleration while maintaining comparable predictive\naccuracy to standard diffusion models in physical spaces.\n","authors":["Xinghao Dong","Huchen Yang","Jin-Long Wu"],"pdf_url":"https://arxiv.org/pdf/2506.20771v1.pdf","comment":null}]},"2025-06-24T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.20051v1","updated":"2025-06-24T23:17:48Z","published":"2025-06-24T23:17:48Z","title":"Controlled Retrieval-augmented Context Evaluation for Long-form RAG","summary":"  Retrieval-augmented generation (RAG) enhances large language models by\nincorporating context retrieved from external knowledge sources. While the\neffectiveness of the retrieval module is typically evaluated with\nrelevance-based ranking metrics, such metrics may be insufficient to reflect\nthe retrieval's impact on the final RAG result, especially in long-form\ngeneration scenarios. We argue that providing a comprehensive\nretrieval-augmented context is important for long-form RAG tasks like report\ngeneration and propose metrics for assessing the context independent of\ngeneration. We introduce CRUX, a \\textbf{C}ontrolled\n\\textbf{R}etrieval-a\\textbf{U}gmented conte\\textbf{X}t evaluation framework\ndesigned to directly assess retrieval-augmented contexts. This framework uses\nhuman-written summaries to control the information scope of knowledge, enabling\nus to measure how well the context covers information essential for long-form\ngeneration. CRUX uses question-based evaluation to assess RAG's retrieval in a\nfine-grained manner. Empirical results show that CRUX offers more reflective\nand diagnostic evaluation. Our findings also reveal substantial room for\nimprovement in current retrieval methods, pointing to promising directions for\nadvancing RAG's retrieval. Our data and code are publicly available to support\nand advance future research on retrieval.\n","authors":["Jia-Huei Ju","Suzan Verberne","Maarten de Rijke","Andrew Yates"],"pdf_url":"https://arxiv.org/pdf/2506.20051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20041v1","updated":"2025-06-24T22:46:47Z","published":"2025-06-24T22:46:47Z","title":"LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for\n  Evolving Multi-Class Imbalanced Classification","summary":"  The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.\n","authors":["Soheil Abadifard","Fazli Can"],"pdf_url":"https://arxiv.org/pdf/2506.20041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19993v1","updated":"2025-06-24T20:27:51Z","published":"2025-06-24T20:27:51Z","title":"CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender\n  Systems","summary":"  Recommender systems play a pivotal role in providing relevant content to\nusers. With the rapid development of large language models (LLMs), researchers\nhave begun utilizing LLMs to build more powerful recommender systems. However,\nexisting approaches that focus on aligning LLMs with recommendation tasks do\nnot fully leverage their sequential information processing capabilities,\nleading to suboptimal performance.\n  In this paper, we propose a novel system called compressed vocabulary\nexpansion (CoVE). In CoVE, each item is assigned a unique ID within the\nexpanded vocabulary. Our framework effectively capitalizes on sequence\nunderstanding abilities of LLMs, significantly enhancing their performance on\nrecommendation tasks. Additionally, we compress the embedding layer, making\nCoVE practical for large-scale industrial applications. The effectiveness and\nperformance of CoVE are demonstrated through comprehensive experiments on\nmultiple recommendation datasets and comparisons with prior works. Our code can\nbe found at https://github.com/HaochenZhang717/CoVE-official-Repo.\n","authors":["Haochen Zhang","Tianyi Zhang","Junze Yin","Oren Gal","Anshumali Shrivastava","Vladimir Braverman"],"pdf_url":"https://arxiv.org/pdf/2506.19993v1.pdf","comment":"Accepted by ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2505.16065v3","updated":"2025-06-24T18:46:45Z","published":"2025-05-21T22:33:40Z","title":"Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated\n  Synthetic Data Augmentation","summary":"  Embedding-Based Retrieval (EBR) is an important technique in modern search\nengines, enabling semantic match between search queries and relevant results.\nHowever, search logging data on platforms like Facebook Marketplace lacks the\ndiversity and details needed for effective EBR model training, limiting the\nmodels' ability to capture nuanced search patterns. To address this challenge,\nwe propose Aug2Search, an EBR-based framework leveraging synthetic data\ngenerated by Generative AI (GenAI) models, in a multimodal and multitask\napproach to optimize query-product relevance. This paper investigates the\ncapabilities of GenAI, particularly Large Language Models (LLMs), in generating\nhigh-quality synthetic data, and analyzing its impact on enhancing EBR models.\nWe conducted experiments using eight Llama models and 100 million data points\nfrom Facebook Marketplace logs. Our synthetic data generation follows three\nstrategies: (1) generate queries, (2) enhance product listings, and (3)\ngenerate queries from enhanced listings. We train EBR models on three different\ndatasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing\nInteractions\")), synthetic data, and a mixture of both engagement and synthetic\ndata to assess their performance across various training sets. Our findings\nunderscore the robustness of Llama models in producing synthetic queries and\nlistings with high coherence, relevance, and diversity, while maintaining low\nlevels of hallucination. Aug2Search achieves an improvement of up to 4% in\nROC_AUC with 100 million synthetic data samples, demonstrating the\neffectiveness of our approach. Moreover, our experiments reveal that with the\nsame volume of training data, models trained exclusively on synthetic data\noften outperform those trained on original data only or a mixture of original\nand synthetic data.\n","authors":["Ruijie Xi","He Ba","Hao Yuan","Rishu Agrawal","Yuxin Tian","Ruoyan Kong","Arul Prakash"],"pdf_url":"https://arxiv.org/pdf/2505.16065v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.03184v3","updated":"2025-06-24T17:56:09Z","published":"2025-04-04T05:23:45Z","title":"Answering Multimodal Exclusion Queries with Lightweight Sparse\n  Disentangled Representations","summary":"  Multimodal representations that enable cross-modal retrieval are widely used.\nHowever, these often lack interpretability making it difficult to explain the\nretrieved results. Solutions such as learning sparse disentangled\nrepresentations are typically guided by the text tokens in the data, making the\ndimensionality of the resulting embeddings very high. We propose an approach\nthat generates smaller dimensionality fixed-size embeddings that are not only\ndisentangled but also offer better control for retrieval tasks. We demonstrate\ntheir utility using challenging exclusion queries over MSCOCO and Conceptual\nCaptions benchmarks. Our experiments show that our approach is superior to\ntraditional dense models such as CLIP, BLIP and VISTA (gains up to 11% in\nAP@10), as well as sparse disentangled models like VDR (gains up to 21% in\nAP@10). We also present qualitative results to further underline the\ninterpretability of disentangled representations.\n","authors":["Prachi J","Sumit Bhatia","Srikanta Bedathur"],"pdf_url":"https://arxiv.org/pdf/2504.03184v3.pdf","comment":"In Proceedings of the 2025 International ACM SIGIR Conference on\n  Innovative Concepts and Theories in Information Retrieval (ICTIR)"},{"id":"http://arxiv.org/abs/2411.10227v3","updated":"2025-06-24T17:18:03Z","published":"2024-11-15T14:40:59Z","title":"Entropy and type-token ratio in gigaword corpora","summary":"  There are different ways of measuring diversity in complex systems. In\nparticular, in language, lexical diversity is characterized in terms of the\ntype-token ratio and the word entropy. We here investigate both diversity\nmetrics in six massive linguistic datasets in English, Spanish, and Turkish,\nconsisting of books, news articles, and tweets. These gigaword corpora\ncorrespond to languages with distinct morphological features and differ in\nregisters and genres, thus constituting a varied testbed for a quantitative\napproach to lexical diversity. We unveil an empirical functional relation\nbetween entropy and type-token ratio of texts of a given corpus and language,\nwhich is a consequence of the statistical laws observed in natural language.\nFurther, in the limit of large text lengths we find an analytical expression\nfor this relation relying on both Zipf and Heaps laws that agrees with our\nempirical findings.\n","authors":["Pablo Rosillo-Rodes","Maxi San Miguel","David Sanchez"],"pdf_url":"https://arxiv.org/pdf/2411.10227v3.pdf","comment":"15 pages, 10 figures, 8 tables"},{"id":"http://arxiv.org/abs/2506.19802v1","updated":"2025-06-24T17:08:58Z","published":"2025-06-24T17:08:58Z","title":"KnowML: Improving Generalization of ML-NIDS with Attack Knowledge Graphs","summary":"  Despite extensive research on Machine Learning-based Network Intrusion\nDetection Systems (ML-NIDS), their capability to detect diverse attack variants\nremains uncertain. Prior studies have largely relied on homogeneous datasets,\nwhich artificially inflate performance scores and offer a false sense of\nsecurity. Designing systems that can effectively detect a wide range of attack\nvariants remains a significant challenge. The progress of ML-NIDS continues to\ndepend heavily on human expertise, which can embed subjective judgments of\nsystem designers into the model, potentially hindering its ability to\ngeneralize across diverse attack types.\n  To address this gap, we propose KnowML, a framework for knowledge-guided\nmachine learning that integrates attack knowledge into ML-NIDS. KnowML\nsystematically explores the threat landscape by leveraging Large Language\nModels (LLMs) to perform automated analysis of attack implementations. It\nconstructs a unified Knowledge Graph (KG) of attack strategies, on which it\napplies symbolic reasoning to generate KG-Augmented Input, embedding domain\nknowledge directly into the design process of ML-NIDS.\n  We evaluate KnowML on 28 realistic attack variants, of which 10 are newly\ncollected for this study. Our findings reveal that baseline ML-NIDS models fail\nto detect several variants entirely, achieving F1 scores as low as 0 %. In\ncontrast, our knowledge-guided approach achieves up to 99 % F1 score while\nmaintaining a False Positive Rate below 0.1 %.\n","authors":["Xin Fan Guo","Albert Merono Penuela","Sergio Maffeis","Fabio Pierazzi"],"pdf_url":"https://arxiv.org/pdf/2506.19802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19794v1","updated":"2025-06-24T17:04:23Z","published":"2025-06-24T17:04:23Z","title":"Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic\n  Empirical Study","summary":"  Large Language Models (LLMs) hold promise in automating data analysis tasks,\nyet open-source models face significant limitations in these kinds of\nreasoning-intensive scenarios. In this work, we investigate strategies to\nenhance the data analysis capabilities of open-source LLMs. By curating a seed\ndataset of diverse, realistic scenarios, we evaluate models across three\ndimensions: data understanding, code generation, and strategic planning. Our\nanalysis reveals three key findings: (1) Strategic planning quality serves as\nthe primary determinant of model performance; (2) Interaction design and task\ncomplexity significantly influence reasoning capabilities; (3) Data quality\ndemonstrates a greater impact than diversity in achieving optimal performance.\nWe leverage these insights to develop a data synthesis methodology,\ndemonstrating significant improvements in open-source LLMs' analytical\nreasoning capabilities.\n","authors":["Yuqi Zhu","Yi Zhong","Jintian Zhang","Ziheng Zhang","Shuofei Qiao","Yujie Luo","Lun Du","Da Zheng","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.19794v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.19777v1","updated":"2025-06-24T16:42:46Z","published":"2025-06-24T16:42:46Z","title":"Alleviating User-Sensitive bias with Fair Generative Sequential\n  Recommendation Model","summary":"  Recommendation fairness has recently attracted much attention. In the real\nworld, recommendation systems are driven by user behavior, and since users with\nthe same sensitive feature (e.g., gender and age) tend to have the same\npatterns, recommendation models can easily capture the strong correlation\npreference of sensitive features and thus cause recommendation unfairness.\nDiffusion model (DM) as a new generative model paradigm has achieved great\nsuccess in recommendation systems. DM's ability to model uncertainty and\nrepresent diversity, and its modeling mechanism has a high degree of\nadaptability with the real-world recommendation process with bias. Therefore,\nwe use DM to effectively model the fairness of recommendation and enhance the\ndiversity. This paper proposes a FairGENerative sequential Recommendation model\nbased on DM, FairGENRec. In the training phase, we inject random noise into the\noriginal distribution under the guidance of the sensitive feature recognition\nmodel, and a sequential denoise model is designed for the reverse\nreconstruction of items. Simultaneously, recommendation fairness modeling is\ncompleted by injecting multi-interests representational information that\neliminates the bias of sensitive user features into the generated results. In\nthe inference phase, the model obtains the noise in the form of noise addition\nby using the history interactions which is followed by reverse iteration to\nreconstruct the target item representation. Finally, our extensive experiments\non three datasets demonstrate the dual enhancement effect of FairGENRec on\naccuracy and fairness, while the statistical analysis of the cases visualizes\nthe degree of improvement on the fairness of the recommendation.\n","authors":["Yang Liu","Feng Wu","Xuefang Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.19777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19743v1","updated":"2025-06-24T16:02:02Z","published":"2025-06-24T16:02:02Z","title":"NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and\n  Ranking","summary":"  E-commerce information retrieval (IR) systems struggle to simultaneously\nachieve high accuracy in interpreting complex user queries and maintain\nefficient processing of vast product catalogs. The dual challenge lies in\nprecisely matching user intent with relevant products while managing the\ncomputational demands of real-time search across massive inventories. In this\npaper, we propose a Nested Embedding Approach to product Retrieval and Ranking,\ncalled NEAR$^2$, which can achieve up to $12$ times efficiency in embedding\nsize at inference time while introducing no extra cost in training and\nimproving performance in accuracy for various encoder-based Transformer models.\nWe validate our approach using different loss functions for the retrieval and\nranking task, including multiple negative ranking loss and online contrastive\nloss, on four different test sets with various IR challenges such as short and\nimplicit queries. Our approach achieves an improved performance over a smaller\nembedding dimension, compared to any existing models.\n","authors":["Shenbin Qian","Diptesh Kanojia","Samarth Agrawal","Hadeel Saadany","Swapnil Bhosale","Constantin Orasan","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2506.19743v1.pdf","comment":"This paper is accepted to the 2025 SIGIR Workshop on eCommerce"},{"id":"http://arxiv.org/abs/2506.18902v2","updated":"2025-06-24T15:52:37Z","published":"2025-06-23T17:59:55Z","title":"jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual\n  Retrieval","summary":"  We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-document retrieval, semantic text similarity, and code search.\nComprehensive evaluations demonstrate that jina-embeddings-v4 achieves\nstate-of-the-art performance on both single-modal and cross-modal retrieval\ntasks, with particular strength in processing visually rich content such as\ntables, charts, diagrams, and mixed-media formats. To facilitate evaluation of\nthis capability, we also introduce Jina-VDR, a novel benchmark specifically\ndesigned for visually rich image retrieval.\n","authors":["Michael Günther","Saba Sturua","Mohammad Kalim Akram","Isabelle Mohr","Andrei Ungureanu","Bo Wang","Sedigheh Eslami","Scott Martens","Maximilian Werk","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2506.18902v2.pdf","comment":"22 pages, 1-10 main, 14-22 experimental results, benchmark tables"},{"id":"http://arxiv.org/abs/2506.19661v1","updated":"2025-06-24T14:24:20Z","published":"2025-06-24T14:24:20Z","title":"Higher-Order Graph Databases","summary":"  Recent advances in graph databases (GDBs) have been driving interest in\nlarge-scale analytics, yet current systems fail to support higher-order (HO)\ninteractions beyond first-order (one-hop) relations, which are crucial for\ntasks such as subgraph counting, polyadic modeling, and HO graph learning. We\naddress this by introducing a new class of systems, higher-order graph\ndatabases (HO-GDBs) that use lifting and lowering paradigms to seamlessly\nextend traditional GDBs with HO. We provide a theoretical analysis of OLTP and\nOLAP queries, ensuring correctness, scalability, and ACID compliance. We\nimplement a lightweight, modular, and parallelizable HO-GDB prototype that\noffers native support for hypergraphs, node-tuples, subgraphs, and other HO\nstructures under a unified API. The prototype scales to large HO OLTP & OLAP\nworkloads and shows how HO improves analytical tasks, for example enhancing\naccuracy of graph neural networks within a GDB by 44%. Our work ensures low\nlatency and high query throughput, and generalizes both ACID-compliant and\neventually consistent systems.\n","authors":["Maciej Besta","Shriram Chandran","Jakub Cudak","Patrick Iff","Marcin Copik","Robert Gerstenberger","Tomasz Szydlo","Jürgen Müller","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2506.19661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19548v1","updated":"2025-06-24T11:54:37Z","published":"2025-06-24T11:54:37Z","title":"Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection","summary":"  Early detection of disease outbreaks is crucial to ensure timely intervention\nby the health authorities. Due to the challenges associated with traditional\nindicator-based surveillance, monitoring informal sources such as online media\nhas become increasingly popular. However, owing to the number of online\narticles getting published everyday, manual screening of the articles is\nimpractical. To address this, we propose Health Sentinel. It is a multi-stage\ninformation extraction pipeline that uses a combination of ML and non-ML\nmethods to extract events-structured information concerning disease outbreaks\nor other unusual health events-from online articles. The extracted events are\nmade available to the Media Scanning and Verification Cell (MSVC) at the\nNational Centre for Disease Control (NCDC), Delhi for analysis, interpretation\nand further dissemination to local agencies for timely intervention. From April\n2022 till date, Health Sentinel has processed over 300 million news articles\nand identified over 95,000 unique health events across India of which over\n3,500 events were shortlisted by the public health experts at NCDC as potential\noutbreaks.\n","authors":["Devesh Pant","Rishi Raj Grandhe","Vipin Samaria","Mukul Paul","Sudhir Kumar","Saransh Khanna","Jatin Agrawal","Jushaan Singh Kalra","Akhil VSSG","Satish V Khalikar","Vipin Garg","Himanshu Chauhan","Pranay Verma","Neha Khandelwal","Soma S Dhavala","Minesh Mathew"],"pdf_url":"https://arxiv.org/pdf/2506.19548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07584v3","updated":"2025-06-24T10:10:56Z","published":"2025-03-10T17:48:10Z","title":"Talking to GDELT Through Knowledge Graphs","summary":"  In this work we study various Retrieval Augmented Regeneration (RAG)\napproaches to gain an understanding of the strengths and weaknesses of each\napproach in a question-answering analysis. To gain this understanding we use a\ncase-study subset of the Global Database of Events, Language, and Tone (GDELT)\ndataset as well as a corpus of raw text scraped from the online news articles.\nTo retrieve information from the text corpus we implement a traditional vector\nstore RAG as well as state-of-the-art large language model (LLM) based\napproaches for automatically constructing KGs and retrieving the relevant\nsubgraphs. In addition to these corpus approaches, we develop a novel\nontology-based framework for constructing knowledge graphs (KGs) from GDELT\ndirectly which leverages the underlying schema of GDELT to create structured\nrepresentations of global events. For retrieving relevant information from the\nontology-based KGs we implement both direct graph queries and state-of-the-art\ngraph retrieval approaches. We compare the performance of each method in a\nquestion-answering task. We find that while our ontology-based KGs are valuable\nfor question-answering, automated extraction of the relevant subgraphs is\nchallenging. Conversely, LLM-generated KGs, while capturing event summaries,\noften lack consistency and interpretability. Our findings suggest benefits of a\nsynergistic approach between ontology and LLM-based KG construction, with\nproposed avenues toward that end.\n","authors":["Audun Myers","Max Vargas","Sinan G. Aksoy","Cliff Joslyn","Benjamin Wilson","Lee Burke","Tom Grimes"],"pdf_url":"https://arxiv.org/pdf/2503.07584v3.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.20023v1","updated":"2025-06-24T21:38:06Z","published":"2025-06-24T21:38:06Z","title":"DIM-SUM: Dynamic IMputation for Smart Utility Management","summary":"  Time series imputation models have traditionally been developed using\ncomplete datasets with artificial masking patterns to simulate missing values.\nHowever, in real-world infrastructure monitoring, practitioners often encounter\ndatasets where large amounts of data are missing and follow complex,\nheterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for\ntraining robust imputation models that bridges the gap between artificially\nmasked training data and real missing patterns. DIM-SUM combines pattern\nclustering and adaptive masking strategies with theoretical learning guarantees\nto handle diverse missing patterns actually observed in the data. Through\nextensive experiments on over 2 billion readings from California water\ndistricts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM\noutperforms traditional methods by reaching similar accuracy with lower\nprocessing time and significantly less training data. When compared against a\nlarge pre-trained model, DIM-SUM averages 2x higher accuracy with significantly\nless inference time.\n","authors":["Ryan Hildebrant","Rahul Bhope","Sharad Mehrotra","Christopher Tull","Nalini Venkatasubramanian"],"pdf_url":"https://arxiv.org/pdf/2506.20023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20010v1","updated":"2025-06-24T20:57:32Z","published":"2025-06-24T20:57:32Z","title":"Near Data Processing in Taurus Database","summary":"  Huawei's cloud-native database system GaussDB for MySQL (also known as\nTaurus) stores data in a separate storage layer consisting of a pool of storage\nservers. Each server has considerable compute power making it possible to push\ndata reduction operations (selection, projection, and aggregation) close to\nstorage. This paper describes the design and implementation of near data\nprocessing (NDP) in Taurus. NDP has several benefits: it reduces the amount of\ndata shipped over the network; frees up CPU capacity in the compute layer; and\nreduces query run time, thereby enabling higher system throughput. Experiments\nwith the TPCH benchmark (100 GB) showed that 18 out of 22 queries benefited\nfrom NDP; data shipped was reduced by 63 percent; and CPU time by 50 percent.\nOn Q15 the impact was even higher: data shipped was reduced by 98 percent; CPU\ntime by 91 percent; and run time by 80 percent.\n","authors":["Shu Lin","Arunprasad P. Marathe","Per-Ȧke Larson","Chong Chen","Calvin Sun","Paul Lee","Weidong Yu"],"pdf_url":"https://arxiv.org/pdf/2506.20010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19661v1","updated":"2025-06-24T14:24:20Z","published":"2025-06-24T14:24:20Z","title":"Higher-Order Graph Databases","summary":"  Recent advances in graph databases (GDBs) have been driving interest in\nlarge-scale analytics, yet current systems fail to support higher-order (HO)\ninteractions beyond first-order (one-hop) relations, which are crucial for\ntasks such as subgraph counting, polyadic modeling, and HO graph learning. We\naddress this by introducing a new class of systems, higher-order graph\ndatabases (HO-GDBs) that use lifting and lowering paradigms to seamlessly\nextend traditional GDBs with HO. We provide a theoretical analysis of OLTP and\nOLAP queries, ensuring correctness, scalability, and ACID compliance. We\nimplement a lightweight, modular, and parallelizable HO-GDB prototype that\noffers native support for hypergraphs, node-tuples, subgraphs, and other HO\nstructures under a unified API. The prototype scales to large HO OLTP & OLAP\nworkloads and shows how HO improves analytical tasks, for example enhancing\naccuracy of graph neural networks within a GDB by 44%. Our work ensures low\nlatency and high query throughput, and generalizes both ACID-compliant and\neventually consistent systems.\n","authors":["Maciej Besta","Shriram Chandran","Jakub Cudak","Patrick Iff","Marcin Copik","Robert Gerstenberger","Tomasz Szydlo","Jürgen Müller","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2506.19661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06102v2","updated":"2025-06-24T11:23:34Z","published":"2024-11-09T07:32:40Z","title":"SiriusBI: A Comprehensive LLM-Powered Solution for Data Analytics in\n  Business Intelligence","summary":"  With the proliferation of Large Language Models (LLMs) in Business\nIntelligence (BI), existing solutions face critical challenges in industrial\ndeployments: functionality deficiencies from legacy systems failing to meet\nevolving LLM-era user demands, interaction limitations from single-round SQL\ngeneration paradigms inadequate for multi-round clarification, and cost for\ndomain adaptation arising from cross-domain methods migration.\n  We present SiriusBI, a practical LLM-powered BI system addressing the\nchallenges of industrial deployments through three key innovations: (a) An\nend-to-end architecture integrating multi-module coordination to overcome\nfunctionality gaps in legacy systems; (b) A multi-round dialogue with querying\nmechanism, consisting of semantic completion, knowledge-guided clarification,\nand proactive querying processes, to resolve interaction constraints in SQL\ngeneration; (c) A data-conditioned SQL generation method selection strategy\nthat supports both an efficient one-step Fine-Tuning approach and a two-step\nmethod leveraging Semantic Intermediate Representation for low-cost\ncross-domain applications. Experiments on both real-world datasets and public\nbenchmarks demonstrate the effectiveness of SiriusBI. User studies further\nconfirm that SiriusBI enhances both productivity and user experience.\n  As an independent service on Tencent's data platform, SiriusBI is deployed\nacross finance, advertising, and cloud sectors, serving dozens of enterprise\nclients. It achieves over 93% accuracy in SQL generation and reduces data\nanalysts' query time from minutes to seconds in real-world applications.\n","authors":["Jie Jiang","Haining Xie"," Siqishen","Yu Shen","Zihan Zhang","Meng Lei","Yifeng Zheng","Yang Li","Chunyou Li","Danqing Huang","Yinjun Wu","Wentao Zhang","Xiaofeng Yang","Bin Cui","Peng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06102v2.pdf","comment":"14 pages, 8 figures"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2506.20062v1","updated":"2025-06-24T23:50:03Z","published":"2025-06-24T23:50:03Z","title":"Beyond Autocomplete: Designing CopilotLens Towards Transparent and\n  Explainable AI Coding Agents","summary":"  AI-powered code assistants are widely used to generate code completions,\nsignificantly boosting developer productivity. However, these tools typically\npresent suggestions without explaining their rationale, leaving their\ndecision-making process inscrutable. This opacity hinders developers' ability\nto critically evaluate the output, form accurate mental models, and build\ncalibrated trust in the system. To address this, we introduce CopilotLens, a\nnovel interactive framework that reframes code completion from a simple\nsuggestion into a transparent, explainable event. CopilotLens operates as an\nexplanation layer that reveals the AI agent's \"thought process\" through a\ndynamic two-level interface, surfacing everything from its reconstructed\nhigh-level plans to the specific codebase context influencing the code. This\npaper presents the design and rationale of CopilotLens, offering a concrete\nframework for building future agentic code assistants that prioritize clarity\nof reasoning over speed of suggestion, thereby fostering deeper comprehension\nand more robust human-AI collaboration.\n","authors":["Runlong Ye","Zeling Zhang","Boushra Almazroua","Michael Liut"],"pdf_url":"https://arxiv.org/pdf/2506.20062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20059v1","updated":"2025-06-24T23:47:21Z","published":"2025-06-24T23:47:21Z","title":"DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test\n  Recommendation and Diagnosis Prediction","summary":"  Recent advances in Large Language Models (LLMs) have led to remarkable\nprogresses in medical consultation. However, existing medical LLMs overlook the\nessential role of Electronic Health Records (EHR) and focus primarily on\ndiagnosis recommendation, limiting their clinical applicability. We propose\nDiaLLM, the first medical LLM that integrates heterogeneous EHR data into\nclinically grounded dialogues, enabling clinical test recommendation, result\ninterpretation, and diagnosis prediction to better align with real-world\nmedical practice. To construct clinically grounded dialogues from EHR, we\ndesign a Clinical Test Reference (CTR) strategy that maps each clinical code to\nits corresponding description and classifies test results as \"normal\" or\n\"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for\nevidence acquisition and automated diagnosis. To handle the large action space,\nwe introduce a reject sampling strategy to reduce redundancy and improve\nexploration efficiency. Furthermore, a confirmation reward and a\nclass-sensitive diagnosis reward are designed to guide accurate diagnosis\nprediction. Extensive experimental results demonstrate that DiaLLM outperforms\nbaselines in clinical test recommendation and diagnosis prediction.\n","authors":["Weijieying Ren","Tianxiang Zhao","Lei Wang","Tianchun Wang","Vasant Honavar"],"pdf_url":"https://arxiv.org/pdf/2506.20059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10304v2","updated":"2025-06-24T23:41:11Z","published":"2025-06-12T02:30:30Z","title":"The Alignment Trap: Complexity Barriers","summary":"  This paper argues that AI alignment is not merely difficult, but is founded\non a fundamental logical contradiction. We first establish The Enumeration\nParadox: we use machine learning precisely because we cannot enumerate all\nnecessary safety rules, yet making ML safe requires examples that can only be\ngenerated from the very enumeration we admit is impossible. This paradox is\nthen confirmed by a set of five independent mathematical proofs, or \"pillars of\nimpossibility.\" Our main results show that: (1) Geometric Impossibility: The\nset of safe policies has measure zero, a necessary consequence of projecting\ninfinite-dimensional world-context requirements onto finite-dimensional models.\n(2) Computational Impossibility: Verifying a policy's safety is coNP-complete,\neven for non-zero error tolerances. (3) Statistical Impossibility: The training\ndata required for safety (abundant examples of rare disasters) is a logical\ncontradiction and thus unobtainable. (4) Information-Theoretic Impossibility:\nSafety rules contain more incompressible, arbitrary information than any\nfeasible network can store. (5) Dynamic Impossibility: The optimization process\nfor increasing AI capability is actively hostile to safety, as the gradients\nfor the two objectives are generally anti-aligned. Together, these results\ndemonstrate that the pursuit of safe, highly capable AI is not a matter of\novercoming technical hurdles, but of confronting fundamental, interlocking\nbarriers. The paper concludes by presenting a strategic trilemma that these\nimpossibilities force upon the field. A formal verification of the core\ntheorems in Lean4 is currently in progress.\n","authors":["Jasper Yao"],"pdf_url":"https://arxiv.org/pdf/2506.10304v2.pdf","comment":"31 Pages, 4 Figures. Substantial revision. Restructured around the\n  Enumeration Paradox and Five Pillars of Impossibility. Core mathematical\n  results unchanged but significantly expanded. Added new impossibility proofs\n  from statistical, information-theoretic, and dynamic perspectives"},{"id":"http://arxiv.org/abs/2506.20049v1","updated":"2025-06-24T23:13:44Z","published":"2025-06-24T23:13:44Z","title":"Robust Robotic Exploration and Mapping Using Generative Occupancy Map\n  Synthesis","summary":"  We present a novel approach for enhancing robotic exploration by using\ngenerative occupancy mapping. We introduce SceneSense, a diffusion model\ndesigned and trained for predicting 3D occupancy maps given partial\nobservations. Our proposed approach probabilistically fuses these predictions\ninto a running occupancy map in real-time, resulting in significant\nimprovements in map quality and traversability. We implement SceneSense onboard\na quadruped robot and validate its performance with real-world experiments to\ndemonstrate the effectiveness of the model. In these experiments, we show that\noccupancy maps enhanced with SceneSense predictions better represent our fully\nobserved ground truth data (24.44% FID improvement around the robot and 75.59%\nimprovement at range). We additionally show that integrating\nSceneSense-enhanced maps into our robotic exploration stack as a \"drop-in\" map\nimprovement, utilizing an existing off-the-shelf planner, results in\nimprovements in robustness and traversability time. Finally we show results of\nfull exploration evaluations with our proposed system in two dissimilar\nenvironments and find that locally enhanced maps provide more consistent\nexploration results than maps constructed only from direct sensor measurements.\n","authors":["Lorin Achey","Alec Reed","Brendan Crowe","Bradley Hayes","Christoffer Heckman"],"pdf_url":"https://arxiv.org/pdf/2506.20049v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2409.10681"},{"id":"http://arxiv.org/abs/2506.20046v1","updated":"2025-06-24T23:08:31Z","published":"2025-06-24T23:08:31Z","title":"GNN's Uncertainty Quantification using Self-Distillation","summary":"  Graph Neural Networks (GNNs) have shown remarkable performance in the\nhealthcare domain. However, what remained challenging is quantifying the\npredictive uncertainty of GNNs, which is an important aspect of trustworthiness\nin clinical settings. While Bayesian and ensemble methods can be used to\nquantify uncertainty, they are computationally expensive. Additionally, the\ndisagreement metric used by ensemble methods to compute uncertainty cannot\ncapture the diversity of models in an ensemble network. In this paper, we\npropose a novel method, based on knowledge distillation, to quantify GNNs'\nuncertainty more efficiently and with higher precision. We apply\nself-distillation, where the same network serves as both the teacher and\nstudent models, thereby avoiding the need to train several networks\nindependently. To ensure the impact of self-distillation, we develop an\nuncertainty metric that captures the diverse nature of the network by assigning\ndifferent weights to each GNN classifier. We experimentally evaluate the\nprecision, performance, and ability of our approach in distinguishing\nout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The\nevaluation results demonstrate that the proposed method can effectively capture\nthe predictive uncertainty of the model while having performance similar to\nthat of the MC Dropout and ensemble methods. The code is publicly available at\nhttps://github.com/tailabTMU/UQ_GNN.\n","authors":["Hirad Daneshvar","Reza Samavi"],"pdf_url":"https://arxiv.org/pdf/2506.20046v1.pdf","comment":"The paper has been accepted in the International Conference on AI in\n  Healthcare (AIiH) 2025 and will appear in the conference proceedings"},{"id":"http://arxiv.org/abs/2506.20041v1","updated":"2025-06-24T22:46:47Z","published":"2025-06-24T22:46:47Z","title":"LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for\n  Evolving Multi-Class Imbalanced Classification","summary":"  The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.\n","authors":["Soheil Abadifard","Fazli Can"],"pdf_url":"https://arxiv.org/pdf/2506.20041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20040v1","updated":"2025-06-24T22:43:36Z","published":"2025-06-24T22:43:36Z","title":"Cross-Layer Discrete Concept Discovery for Interpreting Language Models","summary":"  Uncovering emergent concepts across transformer layers remains a significant\nchallenge because the residual stream linearly mixes and duplicates\ninformation, obscuring how features evolve within large language models.\nCurrent research efforts primarily inspect neural representations at single\nlayers, thereby overlooking this cross-layer superposition and the redundancy\nit introduces. These representations are typically either analyzed directly for\nactivation patterns or passed to probing classifiers that map them to a limited\nset of predefined concepts. To address these limitations, we propose\n\\gls{clvqvae}, a framework that uses vector quantization to map representations\nacross layers and in the process collapse duplicated residual-stream features\ninto compact, interpretable concept vectors. Our approach uniquely combines\ntop-$k$ temperature-based sampling during quantization with EMA codebook\nupdates, providing controlled exploration of the discrete latent space while\nmaintaining code-book diversity. We further enhance the framework with\nscaled-spherical k-means++ for codebook initialization, which clusters by\ndirectional similarity rather than magnitude, better aligning with semantic\nstructure in word embedding space.\n","authors":["Ankur Garg","Xuemin Yu","Hassan Sajjad","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2506.20040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20039v1","updated":"2025-06-24T22:40:05Z","published":"2025-06-24T22:40:05Z","title":"Learning Bilateral Team Formation in Cooperative Multi-Agent\n  Reinforcement Learning","summary":"  Team formation and the dynamics of team-based learning have drawn significant\ninterest in the context of Multi-Agent Reinforcement Learning (MARL). However,\nexisting studies primarily focus on unilateral groupings, predefined teams, or\nfixed-population settings, leaving the effects of algorithmic bilateral\ngrouping choices in dynamic populations underexplored. To address this gap, we\nintroduce a framework for learning two-sided team formation in dynamic\nmulti-agent systems. Through this study, we gain insight into what algorithmic\nproperties in bilateral team formation influence policy performance and\ngeneralization. We validate our approach using widely adopted multi-agent\nscenarios, demonstrating competitive performance and improved generalization in\nmost scenarios.\n","authors":["Koorosh Moslemi","Chi-Guhn Lee"],"pdf_url":"https://arxiv.org/pdf/2506.20039v1.pdf","comment":"Accepted to the 2nd Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning (CoCoMARL) Workshop at RLC 2025"},{"id":"http://arxiv.org/abs/2506.20036v1","updated":"2025-06-24T22:19:15Z","published":"2025-06-24T22:19:15Z","title":"Hierarchical Reinforcement Learning and Value Optimization for\n  Challenging Quadruped Locomotion","summary":"  We propose a novel hierarchical reinforcement learning framework for\nquadruped locomotion over challenging terrain. Our approach incorporates a\ntwo-layer hierarchy in which a high-level policy (HLP) selects optimal goals\nfor a low-level policy (LLP). The LLP is trained using an on-policy\nactor-critic RL algorithm and is given footstep placements as goals. We propose\nan HLP that does not require any additional training or environment samples and\ninstead operates via an online optimization process over the learned value\nfunction of the LLP. We demonstrate the benefits of this framework by comparing\nit with an end-to-end reinforcement learning (RL) approach. We observe\nimprovements in its ability to achieve higher rewards with fewer collisions\nacross an array of different terrains, including terrains more difficult than\nany encountered during training.\n","authors":["Jeremiah Coholich","Muhammad Ali Murtaza","Seth Hutchinson","Zsolt Kira"],"pdf_url":"https://arxiv.org/pdf/2506.20036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20031v1","updated":"2025-06-24T21:58:30Z","published":"2025-06-24T21:58:30Z","title":"Automated Generation of Diverse Courses of Actions for Multi-Agent\n  Operations using Binary Optimization and Graph Learning","summary":"  Operations in disaster response, search \\& rescue, and military missions that\ninvolve multiple agents demand automated processes to support the planning of\nthe courses of action (COA). Moreover, traverse-affecting changes in the\nenvironment (rain, snow, blockades, etc.) may impact the expected performance\nof a COA, making it desirable to have a pool of COAs that are diverse in task\ndistributions across agents. Further, variations in agent capabilities, which\ncould be human crews and/or autonomous systems, present practical opportunities\nand computational challenges to the planning process. This paper presents a new\ntheoretical formulation and computational framework to generate such diverse\npools of COAs for operations with soft variations in agent-task compatibility.\nKey to the problem formulation is a graph abstraction of the task space and the\npool of COAs itself to quantify its diversity. Formulating the COAs as a\ncentralized multi-robot task allocation problem, a genetic algorithm is used\nfor (order-ignoring) allocations of tasks to each agent that jointly maximize\ndiversity within the COA pool and overall compatibility of the agent-task\nmappings. A graph neural network is trained using a policy gradient approach to\nthen perform single agent task sequencing in each COA, which maximizes\ncompletion rates adaptive to task features. Our tests of the COA generation\nprocess in a simulated environment demonstrate significant performance gain\nover a random walk baseline, small optimality gap in task sequencing, and\nexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task\noperations.\n","authors":["Prithvi Poddar","Ehsan Tarkesh Esfahani","Karthik Dantu","Souma Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2506.20031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21049v2","updated":"2025-06-24T21:45:07Z","published":"2024-07-23T02:45:22Z","title":"Evaluating Long Range Dependency Handling in Code Generation LLMs","summary":"  As language models support larger and larger context sizes, evaluating their\nability to make effective use of that context becomes increasingly important.\nWe analyze the ability of several code generation models to handle long range\ndependencies using a suite of multi-step key retrieval tasks in context windows\nup to 8k tokens in length. The tasks progressively increase in difficulty and\nallow more nuanced evaluation of model capabilities than tests like the popular\nneedle-in-the-haystack test. We find that performance degrades significantly\nfor many models (up to 2x) when a function references another function that is\ndefined later in the prompt. We also observe that models that use sliding\nwindow attention mechanisms have difficulty handling references further than\nthe size of a single window. We perform simple prompt modifications using call\ngraph information to improve multi-step retrieval performance up to 3x. Our\nanalysis highlights ways that long-context performance needs deeper\nconsideration beyond retrieval of single facts within a document.\n","authors":["Yannick Assogba","Donghao Ren"],"pdf_url":"https://arxiv.org/pdf/2407.21049v2.pdf","comment":"36 pages, 18 figures"},{"id":"http://arxiv.org/abs/2506.20024v1","updated":"2025-06-24T21:44:31Z","published":"2025-06-24T21:44:31Z","title":"Elucidated Rolling Diffusion Models for Probabilistic Weather\n  Forecasting","summary":"  Diffusion models are a powerful tool for probabilistic forecasting, yet most\napplications in high-dimensional chaotic systems predict future snapshots\none-by-one. This common approach struggles to model complex temporal\ndependencies and fails to explicitly account for the progressive growth of\nuncertainty inherent to such systems. While rolling diffusion frameworks, which\napply increasing noise to forecasts at longer lead times, have been proposed to\naddress this, their integration with state-of-the-art, high-fidelity diffusion\ntechniques remains a significant challenge. We tackle this problem by\nintroducing Elucidated Rolling Diffusion Models (ERDM), the first framework to\nsuccessfully unify a rolling forecast structure with the principled, performant\ndesign of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM\ncomponents-its noise schedule, network preconditioning, and Heun sampler-to the\nrolling forecast setting. The success of this integration is driven by three\nkey contributions: (i) a novel loss weighting scheme that focuses model\ncapacity on the mid-range forecast horizons where determinism gives way to\nstochasticity; (ii) an efficient initialization strategy using a pre-trained\nEDM for the initial window; and (iii) a bespoke hybrid sequence architecture\nfor robust spatiotemporal feature extraction under progressive denoising. On 2D\nNavier-Stokes simulations and ERA5 global weather forecasting at 1.5^\\circ\nresolution, ERDM consistently outperforms key diffusion-based baselines,\nincluding conditional autoregressive EDM. ERDM offers a flexible and powerful\ngeneral framework for tackling diffusion-based sequence generation problems\nwhere modeling escalating uncertainty is paramount. Code is available at:\nhttps://github.com/salvaRC/erdm\n","authors":["Salva Rühling Cachay","Miika Aittala","Karsten Kreis","Noah Brenowitz","Arash Vahdat","Morteza Mardani","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2506.20024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20020v1","updated":"2025-06-24T21:35:17Z","published":"2025-06-24T21:35:17Z","title":"Persona-Assigned Large Language Models Exhibit Human-Like Motivated\n  Reasoning","summary":"  Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.\n","authors":["Saloni Dash","Amélie Reymond","Emma S. Spiro","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2506.20020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20018v1","updated":"2025-06-24T21:22:25Z","published":"2025-06-24T21:22:25Z","title":"Achieving Trustworthy Real-Time Decision Support Systems with\n  Low-Latency Interpretable AI Models","summary":"  This paper investigates real-time decision support systems that leverage\nlow-latency AI models, bringing together recent progress in holistic AI-driven\ndecision tools, integration with Edge-IoT technologies, and approaches for\neffective human-AI teamwork. It looks into how large language models can assist\ndecision-making, especially when resources are limited. The research also\nexamines the effects of technical developments such as DeLLMa, methods for\ncompressing models, and improvements for analytics on edge devices, while also\naddressing issues like limited resources and the need for adaptable frameworks.\nThrough a detailed review, the paper offers practical perspectives on\ndevelopment strategies and areas of application, adding to the field by\npointing out opportunities for more efficient and flexible AI-supported\nsystems. The conclusions set the stage for future breakthroughs in this\nfast-changing area, highlighting how AI can reshape real-time decision support.\n","authors":["Zechun Deng","Ziwei Liu","Ziqian Bi","Junhao Song","Chia Xin Liang","Joe Yeong","Junfeng Hao"],"pdf_url":"https://arxiv.org/pdf/2506.20018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20016v1","updated":"2025-06-24T21:17:48Z","published":"2025-06-24T21:17:48Z","title":"New Insights on Unfolding and Fine-tuning Quantum Federated Learning","summary":"  Client heterogeneity poses significant challenges to the performance of\nQuantum Federated Learning (QFL). To overcome these limitations, we propose a\nnew approach leveraging deep unfolding, which enables clients to autonomously\noptimize hyperparameters, such as learning rates and regularization factors,\nbased on their specific training behavior. This dynamic adaptation mitigates\noverfitting and ensures robust optimization in highly heterogeneous\nenvironments where standard aggregation methods often fail. Our framework\nachieves approximately 90% accuracy, significantly outperforming traditional\nmethods, which typically yield around 55% accuracy, as demonstrated through\nreal-time training on IBM quantum hardware and Qiskit Aer simulators. By\ndeveloping self adaptive fine tuning, the proposed method proves particularly\neffective in critical applications such as gene expression analysis and cancer\ndetection, enhancing diagnostic precision and predictive modeling within\nquantum systems. Our results are attributed to convergence-aware, learnable\noptimization steps intrinsic to the deep unfolded framework, which maintains\nthe generalization. Hence, this study addresses the core limitations of\nconventional QFL, streamlining its applicability to any complex challenges such\nas healthcare and genomic research.\n","authors":["Shanika Iroshi Nanayakkara","Shiva Raj Pokhrel"],"pdf_url":"https://arxiv.org/pdf/2506.20016v1.pdf","comment":"12 pages, 9 figures, 7 Tables, Submitted to IEEE/ACM journal 2025"},{"id":"http://arxiv.org/abs/2406.11898v3","updated":"2025-06-24T21:16:19Z","published":"2024-06-14T21:01:46Z","title":"Towards Better Benchmark Datasets for Inductive Knowledge Graph\n  Completion","summary":"  Knowledge Graph Completion (KGC) attempts to predict missing facts in a\nKnowledge Graph (KG). Recently, there's been an increased focus on designing\nKGC methods that can excel in the inductive setting, where a portion or all of\nthe entities and relations seen in inference are unobserved during training.\nNumerous benchmark datasets have been proposed for inductive KGC, all of which\nare subsets of existing KGs used for transductive KGC. However, we find that\nthe current procedure for constructing inductive KGC datasets inadvertently\ncreates a shortcut that can be exploited even while disregarding the relational\ninformation. Specifically, we observe that the Personalized PageRank (PPR)\nscore can achieve strong or near SOTA performance on most datasets. In this\npaper, we study the root cause of this problem. Using these insights, we\npropose an alternative strategy for constructing inductive KGC datasets that\nhelps mitigate the PPR shortcut. We then benchmark multiple popular methods\nusing the newly constructed datasets and analyze their performance. The new\nbenchmark datasets help promote a better understanding of the capabilities and\nchallenges of inductive KGC by removing any shortcuts that obfuscate\nperformance. The code and dataset and can be found at\nhttps://github.com/HarryShomer/Better-Inductive-KGC.\n","authors":["Harry Shomer","Jay Revolinsky","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2406.11898v3.pdf","comment":"KDD'25 Datasets & Benchmark Track"},{"id":"http://arxiv.org/abs/2506.20009v1","updated":"2025-06-24T20:56:03Z","published":"2025-06-24T20:56:03Z","title":"Accurate and Energy Efficient: Local Retrieval-Augmented Generation\n  Models Outperform Commercial Large Language Models in Medical Tasks","summary":"  Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.\n","authors":["Konstantinos Vrettos","Michail E. Klontzas"],"pdf_url":"https://arxiv.org/pdf/2506.20009v1.pdf","comment":"18 pages, 3 Figures"},{"id":"http://arxiv.org/abs/2506.20008v1","updated":"2025-06-24T20:54:56Z","published":"2025-06-24T20:54:56Z","title":"QHackBench: Benchmarking Large Language Models for Quantum Code\n  Generation Using PennyLane Hackathon Challenges","summary":"  Recent advances in Large Language Models (LLMs) have demonstrated strong\npotential in code generation, yet their effectiveness in quantum computing\nremains underexplored. This paper benchmarks LLMs for PennyLane-based quantum\ncode generation using real-world challenges from the Quantum Hackathon (QHack).\nWe introduce QHackBench, a novel benchmark dataset derived from QHack\ncompetitions, and evaluate model performance under vanilla prompting and\nRetrieval-Augmented Generation (RAG). Our structured evaluation framework\nassesses functional correctness, syntactic validity, and execution success\nacross varying challenge difficulties. Results indicate that RAG-enhanced\nmodels, supplemented with an augmented PennyLane dataset, approximately\ngenerate similar results as the standard prompting, particularly in complex\nquantum algorithms. Additionally, we introduce a multi-agent evaluation\npipeline that iteratively refines incorrect solutions, further enhancing\nexecution success rates. To foster further research, we commit to publicly\nreleasing QHackBench, along with our evaluation framework and experimental\nresults, enabling continued advancements in AI-assisted quantum programming.\n","authors":["Abdul Basit","Minghao Shao","Haider Asif","Nouhaila Innan","Muhammad Kashif","Alberto Marchisio","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2506.20008v1.pdf","comment":"8 pages, 6 figures, 3 tables, submitted to QAI 2025"},{"id":"http://arxiv.org/abs/2506.19997v1","updated":"2025-06-24T20:29:24Z","published":"2025-06-24T20:29:24Z","title":"TRACED: Transition-aware Regret Approximation with Co-learnability for\n  Environment Design","summary":"  Generalizing deep reinforcement learning agents to unseen environments\nremains a significant challenge. One promising solution is Unsupervised\nEnvironment Design (UED), a co-evolutionary framework in which a teacher\nadaptively generates tasks with high learning potential, while a student learns\na robust policy from this evolving curriculum. Existing UED methods typically\nmeasure learning potential via regret, the gap between optimal and current\nperformance, approximated solely by value-function loss. Building on these\napproaches, we introduce the transition prediction error as an additional term\nin our regret approximation. To capture how training on one task affects\nperformance on others, we further propose a lightweight metric called\nco-learnability. By combining these two measures, we present Transition-aware\nRegret Approximation with Co-learnability for Environment Design (TRACED).\nEmpirical evaluations show that TRACED yields curricula that improve zero-shot\ngeneralization across multiple benchmarks while requiring up to 2x fewer\nenvironment interactions than strong baselines. Ablation studies confirm that\nthe transition prediction error drives rapid complexity ramp-up and that\nco-learnability delivers additional gains when paired with the transition\nprediction error. These results demonstrate how refined regret approximation\nand explicit modeling of task relationships can be leveraged for\nsample-efficient curriculum design in UED.\n","authors":["Geonwoo Cho","Jaegyun Im","Jihwan Lee","Hojun Yi","Sejin Kim","Sundong Kim"],"pdf_url":"https://arxiv.org/pdf/2506.19997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19992v1","updated":"2025-06-24T20:22:00Z","published":"2025-06-24T20:22:00Z","title":"HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs\n  for Efficient Summarization","summary":"  The explosive growth of complex datasets across various modalities\nnecessitates advanced analytical tools that not only group data effectively but\nalso provide human-understandable insights into the discovered structures. We\nintroduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using\nLLMs for Efficient Summarization), a novel algorithm and Python package\ndesigned for hierarchical k-means clustering of diverse data types, including\ntext, images, and numeric data (processed one modality per run). HERCULES\nconstructs a cluster hierarchy by recursively applying k-means clustering,\nstarting from individual data points at level 0. A key innovation is its deep\nintegration of Large Language Models (LLMs) to generate semantically rich\ntitles and descriptions for clusters at each level of the hierarchy,\nsignificantly enhancing interpretability. The algorithm supports two main\nrepresentation modes: `direct' mode, which clusters based on original data\nembeddings or scaled numeric features, and `description' mode, which clusters\nbased on embeddings derived from LLM-generated summaries. Users can provide a\n`topic\\_seed' to guide LLM-generated summaries towards specific themes. An\ninteractive visualization tool facilitates thorough analysis and understanding\nof the clustering results. We demonstrate HERCULES's capabilities and discuss\nits potential for extracting meaningful, hierarchical knowledge from complex\ndatasets.\n","authors":["Gabor Petnehazi","Bernadett Aradi"],"pdf_url":"https://arxiv.org/pdf/2506.19992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07813v2","updated":"2025-06-24T20:04:30Z","published":"2025-03-10T19:53:20Z","title":"MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of\n  Field-Grown Maize from a Diversity Panel","summary":"  The development of artificial intelligence (AI) and machine learning (ML)\nbased tools for 3D phenotyping, especially for maize, has been limited due to\nthe lack of large and diverse 3D datasets. 2D image datasets fail to capture\nessential structural details such as leaf architecture, plant volume, and\nspatial arrangements that 3D data provide. To address this limitation, we\npresent MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated\ndataset of 3D point clouds of field-grown maize plants from a diverse genetic\npanel, designed to be AI-ready for advancing agricultural research. Our dataset\nincludes 1,045 high-quality point clouds of field-grown maize collected using a\nterrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset\nwere segmented and annotated using a graph-based segmentation method to isolate\nindividual leaves and stalks, ensuring consistent labeling across all samples.\nThis labeled data was then used for fitting procedural models that provide a\nstructured parametric representation of the maize plants. The leaves of the\nmaize plants in the procedural models are represented using Non-Uniform\nRational B-Spline (NURBS) surfaces that were generated using a two-step\noptimization process combining gradient-free and gradient-based methods. We\nconducted rigorous manual quality control on all datasets, correcting errors in\nsegmentation, ensuring accurate leaf ordering, and validating metadata\nannotations. The dataset also includes metadata detailing plant morphology and\nquality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k\npoints), which can be readily used for different downstream computational\ntasks. MaizeField3D will serve as a comprehensive foundational dataset for\nAI-driven phenotyping, plant structural analysis, and 3D applications in\nagricultural research.\n","authors":["Elvis Kimara","Mozhgan Hadadi","Jackson Godbersen","Aditya Balu","Talukder Jubery","Yawei Li","Adarsh Krishnamurthy","Patrick S. Schnable","Baskar Ganapathysubramanian"],"pdf_url":"https://arxiv.org/pdf/2503.07813v2.pdf","comment":"Elvis Kimara and Mozhgan Hadadi contributed equally to this work"},{"id":"http://arxiv.org/abs/2311.09410v4","updated":"2025-06-24T19:59:56Z","published":"2023-11-15T22:18:33Z","title":"When Large Language Models contradict humans? Large Language Models'\n  Sycophantic Behaviour","summary":"  Large Language Models have been demonstrating broadly satisfactory generative\nabilities for users, which seems to be due to the intensive use of human\nfeedback that refines responses. Nevertheless, suggestibility inherited via\nhuman feedback improves the inclination to produce answers corresponding to\nusers' viewpoints. This behaviour is known as sycophancy and depicts the\ntendency of LLMs to generate misleading responses as long as they align with\nhumans. This phenomenon induces bias and reduces the robustness and,\nconsequently, the reliability of these models. In this paper, we study the\nsuggestibility of Large Language Models (LLMs) to sycophantic behaviour,\nanalysing these tendencies via systematic human-interventions prompts over\ndifferent tasks. Our investigation demonstrates that LLMs have sycophantic\ntendencies when answering queries that involve subjective opinions and\nstatements that should elicit a contrary response based on facts. In contrast,\nwhen faced with math tasks or queries with an objective answer, they, at\nvarious scales, do not follow the users' hints by demonstrating confidence in\ngenerating the correct answers.\n","authors":["Leonardo Ranaldi","Giulia Pucci"],"pdf_url":"https://arxiv.org/pdf/2311.09410v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19977v1","updated":"2025-06-24T19:47:27Z","published":"2025-06-24T19:47:27Z","title":"Context Attribution with Multi-Armed Bandit Optimization","summary":"  Understanding which parts of the retrieved context contribute to a large\nlanguage model's generated answer is essential for building interpretable and\ntrustworthy generative QA systems. We propose a novel framework that formulates\ncontext attribution as a combinatorial multi-armed bandit (CMAB) problem. Each\ncontext segment is treated as a bandit arm, and we employ Combinatorial\nThompson Sampling (CTS) to efficiently explore the exponentially large space of\ncontext subsets under a limited query budget. Our method defines a reward\nfunction based on normalized token likelihoods, capturing how well a subset of\nsegments supports the original model response. Unlike traditional\nperturbation-based attribution methods such as SHAP, which sample subsets\nuniformly and incur high computational costs, our approach adaptively balances\nexploration and exploitation by leveraging posterior estimates of segment\nrelevance. This leads to substantially improved query efficiency while\nmaintaining high attribution fidelity. Extensive experiments on diverse\ndatasets and LLMs demonstrate that our method achieves competitive attribution\nquality with fewer model queries.\n","authors":["Deng Pan","Keerthiram Murugesan","Nuno Moniz","Nitesh Chawla"],"pdf_url":"https://arxiv.org/pdf/2506.19977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19975v1","updated":"2025-06-24T19:44:04Z","published":"2025-06-24T19:44:04Z","title":"VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in\n  Deformable Abdominal CT Registration","summary":"  Recent developments in neural networks have improved deformable image\nregistration (DIR) by amortizing iterative optimization, enabling fast and\naccurate DIR results. However, learning-based methods often face challenges\nwith limited training data, large deformations, and tend to underperform\ncompared to iterative approaches when label supervision is unavailable. While\niterative methods can achieve higher accuracy in such scenarios, they are\nconsiderably slower than learning-based methods. To address these limitations,\nwe propose VoxelOpt, a discrete optimization-based DIR framework that combines\nthe strengths of learning-based and iterative methods to achieve a better\nbalance between registration accuracy and runtime. VoxelOpt uses displacement\nentropy from local cost volumes to measure displacement signal strength at each\nvoxel, which differs from earlier approaches in three key aspects. First, it\nintroduces voxel-wise adaptive message passing, where voxels with lower entropy\nreceives less influence from their neighbors. Second, it employs a multi-level\nimage pyramid with 27-neighbor cost volumes at each level, avoiding exponential\ncomplexity growth. Third, it replaces hand-crafted features or contrastive\nlearning with a pretrained foundational segmentation model for feature\nextraction. In abdominal CT registration, these changes allow VoxelOpt to\noutperform leading iterative in both efficiency and accuracy, while matching\nstate-of-the-art learning-based methods trained with label supervision. The\nsource code will be available at https://github.com/tinymilky/VoxelOpt\n","authors":["Hang Zhang","Yuxi Zhang","Jiazheng Wang","Xiang Chen","Renjiu Hu","Xin Tian","Gaolei Li","Min Liu"],"pdf_url":"https://arxiv.org/pdf/2506.19975v1.pdf","comment":"Accepted for publication at MICCAI 2025"},{"id":"http://arxiv.org/abs/2506.19973v1","updated":"2025-06-24T19:40:39Z","published":"2025-06-24T19:40:39Z","title":"Quantum Neural Networks for Propensity Score Estimation and Survival\n  Analysis in Observational Biomedical Studies","summary":"  This study investigates the application of quantum neural networks (QNNs) for\npropensity score estimation to address selection bias in comparing survival\noutcomes between laparoscopic and open surgical techniques in a cohort of 1177\ncolorectal carcinoma patients treated at University Hospital Ostrava\n(2001-2009). Using a dataset with 77 variables, including patient demographics\nand tumor characteristics, we developed QNN-based propensity score models\nfocusing on four key covariates (Age, Sex, Stage, BMI). The QNN architecture\nemployed a linear ZFeatureMap for data encoding, a SummedPaulis operator for\npredictions, and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\nfor robust, gradient-free optimization in noisy quantum environments. Variance\nregularization was integrated to mitigate quantum measurement noise, with\nsimulations conducted under exact, sampling (1024 shots), and noisy hardware\n(FakeManhattanV2) conditions. QNNs, particularly with simulated hardware noise,\noutperformed classical logistic regression and gradient boosted machines in\nsmall samples (AUC up to 0.750 for n=100), with noise modeling enhancing\npredictive stability. Propensity score matching and weighting, optimized via\ngenetic matching and matching weights, achieved covariate balance with\nstandardized mean differences of 0.0849 and 0.0869, respectively. Survival\nanalyses using Kaplan-Meier estimation, Cox proportional hazards, and Aalen\nadditive regression revealed no significant survival differences\npost-adjustment (p-values 0.287-0.851), indicating confounding bias in\nunadjusted outcomes. These results highlight QNNs' potential, enhanced by\nCMA-ES and noise-aware strategies, to improve causal inference in biomedical\nresearch, particularly for small-sample, high-dimensional datasets.\n","authors":["Vojtěch Novák","Ivan Zelinka","Lenka Přibylová","Lubomír Martínek"],"pdf_url":"https://arxiv.org/pdf/2506.19973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05928v2","updated":"2025-06-24T19:40:14Z","published":"2025-01-10T12:49:12Z","title":"Towards Backdoor Stealthiness in Model Parameter Space","summary":"  Recent research on backdoor stealthiness focuses mainly on indistinguishable\ntriggers in input space and inseparable backdoor representations in feature\nspace, aiming to circumvent backdoor defenses that examine these respective\nspaces. However, existing backdoor attacks are typically designed to resist a\nspecific type of backdoor defense without considering the diverse range of\ndefense mechanisms. Based on this observation, we pose a natural question: Are\ncurrent backdoor attacks truly a real-world threat when facing diverse\npractical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on\ninput-space or feature-space stealthiness and 17 diverse representative\ndefenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks\ndesigned to be stealthy in input and feature spaces can be mitigated by\nexamining backdoored models in parameter space. To investigate the underlying\ncauses behind this common vulnerability, we study the characteristics of\nbackdoor attacks in the parameter space. Notably, we find that input- and\nfeature-space attacks introduce prominent backdoor-related neurons in parameter\nspace, which are not thoroughly considered by current backdoor attacks. Taking\ncomprehensive stealthiness into account, we propose a novel supply-chain attack\ncalled Grond. Grond limits the parameter changes by a simple yet effective\nmodule, Adversarial Backdoor Injection (ABI), which adaptively increases the\nparameter-space stealthiness during the backdoor injection. Extensive\nexperiments demonstrate that Grond outperforms all 12 backdoor attacks against\nstate-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset\nof ImageNet. In addition, we show that ABI consistently improves the\neffectiveness of common backdoor attacks.\n","authors":["Xiaoyun Xu","Zhuoran Liu","Stefanos Koffas","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2501.05928v2.pdf","comment":"to appear at CCS 2025"},{"id":"http://arxiv.org/abs/2506.19967v1","updated":"2025-06-24T19:31:03Z","published":"2025-06-24T19:31:03Z","title":"Inference Scaled GraphRAG: Improving Multi Hop Question Answering on\n  Knowledge Graphs","summary":"  Large Language Models (LLMs) have achieved impressive capabilities in\nlanguage understanding and generation, yet they continue to underperform on\nknowledge-intensive reasoning tasks due to limited access to structured context\nand multi-hop information. Retrieval-Augmented Generation (RAG) partially\nmitigates this by grounding generation in retrieved context, but conventional\nRAG and GraphRAG methods often fail to capture relational structure across\nnodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel\nframework that enhances LLM-based graph reasoning by applying inference-time\ncompute scaling. Our method combines sequential scaling with deep\nchain-of-thought graph traversal, and parallel scaling with majority voting\nover sampled trajectories within an interleaved reasoning-execution loop.\nExperiments on the GRBench benchmark demonstrate that our approach\nsignificantly improves multi-hop question answering performance, achieving\nsubstantial gains over both traditional GraphRAG and prior graph traversal\nbaselines. These findings suggest that inference-time scaling is a practical\nand architecture-agnostic solution for structured knowledge reasoning with LLMs\n","authors":["Travis Thompson","Seung-Hwan Lim","Paul Liu","Ruoying He","Dongkuan Xu"],"pdf_url":"https://arxiv.org/pdf/2506.19967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14488v3","updated":"2025-06-24T19:26:15Z","published":"2024-03-21T15:36:26Z","title":"COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic\n  Programming for Robot Manipulation Under Uncertainty","summary":"  Manipulation tasks require robots to reason about cause and effect when\ninteracting with objects. Yet, many data-driven approaches lack causal\nsemantics and thus only consider correlations. We introduce COBRA-PPM, a novel\ncausal Bayesian reasoning architecture that combines causal Bayesian networks\nand probabilistic programming to perform interventional inference for robot\nmanipulation under uncertainty. We demonstrate its capabilities through\nhigh-fidelity Gazebo-based experiments on an exemplar block stacking task,\nwhere it predicts manipulation outcomes with high accuracy (Pred Acc: 88.6%)\nand performs greedy next-best action selection with a 94.2% task success rate.\nWe further demonstrate sim2real transfer on a domestic robot, showing\neffectiveness in handling real-world uncertainty from sensor noise and\nstochastic actions. Our generalised and extensible framework supports a wide\nrange of manipulation scenarios and lays a foundation for future work at the\nintersection of robotics and causality.\n","authors":["Ricardo Cannizzaro","Michael Groom","Jonathan Routley","Robert Osazuwa Ness","Lars Kunze"],"pdf_url":"https://arxiv.org/pdf/2403.14488v3.pdf","comment":"8 pages, 7 figures, accepted to the 2025 IEEE European Conference on\n  Mobile Robots (ECMR 2025)"},{"id":"http://arxiv.org/abs/2506.19960v1","updated":"2025-06-24T19:12:45Z","published":"2025-06-24T19:12:45Z","title":"An ab initio foundation model of wavefunctions that accurately describes\n  chemical bond breaking","summary":"  Reliable description of bond breaking remains a major challenge for quantum\nchemistry due to the multireferential character of the electronic structure in\ndissociating species. Multireferential methods in particular suffer from large\ncomputational cost, which under the normal paradigm has to be paid anew for\neach system at a full price, ignoring commonalities in electronic structure\nacross molecules. Quantum Monte Carlo with deep neural networks (deep QMC)\nuniquely offers to exploit such commonalities by pretraining transferable\nwavefunction models, but all such attempts were so far limited in scope. Here,\nwe bring this new paradigm to fruition with Orbformer, a novel transferable\nwavefunction model pretrained on 22,000 equilibrium and dissociating structures\nthat can be fine-tuned on unseen molecules reaching an accuracy-cost ratio\nrivalling classical multireferential methods. On established benchmarks as well\nas more challenging bond dissociations and Diels-Alder reactions, Orbformer is\nthe only method that consistently converges to chemical accuracy (1 kcal/mol).\nThis work turns the idea of amortizing the cost of solving the Schr\\\"odinger\nequation over many molecules into a practical approach in quantum chemistry.\n","authors":["Adam Foster","Zeno Schätzle","P. Bernát Szabó","Lixue Cheng","Jonas Köhler","Gino Cassella","Nicholas Gao","Jiawei Li","Frank Noé","Jan Hermann"],"pdf_url":"https://arxiv.org/pdf/2506.19960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19952v1","updated":"2025-06-24T18:56:57Z","published":"2025-06-24T18:56:57Z","title":"CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical\n  Distillation","summary":"  Large language models (LLMs), despite their ability to perform few-shot\nmachine translation (MT), often lag behind dedicated MT systems trained on\nparallel corpora, which are crucial for high quality machine translation (MT).\nHowever, parallel corpora are often scarce or non-existent for low-resource\nlanguages. In this paper, we propose CycleDistill, a bootstrapping approach\nleveraging LLMs and few-shot translation to obtain high-quality MT systems.\nCycleDistill involves iteratively generating synthetic parallel corpora from\nmonolingual corpora via zero- or few-shot MT, which is then used to fine-tune\nthe model that was used for generating said data for MT. CycleDistill does not\nneed parallel corpora beyond 1 to 4 few-shot examples, and in our experiments\nfocusing on three Indian languages, by relying solely on monolingual corpora,\nit can achieve high-quality machine translation, improving upon a few-shot\nbaseline model by over 20-30 chrF points on average in the first iteration. We\nalso study the effect of leveraging softmax activations during the distillation\nprocess and observe mild improvements in translation quality.\n","authors":["Deepon Halder","Thanmay Jayakumar","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2506.19952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00523v3","updated":"2025-06-24T18:55:29Z","published":"2024-08-01T12:54:46Z","title":"Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient\n  Framework for Jailbreaking Text-To-Image Generation Models","summary":"  Text-to-image (T2I) generative models have revolutionized content creation by\ntransforming textual descriptions into high-quality images. However, these\nmodels are vulnerable to jailbreaking attacks, where carefully crafted prompts\nbypass safety mechanisms to produce unsafe content. While researchers have\ndeveloped various jailbreak attacks to expose this risk, these methods face\nsignificant limitations, including impractical access requirements, easily\ndetectable unnatural prompts, restricted search spaces, and high query demands\non the target system. In this paper, we propose JailFuzzer, a novel fuzzing\nframework driven by large language model (LLM) agents, designed to efficiently\ngenerate natural and semantically meaningful jailbreak prompts in a black-box\nsetting. Specifically, JailFuzzer employs fuzz-testing principles with three\ncomponents: a seed pool for initial and jailbreak prompts, a guided mutation\nengine for generating meaningful variations, and an oracle function to evaluate\njailbreak success. Furthermore, we construct the guided mutation engine and\noracle function by LLM-based agents, which further ensures efficiency and\nadaptability in black-box settings. Extensive experiments demonstrate that\nJailFuzzer has significant advantages in jailbreaking T2I models. It generates\nnatural and semantically coherent prompts, reducing the likelihood of detection\nby traditional defenses. Additionally, it achieves a high success rate in\njailbreak attacks with minimal query overhead, outperforming existing methods\nacross all key metrics. This study underscores the need for stronger safety\nmechanisms in generative models and provides a foundation for future research\non defending against sophisticated jailbreaking attacks. JailFuzzer is\nopen-source and available at this repository:\nhttps://github.com/YingkaiD/JailFuzzer.\n","authors":["Yingkai Dong","Xiangtao Meng","Ning Yu","Zheng Li","Shanqing Guo"],"pdf_url":"https://arxiv.org/pdf/2408.00523v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00089v2","updated":"2025-06-24T18:54:25Z","published":"2025-02-28T15:14:33Z","title":"Protein Structure Tokenization: Benchmarking and New Recipe","summary":"  Recent years have witnessed a surge in the development of protein structural\ntokenization methods, which chunk protein 3D structures into discrete or\ncontinuous representations. Structure tokenization enables the direct\napplication of powerful techniques like language modeling for protein\nstructures, and large multimodal models to integrate structures with protein\nsequences and functional texts. Despite the progress, the capabilities and\nlimitations of these methods remain poorly understood due to the lack of a\nunified evaluation framework. We first introduce StructTokenBench, a framework\nthat comprehensively evaluates the quality and efficiency of structure\ntokenizers, focusing on fine-grained local substructures rather than global\nstructures, as typical in existing benchmarks. Our evaluations reveal that no\nsingle model dominates all benchmarking perspectives. Observations of codebook\nunder-utilization led us to develop AminoAseed, a simple yet effective strategy\nthat enhances codebook gradient updates and optimally balances codebook size\nand dimension for improved tokenizer utilization and quality. Compared to the\nleading model ESM3, our method achieves an average of 6.31% performance\nimprovement across 24 supervised tasks, with sensitivity and utilization rates\nincreased by 12.83% and 124.03%, respectively. Source code and model weights\nare available at https://github.com/KatarinaYuan/StructTokenBench\n","authors":["Xinyu Yuan","Zichen Wang","Marcus Collins","Huzefa Rangwala"],"pdf_url":"https://arxiv.org/pdf/2503.00089v2.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2506.20685v1","updated":"2025-06-24T18:50:33Z","published":"2025-06-24T18:50:33Z","title":"Progressive Size-Adaptive Federated Learning: A Comprehensive Framework\n  for Heterogeneous Multi-Modal Data Systems","summary":"  Federated Learning (FL) has emerged as a transformative paradigm for\ndistributed machine learning while preserving data privacy. However, existing\napproaches predominantly focus on model heterogeneity and aggregation\ntechniques, largely overlooking the fundamental impact of dataset size\ncharacteristics on federated training dynamics. This paper introduces\nSize-Based Adaptive Federated Learning (SAFL), a novel progressive training\nframework that systematically organizes federated learning based on dataset\nsize characteristics across heterogeneous multi-modal data. Our comprehensive\nexperimental evaluation across 13 diverse datasets spanning 7 modalities\n(vision, text, time series, audio, sensor, medical vision, and multimodal)\nreveals critical insights: 1) an optimal dataset size range of 1000-1500\nsamples for federated learning effectiveness; 2) a clear modality performance\nhierarchy with structured data (time series, sensor) significantly\noutperforming unstructured data (text, multimodal); and 3) systematic\nperformance degradation for large datasets exceeding 2000 samples. SAFL\nachieves an average accuracy of 87.68% across all datasets, with structured\ndata modalities reaching 99%+ accuracy. The framework demonstrates superior\ncommunication efficiency, reducing total data transfer to 7.38 GB across 558\ncommunications while maintaining high performance. Our real-time monitoring\nframework provides unprecedented insights into system resource utilization,\nnetwork efficiency, and training dynamics. This work fills critical gaps in\nunderstanding how data characteristics should drive federated learning\nstrategies, providing both theoretical insights and practical guidance for\nreal-world FL deployments in neural network and learning systems.\n","authors":["Sajid Hussain","Muhammad Sohail","Nauman Ali Khan","Naima Iltaf","Ihtesham ul Islam"],"pdf_url":"https://arxiv.org/pdf/2506.20685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19923v1","updated":"2025-06-24T18:01:52Z","published":"2025-06-24T18:01:52Z","title":"Prover Agent: An Agent-based Framework for Formal Mathematical Proofs","summary":"  We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.\n","authors":["Kaito Baba","Chaoran Liu","Shuhei Kurita","Akiyoshi Sannai"],"pdf_url":"https://arxiv.org/pdf/2506.19923v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2506.19852v1","updated":"2025-06-24T17:59:59Z","published":"2025-06-24T17:59:59Z","title":"Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for\n  Long Video Generation","summary":"  Recent advances in diffusion models have enabled high-quality video\ngeneration, but the additional temporal dimension significantly increases\ncomputational costs, making training and inference on long videos prohibitively\nexpensive. In this paper, we identify a phenomenon we term Spatiotemporal\nEnergy Decay in video diffusion models: post-softmax attention scores diminish\nas spatial and temporal distance between tokens increase, akin to the physical\ndecay of signal or waves over space and time in nature. Motivated by this, we\npropose Radial Attention, a scalable sparse attention mechanism with $O(n \\log\nn)$ complexity that translates energy decay into exponentially decaying compute\ndensity, which is significantly more efficient than standard $O(n^2)$ dense\nattention and more expressive than linear attention. Specifically, Radial\nAttention employs a simple, static attention mask where each token attends to\nspatially nearby tokens, with the attention window size shrinking with temporal\ndistance. Moreover, it allows pre-trained video diffusion models to extend\ntheir generation length with efficient LoRA-based fine-tuning. Extensive\nexperiments show that Radial Attention maintains video quality across\nWan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$\\times$ speedup\nover the original dense attention. With minimal tuning, it enables video\ngeneration up to 4$\\times$ longer while reducing training costs by up to\n4.4$\\times$ compared to direct fine-tuning and accelerating inference by up to\n3.7$\\times$ compared to dense attention inference.\n","authors":["Xingyang Li","Muyang Li","Tianle Cai","Haocheng Xi","Shuo Yang","Yujun Lin","Lvmin Zhang","Songlin Yang","Jinbo Hu","Kelly Peng","Maneesh Agrawala","Ion Stoica","Kurt Keutzer","Song Han"],"pdf_url":"https://arxiv.org/pdf/2506.19852v1.pdf","comment":"Code: https://github.com/mit-han-lab/radial-attention"},{"id":"http://arxiv.org/abs/2506.19847v1","updated":"2025-06-24T17:59:49Z","published":"2025-06-24T17:59:49Z","title":"Orthogonal Finetuning Made Scalable","summary":"  Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation\nwhile preventing catastrophic forgetting, but its high runtime and memory\ndemands limit practical deployment. We identify the core computational\nbottleneck in OFT as its weight-centric implementation, which relies on costly\nmatrix-matrix multiplications with cubic complexity. To overcome this, we\npropose OFTv2, an input-centric reformulation that instead uses matrix-vector\nmultiplications (i.e., matrix-free computation), reducing the computational\ncost to quadratic. We further introduce the Cayley-Neumann parameterization, an\nefficient orthogonal parameterization that approximates the matrix inversion in\nCayley transform via a truncated Neumann series. These modifications allow\nOFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage\nwithout compromising performance. In addition, we extend OFTv2 to support\nfinetuning quantized foundation models and show that it outperforms the popular\nQLoRA in training stability, efficiency, and memory usage.\n","authors":["Zeju Qiu","Weiyang Liu","Adrian Weller","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2506.19847v1.pdf","comment":"Technical report (17 pages, 7 figures, project page:\n  https://spherelab.ai/oftv2/)"},{"id":"http://arxiv.org/abs/2506.19846v1","updated":"2025-06-24T17:59:31Z","published":"2025-06-24T17:59:31Z","title":"JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents\n  with Reinforcement Learning","summary":"  Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm\nfor increasingly complex tasks. However, joint evolution across heterogeneous\nagents remains challenging due to cooperative inefficiency and training\ninstability. In this paper, we propose the joint evolution dynamics for MARL\ncalled JoyAgents-R1, which first applies Group Relative Policy Optimization\n(GRPO) to the joint training of heterogeneous multi-agents. By iteratively\nrefining agents' large language models (LLMs) and memories, the method achieves\nholistic equilibrium with optimal decision-making and memory capabilities.\nSpecifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on\nthe behavior of each agent across entire reasoning trajectories to enhance GRPO\nsampling efficiency while maintaining policy diversity. Then, our marginal\nbenefit-driven selection strategy identifies top-$K$ sampling groups with\nmaximal reward fluctuations, enabling targeted agent model updates that improve\ntraining stability and maximize joint benefits through cost-effective parameter\nadjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution\nmechanism that repurposes GRPO rewards as cost-free supervisory signals to\neliminate repetitive reasoning and accelerate convergence. Experiments across\ngeneral and domain-specific scenarios demonstrate that JoyAgents-R1 achieves\nperformance comparable to that of larger LLMs while built on smaller\nopen-source models.\n","authors":["Ai Han","Junxing Hu","Pu Wei","Zhiqian Zhang","Yuhang Guo","Jiawei Lu","Zicheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.19846v1.pdf","comment":"33 pages, 7 figures, under review"},{"id":"http://arxiv.org/abs/2506.19843v1","updated":"2025-06-24T17:59:12Z","published":"2025-06-24T17:59:12Z","title":"Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse\n  Reinforcement Learning","summary":"  Predicting port congestion is crucial for maintaining reliable global supply\nchains. Accurate forecasts enableimprovedshipment planning, reducedelaysand\ncosts, and optimizeinventoryanddistributionstrategies, thereby ensuring timely\ndeliveries and enhancing supply chain resilience. To achieve accurate\npredictions, analyzing vessel behavior and their stay times at specific port\nterminals is essential, focusing particularly on berth scheduling under various\nconditions. Crucially, the model must capture and learn the underlying\npriorities and patterns of berth scheduling. Berth scheduling and planning are\ninfluenced by a range of factors, including incoming vessel size, waiting\ntimes, and the status of vessels within the port terminal. By observing\nhistorical Automatic Identification System (AIS) positions of vessels, we\nreconstruct berth schedules, which are subsequently utilized to determine the\nreward function via Inverse Reinforcement Learning (IRL). For this purpose, we\nmodeled a specific terminal at the Port of New York/New Jersey and developed\nTemporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel\nsequencing at the terminal and estimate vessel port stay, encompassing both\nwaiting and berthing times, to forecast port congestion. Utilizing data from\nMaher Terminal spanning January 2015 to September 2023, we trained and tested\nthe model, achieving demonstrably excellent results.\n","authors":["Guo Li","Zixiang Xu","Wei Zhang","Yikuan Hu","Xinyu Yang","Nikolay Aristov","Mingjie Tang","Elenna R Dugundji"],"pdf_url":"https://arxiv.org/pdf/2506.19843v1.pdf","comment":"TRB2025"},{"id":"http://arxiv.org/abs/2506.19842v1","updated":"2025-06-24T17:59:06Z","published":"2025-06-24T17:59:06Z","title":"ManiGaussian++: General Robotic Bimanual Manipulation with Hierarchical\n  Gaussian World Model","summary":"  Multi-task robotic bimanual manipulation is becoming increasingly popular as\nit enables sophisticated tasks that require diverse dual-arm collaboration\npatterns. Compared to unimanual manipulation, bimanual tasks pose challenges to\nunderstanding the multi-body spatiotemporal dynamics. An existing method\nManiGaussian pioneers encoding the spatiotemporal dynamics into the visual\nrepresentation via Gaussian world model for single-arm settings, which ignores\nthe interaction of multiple embodiments for dual-arm systems with significant\nperformance drop. In this paper, we propose ManiGaussian++, an extension of\nManiGaussian framework that improves multi-task bimanual manipulation by\ndigesting multi-body scene dynamics through a hierarchical Gaussian world\nmodel. To be specific, we first generate task-oriented Gaussian Splatting from\nintermediate visual features, which aims to differentiate acting and\nstabilizing arms for multi-body spatiotemporal dynamics modeling. We then build\na hierarchical Gaussian world model with the leader-follower architecture,\nwhere the multi-body spatiotemporal dynamics is mined for intermediate visual\nrepresentation via future scene prediction. The leader predicts Gaussian\nSplatting deformation caused by motions of the stabilizing arm, through which\nthe follower generates the physical consequences resulted from the movement of\nthe acting arm. As a result, our method significantly outperforms the current\nstate-of-the-art bimanual manipulation techniques by an improvement of 20.2% in\n10 simulated tasks, and achieves 60% success rate on average in 9 challenging\nreal-world tasks. Our code is available at\nhttps://github.com/April-Yz/ManiGaussian_Bimanual.\n","authors":["Tengbo Yu","Guanxing Lu","Zaijia Yang","Haoyuan Deng","Season Si Chen","Jiwen Lu","Wenbo Ding","Guoqiang Hu","Yansong Tang","Ziwei Wang"],"pdf_url":"https://arxiv.org/pdf/2506.19842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19839v1","updated":"2025-06-24T17:58:02Z","published":"2025-06-24T17:58:02Z","title":"Improving Progressive Generation with Decomposable Flow Matching","summary":"  Generating high-dimensional visual modalities is a computationally intensive\ntask. A common solution is progressive generation, where the outputs are\nsynthesized in a coarse-to-fine spectral autoregressive manner. While diffusion\nmodels benefit from the coarse-to-fine nature of denoising, explicit\nmulti-stage architectures are rarely adopted. These architectures have\nincreased the complexity of the overall approach, introducing the need for a\ncustom diffusion formulation, decomposition-dependent stage transitions,\nadd-hoc samplers, or a model cascade. Our contribution, Decomposable Flow\nMatching (DFM), is a simple and effective framework for the progressive\ngeneration of visual media. DFM applies Flow Matching independently at each\nlevel of a user-defined multi-scale representation (such as Laplacian pyramid).\nAs shown by our experiments, our approach improves visual quality for both\nimages and videos, featuring superior results compared to prior multistage\nframeworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores\nover the base architecture and 26.4% over the best-performing baseline, under\nthe same training compute. When applied to finetuning of large models, such as\nFLUX, DFM shows faster convergence speed to the training distribution.\nCrucially, all these advantages are achieved with a single model, architectural\nsimplicity, and minimal modifications to existing training pipelines.\n","authors":["Moayed Haji-Ali","Willi Menapace","Ivan Skorokhodov","Arpit Sahni","Sergey Tulyakov","Vicente Ordonez","Aliaksandr Siarohin"],"pdf_url":"https://arxiv.org/pdf/2506.19839v1.pdf","comment":"Project Webpage: https://snap-research.github.io/dfm/"},{"id":"http://arxiv.org/abs/2506.19834v1","updated":"2025-06-24T17:50:49Z","published":"2025-06-24T17:50:49Z","title":"A standard transformer and attention with linear biases for molecular\n  conformer generation","summary":"  Sampling low-energy molecular conformations, spatial arrangements of atoms in\na molecule, is a critical task for many different calculations performed in the\ndrug discovery and optimization process. Numerous specialized equivariant\nnetworks have been designed to generate molecular conformations from 2D\nmolecular graphs. Recently, non-equivariant transformer models have emerged as\na viable alternative due to their capability to scale to improve\ngeneralization. However, the concern has been that non-equivariant models\nrequire a large model size to compensate the lack of equivariant bias. In this\npaper, we demonstrate that a well-chosen positional encoding effectively\naddresses these size limitations. A standard transformer model incorporating\nrelative positional encoding for molecular graphs when scaled to 25 million\nparameters surpasses the current state-of-the-art non-equivariant base model\nwith 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative\npositional encoding as a negative attention bias that linearly increases with\nthe shortest path distances between graph nodes at varying slopes for different\nattention heads, similar to ALiBi, a widely adopted relative positional\nencoding technique in the NLP domain. This architecture has the potential to\nserve as a foundation for a novel class of generative models for molecular\nconformations.\n","authors":["Viatcheslav Gurev","Timothy Rumbell"],"pdf_url":"https://arxiv.org/pdf/2506.19834v1.pdf","comment":"Revision of paper at OpenReview:\n  https://openreview.net/forum?id=BjjerMYL3F"},{"id":"http://arxiv.org/abs/2506.19825v1","updated":"2025-06-24T17:42:36Z","published":"2025-06-24T17:42:36Z","title":"Evaluating Compliance with Visualization Guidelines in Diagrams for\n  Scientific Publications Using Large Vision Language Models","summary":"  Diagrams are widely used to visualize data in publications. The research\nfield of data visualization deals with defining principles and guidelines for\nthe creation and use of these diagrams, which are often not known or adhered to\nby researchers, leading to misinformation caused by providing inaccurate or\nincomplete information.\n  In this work, large Vision Language Models (VLMs) are used to analyze\ndiagrams in order to identify potential problems in regards to selected data\nvisualization principles and guidelines. To determine the suitability of VLMs\nfor these tasks, five open source VLMs and five prompting strategies are\ncompared using a set of questions derived from selected data visualization\nguidelines.\n  The results show that the employed VLMs work well to accurately analyze\ndiagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels\n(F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score\n96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the\nimage quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among\nthe employed VLMs, Qwen2.5VL performs best, and the summarizing prompting\nstrategy performs best for most of the experimental questions.\n  It is shown that VLMs can be used to automatically identify a number of\npotential issues in diagrams, such as missing axes labels, missing legends, and\nunnecessary 3D effects. The approach laid out in this work can be extended for\nfurther aspects of data visualization.\n","authors":["Johannes Rückert","Louise Bloch","Christoph M. Friedrich"],"pdf_url":"https://arxiv.org/pdf/2506.19825v1.pdf","comment":"Accepted at ICDAR 2025"},{"id":"http://arxiv.org/abs/2506.19823v1","updated":"2025-06-24T17:38:21Z","published":"2025-06-24T17:38:21Z","title":"Persona Features Control Emergent Misalignment","summary":"  Understanding how language models generalize behaviors from their training to\na broader deployment distribution is an important problem in AI safety. Betley\net al. discovered that fine-tuning GPT-4o on intentionally insecure code causes\n\"emergent misalignment,\" where models give stereotypically malicious responses\nto unrelated prompts. We extend this work, demonstrating emergent misalignment\nacross diverse conditions, including reinforcement learning on reasoning\nmodels, fine-tuning on various synthetic datasets, and in models without safety\ntraining. To investigate the mechanisms behind this generalized misalignment,\nwe apply a \"model diffing\" approach using sparse autoencoders to compare\ninternal model representations before and after fine-tuning. This approach\nreveals several \"misaligned persona\" features in activation space, including a\ntoxic persona feature which most strongly controls emergent misalignment and\ncan be used to predict whether a model will exhibit such behavior.\nAdditionally, we investigate mitigation strategies, discovering that\nfine-tuning an emergently misaligned model on just a few hundred benign samples\nefficiently restores alignment.\n","authors":["Miles Wang","Tom Dupré la Tour","Olivia Watkins","Alex Makelov","Ryan A. Chi","Samuel Miserendino","Johannes Heidecke","Tejal Patwardhan","Dan Mossing"],"pdf_url":"https://arxiv.org/pdf/2506.19823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20683v1","updated":"2025-06-24T17:19:39Z","published":"2025-06-24T17:19:39Z","title":"Global and Local Contrastive Learning for Joint Representations from\n  Cardiac MRI and ECG","summary":"  An electrocardiogram (ECG) is a widely used, cost-effective tool for\ndetecting electrical abnormalities in the heart. However, it cannot directly\nmeasure functional parameters, such as ventricular volumes and ejection\nfraction, which are crucial for assessing cardiac function. Cardiac magnetic\nresonance (CMR) is the gold standard for these measurements, providing detailed\nstructural and functional insights, but is expensive and less accessible. To\nbridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive\nLearning), a multimodal contrastive learning framework that enhances ECG\nrepresentations by integrating spatio-temporal information from CMR. PTACL uses\nglobal patient-level contrastive loss and local temporal-level contrastive\nloss. The global loss aligns patient-level representations by pulling ECG and\nCMR embeddings from the same patient closer together, while pushing apart\nembeddings from different patients. Local loss enforces fine-grained temporal\nalignment within each patient by contrasting encoded ECG segments with\ncorresponding encoded CMR frames. This approach enriches ECG representations\nwith diagnostic information beyond electrical activity and transfers more\ninsights between modalities than global alignment alone, all without\nintroducing new learnable weights. We evaluate PTACL on paired ECG-CMR data\nfrom 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL\nachieves better performance in two clinically relevant tasks: (1) retrieving\npatients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac\nfunction parameters, such as ventricular volumes and ejection fraction. Our\nresults highlight the potential of PTACL to enhance non-invasive cardiac\ndiagnostics using ECG. The code is available at:\nhttps://github.com/alsalivan/ecgcmr\n","authors":["Alexander Selivanov","Philip Müller","Özgün Turgut","Nil Stolt-Ansó","Daniel Rückert"],"pdf_url":"https://arxiv.org/pdf/2506.20683v1.pdf","comment":"accepted to MICCAI 2025 (Springer LNCS)"},{"id":"http://arxiv.org/abs/2506.19807v1","updated":"2025-06-24T17:17:17Z","published":"2025-06-24T17:17:17Z","title":"KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality","summary":"  Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL.\n","authors":["Baochang Ren","Shuofei Qiao","Wenhao Yu","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.19807v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.19794v1","updated":"2025-06-24T17:04:23Z","published":"2025-06-24T17:04:23Z","title":"Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic\n  Empirical Study","summary":"  Large Language Models (LLMs) hold promise in automating data analysis tasks,\nyet open-source models face significant limitations in these kinds of\nreasoning-intensive scenarios. In this work, we investigate strategies to\nenhance the data analysis capabilities of open-source LLMs. By curating a seed\ndataset of diverse, realistic scenarios, we evaluate models across three\ndimensions: data understanding, code generation, and strategic planning. Our\nanalysis reveals three key findings: (1) Strategic planning quality serves as\nthe primary determinant of model performance; (2) Interaction design and task\ncomplexity significantly influence reasoning capabilities; (3) Data quality\ndemonstrates a greater impact than diversity in achieving optimal performance.\nWe leverage these insights to develop a data synthesis methodology,\ndemonstrating significant improvements in open-source LLMs' analytical\nreasoning capabilities.\n","authors":["Yuqi Zhu","Yi Zhong","Jintian Zhang","Ziheng Zhang","Shuofei Qiao","Yujie Luo","Lun Du","Da Zheng","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.19794v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2506.19785v1","updated":"2025-06-24T16:52:00Z","published":"2025-06-24T16:52:00Z","title":"Learning Task Belief Similarity with Latent Dynamics for\n  Meta-Reinforcement Learning","summary":"  Meta-reinforcement learning requires utilizing prior task distribution\ninformation obtained during exploration to rapidly adapt to unknown tasks. The\nefficiency of an agent's exploration hinges on accurately identifying the\ncurrent task. Recent Bayes-Adaptive Deep RL approaches often rely on\nreconstructing the environment's reward signal, which is challenging in sparse\nreward settings, leading to suboptimal exploitation. Inspired by bisimulation\nmetrics, which robustly extracts behavioral similarity in continuous MDPs, we\npropose SimBelief-a novel meta-RL framework via measuring similarity of task\nbelief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common\nfeatures of similar task distributions, enabling efficient task identification\nand exploration in sparse reward environments. We introduce latent task belief\nmetric to learn the common structure of similar tasks and incorporate it into\nthe specific task belief. By learning the latent dynamics across task\ndistributions, we connect shared latent task belief features with specific task\nfeatures, facilitating rapid task identification and adaptation. Our method\noutperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym\ntasks.\n","authors":["Menglong Zhang","Fuyuan Qian"],"pdf_url":"https://arxiv.org/pdf/2506.19785v1.pdf","comment":"ICLR2025 https://openreview.net/forum?id=5YbuOTUFQ4"},{"id":"http://arxiv.org/abs/2506.19783v1","updated":"2025-06-24T16:50:51Z","published":"2025-06-24T16:50:51Z","title":"SAGE: Strategy-Adaptive Generation Engine for Query Rewriting","summary":"  Query rewriting is pivotal for enhancing dense retrieval, yet current methods\ndemand large-scale supervised data or suffer from inefficient reinforcement\nlearning (RL) exploration. In this work, we first establish that guiding Large\nLanguage Models (LLMs) with a concise set of expert-crafted strategies, such as\nsemantic expansion and entity disambiguation, substantially improves retrieval\neffectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus,\nand SciFact. Building on this insight, we introduce the Strategy-Adaptive\nGeneration Engine (SAGE), which operationalizes these strategies in an RL\nframework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit\nShaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative\nlearning signals. This strategy-guided approach not only achieves new\nstate-of-the-art NDCG@10 results, but also uncovers a compelling emergent\nbehavior: the agent learns to select optimal strategies, reduces unnecessary\nexploration, and generates concise rewrites, lowering inference cost without\nsacrificing performance. Our findings demonstrate that strategy-guided RL,\nenhanced with nuanced reward shaping, offers a scalable, efficient, and more\ninterpretable paradigm for developing the next generation of robust information\nretrieval systems.\n","authors":["Teng Wang","Hailei Gong","Changwang Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2506.19783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10326v2","updated":"2025-06-24T16:45:26Z","published":"2025-01-17T17:56:58Z","title":"Large language models for automated scholarly paper review: A survey","summary":"  Large language models (LLMs) have significantly impacted human society,\ninfluencing various domains. Among them, academia is not simply a domain\naffected by LLMs, but it is also the pivotal force in the development of LLMs.\nIn academic publication, this phenomenon is represented during the\nincorporation of LLMs into the peer review mechanism for reviewing manuscripts.\nLLMs hold transformative potential for the full-scale implementation of\nautomated scholarly paper review (ASPR), but they also pose new issues and\nchallenges that need to be addressed. In this survey paper, we aim to provide a\nholistic view of ASPR in the era of LLMs. We begin with a survey to find out\nwhich LLMs are used to conduct ASPR. Then, we review what ASPR-related\ntechnological bottlenecks have been solved with the incorporation of LLM\ntechnology. After that, we move on to explore new methods, new datasets, new\nsource code, and new online systems that come with LLMs for ASPR. Furthermore,\nwe summarize the performance and issues of LLMs in ASPR, and investigate the\nattitudes and reactions of publishers and academia to ASPR. Lastly, we discuss\nthe challenges and future directions associated with the development of LLMs\nfor ASPR. This survey serves as an inspirational reference for the researchers\nand can promote the progress of ASPR for its actual implementation.\n","authors":["Zhenzhen Zhuang","Jiandong Chen","Hongfeng Xu","Yuwen Jiang","Jialiang Lin"],"pdf_url":"https://arxiv.org/pdf/2501.10326v2.pdf","comment":"Please cite the version of Information Fusion"},{"id":"http://arxiv.org/abs/2401.08405v4","updated":"2025-06-24T16:45:18Z","published":"2024-01-16T14:44:13Z","title":"Interrogating AI: Characterizing Emergent Playful Interactions with\n  ChatGPT","summary":"  In an era of AI's growing capabilities and influences, recent advancements\nare reshaping HCI and CSCW's view of AI. Playful interactions emerged as an\nimportant way for users to make sense of the ever-changing AI technologies, yet\nremained underexamined. We target this gap by investigating playful\ninteractions exhibited by users of a popular AI technology, ChatGPT. Through a\nthematic analysis of 372 user-generated posts on the ChatGPT subreddit, we\nfound that more than half (54\\%) of user discourse revolved around playful\ninteractions. The analysis further allowed us to construct a preliminary\nframework to describe these interactions, categorizing them into six types:\nreflecting, jesting, imitating, challenging, tricking, and contriving; each\nincluded sub-categories. This study contributes to HCI and CSCW by identifying\nthe diverse ways users engage in playful interactions with AI. It examines how\nthese interactions can help users understand AI's agency, shape human-AI\nrelationships, and provide insights for designing AI systems.\n","authors":["Mohammad Ronagh Nikghalb","Jinghui Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.08405v4.pdf","comment":"Accepted to CSCW 2025; 23 pages"},{"id":"http://arxiv.org/abs/2506.19777v1","updated":"2025-06-24T16:42:46Z","published":"2025-06-24T16:42:46Z","title":"Alleviating User-Sensitive bias with Fair Generative Sequential\n  Recommendation Model","summary":"  Recommendation fairness has recently attracted much attention. In the real\nworld, recommendation systems are driven by user behavior, and since users with\nthe same sensitive feature (e.g., gender and age) tend to have the same\npatterns, recommendation models can easily capture the strong correlation\npreference of sensitive features and thus cause recommendation unfairness.\nDiffusion model (DM) as a new generative model paradigm has achieved great\nsuccess in recommendation systems. DM's ability to model uncertainty and\nrepresent diversity, and its modeling mechanism has a high degree of\nadaptability with the real-world recommendation process with bias. Therefore,\nwe use DM to effectively model the fairness of recommendation and enhance the\ndiversity. This paper proposes a FairGENerative sequential Recommendation model\nbased on DM, FairGENRec. In the training phase, we inject random noise into the\noriginal distribution under the guidance of the sensitive feature recognition\nmodel, and a sequential denoise model is designed for the reverse\nreconstruction of items. Simultaneously, recommendation fairness modeling is\ncompleted by injecting multi-interests representational information that\neliminates the bias of sensitive user features into the generated results. In\nthe inference phase, the model obtains the noise in the form of noise addition\nby using the history interactions which is followed by reverse iteration to\nreconstruct the target item representation. Finally, our extensive experiments\non three datasets demonstrate the dual enhancement effect of FairGENRec on\naccuracy and fairness, while the statistical analysis of the cases visualizes\nthe degree of improvement on the fairness of the recommendation.\n","authors":["Yang Liu","Feng Wu","Xuefang Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.19777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19774v1","updated":"2025-06-24T16:39:39Z","published":"2025-06-24T16:39:39Z","title":"Kling-Foley: Multimodal Diffusion Transformer for High-Quality\n  Video-to-Audio Generation","summary":"  We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation\nmodel that synthesizes high-quality audio synchronized with video content. In\nKling-Foley, we introduce multimodal diffusion transformers to model the\ninteractions between video, audio, and text modalities, and combine it with a\nvisual semantic representation module and an audio-visual synchronization\nmodule to enhance alignment capabilities. Specifically, these modules align\nvideo conditions with latent audio elements at the frame level, thereby\nimproving semantic alignment and audio-visual synchronization. Together with\ntext conditions, this integrated approach enables precise generation of\nvideo-matching sound effects. In addition, we propose a universal latent audio\ncodec that can achieve high-quality modeling in various scenarios such as sound\neffects, speech, singing, and music. We employ a stereo rendering method that\nimbues synthesized audio with a spatial presence. At the same time, in order to\nmake up for the incomplete types and annotations of the open-source benchmark,\nwe also open-source an industrial-level benchmark Kling-Audio-Eval. Our\nexperiments show that Kling-Foley trained with the flow matching objective\nachieves new audio-visual SOTA performance among public models in terms of\ndistribution matching, semantic alignment, temporal alignment and audio\nquality.\n","authors":["Jun Wang","Xijuan Zeng","Chunyu Qiang","Ruilong Chen","Shiyao Wang","Le Wang","Wangjing Zhou","Pengfei Cai","Jiahui Zhao","Nan Li","Zihan Li","Yuzhe Liang","Xiaopeng Wang","Haorui Zheng","Ming Wen","Kang Yin","Yiran Wang","Nan Li","Feng Deng","Liang Dong","Chen Zhang","Di Zhang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2506.19774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19773v1","updated":"2025-06-24T16:38:49Z","published":"2025-06-24T16:38:49Z","title":"Automatic Prompt Optimization for Knowledge Graph Construction: Insights\n  from an Empirical Study","summary":"  A KG represents a network of entities and illustrates relationships between\nthem. KGs are used for various applications, including semantic search and\ndiscovery, reasoning, decision-making, natural language processing, machine\nlearning, and recommendation systems. Triple (subject-relation-object)\nextraction from text is the fundamental building block of KG construction and\nhas been widely studied, for example, in early benchmarks such as ACE 2002 to\nmore recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs\nis explored for KG construction, handcrafting reasonable task-specific prompts\nfor LLMs is a labour-intensive exercise and can be brittle due to subtle\nchanges in the LLM models employed. Recent work in NLP tasks (e.g. autonomy\ngeneration) uses automatic prompt optimization/engineering to address this\nchallenge by generating optimal or near-optimal task-specific prompts given\ninput-output examples.\n  This empirical study explores the application of automatic prompt\noptimization for the triple extraction task using experimental benchmarking. We\nevaluate different settings by changing (a) the prompting strategy, (b) the LLM\nbeing used for prompt optimization and task execution, (c) the number of\ncanonical relations in the schema (schema complexity), (d) the length and\ndiversity of input text, (e) the metric used to drive the prompt optimization,\nand (f) the dataset being used for training and testing. We evaluate three\ndifferent automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use\ntwo different triple extraction datasets, SynthIE and REBEL. Through rigorous\nempirical evaluation, our main contribution highlights that automatic prompt\noptimization techniques can generate reasonable prompts similar to humans for\ntriple extraction. In turn, these optimized prompts achieve improved results,\nparticularly with increasing schema complexity and text size.\n","authors":["Nandana Mihindukulasooriya","Niharika S. D'Souza","Faisal Chowdhury","Horst Samulowitz"],"pdf_url":"https://arxiv.org/pdf/2506.19773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19769v1","updated":"2025-06-24T16:34:56Z","published":"2025-06-24T16:34:56Z","title":"A Survey of Multi-sensor Fusion Perception for Embodied AI: Background,\n  Methods, Challenges and Prospects","summary":"  Multi-sensor fusion perception (MSFP) is a key technology for embodied AI,\nwhich can serve a variety of downstream tasks (e.g., 3D object detection and\nsemantic segmentation) and application scenarios (e.g., autonomous driving and\nswarm robotics). Recently, impressive achievements on AI-based MSFP methods\nhave been reviewed in relevant surveys. However, we observe that the existing\nsurveys have some limitations after a rigorous and detailed investigation. For\none thing, most surveys are oriented to a single task or research field, such\nas 3D object detection or autonomous driving. Therefore, researchers in other\nrelated tasks often find it difficult to benefit directly. For another, most\nsurveys only introduce MSFP from a single perspective of multi-modal fusion,\nwhile lacking consideration of the diversity of MSFP methods, such as\nmulti-view fusion and time-series fusion. To this end, in this paper, we hope\nto organize MSFP research from a task-agnostic perspective, where methods are\nreported from various technical views. Specifically, we first introduce the\nbackground of MSFP. Next, we review multi-modal and multi-agent fusion methods.\nA step further, time-series fusion methods are analyzed. In the era of LLM, we\nalso investigate multimodal LLM fusion methods. Finally, we discuss open\nchallenges and future directions for MSFP. We hope this survey can help\nresearchers understand the important progress in MSFP and provide possible\ninsights for future research.\n","authors":["Shulan Ruan","Rongwei Wang","Xuchen Shen","Huijie Liu","Baihui Xiao","Jun Shi","Kun Zhang","Zhenya Huang","Yu Liu","Enhong Chen","You He"],"pdf_url":"https://arxiv.org/pdf/2506.19769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19767v1","updated":"2025-06-24T16:31:37Z","published":"2025-06-24T16:31:37Z","title":"SRFT: A Single-Stage Method with Supervised and Reinforcement\n  Fine-Tuning for Reasoning","summary":"  Large language models (LLMs) have achieved remarkable progress in reasoning\ntasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) remains a fundamental challenge. Through\ncomprehensive analysis of token distributions, learning dynamics, and\nintegration mechanisms from entropy-based perspectives, we reveal key\ndifferences between these paradigms: SFT induces coarse-grained global changes\nto LLM policy distributions, while RL performs fine-grained selective\noptimizations, with entropy serving as a critical indicator of training\neffectiveness. Building on these observations, we propose Supervised\nReinforcement Fine-Tuning (SRFT), a single-stage method that unifies both\nfine-tuning paradigms through entropy-aware weighting mechanisms. Our approach\nsimultaneously applies SFT and RL to directly optimize the LLM using\ndemonstrations and self-exploration rollouts rather than through two-stage\nsequential methods. Extensive experiments show that SRFT achieves 59.1% average\naccuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning\nbenchmarks and 10.9% on three out-of-distribution benchmarks.\n","authors":["Yuqian Fu","Tinghong Chen","Jiajun Chai","Xihuai Wang","Songjun Tu","Guojun Yin","Wei Lin","Qichao Zhang","Yuanheng Zhu","Dongbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.19767v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19755v1","updated":"2025-06-24T16:15:50Z","published":"2025-06-24T16:15:50Z","title":"Cross-regularization: Adaptive Model Complexity through Validation\n  Gradients","summary":"  Model regularization requires extensive manual tuning to balance complexity\nagainst overfitting. Cross-regularization resolves this tradeoff by directly\nadapting regularization parameters through validation gradients during\ntraining. The method splits parameter optimization - training data guides\nfeature learning while validation data shapes complexity controls - converging\nprovably to cross-validation optima. When implemented through noise injection\nin neural networks, this approach reveals striking patterns: unexpectedly high\nnoise tolerance and architecture-specific regularization that emerges\norganically during training. Beyond complexity control, the framework\nintegrates seamlessly with data augmentation, uncertainty calibration and\ngrowing datasets while maintaining single-run efficiency through a simple\ngradient-based approach.\n","authors":["Carlos Stein Brito"],"pdf_url":"https://arxiv.org/pdf/2506.19755v1.pdf","comment":"21 pages, 13 figures. Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2506.19753v1","updated":"2025-06-24T16:06:58Z","published":"2025-06-24T16:06:58Z","title":"Arabic Dialect Classification using RNNs, Transformers, and Large\n  Language Models: A Comparative Analysis","summary":"  The Arabic language is among the most popular languages in the world with a\nhuge variety of dialects spoken in 22 countries. In this study, we address the\nproblem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets.\nRNN models, Transformer models, and large language models (LLMs) via prompt\nengineering are created and tested. Among these, MARBERTv2 performed best with\n65% accuracy and 64% F1-score. Through the use of state-of-the-art\npreprocessing techniques and the latest NLP models, this paper identifies the\nmost significant linguistic issues in Arabic dialect identification. The\nresults corroborate applications like personalized chatbots that respond in\nusers' dialects, social media monitoring, and greater accessibility for Arabic\ncommunities.\n","authors":["Omar A. Essameldin","Ali O. Elbeih","Wael H. Gomaa","Wael F. Elsersy"],"pdf_url":"https://arxiv.org/pdf/2506.19753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12743v2","updated":"2025-06-24T16:03:17Z","published":"2025-02-18T11:00:28Z","title":"\"I know myself better, but not really greatly\": How Well Can LLMs Detect\n  and Explain LLM-Generated Texts?","summary":"  Distinguishing between human- and LLM-generated texts is crucial given the\nrisks associated with misuse of LLMs. This paper investigates detection and\nexplanation capabilities of current LLMs across two settings: binary (human vs.\nLLM-generated) and ternary classification (including an ``undecided'' class).\nWe evaluate 6 close- and open-source LLMs of varying sizes and find that\nself-detection (LLMs identifying their own outputs) consistently outperforms\ncross-detection (identifying outputs from other LLMs), though both remain\nsuboptimal. Introducing a ternary classification framework improves both\ndetection accuracy and explanation quality across all models. Through\ncomprehensive quantitative and qualitative analyses using our human-annotated\ndataset, we identify key explanation failures, primarily reliance on inaccurate\nfeatures, hallucinations, and flawed reasoning. Our findings underscore the\nlimitations of current LLMs in self-detection and self-explanation,\nhighlighting the need for further research to address overfitting and enhance\ngeneralizability.\n","authors":["Jiazhou Ji","Jie Guo","Weidong Qiu","Zheng Huang","Yang Xu","Xinru Lu","Xiaoyu Jiang","Ruizhe Li","Shujun Li"],"pdf_url":"https://arxiv.org/pdf/2502.12743v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2506.19742v1","updated":"2025-06-24T16:01:45Z","published":"2025-06-24T16:01:45Z","title":"NeRF-based CBCT Reconstruction needs Normalization and Initialization","summary":"  Cone Beam Computed Tomography (CBCT) is widely used in medical imaging.\nHowever, the limited number and intensity of X-ray projections make\nreconstruction an ill-posed problem with severe artifacts. NeRF-based methods\nhave achieved great success in this task. However, they suffer from a\nlocal-global training mismatch between their two key components: the hash\nencoder and the neural network. Specifically, in each training step, only a\nsubset of the hash encoder's parameters is used (local sparse), whereas all\nparameters in the neural network participate (global dense). Consequently, hash\nfeatures generated in each step are highly misaligned, as they come from\ndifferent subsets of the hash encoder. These misalignments from different\ntraining steps are then fed into the neural network, causing repeated\ninconsistent global updates in training, which leads to unstable training,\nslower convergence, and degraded reconstruction quality. Aiming to alleviate\nthe impact of this local-global optimization mismatch, we introduce a\nNormalized Hash Encoder, which enhances feature consistency and mitigates the\nmismatch. Additionally, we propose a Mapping Consistency Initialization(MCI)\nstrategy that initializes the neural network before training by leveraging the\nglobal mapping property from a well-trained model. The initialized neural\nnetwork exhibits improved stability during early training, enabling faster\nconvergence and enhanced reconstruction performance. Our method is simple yet\neffective, requiring only a few lines of code while substantially improving\ntraining efficiency on 128 CT cases collected from 4 different datasets,\ncovering 7 distinct anatomical regions.\n","authors":["Zhuowei Xu","Han Li","Dai Sun","Zhicheng Li","Yujia Li","Qingpeng Kong","Zhiwei Cheng","Nassir Navab","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.19742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02978v2","updated":"2025-06-24T15:54:23Z","published":"2024-08-06T06:24:10Z","title":"ASR-enhanced Multimodal Representation Learning for Cross-Domain Product\n  Retrieval","summary":"  E-commerce is increasingly multimedia-enriched, with products exhibited in a\nbroad-domain manner as images, short videos, or live stream promotions. A\nunified and vectorized cross-domain production representation is essential. Due\nto large intra-product variance and high inter-product similarity in the\nbroad-domain scenario, a visual-only representation is inadequate. While\nAutomatic Speech Recognition (ASR) text derived from the short or live-stream\nvideos is readily accessible, how to de-noise the excessively noisy text for\nmultimodal representation learning is mostly untouched. We propose ASR-enhanced\nMultimodal Product Representation Learning (AMPere). In order to extract\nproduct-specific information from the raw ASR text, AMPere uses an\neasy-to-implement LLM-based ASR text summarizer. The LLM-summarized text,\ntogether with visual data, is then fed into a multi-branch network to generate\ncompact multimodal embeddings. Extensive experiments on a large-scale\ntri-domain dataset verify the effectiveness of AMPere in obtaining a unified\nmultimodal product representation that clearly improves cross-domain product\nretrieval.\n","authors":["Ruixiang Zhao","Jian Jia","Yan Li","Xuehan Bai","Quan Chen","Han Li","Peng Jiang","Xirong Li"],"pdf_url":"https://arxiv.org/pdf/2408.02978v2.pdf","comment":"accepted for publication as a REGULAR paper in the IEEE Transactions\n  on Multimedia"},{"id":"http://arxiv.org/abs/2506.18729v2","updated":"2025-06-24T15:53:56Z","published":"2025-06-23T15:08:03Z","title":"MuseControlLite: Multifunctional Music Generation with Lightweight\n  Conditioners","summary":"  We propose MuseControlLite, a lightweight mechanism designed to fine-tune\ntext-to-music generation models for precise conditioning using various\ntime-varying musical attributes and reference audio signals. The key finding is\nthat positional embeddings, which have been seldom used by text-to-music\ngeneration models in the conditioner for text conditions, are critical when the\ncondition of interest is a function of time. Using melody control as an\nexample, our experiments show that simply adding rotary positional embeddings\nto the decoupled cross-attention layers increases control accuracy from 56.6%\nto 61.1%, while requiring 6.75 times fewer trainable parameters than\nstate-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion\nTransformer model of Stable Audio Open. We evaluate various forms of musical\nattribute control, audio inpainting, and audio outpainting, demonstrating\nimproved controllability over MusicGen-Large and Stable Audio Open ControlNet\nat a significantly lower fine-tuning cost, with only 85M trainble parameters.\nSource code, model checkpoints, and demo examples are available at:\nhttps://musecontrollite.github.io/web/.\n","authors":["Fang-Duo Tsai","Shih-Lun Wu","Weijaw Lee","Sheng-Ping Yang","Bo-Rui Chen","Hao-Chung Cheng","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2506.18729v2.pdf","comment":"Accepted by the 42nd International Conference on Machine Learning\n  (ICML 2025)"},{"id":"http://arxiv.org/abs/2506.18902v2","updated":"2025-06-24T15:52:37Z","published":"2025-06-23T17:59:55Z","title":"jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual\n  Retrieval","summary":"  We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding\nmodel that unifies text and image representations through a novel architecture\nsupporting both single-vector and multi-vector embeddings in the late\ninteraction style. The model incorporates task-specific Low-Rank Adaptation\n(LoRA) adapters to optimize performance across diverse retrieval scenarios,\nincluding query-document retrieval, semantic text similarity, and code search.\nComprehensive evaluations demonstrate that jina-embeddings-v4 achieves\nstate-of-the-art performance on both single-modal and cross-modal retrieval\ntasks, with particular strength in processing visually rich content such as\ntables, charts, diagrams, and mixed-media formats. To facilitate evaluation of\nthis capability, we also introduce Jina-VDR, a novel benchmark specifically\ndesigned for visually rich image retrieval.\n","authors":["Michael Günther","Saba Sturua","Mohammad Kalim Akram","Isabelle Mohr","Andrei Ungureanu","Bo Wang","Sedigheh Eslami","Scott Martens","Maximilian Werk","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2506.18902v2.pdf","comment":"22 pages, 1-10 main, 14-22 experimental results, benchmark tables"},{"id":"http://arxiv.org/abs/2506.19732v1","updated":"2025-06-24T15:50:35Z","published":"2025-06-24T15:50:35Z","title":"Who Does What in Deep Learning? Multidimensional Game-Theoretic\n  Attribution of Function of Neural Units","summary":"  Neural networks now generate text, images, and speech with billions of\nparameters, producing a need to know how each neural unit contributes to these\nhigh-dimensional outputs. Existing explainable-AI methods, such as SHAP,\nattribute importance to inputs, but cannot quantify the contributions of neural\nunits across thousands of output pixels, tokens, or logits. Here we close that\ngap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic\ngame-theoretic framework. By systematically lesioning combinations of units,\nMSA yields Shapley Modes, unit-wise contribution maps that share the exact\ndimensionality of the model's output. We apply MSA across scales, from\nmulti-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative\nAdversarial Networks (GAN). The approach demonstrates how regularisation\nconcentrates computation in a few hubs, exposes language-specific experts\ninside the LLM, and reveals an inverted pixel-generation hierarchy in GANs.\nTogether, these results showcase MSA as a powerful approach for interpreting,\nediting, and compressing deep neural networks.\n","authors":["Shrey Dixit","Kayson Fakhar","Fatemeh Hadaeghi","Patrick Mineault","Konrad P. Kording","Claus C. Hilgetag"],"pdf_url":"https://arxiv.org/pdf/2506.19732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18259v2","updated":"2025-06-24T15:45:05Z","published":"2024-06-26T11:11:47Z","title":"Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and\n  Explainability is Complicated","summary":"  As LLMs rapidly advance, increasing concerns arise regarding risks about\nactual authorship of texts we see online and in real world. The task of\ndistinguishing LLM-authored texts is complicated by the nuanced and overlapping\nbehaviors of both machines and humans. In this paper, we challenge the current\npractice of considering LLM-generated text detection a binary classification\ntask of differentiating human from AI. Instead, we introduce a novel ternary\ntext classification scheme, adding an \"undecided\" category for texts that could\nbe attributed to either source, and we show that this new category is crucial\nto understand how to make the detection result more explainable to lay users.\nThis research shifts the paradigm from merely classifying to explaining\nmachine-generated texts, emphasizing need for detectors to provide clear and\nunderstandable explanations to users. Our study involves creating four new\ndatasets comprised of texts from various LLMs and human authors. Based on new\ndatasets, we performed binary classification tests to ascertain the most\neffective SOTA detection methods and identified SOTA LLMs capable of producing\nharder-to-detect texts. We constructed a new dataset of texts generated by two\ntop-performing LLMs and human authors, and asked three human annotators to\nproduce ternary labels with explanation notes. This dataset was used to\ninvestigate how three top-performing SOTA detectors behave in new ternary\nclassification context. Our results highlight why \"undecided\" category is much\nneeded from the viewpoint of explainability. Additionally, we conducted an\nanalysis of explainability of the three best-performing detectors and the\nexplanation notes of the human annotators, revealing insights about the\ncomplexity of explainable detection of machine-generated texts. Finally, we\npropose guidelines for developing future detection systems with improved\nexplanatory power.\n","authors":["Jiazhou Ji","Ruizhe Li","Shujun Li","Jie Guo","Weidong Qiu","Zheng Huang","Chiyu Chen","Xiaoyu Jiang","Xinru Lu"],"pdf_url":"https://arxiv.org/pdf/2406.18259v2.pdf","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.10611v2","updated":"2025-06-24T15:45:04Z","published":"2024-05-17T08:16:32Z","title":"A Certified Proof Checker for Deep Neural Network Verification in\n  Imandra","summary":"  Recent advances in the verification of deep neural networks (DNNs) have\nopened the way for a broader usage of DNN verification technology in many\napplication areas, including safety-critical ones. However, DNN verifiers are\nthemselves complex programs that have been shown to be susceptible to errors\nand numerical imprecision; this, in turn, has raised the question of trust in\nDNN verifiers. One prominent attempt to address this issue is enhancing DNN\nverifiers with the capability of producing certificates of their results that\nare subject to independent algorithmic checking. While formulations of Marabou\ncertificate checking already exist on top of the state-of-the-art DNN verifier\nMarabou, they are implemented in C++, and that code itself raises the question\nof trust (e.g., in the precision of floating point calculations or guarantees\nfor implementation soundness). Here, we present an alternative implementation\nof the Marabou certificate checking in Imandra -- an industrial functional\nprogramming language and an interactive theorem prover (ITP) -- that allows us\nto obtain full proof of certificate correctness. The significance of the result\nis two-fold. Firstly, it gives stronger independent guarantees for Marabou\nproofs. Secondly, it opens the way for the wider adoption of DNN verifiers in\ninteractive theorem proving in the same way as many ITPs already incorporate\nSMT solvers.\n","authors":["Remi Desmartin","Omri Isac","Grant Passmore","Ekaterina Komendantskaya","Kathrin Stark","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2405.10611v2.pdf","comment":"Accepted at ITP 2025, Interactive Theorem Proving"},{"id":"http://arxiv.org/abs/2503.09730v2","updated":"2025-06-24T15:42:55Z","published":"2025-03-12T18:20:47Z","title":"Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem\n  Proving","summary":"  The most promising recent methods for AI reasoning require applying variants\nof reinforcement learning (RL) either on rolled out trajectories from the LLMs,\neven for the step-wise rewards, or large quantities of human-annotated\ntrajectory data. The reliance on the rolled-out trajectory renders the compute\ncost and time prohibitively high. In particular, the correctness of a reasoning\ntrajectory can typically only be judged at its completion, leading to sparse\nrewards in RL or requiring expensive synthetic data generation in expert\niteration-like methods. In this work, we focus on the Automatic Theorem Proving\n(ATP) task and propose a novel verifier-in-the-loop design, which, unlike\nexisting approaches that leverage feedback on the entire reasoning trajectory,\nemploys an automated verifier to give intermediate feedback at each step of the\nreasoning process. Using Lean as the verifier, we empirically show that the\nstep-by-step local verification produces a global improvement in the model's\nreasoning accuracy and efficiency.\n","authors":["Sara Rajaee","Kumar Pratik","Gabriele Cesa","Arash Behboodi"],"pdf_url":"https://arxiv.org/pdf/2503.09730v2.pdf","comment":"Accepted at the Findings of ACL 2025, Accepted at ICLR 2025 Workshop\n  on Reasoning and Planning for Large Language Models"},{"id":"http://arxiv.org/abs/2506.19726v1","updated":"2025-06-24T15:42:00Z","published":"2025-06-24T15:42:00Z","title":"Geometric-Aware Variational Inference: Robust and Adaptive\n  Regularization with Directional Weight Uncertainty","summary":"  Deep neural networks require principled uncertainty quantification, yet\nexisting variational inference methods often employ isotropic Gaussian\napproximations in weight space that poorly match the network's inherent\ngeometry. We address this mismatch by introducing Concentration-Adapted\nPerturbations (CAP), a variational framework that models weight uncertainties\ndirectly on the unit hypersphere using von Mises-Fisher distributions. Building\non recent work in radial-directional posterior decompositions and spherical\nweight constraints, CAP provides the first complete theoretical framework\nconnecting directional statistics to practical noise regularization in neural\nnetworks. Our key contribution is an analytical derivation linking vMF\nconcentration parameters to activation noise variance, enabling each layer to\nlearn its optimal uncertainty level through a novel closed-form KL divergence\nregularizer. In experiments on CIFAR-10, CAP significantly improves model\ncalibration - reducing Expected Calibration Error by 5.6x - while providing\ninterpretable layer-wise uncertainty profiles. CAP requires minimal\ncomputational overhead and integrates seamlessly into standard architectures,\noffering a theoretically grounded yet practical approach to uncertainty\nquantification in deep learning.\n","authors":["Carlos Stein Brito"],"pdf_url":"https://arxiv.org/pdf/2506.19726v1.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2506.19724v1","updated":"2025-06-24T15:39:20Z","published":"2025-06-24T15:39:20Z","title":"From Reproduction to Replication: Evaluating Research Agents with\n  Progressive Code Masking","summary":"  Recent progress in autonomous code generation has fueled excitement around AI\nagents capable of accelerating scientific discovery by running experiments.\nHowever, there is currently no benchmark that evaluates whether such agents can\nimplement scientific ideas when given varied amounts of code as a starting\npoint, interpolating between reproduction (running code) and from-scratch\nreplication (fully re-implementing and running code). We introduce\nAutoExperiment, a benchmark that evaluates AI agents' ability to implement and\nrun machine learning experiments based on natural language descriptions in\nresearch papers. In each task, agents are given a research paper, a codebase\nwith key functions masked out, and a command to run the experiment. The goal is\nto generate the missing code, execute the experiment in a sandboxed\nenvironment, and reproduce the results. AutoExperiment scales in difficulty by\nvarying the number of missing functions $n$, ranging from partial reproduction\nto full replication. We evaluate state-of-the-art agents and find that\nperformance degrades rapidly as $n$ increases. Agents that can dynamically\ninteract with the environment (e.g. to debug their code) can outperform agents\nin fixed \"agentless\" harnesses, and there exists a significant gap between\nsingle-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating\nverifier approaches to our benchmark. Our findings highlight critical\nchallenges in long-horizon code generation, context retrieval, and autonomous\nexperiment execution, establishing AutoExperiment as a new benchmark for\nevaluating progress in AI-driven scientific experimentation. Our data and code\nare open-sourced at https://github.com/j1mk1m/AutoExperiment .\n","authors":["Gyeongwon James Kim","Alex Wilf","Louis-Philippe Morency","Daniel Fried"],"pdf_url":"https://arxiv.org/pdf/2506.19724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.06469v3","updated":"2025-06-24T15:36:26Z","published":"2025-04-08T22:21:54Z","title":"AI-Assisted Transport of Radioactive Ion Beams","summary":"  Beams of radioactive heavy ions allow researchers to study rare and unstable\natomic nuclei, shedding light into the internal structure of exotic nuclei and\non how chemical elements are formed in stars. However, the extraction and\ntransport of radioactive beams rely on time-consuming expert-driven tuning\nmethods, where hundreds of parameters are manually optimized. Here, we\nintroduce a system that employs Artificial Intelligence (AI), specifically\nutilizing Bayesian Optimization, to assist in the transport process of\nradioactive beams. We apply our methodology to real-life scenarios showing\nadvantages when compared with standard tuning methods. This AI-assisted\napproach can be extended to other radioactive beam facilities around the world\nto improve operational efficiency and enhance scientific output.\n","authors":["Sergio Lopez-Caceres","Daniel Santiago-Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2504.06469v3.pdf","comment":"6 pages, 6 figures; Results section expanded. More references and DOI\n  added"},{"id":"http://arxiv.org/abs/2506.19708v1","updated":"2025-06-24T15:15:15Z","published":"2025-06-24T15:15:15Z","title":"Uncovering Conceptual Blindspots in Generative Image Models Using Sparse\n  Autoencoders","summary":"  Despite their impressive performance, generative image models trained on\nlarge-scale datasets frequently fail to produce images with seemingly simple\nconcepts -- e.g., human hands or objects appearing in groups of four -- that\nare reasonably expected to appear in the training data. These failure modes\nhave largely been documented anecdotally, leaving open the question of whether\nthey reflect idiosyncratic anomalies or more structural limitations of these\nmodels. To address this, we introduce a systematic approach for identifying and\ncharacterizing \"conceptual blindspots\" -- concepts present in the training data\nbut absent or misrepresented in a model's generations. Our method leverages\nsparse autoencoders (SAEs) to extract interpretable concept embeddings,\nenabling a quantitative comparison of concept prevalence between real and\ngenerated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with\n32,000 concepts -- the largest such SAE to date -- enabling fine-grained\nanalysis of conceptual disparities. Applied to four popular generative models\n(Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals\nspecific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces\non documents) and exaggerated blindspots (e.g., wood background texture and\npalm trees). At the individual datapoint level, we further isolate memorization\nartifacts -- instances where models reproduce highly specific visual templates\nseen during training. Overall, we propose a theoretically grounded framework\nfor systematically identifying conceptual blindspots in generative models by\nassessing their conceptual fidelity with respect to the underlying\ndata-generating process.\n","authors":["Matyas Bohacek","Thomas Fel","Maneesh Agrawala","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2506.19708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19702v1","updated":"2025-06-24T15:12:42Z","published":"2025-06-24T15:12:42Z","title":"LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology\n  and Differential Diagnosis","summary":"  Medical document analysis plays a crucial role in extracting essential\nclinical insights from unstructured healthcare records, supporting critical\ntasks such as differential diagnosis. Determining the most probable condition\namong overlapping symptoms requires precise evaluation and deep medical\nexpertise. While recent advancements in large language models (LLMs) have\nsignificantly enhanced performance in medical document analysis, privacy\nconcerns related to sensitive patient data limit the use of online LLMs\nservices in clinical settings. To address these challenges, we propose a\ntrustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using\nlow-rank adaptation, specifically optimized for differential diagnosis tasks.\nOur approach utilizes DDXPlus, the largest benchmark dataset for differential\ndiagnosis, and demonstrates superior performance in pathology prediction and\nvariable-length differential diagnosis compared to existing methods. The\ndeveloped web-based platform allows users to submit their own unstructured\nmedical documents and receive accurate, explainable diagnostic results. By\nincorporating advanced explainability techniques, the system ensures\ntransparent and reliable predictions, fostering user trust and confidence.\nExtensive evaluations confirm that the proposed method surpasses current\nstate-of-the-art models in predictive accuracy while offering practical utility\nin clinical settings. This work addresses the urgent need for reliable,\nexplainable, and privacy-preserving artificial intelligence solutions,\nrepresenting a significant advancement in intelligent medical document analysis\nfor real-world healthcare applications. The code can be found at\n\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.\n","authors":["Lei Kang","Xuanshuo Fu","Oriol Ramos Terrades","Javier Vazquez-Corral","Ernest Valveny","Dimosthenis Karatzas"],"pdf_url":"https://arxiv.org/pdf/2506.19702v1.pdf","comment":"Accepted at ICDAR 2025"},{"id":"http://arxiv.org/abs/2506.19698v1","updated":"2025-06-24T15:10:15Z","published":"2025-06-24T15:10:15Z","title":"Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize\n  Framework for Predictive Maintenance","summary":"  Recent research increasingly integrates machine learning (ML) into predictive\nmaintenance (PdM) to reduce operational and maintenance costs in data-rich\noperational settings. However, uncertainty due to model misspecification\ncontinues to limit widespread industrial adoption. This paper proposes a PdM\nframework in which sensor-driven prognostics inform decision-making under\neconomic trade-offs within a finite decision space. We investigate two key\nquestions: (1) Does higher predictive accuracy necessarily lead to better\nmaintenance decisions? (2) If not, how can the impact of prediction errors on\ndownstream maintenance decisions be mitigated? We first demonstrate that in the\ntraditional estimate-then-optimize (ETO) framework, errors in probabilistic\nprediction can result in inconsistent and suboptimal maintenance decisions. To\naddress this, we propose an integrated estimate-optimize (IEO) framework that\njointly tunes predictive models while directly optimizing for maintenance\noutcomes. We establish theoretical finite-sample guarantees on decision\nconsistency under standard assumptions. Specifically, we develop a stochastic\nperturbation gradient descent algorithm suitable for small run-to-failure\ndatasets. Empirical evaluations on a turbofan maintenance case study show that\nthe IEO framework reduces average maintenance regret up to 22% compared to ETO.\nThis study provides a principled approach to managing prediction errors in\ndata-driven PdM. By aligning prognostic model training with maintenance\nobjectives, the IEO framework improves robustness under model misspecification\nand improves decision quality. The improvement is particularly pronounced when\nthe decision-making policy is misaligned with the decision-maker's target.\nThese findings support more reliable maintenance planning in uncertain\noperational environments.\n","authors":["Zhuojun Xie","Adam Abdin","Yiping Fang"],"pdf_url":"https://arxiv.org/pdf/2506.19698v1.pdf","comment":"22 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2506.19697v1","updated":"2025-06-24T15:03:57Z","published":"2025-06-24T15:03:57Z","title":"Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large\n  Language Models","summary":"  Extreme activation outliers in Large Language Models (LLMs) critically\ndegrade quantization performance, hindering efficient on-device deployment.\nWhile channel-wise operations and adaptive gradient scaling are recognized\ncauses, practical mitigation remains challenging. We introduce Outlier-Safe\nPre-Training (OSP), a practical guideline that proactively prevents outlier\nformation rather than relying on post-hoc mitigation. OSP combines three key\ninnovations: (1) the Muon optimizer, eliminating privileged bases while\nmaintaining training efficiency; (2) Single-Scale RMSNorm, preventing\nchannel-wise amplification; and (3) a learnable embedding projection,\nredistributing activation magnitudes originating from embedding matrices. We\nvalidate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is\nthe first production-scale LLM trained without such outliers. Under aggressive\n4-bit quantization, our OSP model achieves a 35.7 average score across 10\nbenchmarks (compared to 26.5 for an Adam-trained model), with only a 2%\ntraining overhead. Remarkably, OSP models exhibit near-zero excess kurtosis\n(0.04) compared to extreme values (1818.56) in standard models, fundamentally\naltering LLM quantization behavior. Our work demonstrates that outliers are not\ninherent to LLMs but are consequences of training strategies, paving the way\nfor more efficient LLM deployment. The source code and pretrained checkpoints\nare available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.\n","authors":["Jungwoo Park","Taewhoo Lee","Chanwoong Yoon","Hyeon Hwang","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2506.19697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19689v1","updated":"2025-06-24T14:57:25Z","published":"2025-06-24T14:57:25Z","title":"When Can We Reuse a Calibration Set for Multiple Conformal Predictions?","summary":"  Reliable uncertainty quantification is crucial for the trustworthiness of\nmachine learning applications. Inductive Conformal Prediction (ICP) offers a\ndistribution-free framework for generating prediction sets or intervals with\nuser-specified confidence. However, standard ICP guarantees are marginal and\ntypically require a fresh calibration set for each new prediction to maintain\ntheir validity. This paper addresses this practical limitation by demonstrating\nhow e-conformal prediction, in conjunction with Hoeffding's inequality, can\nenable the repeated use of a single calibration set with a high probability of\npreserving the desired coverage. Through a case study on the CIFAR-10 dataset,\nwe train a deep neural network and utilise a calibration set to estimate a\nHoeffding correction. This correction allows us to apply a modified Markov's\ninequality, leading to the construction of prediction sets with quantifiable\nconfidence. Our results illustrate the feasibility of maintaining provable\nperformance in conformal prediction while enhancing its practicality by\nreducing the need for repeated calibration. The code for this work is publicly\navailable.\n","authors":["A. A. Balinsky","A. D. Balinsky"],"pdf_url":"https://arxiv.org/pdf/2506.19689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15196v2","updated":"2025-06-24T14:48:12Z","published":"2025-06-18T07:20:01Z","title":"HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial\n  Optimization Challenges","summary":"  Heuristic algorithms play a vital role in solving combinatorial optimization\n(CO) problems, yet traditional designs depend heavily on manual expertise and\nstruggle to generalize across diverse instances. We introduce\n\\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large\nlanguage models (LLMs) that first evolves heuristics and then selects among\nthem automatically. In the heuristic evolution phase, HeurAgenix leverages an\nLLM to compare seed heuristic solutions with higher-quality solutions and\nextract reusable evolution strategies. During problem solving, it dynamically\npicks the most promising heuristic for each problem state, guided by the LLM's\nperception ability. For flexibility, this selector can be either a\nstate-of-the-art LLM or a fine-tuned lightweight model with lower inference\ncost. To mitigate the scarcity of reliable supervision caused by CO complexity,\nwe fine-tune the lightweight heuristic selector with a dual-reward mechanism\nthat jointly exploits singals from selection preferences and state perception,\nenabling robust selection under noisy annotations. Extensive experiments on\ncanonical benchmarks show that HeurAgenix not only outperforms existing\nLLM-based hyper-heuristics but also matches or exceeds specialized solvers.\nCode is available at https://github.com/microsoft/HeurAgenix.\n","authors":["Xianliang Yang","Ling Zhang","Haolong Qian","Lei Song","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2506.15196v2.pdf","comment":"27 pages,9 figures"},{"id":"http://arxiv.org/abs/2409.10394v3","updated":"2025-06-24T14:38:57Z","published":"2024-09-16T15:31:04Z","title":"MOST: MR reconstruction Optimization for multiple downStream Tasks via\n  continual learning","summary":"  Deep learning-based Magnetic Resonance (MR) reconstruction methods have\nfocused on generating high-quality images but often overlook the impact on\ndownstream tasks (e.g., segmentation) that utilize the reconstructed images.\nCascading separately trained reconstruction network and downstream task network\nhas been shown to introduce performance degradation due to error propagation\nand domain gaps between training datasets. To mitigate this issue, downstream\ntask-oriented reconstruction optimization has been proposed for a single\ndownstream task. Expanding this optimization to multi-task scenarios is not\nstraightforward. In this work, we extended this optimization to sequentially\nintroduced multiple downstream tasks and demonstrated that a single MR\nreconstruction network can be optimized for multiple downstream tasks by\ndeploying continual learning (MOST). MOST integrated techniques from\nreplay-based continual learning and image-guided loss to overcome catastrophic\nforgetting. Comparative experiments demonstrated that MOST outperformed a\nreconstruction network without finetuning, a reconstruction network with\nna\\\"ive finetuning, and conventional continual learning methods. The source\ncode is available at: https://github.com/SNU-LIST/MOST.\n","authors":["Hwihun Jeong","Se Young Chun","Jongho Lee"],"pdf_url":"https://arxiv.org/pdf/2409.10394v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04942v3","updated":"2025-06-24T14:21:33Z","published":"2025-04-07T11:30:36Z","title":"Lemmanaid: Neuro-Symbolic Lemma Conjecturing","summary":"  Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Lemmanaid\noutperforms both neural and symbolic methods on test sets from Isabelle's HOL\nlibrary and from its Archive of Formal Proofs, discovering between 29-39.5% of\nthe gold standard human written lemmas. This is 8-15% more lemmas than the\nneural-only method. By leveraging the best of both symbolic and neural methods\nwe can generate useful lemmas for a wide range of input domains, facilitating\ncomputer-assisted theory development and formalization.\n","authors":["Yousef Alhessi","Sólrún Halla Einarsdóttir","George Granberry","Emily First","Moa Johansson","Sorin Lerner","Nicholas Smallbone"],"pdf_url":"https://arxiv.org/pdf/2504.04942v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19652v1","updated":"2025-06-24T14:15:26Z","published":"2025-06-24T14:15:26Z","title":"Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager","summary":"  In this work, we propose a novel framework that integrates large language\nmodels (LLMs) with an RL-based dialogue manager for open-ended dialogue with a\nspecific goal. By leveraging hierarchical reinforcement learning to model the\nstructured phases of dialogue and employ meta-learning to enhance adaptability\nacross diverse user profiles, our approach enhances adaptability and\nefficiency, enabling the system to learn from limited data, transition fluidly\nbetween dialogue phases, and personalize responses to heterogeneous patient\nneeds. We apply our framework to Motivational Interviews, aiming to foster\nbehavior change, and demonstrate that the proposed dialogue manager outperforms\na state-of-the-art LLM baseline in terms of reward, showing a potential benefit\nof conditioning LLMs to create open-ended dialogue systems with specific goals.\n","authors":["Lucie Galland","Catherine Pelachaud","Florian Pecune"],"pdf_url":"https://arxiv.org/pdf/2506.19652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19650v1","updated":"2025-06-24T14:14:43Z","published":"2025-06-24T14:14:43Z","title":"Identifying Macro Causal Effects in C-DMGs over DMGs","summary":"  The do-calculus is a sound and complete tool for identifying causal effects\nin acyclic directed mixed graphs (ADMGs) induced by structural causal models\n(SCMs). However, in many real-world applications, especially in\nhigh-dimensional setting, constructing a fully specified ADMG is often\ninfeasible. This limitation has led to growing interest in partially specified\ncausal representations, particularly through cluster-directed mixed graphs\n(C-DMGs), which group variables into clusters and offer a more abstract yet\npractical view of causal dependencies. While these representations can include\ncycles, recent work has shown that the do-calculus remains sound and complete\nfor identifying macro-level causal effects in C-DMGs over ADMGs under the\nassumption that all clusters size are greater than 1. Nevertheless, real-world\nsystems often exhibit cyclic causal dynamics at the structural level. To\naccount for this, input-output structural causal models (ioSCMs) have been\nintroduced as a generalization of SCMs that allow for cycles. ioSCMs induce\nanother type of graph structure known as a directed mixed graph (DMG).\nAnalogous to the ADMG setting, one can define C-DMGs over DMGs as high-level\nrepresentations of causal relations among clusters of variables. In this paper,\nwe prove that, unlike in the ADMG setting, the do-calculus is unconditionally\nsound and complete for identifying macro causal effects in C-DMGs over DMGs.\nFurthermore, we show that the graphical criteria for non-identifiability of\nmacro causal effects previously established C-DMGs over ADMGs naturally extends\nto a subset of C-DMGs over DMGs.\n","authors":["Simon Ferreira","Charles K. Assaad"],"pdf_url":"https://arxiv.org/pdf/2506.19650v1.pdf","comment":"Accepted to the UAI2025 workshop on Causal Abstractions and\n  Representations. arXiv admin note: substantial text overlap with\n  arXiv:2504.01551"},{"id":"http://arxiv.org/abs/2506.19642v1","updated":"2025-06-24T14:04:15Z","published":"2025-06-24T14:04:15Z","title":"The receptron is a nonlinear threshold logic gate with intrinsic\n  multi-dimensional selective capabilities for analog inputs","summary":"  Threshold logic gates (TLGs) have been proposed as artificial counterparts of\nbiological neurons with classification capabilities based on a linear predictor\nfunction combining a set of weights with the feature vector. The linearity of\nTLGs limits their classification capabilities requiring the use of networks for\nthe accomplishment of complex tasks. A generalization of the TLG model called\nreceptron, characterized by input-dependent weight functions allows for a\nsignificant enhancement of classification performances even with the use of a\nsingle unit. Here we formally demonstrate that a receptron, characterized by\nnonlinear input-dependent weight functions, exhibit intrinsic selective\nactivation properties for analog inputs, when the input vector is within cubic\ndomains in a 3D space. The proposed model can be extended to the n-dimensional\ncase for multidimensional applications. Our results suggest that\nreceptron-based networks can represent a new class of devices capable to manage\na large number of analog inputs, for edge applications requiring high\nselectivity and classification capabilities without the burden of complex\ntraining.\n","authors":["B. Paroli","F. Borghi","M. A. C. Potenza","P. Milani"],"pdf_url":"https://arxiv.org/pdf/2506.19642v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.17036v2","updated":"2025-06-24T14:03:01Z","published":"2025-02-24T10:37:13Z","title":"Language Model Re-rankers are Fooled by Lexical Similarities","summary":"  Language model (LM) re-rankers are used to refine retrieval results for\nretrieval-augmented generation (RAG). They are more expensive than lexical\nmatching methods like BM25 but assumed to better process semantic information\nand the relations between the query and the retrieved answers. To understand\nwhether LM re-rankers always live up to this assumption, we evaluate 6\ndifferent LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show\nthat LM re-rankers struggle to outperform a simple BM25 baseline on DRUID.\nLeveraging a novel separation metric based on BM25 scores, we explain and\nidentify re-ranker errors stemming from lexical dissimilarities. We also\ninvestigate different methods to improve LM re-ranker performance and find\nthese methods mainly useful for NQ. Taken together, our work identifies and\nexplains weaknesses of LM re-rankers and points to the need for more\nadversarial and realistic datasets for their evaluation.\n","authors":["Lovisa Hagström","Ercong Nie","Ruben Halifa","Helmut Schmid","Richard Johansson","Alexander Junge"],"pdf_url":"https://arxiv.org/pdf/2502.17036v2.pdf","comment":"Accepted to FEVER 2025"},{"id":"http://arxiv.org/abs/2506.19635v1","updated":"2025-06-24T13:56:09Z","published":"2025-06-24T13:56:09Z","title":"On the efficacy of old features for the detection of new bots","summary":"  For more than a decade now, academicians and online platform administrators\nhave been studying solutions to the problem of bot detection. Bots are computer\nalgorithms whose use is far from being benign: malicious bots are purposely\ncreated to distribute spam, sponsor public characters and, ultimately, induce a\nbias within the public opinion. To fight the bot invasion on our online\necosystem, several approaches have been implemented, mostly based on\n(supervised and unsupervised) classifiers, which adopt the most varied account\nfeatures, from the simplest to the most expensive ones to be extracted from the\nraw data obtainable through the Twitter public APIs. In this exploratory study,\nusing Twitter as a benchmark, we compare the performances of four state-of-art\nfeature sets in detecting novel bots: one of the output scores of the popular\nbot detector Botometer, which considers more than 1,000 features of an account\nto take a decision; two feature sets based on the account profile and timeline;\nand the information about the Twitter client from which the user tweets. The\nresults of our analysis, conducted on six recently released datasets of Twitter\naccounts, hint at the possible use of general-purpose classifiers and\ncheap-to-compute account features for the detection of evolved bots.\n","authors":["Rocco De Nicola","Marinella Petrocchi","Manuel Pratelli"],"pdf_url":"https://arxiv.org/pdf/2506.19635v1.pdf","comment":"pre-print version"},{"id":"http://arxiv.org/abs/2506.19633v1","updated":"2025-06-24T13:54:47Z","published":"2025-06-24T13:54:47Z","title":"Hierarchical Time Series Forecasting Via Latent Mean Encoding","summary":"  Coherently forecasting the behaviour of a target variable across both coarse\nand fine temporal scales is crucial for profit-optimized decision-making in\nseveral business applications, and remains an open research problem in temporal\nhierarchical forecasting. Here, we propose a new hierarchical architecture that\ntackles this problem by leveraging modules that specialize in forecasting the\ndifferent temporal aggregation levels of interest. The architecture, which\nlearns to encode the average behaviour of the target variable within its hidden\nlayers, makes accurate and coherent forecasts across the target temporal\nhierarchies. We validate our architecture on the challenging, real-world M5\ndataset and show that it outperforms established methods, such as the TSMixer\nmodel.\n","authors":["Alessandro Salatiello","Stefan Birr","Manuel Kunz"],"pdf_url":"https://arxiv.org/pdf/2506.19633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19630v1","updated":"2025-06-24T13:54:12Z","published":"2025-06-24T13:54:12Z","title":"Why Uncertainty Calibration Matters for Reliable Perturbation-based\n  Explanations","summary":"  Perturbation-based explanations are widely utilized to enhance the\ntransparency of modern machine-learning models. However, their reliability is\noften compromised by the unknown model behavior under the specific\nperturbations used. This paper investigates the relationship between\nuncertainty calibration - the alignment of model confidence with actual\naccuracy - and perturbation-based explanations. We show that models frequently\nproduce unreliable probability estimates when subjected to\nexplainability-specific perturbations and theoretically prove that this\ndirectly undermines explanation quality. To address this, we introduce ReCalX,\na novel approach to recalibrate models for improved perturbation-based\nexplanations while preserving their original predictions. Experiments on\npopular computer vision models demonstrate that our calibration strategy\nproduces explanations that are more aligned with human perception and actual\nobject locations.\n","authors":["Thomas Decker","Volker Tresp","Florian Buettner"],"pdf_url":"https://arxiv.org/pdf/2506.19630v1.pdf","comment":"ICLR 2025 Workshop: XAI4Science: From Understanding Model Behavior to\n  Discovering New Scientific Knowledge"},{"id":"http://arxiv.org/abs/2407.16804v2","updated":"2025-06-24T13:40:09Z","published":"2024-07-23T19:07:56Z","title":"Multimodal Machine Learning in Mental Health: A Survey of Data,\n  Algorithms, and Challenges","summary":"  Multimodal machine learning (MML) is rapidly reshaping the way mental-health\ndisorders are detected, characterized, and longitudinally monitored. Whereas\nearly studies relied on isolated data streams -- such as speech, text, or\nwearable signals -- recent research has converged on architectures that\nintegrate heterogeneous modalities to capture the rich, complex signatures of\npsychiatric conditions. This survey provides the first comprehensive,\nclinically grounded synthesis of MML for mental health. We (i) catalog 26\npublic datasets spanning audio, visual, physiological signals, and text\nmodalities; (ii) systematically compare transformer, graph, and hybrid-based\nfusion strategies across 28 models, highlighting trends in representation\nlearning and cross-modal alignment. Beyond summarizing current capabilities, we\ninterrogate open challenges: data governance and privacy, demographic and\nintersectional fairness, evaluation explainability, and the complexity of\nmental health disorders in multimodal settings. By bridging methodological\ninnovation with psychiatric utility, this survey aims to orient both ML\nresearchers and mental-health practitioners toward the next generation of\ntrustworthy, multimodal decision-support systems.\n","authors":["Zahraa Al Sahili","Ioannis Patras","Matthew Purver"],"pdf_url":"https://arxiv.org/pdf/2407.16804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19621v1","updated":"2025-06-24T13:39:47Z","published":"2025-06-24T13:39:47Z","title":"VideoPCDNet: Video Parsing and Prediction with Phase Correlation\n  Networks","summary":"  Understanding and predicting video content is essential for planning and\nreasoning in dynamic environments. Despite advancements, unsupervised learning\nof object representations and dynamics remains challenging. We present\nVideoPCDNet, an unsupervised framework for object-centric video decomposition\nand prediction. Our model uses frequency-domain phase correlation techniques to\nrecursively parse videos into object components, which are represented as\ntransformed versions of learned object prototypes, enabling accurate and\ninterpretable tracking. By explicitly modeling object motion through a\ncombination of frequency domain operations and lightweight learned modules,\nVideoPCDNet enables accurate unsupervised object tracking and prediction of\nfuture video frames. In our experiments, we demonstrate that VideoPCDNet\noutperforms multiple object-centric baseline models for unsupervised tracking\nand prediction on several synthetic datasets, while learning interpretable\nobject and motion representations.\n","authors":["Noel José Rodrigues Vicente","Enrique Lehner","Angel Villar-Corrales","Jan Nogga","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2506.19621v1.pdf","comment":"Accepted for Publication at ICANN 2025"},{"id":"http://arxiv.org/abs/2506.17364v2","updated":"2025-06-24T13:38:12Z","published":"2025-06-20T11:37:19Z","title":"AI-based Multimodal Biometrics for Detecting Smartphone Distractions:\n  Application to Online Learning","summary":"  This work investigates the use of multimodal biometrics to detect\ndistractions caused by smartphone use during tasks that require sustained\nattention, with a focus on computer-based online learning. Although the methods\nare applicable to various domains, such as autonomous driving, we concentrate\non the challenges learners face in maintaining engagement amid internal (e.g.,\nmotivation), system-related (e.g., course design) and contextual (e.g.,\nsmartphone use) factors. Traditional learning platforms often lack detailed\nbehavioral data, but Multimodal Learning Analytics (MMLA) and biosensors\nprovide new insights into learner attention. We propose an AI-based approach\nthat leverages physiological signals and head pose data to detect phone use.\nOur results show that single biometric signals, such as brain waves or heart\nrate, offer limited accuracy, while head pose alone achieves 87%. A multimodal\nmodel combining all signals reaches 91% accuracy, highlighting the benefits of\nintegration. We conclude by discussing the implications and limitations of\ndeploying these models for real-time support in online learning environments.\n","authors":["Alvaro Becerra","Roberto Daza","Ruth Cobos","Aythami Morales","Mutlu Cukurova","Julian Fierrez"],"pdf_url":"https://arxiv.org/pdf/2506.17364v2.pdf","comment":"Accepted in EC-TEL25: 20th European Conference on Technology Enhanced\n  Learning, Newcastle and Durham, UK, 15-19 September 2025"},{"id":"http://arxiv.org/abs/2405.09567v2","updated":"2025-06-24T13:37:46Z","published":"2024-05-08T19:59:16Z","title":"ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of\n  Occlusion Myocardial Infarction","summary":"  Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion\nmyocardial infarction (OMI) identification. OMI is a severe form of heart\nattack characterized by complete blockage of one or more coronary arteries\nrequiring immediate referral for cardiac catheterization to restore blood flow\nto the heart. Two thirds of OMI cases are difficult to visually identify from a\n12-lead electrocardiogram (ECG) and can be potentially fatal if not identified\nquickly. Previous works on this topic are scarce, and current state-of-the-art\nevidence suggests both feature-based random forests and convolutional neural\nnetworks (CNNs) are promising approaches to improve ECG detection of OMI.\nMethods: While the ResNet architecture has been adapted for use with ECG\nrecordings, it is not ideally suited to capture informative temporal features\nwithin each lead and the spatial concordance or discordance across leads. We\npropose a clinically informed modification of the ResNet-18 architecture. The\nmodel first learns temporal features through temporal convolutional layers with\n1xk kernels followed by a spatial convolutional layer, after the residual\nblocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was\nbenchmarked against the original ResNet-18 and other state-of-the-art models on\na multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397\nunique patients (rate of OMI =7.2%). ECG-SMART-NET outperformed other models in\nthe classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion\nand Significance: ECG-SMART-NET can outperform the state-of-the-art random\nforest for OMI prediction and is better suited for this task than the original\nResNet-18 architecture.\n","authors":["Nathan T. Riek","Murat Akcakaya","Zeineb Bouzid","Tanmay Gokhale","Stephanie Helman","Karina Kraevsky-Philips","Rui Qi Ji","Ervin Sejdic","Jessica K. Zègre-Hemsey","Christian Martin-Gill","Clifton W. Callaway","Samir Saba","Salah Al-Zaiti"],"pdf_url":"https://arxiv.org/pdf/2405.09567v2.pdf","comment":"9 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2506.19613v1","updated":"2025-06-24T13:31:44Z","published":"2025-06-24T13:31:44Z","title":"Position: Intelligent Science Laboratory Requires the Integration of\n  Cognitive and Embodied AI","summary":"  Scientific discovery has long been constrained by human limitations in\nexpertise, physical capability, and sleep cycles. The recent rise of AI\nscientists and automated laboratories has accelerated both the cognitive and\noperational aspects of research. However, key limitations persist: AI systems\nare often confined to virtual environments, while automated laboratories lack\nthe flexibility and autonomy to adaptively test new hypotheses in the physical\nworld. Recent advances in embodied AI, such as generalist robot foundation\nmodels, diffusion-based action policies, fine-grained manipulation learning,\nand sim-to-real transfer, highlight the promise of integrating cognitive and\nembodied intelligence. This convergence opens the door to closed-loop systems\nthat support iterative, autonomous experimentation and the possibility of\nserendipitous discovery. In this position paper, we propose the paradigm of\nIntelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework\nthat deeply integrates cognitive and embodied intelligence. ISLs unify\nfoundation models for scientific reasoning, agent-based workflow orchestration,\nand embodied agents for robust physical experimentation. We argue that such\nsystems are essential for overcoming the current limitations of scientific\ndiscovery and for realizing the full transformative potential of AI-driven\nscience.\n","authors":["Sha Zhang","Suorong Yang","Tong Xie","Xiangyuan Xue","Zixuan Hu","Rui Li","Wenxi Qu","Zhenfei Yin","Tianfan Fu","Di Hu","Andres M Bran","Nian Ran","Bram Hoex","Wangmeng Zuo","Philippe Schwaller","Wanli Ouyang","Lei Bai","Yanyong Zhang","Lingyu Duan","Shixiang Tang","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.19613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19608v1","updated":"2025-06-24T13:22:06Z","published":"2025-06-24T13:22:06Z","title":"ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain\n  Incremental Learning in CLIP","summary":"  Continual learning (CL) empowers pre-trained vision-language models to adapt\neffectively to novel or previously underrepresented data distributions without\ncomprehensive retraining, enhancing their adaptability and efficiency. While\nvision-language models like CLIP show great promise, they struggle to maintain\nperformance across domains in incremental learning scenarios. Existing prompt\nlearning methods face two main limitations: 1) they primarily focus on\nclass-incremental learning scenarios, lacking specific strategies for\nmulti-domain task incremental learning; 2) most current approaches employ\nsingle-modal prompts, neglecting the potential benefits of cross-modal\ninformation exchange. To address these challenges, we propose the \\ChordPrompt\nframework, which facilitates a harmonious interplay between visual and textual\nprompts. \\ChordPrompt introduces cross-modal prompts to leverage interactions\nbetween visual and textual information. Our approach also employs\ndomain-adaptive text prompts to select appropriate prompts for continual\nadaptation across multiple domains. Comprehensive experiments on multi-domain\nincremental learning benchmarks demonstrate that \\ChordPrompt outperforms\nstate-of-the-art methods in zero-shot generalization and downstream task\nperformance.\n","authors":["Zhiyuan Wang","Bokui Chen"],"pdf_url":"https://arxiv.org/pdf/2506.19608v1.pdf","comment":"Accept by ECML-PKDD 2025"},{"id":"http://arxiv.org/abs/2506.14677v2","updated":"2025-06-24T13:11:34Z","published":"2025-06-17T16:08:48Z","title":"Human-Centered Editable Speech-to-Sign-Language Generation via Streaming\n  Conformer-Transformer and Resampling Hook","summary":"  Existing end-to-end sign-language animation systems suffer from low\nnaturalness, limited facial/body expressivity, and no user control. We propose\na human-centered, real-time speech-to-sign animation framework that integrates\n(1) a streaming Conformer encoder with an autoregressive Transformer-MDN\ndecoder for synchronized upper-body and facial motion generation, (2) a\ntransparent, editable JSON intermediate representation empowering deaf users\nand experts to inspect and modify each sign segment, and (3) a\nhuman-in-the-loop optimization loop that refines the model based on user edits\nand ratings. Deployed on Unity3D, our system achieves a 13 ms average\nframe-inference time and a 103 ms end-to-end latency on an RTX 4070. Our key\ncontributions include the design of a JSON-centric editing mechanism for\nfine-grained sign-level personalization and the first application of an\nMDN-based feedback loop for continuous model adaptation. This combination\nestablishes a generalizable, explainable AI paradigm for user-adaptive,\nlow-latency multimodal systems. In studies with 20 deaf signers and 5\nprofessional interpreters, we observe a +13 point SUS improvement, 6.7 point\nreduction in cognitive load, and significant gains in naturalness and trust (p\n$<$ .001) over baselines. This work establishes a scalable, explainable AI\nparadigm for accessible sign-language technologies.\n","authors":["Yingchao Li"],"pdf_url":"https://arxiv.org/pdf/2506.14677v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19599v1","updated":"2025-06-24T13:09:53Z","published":"2025-06-24T13:09:53Z","title":"ECCoT: A Framework for Enhancing Effective Cognition via Chain of\n  Thought in Large Language Model","summary":"  In the era of large-scale artificial intelligence, Large Language Models\n(LLMs) have made significant strides in natural language processing. However,\nthey often lack transparency and generate unreliable outputs, raising concerns\nabout their interpretability. To address this, the Chain of Thought (CoT)\nprompting method structures reasoning into step-by-step deductions. Yet, not\nall reasoning chains are valid, and errors can lead to unreliable conclusions.\nWe propose ECCoT, an End-to-End Cognitive Chain of Thought Validation\nFramework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates\nthe Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT\ngeneration and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By\nfiltering ineffective chains using structured ordering statistics, ECCoT\nimproves interpretability, reduces biases, and enhances the trustworthiness of\nLLM-based decision-making. Key contributions include the introduction of ECCoT,\nMRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning\nenhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.\n","authors":["Zhenke Duan","Jiqun Pan","Jiani Tu","Xiaoyi Wang","Yanqing Wang"],"pdf_url":"https://arxiv.org/pdf/2506.19599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18810v2","updated":"2025-06-24T13:08:33Z","published":"2025-06-23T16:20:44Z","title":"ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints\n  during Generation","summary":"  Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and\nOpenAI o1 series have achieved notable performance enhancements on complex\nreasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).\nHowever, an emerging issue is their inclination to produce excessively verbose\nreasoning processes, leading to the inefficiency problem. Existing literature\non improving efficiency mainly adheres to the before-reasoning paradigms such\nas prompting and reasoning or fine-tuning and reasoning, but ignores the\npromising direction of directly encouraging the model to speak concisely by\nintervening during the generation of reasoning. In order to fill the blank, we\npropose a framework dubbed ConciseHint, which continuously encourages the\nreasoning model to speak concisely by injecting the textual hint (manually\ndesigned or trained on the concise data) during the token generation of the\nreasoning process. Besides, ConciseHint is adaptive to the complexity of the\nquery by adaptively adjusting the hint intensity, which ensures it will not\nundermine model performance. Experiments on the state-of-the-art LRMs,\nincluding DeepSeek-R1 and Qwen-3 series, demonstrate that our method can\neffectively produce concise reasoning processes while maintaining performance\nwell. For instance, we achieve a reduction ratio of 65\\% for the reasoning\nlength on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.\n","authors":["Siao Tang","Xinyin Ma","Gongfan Fang","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2506.18810v2.pdf","comment":"Codes are available at https://github.com/tsa18/ConciseHint"},{"id":"http://arxiv.org/abs/2506.19597v1","updated":"2025-06-24T13:07:43Z","published":"2025-06-24T13:07:43Z","title":"Robotics Under Construction: Challenges on Job Sites","summary":"  As labor shortages and productivity stagnation increasingly challenge the\nconstruction industry, automation has become essential for sustainable\ninfrastructure development. This paper presents an autonomous payload\ntransportation system as an initial step toward fully unmanned construction\nsites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous\nnavigation, fleet management, and GNSS-based localization to facilitate\nmaterial transport in construction site environments. While the current system\ndoes not yet incorporate dynamic environment adaptation algorithms, we have\nbegun fundamental investigations into external-sensor based perception and\nmapping system. Preliminary results highlight the potential challenges,\nincluding navigation in evolving terrain, environmental perception under\nconstruction-specific conditions, and sensor placement optimization for\nimproving autonomy and efficiency. Looking forward, we envision a construction\necosystem where collaborative autonomous agents dynamically adapt to site\nconditions, optimizing workflow and reducing human intervention. This paper\nprovides foundational insights into the future of robotics-driven construction\nautomation and identifies critical areas for further technological development.\n","authors":["Haruki Uchiito","Akhilesh Bhat","Koji Kusaka","Xiaoya Zhang","Hiraku Kinjo","Honoka Uehara","Motoki Koyama","Shinji Natsume"],"pdf_url":"https://arxiv.org/pdf/2506.19597v1.pdf","comment":"Workshop on Field Robotics, ICRA"},{"id":"http://arxiv.org/abs/2506.19897v1","updated":"2025-06-24T13:02:35Z","published":"2025-06-24T13:02:35Z","title":"Can LLMs Replace Humans During Code Chunking?","summary":"  Large language models (LLMs) have become essential tools in computer science,\nespecially for tasks involving code understanding and generation. However,\nexisting work does not address many of the unique challenges presented by code\nwritten for government applications. In particular, government enterprise\nsoftware is often written in legacy languages like MUMPS or assembly language\ncode (ALC) and the overall token lengths of these systems exceed the context\nwindow size for current commercially available LLMs. Additionally, LLMs are\nprimarily trained on modern software languages and have undergone limited\ntesting with legacy languages, making their ability to understand legacy\nlanguages unknown and, hence, an area for empirical study. This paper examines\nthe application of LLMs in the modernization of legacy government code written\nin ALC and MUMPS, addressing the challenges of input limitations. We\ninvestigate various code-chunking methods to optimize the generation of summary\nmodule comments for legacy code files, evaluating the impact of code-chunking\nmethods on the quality of documentation produced by different LLMs, including\nGPT-4o, Claude 3 Sonnet, Mixtral, and Llama 3. Our results indicate that LLMs\ncan select partition points closely aligned with human expert partitioning. We\nalso find that chunking approaches have significant impact on downstream tasks\nsuch as documentation generation. LLM-created partitions produce comments that\nare up to 20% more factual and up to 10% more useful than when humans create\npartitions. Therefore, we conclude that LLMs can be used as suitable\nreplacements for human partitioning of large codebases during LLM-aided\nmodernization.\n","authors":["Christopher Glasz","Emily Escamilla","Eric O. Scott","Anand Patel","Jacob Zimmer","Colin Diggs","Michael Doyle","Scott Rosen","Nitin Naik","Justin F. Brunelle","Samruddhi Thaker","Parthav Poudel","Arun Sridharan","Amit Madan","Doug Wendt","William Macke","Thomas Schill"],"pdf_url":"https://arxiv.org/pdf/2506.19897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19592v1","updated":"2025-06-24T13:02:06Z","published":"2025-06-24T13:02:06Z","title":"Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to\n  Task Planning","summary":"  We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a\nmulti-agent framework that integrates Large Language Models (LLMs) with\nsymbolic planning to solve complex tasks without the need for manually defined\nenvironment models. TAPAS employs specialized LLM-based agents that\ncollaboratively generate and adapt domain models, initial states, and goal\nspecifications as needed using structured tool-calling mechanisms. Through this\ntool-based interaction, downstream agents can request modifications from\nupstream agents, enabling adaptation to novel attributes and constraints\nwithout manual domain redefinition. A ReAct (Reason+Act)-style execution agent,\ncoupled with natural language plan translation, bridges the gap between\ndynamically generated plans and real-world robot capabilities. TAPAS\ndemonstrates strong performance in benchmark planning domains and in the\nVirtualHome simulated real-world environment.\n","authors":["Harisankar Babu","Philipp Schillinger","Tamim Asfour"],"pdf_url":"https://arxiv.org/pdf/2506.19592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19591v1","updated":"2025-06-24T13:00:36Z","published":"2025-06-24T13:00:36Z","title":"Vision Transformer-Based Time-Series Image Reconstruction for\n  Cloud-Filling Applications","summary":"  Cloud cover in multispectral imagery (MSI) poses significant challenges for\nearly season crop mapping, as it leads to missing or corrupted spectral\ninformation. Synthetic aperture radar (SAR) data, which is not affected by\ncloud interference, offers a complementary solution, but lack sufficient\nspectral detail for precise crop mapping. To address this, we propose a novel\nframework, Time-series MSI Image Reconstruction using Vision Transformer (ViT),\nto reconstruct MSI data in cloud-covered regions by leveraging the temporal\ncoherence of MSI and the complementary information from SAR from the attention\nmechanism. Comprehensive experiments, using rigorous reconstruction evaluation\nmetrics, demonstrate that Time-series ViT framework significantly outperforms\nbaselines that use non-time-series MSI and SAR or time-series MSI without SAR,\neffectively enhancing MSI image reconstruction in cloud-covered regions.\n","authors":["Lujun Li","Yiqun Wang","Radu State"],"pdf_url":"https://arxiv.org/pdf/2506.19591v1.pdf","comment":"This paper has been accepted as a conference paper at the 2025 IEEE\n  International Geoscience and Remote Sensing Symposium (IGARSS)"},{"id":"http://arxiv.org/abs/2506.17728v2","updated":"2025-06-24T12:50:57Z","published":"2025-06-21T14:58:53Z","title":"KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via\n  Knowledge-Augmented Generation","summary":"  In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn\ninteractive thinking and deep reasoning framework powered by a dedicated\nparameter-light large language model (LLM). Our approach constructs a\nstructured thinking process for solving complex problems, enhancing the the\nlogical coherence and contextual consistency of the reasoning process in\nquestion-answering (Q&A) tasks on domain-specific knowledge bases (KBs) within\nLLMs. Following the \\textbf{Logical Form} guided retrieval and reasoning\ntechnology route of KAG, this framework first decomposes complex questions into\nindependently solvable sub-problems (which are also referred to as logical\nforms) through \\textbf{breadth decomposition}. Each such logical form is\nrepresented in two equivalent forms-natural language and logical function-and\nsubsequently classified as either a Knowledge Retrieval or Reasoning Analysis\ntask. Dependencies and parameter passing between these tasks are explicitly\nmodeled via logical function interfaces. In the solving process, the Retrieval\nfunction performs retrieval tasks. It retrieves one-hop structured and\nunstructured information of specified knowledge unit. While the Math and Deduce\nfunctions are used to perform reasoning analysis tasks. Secondly, it is worth\nnoting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external\nknowledge sources are regarded as equivalent KBs. We use the \\textbf{knowledge\nboundary} module to determine the optimal source using self-regulatory\nmechanisms such as confidence calibration and reflective reasoning, and use the\n\\textbf{depth solving} module to enhance the comprehensiveness of knowledge\nacquisition...\n","authors":["Dalong Zhang","Jun Xu","Jun Zhou","Lei Liang","Lin Yuan","Ling Zhong","Mengshu Sun","Peilong Zhao","QiWei Wang","Xiaorui Wang","Xinkai Du","YangYang Hou","Yu Ao","ZhaoYang Wang","Zhengke Gui","ZhiYing Yi","Zhongpu Bo"],"pdf_url":"https://arxiv.org/pdf/2506.17728v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19579v1","updated":"2025-06-24T12:45:09Z","published":"2025-06-24T12:45:09Z","title":"Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language\n  Models on Real and 3D-Printed Objects","summary":"  Robotic scene understanding increasingly relies on vision-language models\n(VLMs) to generate natural language descriptions of the environment. In this\nwork, we present a comparative study of captioning strategies for tabletop\nscenes captured by a robotic arm equipped with an RGB camera. The robot\ncollects images of objects from multiple viewpoints, and we evaluate several\nmodels that generate scene descriptions. We compare the performance of various\ncaptioning models, like BLIP and VLMs. Our experiments examine the trade-offs\nbetween single-view and multi-view captioning, and difference between\nrecognising real-world and 3D printed objects. We quantitatively evaluate\nobject identification accuracy, completeness, and naturalness of the generated\ncaptions. Results show that VLMs can be used in robotic settings where common\nobjects need to be recognised, but fail to generalise to novel representations.\nOur findings provide practical insights into deploying foundation models for\nembodied agents in real-world settings.\n","authors":["Federico Tavella","Kathryn Mearns","Angelo Cangelosi"],"pdf_url":"https://arxiv.org/pdf/2506.19579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19578v1","updated":"2025-06-24T12:42:36Z","published":"2025-06-24T12:42:36Z","title":"Towards an Introspective Dynamic Model of Globally Distributed Computing\n  Infrastructures","summary":"  Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and\nothers involve hundreds of research institutes and thousands of researchers\nspread across the globe. These experiments generate petabytes of data, with\nvolumes soon expected to reach exabytes. Consequently, there is a growing need\nfor computation, including structured data processing from raw data to\nconsumer-ready derived data, extensive Monte Carlo simulation campaigns, and a\nwide range of end-user analysis. To manage these computational and storage\ndemands, centralized workflow and data management systems are implemented.\nHowever, decisions regarding data placement and payload allocation are often\nmade disjointly and via heuristic means. A significant obstacle in adopting\nmore effective heuristic or AI-driven solutions is the absence of a quick and\nreliable introspective dynamic model to evaluate and refine alternative\napproaches. In this study, we aim to develop such an interactive system using\nreal-world data. By examining job execution records from the PanDA workflow\nmanagement system, we have pinpointed key performance indicators such as\nqueuing time, error rate, and the extent of remote data access. The dataset\nincludes five months of activity. Additionally, we are creating a generative AI\nmodel to simulate time series of payloads, which incorporate visible features\nlike category, event count, and submitting group, as well as hidden features\nlike the total computational load-derived from existing PanDA records and\ncomputing site capabilities. These hidden features, which are not visible to\njob allocators, whether heuristic or AI-driven, influence factors such as\nqueuing times and data movement.\n","authors":["Ozgur O. Kilic","David K. Park","Yihui Ren","Tatiana Korchuganova","Sairam Sri Vatsavai","Joseph Boudreau","Tasnuva Chowdhury","Shengyu Feng","Raees Khan","Jaehyung Kim","Scott Klasky","Tadashi Maeno","Paul Nilsson","Verena Ingrid Martinez Outschoorn","Norbert Podhorszki","Frédéric Suter","Wei Yang","Yiming Yang","Shinjae Yoo","Alexei Klimentov","Adolfy Hoisie"],"pdf_url":"https://arxiv.org/pdf/2506.19578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19573v1","updated":"2025-06-24T12:37:17Z","published":"2025-06-24T12:37:17Z","title":"Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer\n  Set Programming","summary":"  Machine learning (ML) techniques play a pivotal role in high-stakes domains\nsuch as healthcare, where accurate predictions can greatly enhance\ndecision-making. However, most high-performing methods such as neural networks\nand ensemble methods are often opaque, limiting trust and broader adoption. In\nparallel, symbolic methods like Answer Set Programming (ASP) offer the\npossibility of interpretable logical rules but do not always match the\npredictive power of ML models. This paper proposes a hybrid approach that\nintegrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML\nclassifiers to selectively correct uncertain predictions and provide\nhuman-readable explanations. Experiments on five medical datasets reveal\nstatistically significant performance gains in accuracy and F1 score. This\nstudy underscores the potential of combining symbolic reasoning with\nconventional ML to achieve high interpretability without sacrificing accuracy.\n","authors":["Sanne Wielinga","Jesse Heyninck"],"pdf_url":"https://arxiv.org/pdf/2506.19573v1.pdf","comment":"accepted for publication as a Technical Communication at ICLP 2025"},{"id":"http://arxiv.org/abs/2506.18710v2","updated":"2025-06-24T12:36:22Z","published":"2025-06-23T14:49:01Z","title":"Benchmarking the Pedagogical Knowledge of Large Language Models","summary":"  Benchmarks like Massive Multitask Language Understanding (MMLU) have played a\npivotal role in evaluating AI's knowledge and abilities across diverse domains.\nHowever, existing benchmarks predominantly focus on content knowledge, leaving\na critical gap in assessing models' understanding of pedagogy - the method and\npractice of teaching. This paper introduces The Pedagogy Benchmark, a novel\ndataset designed to evaluate large language models on their Cross-Domain\nPedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)\npedagogical knowledge. These benchmarks are built on a carefully curated set of\nquestions sourced from professional development exams for teachers, which cover\na range of pedagogical subdomains such as teaching strategies and assessment\nmethods. Here we outline the methodology and development of these benchmarks.\nWe report results for 97 models, with accuracies spanning a range from 28% to\n89% on the pedagogical knowledge questions. We consider the relationship\nbetween cost and accuracy and chart the progression of the Pareto value\nfrontier over time. We provide online leaderboards at\nhttps://rebrand.ly/pedagogy which are updated with new models and allow\ninteractive exploration and filtering based on various model properties, such\nas cost per token and open-vs-closed weights, as well as looking at performance\nin different subjects. LLMs and generative AI have tremendous potential to\ninfluence education and help to address the global learning crisis.\nEducation-focused benchmarks are crucial to measure models' capacities to\nunderstand pedagogical concepts, respond appropriately to learners' needs, and\nsupport effective teaching practices across diverse contexts. They are needed\nfor informing the responsible and evidence-based deployment of LLMs and\nLLM-based tools in educational settings, and for guiding both development and\npolicy decisions.\n","authors":["Maxime Lelièvre","Amy Waldock","Meng Liu","Natalia Valdés Aspillaga","Alasdair Mackintosh","María José Ogando Portela","Jared Lee","Paul Atherton","Robin A. A. Ince","Oliver G. B. Garrod"],"pdf_url":"https://arxiv.org/pdf/2506.18710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19571v1","updated":"2025-06-24T12:35:00Z","published":"2025-06-24T12:35:00Z","title":"Has Machine Translation Evaluation Achieved Human Parity? The Human\n  Reference and the Limits of Progress","summary":"  In Machine Translation (MT) evaluation, metric performance is assessed based\non agreement with human judgments. In recent years, automatic metrics have\ndemonstrated increasingly high levels of agreement with humans. To gain a\nclearer understanding of metric performance and establish an upper bound, we\nincorporate human baselines in the MT meta-evaluation, that is, the assessment\nof MT metrics' capabilities. Our results show that human annotators are not\nconsistently superior to automatic metrics, with state-of-the-art metrics often\nranking on par with or higher than human baselines. Despite these findings\nsuggesting human parity, we discuss several reasons for caution. Finally, we\nexplore the broader implications of our results for the research field, asking:\nCan we still reliably measure improvements in MT evaluation? With this work, we\naim to shed light on the limits of our ability to measure progress in the\nfield, fostering discussion on an issue that we believe is crucial to the\nentire MT evaluation community.\n","authors":["Lorenzo Proietti","Stefano Perrella","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2506.19571v1.pdf","comment":"Accepted at ACL 2025 Main Conference. 24 pages"},{"id":"http://arxiv.org/abs/2506.19567v1","updated":"2025-06-24T12:28:38Z","published":"2025-06-24T12:28:38Z","title":"FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting","summary":"  Multi-task and few-shot time series forecasting tasks are commonly\nencountered in scenarios such as the launch of new products in different\ncities. However, traditional time series forecasting methods suffer from\ninsufficient historical data, which stems from a disregard for the generalized\nand specific features among different tasks. For the aforementioned challenges,\nwe propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which\nconsists of three key components: the Generalized Knowledge Module (GKM), the\nTask-Specific Module (TSM), and the Rank Module (RM). During training phase,\nthe GKM is updated through a meta-learning mechanism that enables the model to\nextract generalized features across related tasks. Meanwhile, the TSM is\ntrained to capture diverse local dynamics through multiple functional regions,\neach of which learns specific features from individual tasks. During testing\nphase, the RM dynamically selects the most relevant functional region from the\nTSM based on input sequence features, which is then combined with the\ngeneralized knowledge learned by the GKM to generate accurate forecasts. This\ndesign enables FAF to achieve robust and personalized forecasting even with\nsparse historical observations We evaluate FAF on five diverse real-world\ndatasets under few-shot time series forecasting settings. Experimental results\ndemonstrate that FAF consistently outperforms baselines that include three\ncategories of time series forecasting methods. In particular, FAF achieves a\n41.81\\% improvement over the best baseline, iTransformer, on the CO$_2$\nemissions dataset.\n","authors":["Pengpeng Ouyang","Dong Chen","Tong Yang","Shuo Feng","Zhao Jin","Mingliang Xu"],"pdf_url":"https://arxiv.org/pdf/2506.19567v1.pdf","comment":"12 pages,4 figures, 8 tables"},{"id":"http://arxiv.org/abs/2506.19563v1","updated":"2025-06-24T12:22:59Z","published":"2025-06-24T12:22:59Z","title":"PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic\n  Consistency and Probability Certainty","summary":"  Large Language Models (LLMs) are widely used in sensitive domains, including\nhealthcare, finance, and legal services, raising concerns about potential\nprivate information leaks during inference. Privacy extraction attacks, such as\njailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the\nmodels to output sensitive information. However, these attacks cannot verify\nwhether the extracted private information is accurate, as no public datasets\nexist for cross-validation, leaving a critical gap in private information\ndetection during inference. To address this, we propose PrivacyXray, a novel\nframework detecting privacy breaches by analyzing LLM inner states. Our\nanalysis reveals that LLMs exhibit higher semantic coherence and probabilistic\ncertainty when generating correct private outputs. Based on this, PrivacyXray\ndetects privacy breaches using four metrics: intra-layer and inter-layer\nsemantic similarity, token-level and sentence-level probability distributions.\nPrivacyXray addresses critical challenges in private information detection by\novercoming the lack of open-source private datasets and eliminating reliance on\nexternal data for validation. It achieves this through the synthesis of\nrealistic private data and a detection mechanism based on the inner states of\nLLMs. Experiments show that PrivacyXray achieves consistent performance, with\nan average accuracy of 92.69% across five LLMs. Compared to state-of-the-art\nmethods, PrivacyXray achieves significant improvements, with an average\naccuracy increase of 20.06%, highlighting its stability and practical utility\nin real-world applications.\n","authors":["Jinwen He","Yiyang Lu","Zijin Lin","Kai Chen","Yue Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.19563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05410v2","updated":"2025-06-24T12:22:55Z","published":"2024-06-08T09:17:54Z","title":"ChatSR: Multimodal Large Language Models for Scientific Formula\n  Discovery","summary":"  Formulas are the language of communication between humans and nature. The\ndiscovery of formulas to describe natural laws from observational data is the\npurpose of scientific research. It is also an important research topic in\nartificial intelligence, which is called a symbolic regression problem. Most of\nthe existing symbolic regression methods generate expressions directly from\nobserved data. Although in some methods, we can inject some prior knowledge\ninto the model by adding constraints or introducing some special character\nhints. However, these methods can only introduce a limited amount of prior\nknowledge specified in advance. Not to mention understanding natural language\ninstructions. In this article, based on the powerful knowledge reserve and\nlanguage understanding ability of multi-modal large language models, we present\nChatSR, which acts like a knowledgeable human scientist, and we can tell it any\nprior knowledge through natural language to guide it in formula generation. By\ntesting on 13 datasets, ChatSR not only shows state-of-the-art performance on\ntraditional symbolic regression tasks. More notably, ChatSR can well understand\nthe prior knowledge contained in natural language prompts and improve the\nquality of generated expressions. In addition, it is exciting that ChatSR has a\ngood zero-shot capability to understand prior knowledge that is not present in\nthe training data.\n","authors":["Yanjie Li","Lina Yu","Weijun Li","Min Wu","Jingyi Liu","Wenqiang Li","Shu Wei","Yusong Deng"],"pdf_url":"https://arxiv.org/pdf/2406.05410v2.pdf","comment":"23 pages,"},{"id":"http://arxiv.org/abs/2506.19561v1","updated":"2025-06-24T12:20:11Z","published":"2025-06-24T12:20:11Z","title":"MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image\n  Classification","summary":"  Recent advances in deep learning for vision tasks have seen the rise of State\nSpace Models (SSMs) like Mamba, celebrated for their linear scalability.\nHowever, their adaptation to 2D visual data often necessitates complex\nmodifications that may diminish efficiency. In this paper, we introduce\nMambaOutRS, a novel hybrid convolutional architecture for remote sensing image\nclassification that re-evaluates the necessity of recurrent SSMs. MambaOutRS\nbuilds upon stacked Gated CNN blocks for local feature extraction and\nintroduces a novel Fourier Filter Gate (FFG) module that operates in the\nfrequency domain to capture global contextual information efficiently. Our\narchitecture employs a four-stage hierarchical design and was extensively\nevaluated on challenging remote sensing datasets: UC Merced, AID,\nNWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art\n(SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant\n(24.0M parameters) attained the highest F1-scores of 98.41\\% on UC Merced and\n95.99\\% on AID, significantly outperforming existing baselines, including\nlarger transformer models and Mamba-based architectures, despite using\nconsiderably fewer parameters. An ablation study conclusively demonstrates the\ncritical role of the Fourier Filter Gate in enhancing the model's ability to\ncapture global spatial patterns, leading to robust and accurate classification.\nThese results strongly suggest that the complexities of recurrent SSMs can be\neffectively superseded by a judicious combination of gated convolutions for\nspatial mixing and frequency-based gates for spectral global context. Thus,\nMambaOutRS provides a compelling and efficient paradigm for developing\nhigh-performance deep learning models in remote sensing and other vision\ndomains, particularly where computational efficiency is paramount.\n","authors":["Minjong Cheon","Changbae Mun"],"pdf_url":"https://arxiv.org/pdf/2506.19561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19552v1","updated":"2025-06-24T12:00:13Z","published":"2025-06-24T12:00:13Z","title":"General Methods Make Great Domain-specific Foundation Models: A\n  Case-study on Fetal Ultrasound","summary":"  With access to large-scale, unlabeled medical datasets, researchers are\nconfronted with two questions: Should they attempt to pretrain a custom\nfoundation model on this medical data, or use transfer-learning from an\nexisting generalist model? And, if a custom model is pretrained, are novel\nmethods required? In this paper we explore these questions by conducting a\ncase-study, in which we train a foundation model on a large regional fetal\nultrasound dataset of 2M images. By selecting the well-established DINOv2\nmethod for pretraining, we achieve state-of-the-art results on three fetal\nultrasound datasets, covering data from different countries, classification,\nsegmentation, and few-shot tasks. We compare against a series of models\npretrained on natural images, ultrasound images, and supervised baselines. Our\nresults demonstrate two key insights: (i) Pretraining on custom data is worth\nit, even if smaller models are trained on less data, as scaling in natural\nimage pretraining does not translate to ultrasound performance. (ii) Well-tuned\nmethods from computer vision are making it feasible to train custom foundation\nmodels for a given medical domain, requiring no hyperparameter tuning and\nlittle methodological adaptation. Given these findings, we argue that a bias\ntowards methodological innovation should be avoided when developing domain\nspecific foundation models under common computational resource constraints.\n","authors":["Jakob Ambsdorf","Asbjørn Munk","Sebastian Llambias","Anders Nymark Christensen","Kamil Mikolaj","Randall Balestriero","Martin Tolsgaard","Aasa Feragen","Mads Nielsen"],"pdf_url":"https://arxiv.org/pdf/2506.19552v1.pdf","comment":"Submitted version of paper accepted at MICCAI 2025"},{"id":"http://arxiv.org/abs/2506.11558v2","updated":"2025-06-24T11:59:30Z","published":"2025-06-13T08:13:05Z","title":"DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning\n  with Video LLMs","summary":"  Large Language Models (LLMs) have recently been extended to the video domain,\nenabling sophisticated video-language understanding. However, existing Video\nLLMs often exhibit limitations in fine-grained temporal reasoning, restricting\ntheir ability to precisely attribute responses to specific video moments,\nespecially under constrained supervision. We introduce DaMO, a data-efficient\nVideo LLM explicitly designed for accurate temporal reasoning and multimodal\nunderstanding. At its core, the proposed Temporal-aware Fuseformer employs a\nhierarchical dual-stream architecture that progressively captures temporal\ndynamics within each modality and effectively fuses complementary visual and\naudio information. To further enhance computational efficiency, DaMO integrates\na global residual that reduces spatial redundancy while preserving essential\nsemantic details. We train DaMO via a structured four-stage progressive\ntraining paradigm, incrementally equipping the model with multimodal alignment,\nsemantic grounding, and temporal reasoning capabilities. This work also\ncontributes multiple datasets augmented from existing ones with GPT-generated\ntemporally grounded QA pairs for tasks requiring temporal supervision.\nComprehensive experiments on temporal grounding and video QA benchmarks\ndemonstrate that DaMO consistently surpasses prior methods, particularly in\ntasks demanding precise temporal alignment and reasoning. Our work establishes\na promising direction for data-efficient video-language modeling.\n","authors":["Bo-Cheng Chiu","Jen-Jee Chen","Yu-Chee Tseng","Feng-Chi Chen"],"pdf_url":"https://arxiv.org/pdf/2506.11558v2.pdf","comment":"I would like to request the withdrawal of this submission because the\n  current version contains significant errors and incomplete results. I intend\n  to revise the manuscript thoroughly before resubmitting. I apologize for the\n  oversight and appreciate your understanding"},{"id":"http://arxiv.org/abs/2506.19549v1","updated":"2025-06-24T11:55:43Z","published":"2025-06-24T11:55:43Z","title":"RCStat: A Statistical Framework for using Relative Contextualization in\n  Transformers","summary":"  Prior work on input-token importance in auto-regressive transformers has\nrelied on Softmax-normalized attention weights, which obscure the richer\nstructure of pre-Softmax query-key logits. We introduce RCStat, a statistical\nframework that harnesses raw attention logits via Relative Contextualization\n(RC), a random variable measuring contextual alignment between token segments,\nand derive an efficient upper bound for RC. We demonstrate two applications:\n(i) Key-Value compression, where RC-based thresholds drive adaptive key-value\neviction for substantial cache reduction with minimal quality loss; and (ii)\nAttribution, where RC yields higher-fidelity token-, sentence-, and chunk-level\nexplanations than post-Softmax methods. Across question answering,\nsummarization, and attribution benchmarks, RCStat achieves significant\nempirical gains, delivering state-of-the-art compression and attribution\nperformance without any model retraining.\n","authors":["Debabrata Mahapatra","Shubham Agarwal","Apoorv Saxena","Subrata Mitra"],"pdf_url":"https://arxiv.org/pdf/2506.19549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19539v1","updated":"2025-06-24T11:49:40Z","published":"2025-06-24T11:49:40Z","title":"Lost in Translation? Converting RegExes for Log Parsing into Dynatrace\n  Pattern Language","summary":"  Log files provide valuable information for detecting and diagnosing problems\nin enterprise software applications and data centers. Several log analytics\ntools and platforms were developed to help filter and extract information from\nlogs, typically using regular expressions (RegExes). Recent commercial log\nanalytics platforms provide domain-specific languages specifically designed for\nlog parsing, such as Grok or the Dynatrace Pattern Language (DPL). However,\nusers who want to migrate to these platforms must manually convert their\nRegExes into the new pattern language, which is costly and error-prone. In this\nwork, we present Reptile, which combines a rule-based approach for converting\nRegExes into DPL patterns with a best-effort approach for cases where a full\nconversion is impossible. Furthermore, it integrates GPT-4 to optimize the\nobtained DPL patterns. The evaluation with 946 RegExes collected from a large\ncompany shows that Reptile safely converted 73.7% of them. The evaluation of\nReptile's pattern optimization with 23 real-world RegExes showed an F1-score\nand MCC above 0.91. These results are promising and have ample practical\nimplications for companies that migrate to a modern log analytics platform,\nsuch as Dynatrace.\n","authors":["Julian Fragner","Christian Macho","Bernhard Dieber","Martin Pinzger"],"pdf_url":"https://arxiv.org/pdf/2506.19539v1.pdf","comment":"18 pages, 7 tables, 18 figures"},{"id":"http://arxiv.org/abs/2506.19531v1","updated":"2025-06-24T11:34:35Z","published":"2025-06-24T11:34:35Z","title":"ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and\n  CT Domain Transformation","summary":"  Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting\nclinical decisions. We propose a deep learning framework for metal artifact\nreduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT).\nThe proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with\nenhanced feature recalibration, effectively reducing artifacts while preserving\nanatomical structures. This ensures that only relevant information is utilized\nin the reconstruction process. By infusing recalibrated features from the\nencoder block, the model focuses on relevant spatial regions (e.g., areas with\nartifacts) and highlights key features across channels (e.g., anatomical\nstructures), leading to improved reconstruction of artifact-corrupted regions.\nUnlike traditional MAR methods, our approach bridges the gap between\nhigh-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy\nplanning. It produces high-quality MVCT-like reconstructions, validated through\nqualitative and quantitative evaluations. Clinically, this enables oncologists\nto rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering\nradiation exposure for cancer patients.\n","authors":["Mubashara Rehman","Niki Martinel","Michele Avanzo","Riccardo Spizzo","Christian Micheloni"],"pdf_url":"https://arxiv.org/pdf/2506.19531v1.pdf","comment":"Accepted in 23rd International Conference on Image Analysis and\n  Processing (ICIAP) 2025, Italy"},{"id":"http://arxiv.org/abs/2506.19530v1","updated":"2025-06-24T11:34:01Z","published":"2025-06-24T11:34:01Z","title":"NTRL: Encounter Generation via Reinforcement Learning for Dynamic\n  Difficulty Adjustment in Dungeons and Dragons","summary":"  Balancing combat encounters in Dungeons & Dragons (D&D) is a complex task\nthat requires Dungeon Masters (DM) to manually assess party strength, enemy\ncomposition, and dynamic player interactions while avoiding interruption of the\nnarrative flow. In this paper, we propose Encounter Generation via\nReinforcement Learning (NTRL), a novel approach that automates Dynamic\nDifficulty Adjustment (DDA) in D&D via combat encounter design. By framing the\nproblem as a contextual bandit, NTRL generates encounters based on real-time\nparty members attributes. In comparison with classic DM heuristics, NTRL\niteratively optimizes encounters to extend combat longevity (+200%), increases\ndamage dealt to party members, reducing post-combat hit points (-16.67%), and\nraises the number of player deaths while maintaining low total party kills\n(TPK). The intensification of combat forces players to act wisely and engage in\ntactical maneuvers, even though the generated encounters guarantee high win\nrates (70%). Even in comparison with encounters designed by human Dungeon\nMasters, NTRL demonstrates superior performance by enhancing the strategic\ndepth of combat while increasing difficulty in a manner that preserves overall\ngame fairness.\n","authors":["Carlo Romeo","Andrew D. Bagdanov"],"pdf_url":"https://arxiv.org/pdf/2506.19530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19525v1","updated":"2025-06-24T11:25:21Z","published":"2025-06-24T11:25:21Z","title":"Automatic Posology Structuration : What role for LLMs?","summary":"  Automatically structuring posology instructions is essential for improving\nmedication safety and enabling clinical decision support. In French\nprescriptions, these instructions are often ambiguous, irregular, or\ncolloquial, limiting the effectiveness of classic ML pipelines. We explore the\nuse of Large Language Models (LLMs) to convert free-text posologies into\nstructured formats, comparing prompt-based methods and fine-tuning against a\n\"pre-LLM\" system based on Named Entity Recognition and Linking (NERL). Our\nresults show that while prompting improves performance, only fine-tuned LLMs\nmatch the accuracy of the baseline. Through error analysis, we observe\ncomplementary strengths: NERL offers structural precision, while LLMs better\nhandle semantic nuances. Based on this, we propose a hybrid pipeline that\nroutes low-confidence cases from NERL (<0.8) to the LLM, selecting outputs\nbased on confidence scores. This strategy achieves 91% structuration accuracy\nwhile minimizing latency and compute. Our results show that this hybrid\napproach improves structuration accuracy while limiting computational cost,\noffering a scalable solution for real-world clinical use.\n","authors":["Natalia Bobkova","Laura Zanella-Calzada","Anyes Tafoughalt","Raphaël Teboul","François Plesse","Félix Gaschi"],"pdf_url":"https://arxiv.org/pdf/2506.19525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06976v3","updated":"2025-06-24T11:12:22Z","published":"2024-07-09T15:52:06Z","title":"Rich Interoperable Metadata for Cultural Heritage Projects at\n  Jagiellonian University","summary":"  The rich metadata created nowadays for objects stored in libraries has\nnowhere to be stored, because core standards, namely MARC 21 and Dublin Core,\nare not flexible enough. The aim of this paper is to summarize our\nwork-in-progress on tackling this problem in research on cultural heritage\nobjects at the Jagiellonian University (JU). We compared the objects' metadata\ncurrently being collected at the JU (with examples of manuscript, placard, and\nobituary) with five widespread metadata standards used by the cultural heritage\ncommunity: Dublin Core, EAD, MODS, EDM and Digital Scriptorium. Our preliminary\nresults showed that mapping between them is indeed problematic, but we\nidentified requirements that should be followed in further work on the JU\ncultural heritage metadata schema in order to achieve maximum interoperability.\nAs we move forward, based on the successive versions of the conceptual model,\nwe will conduct experiments to validate the practical feasibility of these\nmappings and the degree to which the proposed model will actually enable\nintegration with data in these various metadata formats.\n","authors":["Luiz do Valle Miranda","Krzysztof Kutt","Elżbieta Sroka","Grzegorz J. Nalepa"],"pdf_url":"https://arxiv.org/pdf/2407.06976v3.pdf","comment":"10 pages; submitted to TPLD 2025; change in v2: heavily rewritten,\n  new content added; change in v3: updated e-mail address"},{"id":"http://arxiv.org/abs/2506.19895v1","updated":"2025-06-24T11:10:41Z","published":"2025-06-24T11:10:41Z","title":"A Framework for Uncertainty Quantification Based on Nearest Neighbors\n  Across Layers","summary":"  Neural Networks have high accuracy in solving problems where it is difficult\nto detect patterns or create a logical model. However, these algorithms\nsometimes return wrong solutions, which become problematic in high-risk domains\nlike medical diagnosis or autonomous driving. One strategy to detect and\nmitigate these errors is the measurement of the uncertainty over neural network\ndecisions. In this paper, we present a novel post-hoc framework for measuring\nthe uncertainty of a decision based on retrieved training cases that have a\nsimilar activation vector to the query for each layer. Based on these retrieved\ncases, we propose two new metrics: Decision Change and Layer Uncertainty, which\ncapture changes in nearest-neighbor class distributions across layers. We\nevaluated our approach in a classification model for two datasets: CIFAR-10 and\nMNIST. The results show that these metrics enhance uncertainty estimation,\nespecially in challenging classification tasks, outperforming softmax-based\nconfidence.\n","authors":["Miguel N. Font","José L. Jorro-Aragoneses","Carlos M. Alaíz"],"pdf_url":"https://arxiv.org/pdf/2506.19895v1.pdf","comment":"This paper has been accepted for presentation at ICANN 2025\n  (International Conference on Artificial Neural Networks) and will appear in\n  the conference proceedings published by Springer Nature in the Lecture Notes\n  in Computer Science (LNCS) series. The final authenticated version will be\n  available on the publisher website"},{"id":"http://arxiv.org/abs/2501.16490v2","updated":"2025-06-24T11:10:26Z","published":"2025-01-27T20:48:25Z","title":"Towards Robust Stability Prediction in Smart Grids: GAN-based Approach\n  under Data Constraints and Adversarial Challenges","summary":"  Smart grids are crucial for meeting rising energy demands driven by global\npopulation growth and urbanization. By integrating renewable energy sources,\nthey enhance efficiency, reliability, and sustainability. However, ensuring\ntheir availability and security requires advanced operational control and\nsafety measures. Although artificial intelligence and machine learning can help\nassess grid stability, challenges such as data scarcity and cybersecurity\nthreats, particularly adversarial attacks, remain. Data scarcity is a major\nissue, as obtaining real-world instances of grid instability requires\nsignificant expertise, resources, and time. Yet, these instances are critical\nfor testing new research advancements and security mitigations. This paper\nintroduces a novel framework for detecting instability in smart grids using\nonly stable data. It employs a Generative Adversarial Network (GAN) where the\ngenerator is designed not to produce near-realistic data but instead to\ngenerate Out-Of-Distribution (OOD) samples with respect to the stable class.\nThese OOD samples represent unstable behavior, anomalies, or disturbances that\ndeviate from the stable data distribution. By training exclusively on stable\ndata and exposing the discriminator to OOD samples, our framework learns a\nrobust decision boundary to distinguish stable conditions from any unstable\nbehavior, without requiring unstable data during training. Furthermore, we\nincorporate an adversarial training layer to enhance resilience against\nattacks. Evaluated on a real-world dataset, our solution achieves up to 98.1\\%\naccuracy in predicting grid stability and 98.9\\% in detecting adversarial\nattacks. Implemented on a single-board computer, it enables real-time\ndecision-making with an average response time of under 7ms.\n","authors":["Emad Efatinasab","Alessandro Brighente","Denis Donadel","Mauro Conti","Mirco Rampazzo"],"pdf_url":"https://arxiv.org/pdf/2501.16490v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08365v3","updated":"2025-06-24T11:08:29Z","published":"2025-02-12T12:51:36Z","title":"Towards Unsupervised Multi-Agent Reinforcement Learning via\n  Task-Agnostic Exploration","summary":"  In reinforcement learning, we typically refer to unsupervised pre-training\nwhen we aim to pre-train a policy without a priori access to the task\nspecification, i.e. rewards, to be later employed for efficient learning of\ndownstream tasks. In single-agent settings, the problem has been extensively\nstudied and mostly understood. A popular approach, called task-agnostic\nexploration, casts the unsupervised objective as maximizing the entropy of the\nstate distribution induced by the agent's policy, from which principles and\nmethods follow.\n  In contrast, little is known about it in multi-agent settings, which are\nubiquitous in the real world. What are the pros and cons of alternative problem\nformulations in this setting? How hard is the problem in theory, how can we\nsolve it in practice? In this paper, we address these questions by first\ncharacterizing those alternative formulations and highlighting how the problem,\neven when tractable in theory, is non-trivial in practice. Then, we present a\nscalable, decentralized, trust-region policy search algorithm to address the\nproblem in practical settings. Finally, we provide numerical validations to\nboth corroborate the theoretical findings and pave the way for unsupervised\nmulti-agent reinforcement learning via task-agnostic exploration in challenging\ndomains, showing that optimizing for a specific objective, namely mixture\nentropy, provides an excellent trade-off between tractability and performances.\n","authors":["Riccardo Zamboni","Mirco Mutti","Marcello Restelli"],"pdf_url":"https://arxiv.org/pdf/2502.08365v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19894v1","updated":"2025-06-24T11:07:19Z","published":"2025-06-24T11:07:19Z","title":"Explaining deep neural network models for electricity price forecasting\n  with XAI","summary":"  Electricity markets are highly complex, involving lots of interactions and\ncomplex dependencies that make it hard to understand the inner workings of the\nmarket and what is driving prices. Econometric methods have been developed for\nthis, white-box models, however, they are not as powerful as deep neural\nnetwork models (DNN). In this paper, we use a DNN to forecast the price and\nthen use XAI methods to understand the factors driving the price dynamics in\nthe market. The objective is to increase our understanding of how different\nelectricity markets work. To do that, we apply explainable methods such as SHAP\nand Gradient, combined with visual techniques like heatmaps (saliency maps) to\nanalyse the behaviour and contributions of various features across five\nelectricity markets. We introduce the novel concepts of SSHAP values and SSHAP\nlines to enhance the complex representation of high-dimensional tabular models.\n","authors":["Antoine Pesenti","Aidan OSullivan"],"pdf_url":"https://arxiv.org/pdf/2506.19894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.14544v2","updated":"2025-06-24T11:01:50Z","published":"2025-05-20T15:59:44Z","title":"Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies","summary":"  Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.\n","authors":["Saahil Mahato"],"pdf_url":"https://arxiv.org/pdf/2505.14544v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15961v2","updated":"2025-06-24T10:50:28Z","published":"2025-06-19T02:10:06Z","title":"TrainVerify: Equivalence-Based Verification for Distributed LLM Training","summary":"  Training large language models (LLMs) at scale requires parallel execution\nacross thousands of devices, incurring enormous computational costs. Yet, these\ncostly distributed trainings are rarely verified, leaving them prone to silent\nerrors and potentially wasting millions of GPU hours. We introduce TrainVerify,\na system for verifiable distributed training of LLMs. Given a deep learning\nmodel's logical specification as the ground truth, TrainVerify formally\nverifies that a distributed parallel execution plan is mathematically\nequivalent to it. Direct verification is notoriously difficult due to the sheer\nscale of LLMs which often involves billions of variables and highly intricate\ncomputation graphs. Therefore, TrainVerify introduces shape-reduction\ntechniques and a stage-wise parallel verification algorithm that significantly\nreduces complexity while preserving formal correctness. TrainVerify scales to\nfrontier LLMs, including the successful verification of the Llama3 (405B) and\nDeepSeek-V3 (671B) training plans.\n","authors":["Yunchi Lu","Youshan Miao","Cheng Tan","Peng Huang","Yi Zhu","Xian Zhang","Fan Yang"],"pdf_url":"https://arxiv.org/pdf/2506.15961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19893v1","updated":"2025-06-24T10:50:14Z","published":"2025-06-24T10:50:14Z","title":"Distillation-Enabled Knowledge Alignment for Generative Semantic\n  Communications in AIGC Provisioning Tasks","summary":"  Due to the surging amount of AI-generated content (AIGC), its provisioning to\nedges and mobile users from the cloud incurs substantial traffic on networks.\nGenerative semantic communication (GSC) offers a promising solution by\ntransmitting highly compact information, i.e., prompt text and latent\nrepresentations, instead of high-dimensional AIGC data. However, GSC relies on\nthe alignment between the knowledge in the cloud generative AI (GAI) and that\npossessed by the edges and users, and between the knowledge for wireless\ntransmission and that of actual channels, which remains challenging. In this\npaper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm\nfor GSC systems. The core idea is to distill the generation knowledge from the\ncloud-GAI into low-rank matrices, which can be incorporated by the edge and\nused to adapt the transmission knowledge to diverse wireless channel\nconditions. DeKA-g comprises two novel methods: metaword-aided knowledge\ndistillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,\nan optimized metaword is employed to enhance the efficiency of knowledge\ndistillation, while VGSA enables efficient adaptation to diverse compression\nrates and SNR ranges. From simulation results, DeKA-g improves the alignment\nbetween the edge-generated images and the cloud-generated ones by 44%.\nMoreover, it adapts to compression rates with 116% higher efficiency than the\nbaseline and enhances the performance in low-SNR conditions by 28%.\n","authors":["Jingzhi Hu","Geoffrey Ye Li"],"pdf_url":"https://arxiv.org/pdf/2506.19893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19892v1","updated":"2025-06-24T10:46:48Z","published":"2025-06-24T10:46:48Z","title":"RepuNet: A Reputation System for Mitigating Malicious Clients in DFL","summary":"  Decentralized Federated Learning (DFL) enables nodes to collaboratively train\nmodels without a central server, introducing new vulnerabilities since each\nnode independently selects peers for model aggregation. Malicious nodes may\nexploit this autonomy by sending corrupted models (model poisoning), delaying\nmodel submissions (delay attack), or flooding the network with excessive\nmessages, negatively affecting system performance. Existing solutions often\ndepend on rigid configurations or additional infrastructures such as\nblockchain, leading to computational overhead, scalability issues, or limited\nadaptability. To overcome these limitations, this paper proposes RepuNet, a\ndecentralized reputation system that categorizes threats in DFL and dynamically\nevaluates node behavior using metrics like model similarity, parameter changes,\nmessage latency, and communication volume. Nodes' influence in model\naggregation is adjusted based on their reputation scores. RepuNet was\nintegrated into the Nebula DFL platform and experimentally evaluated with MNIST\nand CIFAR-10 datasets under non-IID distributions, using federations of up to\n25 nodes in both fully connected and random topologies. Different attack\nintensities, frequencies, and activation intervals were tested. Results\ndemonstrated that RepuNet effectively detects and mitigates malicious behavior,\nachieving F1 scores above 95% for MNIST scenarios and approximately 76% for\nCIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,\nand practical potential for mitigating threats in decentralized federated\nlearning environments.\n","authors":["Isaac Marroqui Penalva","Enrique Tomás Martínez Beltrán","Manuel Gil Pérez","Alberto Huertas Celdrán"],"pdf_url":"https://arxiv.org/pdf/2506.19892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19502v1","updated":"2025-06-24T10:40:23Z","published":"2025-06-24T10:40:23Z","title":"MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility\n  Applications","summary":"  Accessibility remains a critical concern in today's society, as many\ntechnologies are not developed to support the full range of user needs.\nExisting multi-agent systems (MAS) often cannot provide comprehensive\nassistance for users in need due to the lack of customization stemming from\nclosed-source designs. Consequently, individuals with disabilities frequently\nencounter significant barriers when attempting to interact with digital\nenvironments. We introduce MATE, a multimodal accessibility MAS, which performs\nthe modality conversions based on the user's needs. The system is useful for\nassisting people with disabilities by ensuring that data will be converted to\nan understandable format. For instance, if the user cannot see well and\nreceives an image, the system converts this image to its audio description.\nMATE can be applied to a wide range of domains, industries, and areas, such as\nhealthcare, and can become a useful assistant for various groups of users. The\nsystem supports multiple types of models, ranging from LLM API calling to using\ncustom machine learning (ML) classifiers. This flexibility ensures that the\nsystem can be adapted to various needs and is compatible with a wide variety of\nhardware. Since the system is expected to run locally, it ensures the privacy\nand security of sensitive information. In addition, the framework can be\neffectively integrated with institutional technologies (e.g., digital\nhealthcare service) for real-time user assistance. Furthermore, we introduce\nModCon-Task-Identifier, a model that is capable of extracting the precise\nmodality conversion task from the user input. Numerous experiments show that\nModCon-Task-Identifier consistently outperforms other LLMs and statistical\nmodels on our custom data. Our code and data are publicly available at\nhttps://github.com/AlgazinovAleksandr/Multi-Agent-MATE.\n","authors":["Aleksandr Algazinov","Matt Laing","Paul Laban"],"pdf_url":"https://arxiv.org/pdf/2506.19502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19500v1","updated":"2025-06-24T10:39:07Z","published":"2025-06-24T10:39:07Z","title":"NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function\n  Calling","summary":"  LLMs' reliance on static knowledge and fragile tool invocation severely\nhinders the orchestration of complex, heterogeneous toolchains, particularly at\nlarge scales. Existing methods typically use rigid single-path execution,\nresulting in poor error recovery and exponentially growing search spaces. We\nintroduce NaviAgent, a graph-navigated bilevel planning architecture for robust\nfunction calling, comprising a Multi-Path Decider and Graph-Encoded Navigator.\nAs an LLM-powered agent, the Multi-Path Decider defines a four-dimensional\ndecision space and continuously perceives environmental states, dynamically\nselecting the optimal action to fully cover all tool invocation scenarios. The\nGraph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph\n(TDHG), where node embeddings explicitly fuse API schema structure with\nhistorical invocation behavior. It also integrates a novel heuristic search\nstrategy that guides the Decider toward efficient and highly successful\ntoolchains, even for unseen tool combinations. Experiments show that NaviAgent\nconsistently achieves the highest task success rate (TSR) across all foundation\nmodels and task complexities, outperforming the average baselines (ReAct,\nToolLLM, {\\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B,\nand Deepseek-V3, respectively. Its execution steps are typically within one\nstep of the most efficient baseline, ensuring a strong balance between quality\nand efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of\n49.5%, surpassing the much larger 32B model (44.9%) under our architecture.\nIncorporating the Graph-Encoded Navigator further boosts TSR by an average of\n2.4 points, with gains up over 9 points on complex tasks for larger models\n(Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain\norchestration.\n","authors":["Yan Jiang","Hao Zhou","LiZhong GU","Ai Han","TianLong Li"],"pdf_url":"https://arxiv.org/pdf/2506.19500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19498v1","updated":"2025-06-24T10:36:15Z","published":"2025-06-24T10:36:15Z","title":"T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic\n  Manipulation with Vision-Language Models","summary":"  Building a general robotic manipulation system capable of performing a wide\nvariety of tasks in real-world settings is a challenging task. Vision-Language\nModels (VLMs) have demonstrated remarkable potential in robotic manipulation\ntasks, primarily due to the extensive world knowledge they gain from\nlarge-scale datasets. In this process, Spatial Representations (such as points\nrepresenting object positions or vectors representing object orientations) act\nas a bridge between VLMs and real-world scene, effectively grounding the\nreasoning abilities of VLMs and applying them to specific task scenarios.\nHowever, existing VLM-based robotic approaches often adopt a fixed spatial\nrepresentation extraction scheme for various tasks, resulting in insufficient\nrepresentational capability or excessive extraction time. In this work, we\nintroduce T-Rex, a Task-Adaptive Framework for Spatial Representation\nExtraction, which dynamically selects the most appropriate spatial\nrepresentation extraction scheme for each entity based on specific task\nrequirements. Our key insight is that task complexity determines the types and\ngranularity of spatial representations, and Stronger representational\ncapabilities are typically associated with Higher overall system operation\ncosts. Through comprehensive experiments in real-world robotic environments, we\nshow that our approach delivers significant advantages in spatial\nunderstanding, efficiency, and stability without additional training.\n","authors":["Yiteng Chen","Wenbo Li","Shiyi Wang","Huiping Zhuang","Qingyao Wu"],"pdf_url":"https://arxiv.org/pdf/2506.19498v1.pdf","comment":"submitted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2506.19491v1","updated":"2025-06-24T10:25:17Z","published":"2025-06-24T10:25:17Z","title":"Experimental Assessment of Neural 3D Reconstruction for Small UAV-based\n  Applications","summary":"  The increasing miniaturization of Unmanned Aerial Vehicles (UAVs) has\nexpanded their deployment potential to indoor and hard-to-reach areas. However,\nthis trend introduces distinct challenges, particularly in terms of flight\ndynamics and power consumption, which limit the UAVs' autonomy and mission\ncapabilities. This paper presents a novel approach to overcoming these\nlimitations by integrating Neural 3D Reconstruction (N3DR) with small UAV\nsystems for fine-grained 3-Dimensional (3D) digital reconstruction of small\nstatic objects. Specifically, we design, implement, and evaluate an N3DR-based\npipeline that leverages advanced models, i.e., Instant-ngp, Nerfacto, and\nSplatfacto, to improve the quality of 3D reconstructions using images of the\nobject captured by a fleet of small UAVs. We assess the performance of the\nconsidered models using various imagery and pointcloud metrics, comparing them\nagainst the baseline Structure from Motion (SfM) algorithm. The experimental\nresults demonstrate that the N3DR-enhanced pipeline significantly improves\nreconstruction quality, making it feasible for small UAVs to support\nhigh-precision 3D mapping and anomaly detection in constrained environments. In\nmore general terms, our results highlight the potential of N3DR in advancing\nthe capabilities of miniaturized UAV systems.\n","authors":["Genís Castillo Gómez-Raya","Álmos Veres-Vitályos","Filip Lemic","Pablo Royo","Mario Montagud","Sergi Fernández","Sergi Abadal","Xavier Costa-Pérez"],"pdf_url":"https://arxiv.org/pdf/2506.19491v1.pdf","comment":"6 pages, 7 figures, 2 tables, accepted at IEEE International\n  Symposium on Personal, Indoor and Mobile Radio Communications 2025"},{"id":"http://arxiv.org/abs/2506.19486v1","updated":"2025-06-24T10:21:10Z","published":"2025-06-24T10:21:10Z","title":"Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy\n  Labelers to Leak Privacy","summary":"  Machine Unlearning (MU) technology facilitates the removal of the influence\nof specific data instances from trained models on request. Despite rapid\nadvancements in MU technology, its vulnerabilities are still underexplored,\nposing potential risks of privacy breaches through leaks of ostensibly\nunlearned information. Current limited research on MU attacks requires access\nto original models containing privacy data, which violates the critical\nprivacy-preserving objective of MU. To address this gap, we initiate an\ninnovative study on recalling the forgotten class memberships from unlearned\nmodels (ULMs) without requiring access to the original one. Specifically, we\nimplement a Membership Recall Attack (MRA) framework with a teacher-student\nknowledge distillation architecture, where ULMs serve as noisy labelers to\ntransfer knowledge to student models. Then, it is translated into a Learning\nwith Noisy Labels (LNL) problem for inferring the correct labels of the\nforgetting instances. Extensive experiments on state-of-the-art MU methods with\nmultiple real datasets demonstrate that the proposed MRA strategy exhibits high\nefficacy in recovering class memberships of unlearned instances. As a result,\nour study and evaluation have established a benchmark for future research on MU\nvulnerabilities.\n","authors":["Zhihao Sui","Liang Hu","Jian Cao","Dora D. Liu","Usman Naseem","Zhongyuan Lai","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.19486v1.pdf","comment":"IJCAI 2025"},{"id":"http://arxiv.org/abs/2506.19484v1","updated":"2025-06-24T10:19:09Z","published":"2025-06-24T10:19:09Z","title":"Dialogic Pedagogy for Large Language Models: Aligning Conversational AI\n  with Proven Theories of Learning","summary":"  Large Language Models (LLMs) are rapidly transforming education by enabling\nrich conversational learning experiences. This article provides a comprehensive\nreview of how LLM-based conversational agents are being used in higher\neducation, with extensions to secondary and lifelong learning contexts. We\nsynthesize existing literature on LLMs in education and theories of\nconversational and dialogic pedagogy - including Vygotsky's sociocultural\nlearning (scaffolding and the Zone of Proximal Development), the Socratic\nmethod, and Laurillard's conversational framework - and examine how prompting\nstrategies and retrieval-augmented generation (RAG) can align LLM behaviors\nwith these pedagogical theories, and how it can support personalized, adaptive\nlearning. We map educational theories to LLM capabilities, highlighting where\nLLM-driven dialogue supports established learning principles and where it\nchallenges or falls short of traditional pedagogical assumptions. Notable gaps\nin applying prior theories to LLMs are identified, such as the models tendency\nto provide direct answers instead of fostering co-construction of knowledge,\nand the need to account for the constant availability and broad but non-human\nexpertise of LLM tutors. In response, we propose practical strategies to better\nalign LLM interactions with sound pedagogy - for example, designing prompts\nthat encourage Socratic questioning, scaffolded guidance, and student\nreflection, as well as integrating retrieval mechanisms to ensure accuracy and\ncontextual relevance. Our aim is to bridge the gap between educational theory\nand the emerging practice of AI-driven conversational learning, offering\ninsights and tools for making LLM-based dialogues more educationally productive\nand theory-aligned.\n","authors":["Russell Beale"],"pdf_url":"https://arxiv.org/pdf/2506.19484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19482v1","updated":"2025-06-24T10:17:38Z","published":"2025-06-24T10:17:38Z","title":"Fast and Distributed Equivariant Graph Neural Networks by Virtual Node\n  Learning","summary":"  Equivariant Graph Neural Networks (GNNs) have achieved remarkable success\nacross diverse scientific applications. However, existing approaches face\ncritical efficiency challenges when scaling to large geometric graphs and\nsuffer significant performance degradation when the input graphs are sparsified\nfor computational tractability. To address these limitations, we introduce\nFastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for\nlarge-scale geometric graphs. FastEGNN employs a key innovation: a small\nordered set of virtual nodes that effectively approximates the large unordered\ngraph of real nodes. Specifically, we implement distinct message passing and\naggregation mechanisms for different virtual nodes to ensure mutual\ndistinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual\nand real coordinates to achieve global distributedness. This design enables\nFastEGNN to maintain high accuracy while efficiently processing large-scale\nsparse graphs. For extremely large-scale geometric graphs, we present DistEGNN,\na distributed extension where virtual nodes act as global bridges between\nsubgraphs in different devices, maintaining consistency while dramatically\nreducing memory and computational overhead. We comprehensively evaluate our\nmodels across four challenging domains: N-body systems (100 nodes), protein\ndynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark\n(113,000 nodes). Results demonstrate superior efficiency and performance,\nestablishing new capabilities in large-scale equivariant graph learning. Code\nis available at https://github.com/GLAD-RUC/DistEGNN.\n","authors":["Yuelin Zhang","Jiacheng Cen","Jiaqi Han","Wenbing Huang"],"pdf_url":"https://arxiv.org/pdf/2506.19482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12374v2","updated":"2025-06-24T10:01:18Z","published":"2025-06-14T07:11:44Z","title":"AntiGrounding: Lifting Robotic Actions into VLM Representation Space for\n  Decision Making","summary":"  Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for\nrobotic manipulation within high-dimensional representation spaces. However,\ncurrent approaches often project them into compressed intermediate\nrepresentations, discarding important task-specific information such as\nfine-grained spatial or semantic details. To address this, we propose\nAntiGrounding, a new framework that reverses the instruction grounding process.\nIt lifts candidate actions directly into the VLM representation space, renders\ntrajectories from multiple views, and uses structured visual question answering\nfor instruction-based decision making. This enables zero-shot synthesis of\noptimal closed-loop robot trajectories for new tasks. We also propose an\noffline policy refinement module that leverages past experience to enhance\nlong-term performance. Experiments in both simulation and real-world\nenvironments show that our method outperforms baselines across diverse robotic\nmanipulation tasks.\n","authors":["Wenbo Li","Shiyi Wang","Yiteng Chen","Huiping Zhuang","Qingyao Wu"],"pdf_url":"https://arxiv.org/pdf/2506.12374v2.pdf","comment":"submitted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2506.19469v1","updated":"2025-06-24T09:53:10Z","published":"2025-06-24T09:53:10Z","title":"Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large\n  Language Model via Reinforcement Learning","summary":"  In recent years, significant progress has been made in the field of surgical\nscene understanding, particularly in the task of Visual Question\nLocalized-Answering in robotic surgery (Surgical-VQLA). However, existing\nSurgical-VQLA models lack deep reasoning capabilities and interpretability in\nsurgical scenes, which limits their reliability and potential for development\nin clinical applications. To address this issue, inspired by the development of\nReasoning Multimodal Large Language Models (MLLMs), we first build the\nSurgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and\nChain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for\nSurgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage\nfine-tuning mechanism to enable the basic MLLM with complex reasoning abilities\nby utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT).\nFurthermore, for an efficient and high-quality rule-based reward system in our\nRFT, we design a Multimodal Coherence reward mechanism to mitigate positional\nillusions that may arise in surgical scenarios. Experiment results demonstrate\nthat Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in\nthe Surgical-VQLA task and widely-used MLLMs, while also validating its\nreasoning capabilities and the effectiveness of our approach. The code and\ndataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.\n","authors":["Pengfei Hao","Shuaibo Li","Hongqiu Wang","Zhizhuo Kou","Junhang Zhang","Guang Yang","Lei Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.19469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19468v1","updated":"2025-06-24T09:53:00Z","published":"2025-06-24T09:53:00Z","title":"MuBench: Assessment of Multilingual Capabilities of Large Language\n  Models Across 61 Languages","summary":"  Multilingual large language models (LLMs) are advancing rapidly, with new\nmodels frequently claiming support for an increasing number of languages.\nHowever, existing evaluation datasets are limited and lack cross-lingual\nalignment, leaving assessments of multilingual capabilities fragmented in both\nlanguage and skill coverage. To address this, we introduce MuBench, a benchmark\ncovering 61 languages and evaluating a broad range of capabilities. We evaluate\nseveral state-of-the-art multilingual LLMs and find notable gaps between\nclaimed and actual language coverage, particularly a persistent performance\ndisparity between English and low-resource languages. Leveraging MuBench's\nalignment, we propose Multilingual Consistency (MLC) as a complementary metric\nto accuracy for analyzing performance bottlenecks and guiding model\nimprovement. Finally, we pretrain a suite of 1.2B-parameter models on English\nand Chinese with 500B tokens, varying language ratios and parallel data\nproportions to investigate cross-lingual transfer dynamics.\n","authors":["Wenhan Han","Yifan Zhang","Zhixun Chen","Binbin Liu","Haobin Lin","Bingni Zhang","Taifeng Wang","Mykola Pechenizkiy","Meng Fang","Yin Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.19468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19891v1","updated":"2025-06-24T09:52:04Z","published":"2025-06-24T09:52:04Z","title":"Orthogonal Soft Pruning for Efficient Class Unlearning","summary":"  Machine unlearning aims to selectively remove class-specific knowledge from\npretrained neural networks to satisfy privacy regulations such as the GDPR.\nExisting methods typically face a trade-off between unlearning speed and\npreservation of predictive accuracy, often incurring either high computational\noverhead or significant performance degradation on retained classes. In this\npaper, we propose a novel class-aware soft pruning framework leveraging\northogonal convolutional kernel regularization to achieve rapid and precise\nforgetting with millisecond-level response times. By enforcing orthogonality\nconstraints during training, our method decorrelates convolutional filters and\ndisentangles feature representations, while efficiently identifying\nclass-specific channels through activation difference analysis. Extensive\nevaluations across multiple architectures and datasets demonstrate stable\npruning with near-instant execution, complete forgetting of targeted classes,\nand minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,\nand TinyImageNet confirm that our approach substantially reduces membership\ninference attack risks and accelerates unlearning by orders of magnitude\ncompared to state-of-the-art baselines. This framework provides an efficient,\npractical solution for real-time machine unlearning in Machine Learning as a\nService (MLaaS) scenarios.\n","authors":["Qinghui Gong","Xue Yang","Xiaohu Tang"],"pdf_url":"https://arxiv.org/pdf/2506.19891v1.pdf","comment":"11 pages,3 figures"},{"id":"http://arxiv.org/abs/2404.08844v3","updated":"2025-06-24T09:49:27Z","published":"2024-04-12T23:11:36Z","title":"ContactDexNet: Multi-fingered Robotic Hand Grasping in Cluttered\n  Environments through Hand-object Contact Semantic Mapping","summary":"  The deep learning models has significantly advanced dexterous manipulation\ntechniques for multi-fingered hand grasping. However, the contact\ninformation-guided grasping in cluttered environments remains largely\nunderexplored. To address this gap, we have developed a method for generating\nmulti-fingered hand grasp samples in cluttered settings through contact\nsemantic map. We introduce a contact semantic conditional variational\nautoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map\nfrom object point cloud. We utilize grasp detection method to estimate hand\ngrasp poses from the contact semantic map. Finally, an unified grasp evaluation\nmodel PointNetGPD++ is designed to assess grasp quality and collision\nprobability, substantially improving the reliability of identifying optimal\ngrasps in cluttered scenarios. Our grasp generation method has demonstrated\nremarkable success, outperforming state-of-the-art methods by at least 4.65%\nwith 81.0% average grasping success rate in real-world single-object\nenvironment and 75.3% grasping success rate in cluttered scenes. We also\nproposed the multi-modal multi-fingered grasping dataset generation method. Our\nmulti-fingered hand grasping dataset outperforms previous datasets in scene\ndiversity, modality diversity. The dataset, code and supplementary materials\ncan be found at https://sites.google.com/view/contact-dexnet.\n","authors":["Lei Zhang","Kaixin Bai","Guowen Huang","Zhenshan Bing","Zhaopeng Chen","Alois Knoll","Jianwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.08844v3.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2506.19467v1","updated":"2025-06-24T09:49:26Z","published":"2025-06-24T09:49:26Z","title":"Can Large Language Models Capture Human Annotator Disagreements?","summary":"  Human annotation variation (i.e., annotation disagreements) is common in NLP\nand often reflects important information such as task subjectivity and sample\nambiguity. While Large Language Models (LLMs) are increasingly used for\nautomatic annotation to reduce human effort, their evaluation often focuses on\npredicting the majority-voted \"ground truth\" labels. It is still unclear,\nhowever, whether these models also capture informative human annotation\nvariation. Our work addresses this gap by extensively evaluating LLMs' ability\nto predict annotation disagreements without access to repeated human labels.\nOur results show that LLMs struggle with modeling disagreements, which can be\noverlooked by majority label-based evaluations. Notably, while RLVR-style\n(Reinforcement learning with verifiable rewards) reasoning generally boosts LLM\nperformance, it degrades performance in disagreement prediction. Our findings\nhighlight the critical need for evaluating and improving LLM annotators in\ndisagreement modeling. Code and data at\nhttps://github.com/EdisonNi-hku/Disagreement_Prediction.\n","authors":["Jingwei Ni","Yu Fan","Vilém Zouhar","Donya Rooein","Alexander Hoyle","Mrinmaya Sachan","Markus Leippold","Dirk Hovy","Elliott Ash"],"pdf_url":"https://arxiv.org/pdf/2506.19467v1.pdf","comment":"Preprint Under Review"},{"id":"http://arxiv.org/abs/2506.19466v1","updated":"2025-06-24T09:48:01Z","published":"2025-06-24T09:48:01Z","title":"KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap\n  for Large Language Models","summary":"  This paper introduces KunLunBaizeRAG, a reinforcement learning-driven\nreasoning framework designed to enhance the reasoning capabilities of large\nlanguage models (LLMs) in complex multi-hop question-answering tasks. The\nframework addresses key limitations of traditional RAG, such as retrieval\ndrift, information redundancy, and strategy rigidity. Key innovations include\nthe RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative\nEnhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR)\nmechanism, and a progressive hybrid training strategy. Experimental results\ndemonstrate significant improvements in exact match (EM) and LLM-judged score\n(LJ) across four benchmarks, highlighting the framework's robustness and\neffectiveness in complex reasoning scenarios.\n","authors":["Cheng Li","Jiexiong Liu","Yixuan Chen","Qihang Zhou","KunLun Meta"],"pdf_url":"https://arxiv.org/pdf/2506.19466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19465v1","updated":"2025-06-24T09:47:31Z","published":"2025-06-24T09:47:31Z","title":"Stylized Structural Patterns for Improved Neural Network Pre-training","summary":"  Modern deep learning models in computer vision require large datasets of real\nimages, which are difficult to curate and pose privacy and legal concerns,\nlimiting their commercial use. Recent works suggest synthetic data as an\nalternative, yet models trained with it often underperform. This paper proposes\na two-step approach to bridge this gap. First, we propose an improved neural\nfractal formulation through which we introduce a new class of synthetic data.\nSecond, we propose reverse stylization, a technique that transfers visual\nfeatures from a small, license-free set of real images onto synthetic datasets,\nenhancing their effectiveness. We analyze the domain gap between our synthetic\ndatasets and real images using Kernel Inception Distance (KID) and show that\nour method achieves a significantly lower distributional gap compared to\nexisting synthetic datasets. Furthermore, our experiments across different\ntasks demonstrate the practical impact of this reduced gap. We show that\npretraining the EDM2 diffusion model on our synthetic dataset leads to an 11%\nreduction in FID during image generation, compared to models trained on\nexisting synthetic datasets, and a 20% decrease in autoencoder reconstruction\nerror, indicating improved performance in data representation. Furthermore, a\nViT-S model trained for classification on this synthetic data achieves over a\n10% improvement in ImageNet-100 accuracy. Our work opens up exciting\npossibilities for training practical models when sufficiently large real\ntraining sets are not available.\n","authors":["Farnood Salehi","Vandit Sharma","Amirhossein Askari Farsangi","Tunç Ozan Aydın"],"pdf_url":"https://arxiv.org/pdf/2506.19465v1.pdf","comment":null}]},"2025-06-23T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.18735v1","updated":"2025-06-23T15:11:43Z","published":"2025-06-23T15:11:43Z","title":"An Audio-centric Multi-task Learning Framework for Streaming Ads\n  Targeting on Spotify","summary":"  Spotify, a large-scale multimedia platform, attracts over 675 million monthly\nactive users who collectively consume millions of hours of music, podcasts,\naudiobooks, and video content. This diverse content consumption pattern\nintroduces unique challenges for computational advertising, which must\neffectively integrate a variety of ad modalities, including audio, video, and\ndisplay, within a single user experience. Traditional ad recommendation models,\nprimarily designed for foregrounded experiences, often struggle to reconcile\nthe platform's inherent audio-centrality with the demands of optimizing ad\nperformance across multiple formats and modalities. To overcome these\nchallenges, we introduce Cross-modal Adaptive Mixture-of-Experts (CAMoE), a\nnovel framework for optimizing click-through rate (CTR) prediction in both\naudio-centric and multi-modal settings. CAMoE enhances traditional\nmixture-of-experts models by incorporating modality-aware task grouping,\nadaptive loss masking, and deep-cross networks (DCN) to capture complex feature\ninteractions within a multi-modal ad ecosystem. Through extensive ablation\nstudies, we demonstrate that this approach achieves near Pareto-optimal\nperformance across audio, video, and display ad formats, significantly\nimproving AUC-PR compared to conventional single-task and content-based\nmulti-task learning baselines. When deployed at scale on Spotify's ad serving\nplatform, CAMoE delivered substantial gains, yielding a 14.5% increase in CTR\nfor audio ads, a 1.3% increase for video ads, and a 4.8% reduction in expected\ncost-per-click (eCPC) for audio slots.\n","authors":["Shivam Verma","Vivian Chen","Darren Mei"],"pdf_url":"https://arxiv.org/pdf/2506.18735v1.pdf","comment":"Accepted at KDD 2025"},{"id":"http://arxiv.org/abs/2506.18670v1","updated":"2025-06-23T14:14:43Z","published":"2025-06-23T14:14:43Z","title":"Harnessing the Power of Reinforcement Learning for Language-Model-Based\n  Information Retriever via Query-Document Co-Augmentation","summary":"  Recent studies have proposed leveraging Large Language Models (LLMs) as\ninformation retrievers through query rewriting. However, for challenging\ncorpora, we argue that enhancing queries alone is insufficient for robust\nsemantic matching; the LLM should also have sufficient understanding of the\ncorpus by directly handling and augmenting the documents themselves. To this\nend, we present an LLM-based retriever empowered to augment both user queries\nand corpus documents, with its policy fully explored via reinforcement learning\n(RL) and minimal human inductive bias. Notably, we find that simply allowing\nthe LLM to modify documents yields little benefit unless paired with our\ncarefully designed bidirectional RL framework, which enables the LLM to\nsimultaneously learn and collaborate on both query and document augmentation\npolicies. A key technical challenge in realizing such a framework lies in\njointly updating both policies during training, where the rewards for the two\ndirections depend on each other, making their entangled reward intractable. Our\napproach addresses this by introducing a reward sampling strategy and a\nspecifically designed RL algorithm that enables effective training with these\nsampled rewards. Experimental results demonstrate that our approach\nsignificantly enhances LLM-based retrieval performance in both sparse and dense\nsettings, particularly in difficult retrieval domains, and achieves strong\ncross-benchmark generalization. Our code is released at\nhttps://github.com/liujm2001/CoAugRetriever.\n","authors":["Jingming Liu","Yumeng Li","Wei Shi","Yao-Xiang Ding","Hui Su","Kun Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.18670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11097v2","updated":"2025-06-23T13:56:31Z","published":"2025-06-06T10:49:49Z","title":"C-SEO Bench: Does Conversational SEO Work?","summary":"  Large Language Models (LLMs) are transforming search engines into\nConversational Search Engines (CSE). Consequently, Search Engine Optimization\n(SEO) is being shifted into Conversational Search Engine Optimization (C-SEO).\nWe are beginning to see dedicated C-SEO methods for modifying web documents to\nincrease their visibility in CSE responses. However, they are often tested only\nfor a limited breadth of application domains; we do not understand whether\ncertain C-SEO methods would be effective for a broad range of domains.\nMoreover, existing evaluations consider only a single-actor scenario where only\none web document adopts a C-SEO method; in reality, multiple players are likely\nto competitively adopt the cutting-edge C-SEO techniques, drawing an analogy\nfrom the dynamics we have seen in SEO. We present C-SEO Bench, the first\nbenchmark designed to evaluate C-SEO methods across multiple tasks, domains,\nand number of actors. We consider two search tasks, question answering and\nproduct recommendation, with three domains each. We also formalize a new\nevaluation protocol with varying adoption rates among involved actors. Our\nexperiments reveal that most current C-SEO methods are largely ineffective,\ncontrary to reported results in the literature. Instead, traditional SEO\nstrategies, those aiming to improve the ranking of the source in the LLM\ncontext, are significantly more effective. We also observe that as we increase\nthe number of C-SEO adopters, the overall gains decrease, depicting a congested\nand zero-sum nature of the problem. Our code and data are available at\nhttps://github.com/parameterlab/c-seo-bench and\nhttps://huggingface.co/datasets/parameterlab/c-seo-bench.\n","authors":["Haritz Puerto","Martin Gubri","Tommaso Green","Seong Joon Oh","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2506.11097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18548v1","updated":"2025-06-23T11:57:11Z","published":"2025-06-23T11:57:11Z","title":"Rethinking Click Models in Light of Carousel Interfaces: Theory-Based\n  Categorization and Design of Click Models","summary":"  Click models are a well-established for modeling user interactions with web\ninterfaces. Previous work has mainly focused on traditional single-list web\nsearch settings; this includes existing surveys that introduced categorizations\nbased on the first generation of probabilistic graphical model (PGM) click\nmodels that have become standard. However, these categorizations have become\noutdated, as their conceptualizations are unable to meaningfully compare PGM\nwith neural network (NN) click models nor generalize to newer interfaces, such\nas carousel interfaces. We argue that this outdated view fails to adequately\nexplain the fundamentals of click model designs, thus hindering the development\nof novel click models.\n  This work reconsiders what should be the fundamental concepts in click model\ndesign, grounding them - unlike previous approaches - in their mathematical\nproperties. We propose three fundamental key-design choices that explain what\nstatistical patterns a click model can capture, and thus indirectly, what user\nbehaviors they can capture. Based on these choices, we create a novel click\nmodel taxonomy that allows a meaningful comparison of all existing click\nmodels; this is the first taxonomy of single-list, grid and carousel click\nmodels that includes PGMs and NNs. Finally, we show how our conceptualization\nprovides a foundation for future click model design by an example derivation of\na novel design for carousel interfaces.\n","authors":["Jingwei Kang","Maarten de Rijke","Santiago de Leon-Martinez","Harrie Oosterhuis"],"pdf_url":"https://arxiv.org/pdf/2506.18548v1.pdf","comment":"Accepted by ICTIR 2025"},{"id":"http://arxiv.org/abs/2506.18535v1","updated":"2025-06-23T11:46:05Z","published":"2025-06-23T11:46:05Z","title":"When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking","summary":"  This paper investigates the counterintuitive phenomenon where fine-tuning\npre-trained transformer models degrades performance on the MS MARCO passage\nranking task. Through comprehensive experiments involving five model\nvariants-including full parameter fine-tuning and parameter efficient LoRA\nadaptations-we demonstrate that all fine-tuning approaches underperform the\nbase sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our\nanalysis reveals that fine-tuning disrupts the optimal embedding space\nstructure learned during the base model's extensive pre-training on 1 billion\nsentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations\nshow progressive embedding space flattening, while training dynamics analysis\nand computational efficiency metrics further support our findings. These\nresults challenge conventional wisdom about transfer learning effectiveness on\nsaturated benchmarks and suggest architectural innovations may be necessary for\nmeaningful improvements.\n","authors":["Manu Pande","Shahil Kumar","Anay Yatin Damle"],"pdf_url":"https://arxiv.org/pdf/2506.18535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.02670v4","updated":"2025-06-23T11:43:03Z","published":"2025-04-03T15:11:55Z","title":"Affordable AI Assistants with Knowledge Graph of Thoughts","summary":"  Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively while also minimizing bias and noise.\nFor example, KGoT achieves a 29% improvement in task success rates on the GAIA\nbenchmark compared to Hugging Face Agents with GPT-4o mini. Moreover,\nharnessing a smaller model dramatically reduces operational costs by over 36x\ncompared to GPT-4o. Improvements for other models (e.g., Qwen2.5-32B and\nDeepseek-R1-70B) and benchmarks (e.g., SimpleQA) are similar. KGoT offers a\nscalable, affordable, versatile, and high-performing solution for AI\nassistants.\n","authors":["Maciej Besta","Lorenzo Paleari","Jia Hao Andrea Jiang","Robert Gerstenberger","You Wu","Jón Gunnar Hannesson","Patrick Iff","Ales Kubicek","Piotr Nyczyk","Diana Khimey","Nils Blach","Haiqiang Zhang","Tao Zhang","Peiran Ma","Grzegorz Kwaśniewski","Marcin Copik","Hubert Niewiadomski","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2504.02670v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18382v1","updated":"2025-06-23T08:15:16Z","published":"2025-06-23T08:15:16Z","title":"PERSCEN: Learning Personalized Interaction Pattern and Scenario\n  Preference for Multi-Scenario Matching","summary":"  With the expansion of business scales and scopes on online platforms,\nmulti-scenario matching has become a mainstream solution to reduce maintenance\ncosts and alleviate data sparsity. The key to effective multi-scenario\nrecommendation lies in capturing both user preferences shared across all\nscenarios and scenario-aware preferences specific to each scenario. However,\nexisting methods often overlook user-specific modeling, limiting the generation\nof personalized user representations. To address this, we propose PERSCEN, an\ninnovative approach that incorporates user-specific modeling into\nmulti-scenario matching. PERSCEN constructs a user-specific feature graph based\non user characteristics and employs a lightweight graph neural network to\ncapture higher-order interaction patterns, enabling personalized extraction of\npreferences shared across scenarios. Additionally, we leverage vector\nquantization techniques to distil scenario-aware preferences from users'\nbehavior sequence within individual scenarios, facilitating user-specific and\nscenario-aware preference modeling. To enhance efficient and flexible\ninformation transfer, we introduce a progressive scenario-aware gated linear\nunit that allows fine-grained, low-latency fusion. Extensive experiments\ndemonstrate that PERSCEN outperforms existing methods. Further efficiency\nanalysis confirms that PERSCEN effectively balances performance with\ncomputational cost, ensuring its practicality for real-world industrial\nsystems.\n","authors":["Haotong Du","Yaqing Wang","Fei Xiong","Lei Shao","Ming Liu","Hao Gu","Quanming Yao","Zhen Wang"],"pdf_url":"https://arxiv.org/pdf/2506.18382v1.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2506.18327v1","updated":"2025-06-23T06:19:02Z","published":"2025-06-23T06:19:02Z","title":"Bias vs Bias -- Dawn of Justice: A Fair Fight in Recommendation Systems","summary":"  Recommendation systems play a crucial role in our daily lives by impacting\nuser experience across various domains, including e-commerce, job\nadvertisements, entertainment, etc. Given the vital role of such systems in our\nlives, practitioners must ensure they do not produce unfair and imbalanced\nrecommendations. Previous work addressing bias in recommendations overlooked\nbias in certain item categories, potentially leaving some biases unaddressed.\nAdditionally, most previous work on fair re-ranking focused on binary-sensitive\nattributes. In this paper, we address these issues by proposing a\nfairness-aware re-ranking approach that helps mitigate bias in different\ncategories of items. This re-ranking approach leverages existing biases to\ncorrect disparities in recommendations across various demographic groups. We\nshow how our approach can mitigate bias on multiple sensitive attributes,\nincluding gender, age, and occupation. We experimented on three real-world\ndatasets to evaluate the effectiveness of our re-ranking scheme in mitigating\nbias in recommendations. Our results show how this approach helps mitigate\nsocial bias with little to no degradation in performance.\n","authors":["Tahsin Alamgir Kheya","Mohamed Reda Bouadjenek","Sunil Aryal"],"pdf_url":"https://arxiv.org/pdf/2506.18327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18316v1","updated":"2025-06-23T06:01:21Z","published":"2025-06-23T06:01:21Z","title":"Team LA at SCIDOCA shared task 2025: Citation Discovery via\n  relation-based zero-shot retrieval","summary":"  The Citation Discovery Shared Task focuses on predicting the correct citation\nfrom a given candidate pool for a given paragraph. The main challenges stem\nfrom the length of the abstract paragraphs and the high similarity among\ncandidate abstracts, making it difficult to determine the exact paper to cite.\nTo address this, we develop a system that first retrieves the top-k most\nsimilar abstracts based on extracted relational features from the given\nparagraph. From this subset, we leverage a Large Language Model (LLM) to\naccurately identify the most relevant citation. We evaluate our framework on\nthe training dataset provided by the SCIDOCA 2025 organizers, demonstrating its\neffectiveness in citation prediction.\n","authors":["Trieu An","Long Nguyen","Minh Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2506.18316v1.pdf","comment":"In the Proceedings of SCIDOCA 2025"},{"id":"http://arxiv.org/abs/2506.18311v1","updated":"2025-06-23T05:55:53Z","published":"2025-06-23T05:55:53Z","title":"Enhancing Document Retrieval in COVID-19 Research: Leveraging Large\n  Language Models for Hidden Relation Extraction","summary":"  In recent years, with the appearance of the COVID-19 pandemic, numerous\npublications relevant to this disease have been issued. Because of the massive\nvolume of publications, an efficient retrieval system is necessary to provide\nresearchers with useful information if an unexpected pandemic happens so\nsuddenly, like COVID-19. In this work, we present a method to help the\nretrieval system, the Covrelex-SE system, to provide more high-quality search\nresults. We exploited the power of the large language models (LLMs) to extract\nthe hidden relationships inside the unlabeled publication that cannot be found\nby the current parsing tools that the system is using. Since then, help the\nsystem to have more useful information during retrieval progress.\n","authors":["Hoang-An Trieu","Dinh-Truong Do","Chau Nguyen","Vu Tran","Minh Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2506.18311v1.pdf","comment":"In the Proceedings of SCIDOCA 2024"},{"id":"http://arxiv.org/abs/2506.18309v1","updated":"2025-06-23T05:51:52Z","published":"2025-06-23T05:51:52Z","title":"LettinGo: Explore User Profile Generation for Recommendation System","summary":"  User profiling is pivotal for recommendation systems, as it transforms raw\nuser interaction data into concise and structured representations that drive\npersonalized recommendations. While traditional embedding-based profiles lack\ninterpretability and adaptability, recent advances with large language models\n(LLMs) enable text-based profiles that are semantically richer and more\ntransparent. However, existing methods often adhere to fixed formats that limit\ntheir ability to capture the full diversity of user behaviors. In this paper,\nwe introduce LettinGo, a novel framework for generating diverse and adaptive\nuser profiles. By leveraging the expressive power of LLMs and incorporating\ndirect feedback from downstream recommendation tasks, our approach avoids the\nrigid constraints imposed by supervised fine-tuning (SFT). Instead, we employ\nDirect Preference Optimization (DPO) to align the profile generator with\ntask-specific performance, ensuring that the profiles remain adaptive and\neffective. LettinGo operates in three stages: (1) exploring diverse user\nprofiles via multiple LLMs, (2) evaluating profile quality based on their\nimpact in recommendation systems, and (3) aligning the profile generation\nthrough pairwise preference data derived from task performance. Experimental\nresults demonstrate that our framework significantly enhances recommendation\naccuracy, flexibility, and contextual awareness. This work enhances profile\ngeneration as a key innovation for next-generation recommendation systems.\n","authors":["Lu Wang","Di Zhang","Fangkai Yang","Pu Zhao","Jianfeng Liu","Yuefeng Zhan","Hao Sun","Qingwei Lin","Weiwei Deng","Dongmei Zhang","Feng Sun","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.18309v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.18297v1","updated":"2025-06-23T05:30:09Z","published":"2025-06-23T05:30:09Z","title":"Comparative Analysis of Lion and AdamW Optimizers for Cross-Encoder\n  Reranking with MiniLM, GTE, and ModernBERT","summary":"  Modern information retrieval systems often employ a two-stage pipeline: an\nefficient initial retrieval stage followed by a computationally intensive\nreranking stage. Cross-encoders have shown strong effectiveness for reranking\ndue to their deep analysis of query-document pairs. This paper studies the\nimpact of the Lion optimizer, a recent alternative to AdamW, during fine-tuning\nof cross-encoder rerankers. We fine-tune three transformer models-MiniLM, GTE,\nand ModernBERT-on the MS MARCO passage ranking dataset using both optimizers.\nGTE and ModernBERT support extended context lengths (up to 8192 tokens). We\nevaluate effectiveness using TREC 2019 Deep Learning Track and MS MARCO dev set\n(MRR@10). Experiments, run on the Modal cloud platform, reveal that ModernBERT\nwith Lion achieves the best NDCG@10 (0.7225) and MAP (0.5121) on TREC DL 2019,\nwhile MiniLM with Lion ties ModernBERT for MRR@10 (0.5988) on MS MARCO dev.\nLion also provides superior GPU efficiency, improving utilization by 2.67% to\n10.33% across models. We analyze performance trends using standard IR metrics\nand discuss the optimizer's impact on training dynamics across architectures.\n","authors":["Shahil Kumar","Manu Pande","Anay Yatin Damle"],"pdf_url":"https://arxiv.org/pdf/2506.18297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16701v2","updated":"2025-06-23T05:28:42Z","published":"2024-12-21T16:59:00Z","title":"AlzheimerRAG: Multimodal Retrieval Augmented Generation for Clinical Use\n  Cases using PubMed articles","summary":"  Recent advancements in generative AI have fostered the development of highly\nadept Large Language Models (LLMs) that integrate diverse data types to empower\ndecision-making. Among these, multimodal retrieval-augmented generation (RAG)\napplications are promising because they combine the strengths of information\nretrieval and generative models, enhancing their utility across various\ndomains, including clinical use cases. This paper introduces AlzheimerRAG, a\nMultimodal RAG application for clinical use cases, primarily focusing on\nAlzheimer's Disease case studies from PubMed articles. This application\nincorporates cross-modal attention fusion techniques to integrate textual and\nvisual data processing by efficiently indexing and accessing vast amounts of\nbiomedical literature. Our experimental results, compared to benchmarks such as\nBioASQ and PubMedQA, have yielded improved performance in the retrieval and\nsynthesis of domain-specific information. We also present a case study using\nour multimodal RAG in various Alzheimer's clinical scenarios. We infer that\nAlzheimerRAG can generate responses with accuracy non-inferior to humans and\nwith low rates of hallucination.\n","authors":["Aritra Kumar Lahiri","Qinmin Vivian Hu"],"pdf_url":"https://arxiv.org/pdf/2412.16701v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.14130v2","updated":"2025-06-23T03:47:42Z","published":"2025-04-19T01:14:55Z","title":"Personalized News Recommendation with Multi-granularity Candidate-aware\n  User Modeling","summary":"  Matching candidate news with user interests is crucial for personalized news\nrecommendations. Most existing methods can represent a user's reading interests\nthrough a single profile based on clicked news, which may not fully capture the\ndiversity of user interests. Although some approaches incorporate candidate\nnews or topic information, they remain insufficient because they neglect the\nmulti-granularity relatedness between candidate news and user interests. To\naddress this, this study proposed a multi-granularity candidate-aware user\nmodeling framework that integrated user interest features across various levels\nof granularity. It consisted of two main components: candidate news encoding\nand user modeling. A news textual information extractor and a\nknowledge-enhanced entity information extractor can capture candidate news\nfeatures, and word-level, entity-level, and news-level candidate-aware\nmechanisms can provide a comprehensive representation of user interests.\nExtensive experiments on a real-world dataset demonstrated that the proposed\nmodel could significantly outperform baseline models.\n","authors":["Qiang Li","Xinze Lin","Shenghao Lv","Faliang Huang","Xiangju Li"],"pdf_url":"https://arxiv.org/pdf/2504.14130v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.18842v1","updated":"2025-06-23T17:00:34Z","published":"2025-06-23T17:00:34Z","title":"LIGHTHOUSE: Fast and precise distance to shoreline calculations from\n  anywhere on earth","summary":"  We introduce a new dataset and algorithm for fast and efficient coastal\ndistance calculations from Anywhere on Earth (AoE). Existing global coastal\ndatasets are only available at coarse resolution (e.g. 1-4 km) which limits\ntheir utility. Publicly available satellite imagery combined with computer\nvision enable much higher precision. We provide a global coastline dataset at\n10 meter resolution, a 100+ fold improvement in precision over existing data.\nTo handle the computational challenge of querying at such an increased scale,\nwe introduce a new library: Layered Iterative Geospatial Hierarchical\nTerrain-Oriented Unified Search Engine (Lighthouse). Lighthouse is both\nexceptionally fast and resource-efficient, requiring only 1 CPU and 2 GB of RAM\nto achieve millisecond online inference, making it well suited for real-time\napplications in resource-constrained environments.\n","authors":["Patrick Beukema","Henry Herzog","Yawen Zhang","Hunter Pitelka","Favyen Bastani"],"pdf_url":"https://arxiv.org/pdf/2506.18842v1.pdf","comment":"8 pages, 7 figures, 1 table, ICML 2025 ML4RS"},{"id":"http://arxiv.org/abs/2506.13144v2","updated":"2025-06-23T11:34:25Z","published":"2025-06-16T06:57:33Z","title":"EnhanceGraph: A Continuously Enhanced Graph-based Index for\n  High-dimensional Approximate Nearest Neighbor Search","summary":"  Recently, Approximate Nearest Neighbor Search in high-dimensional vector\nspaces has garnered considerable attention due to the rapid advancement of deep\nlearning techniques. We observed that a substantial amount of search and\nconstruction logs are generated throughout the lifespan of a graph-based index.\nHowever, these two types of valuable logs are not fully exploited due to the\nstatic nature of existing indexes. We present the EnhanceGraph framework, which\nintegrates two types of logs into a novel structure called a conjugate graph.\nThe conjugate graph is then used to improve search quality. Through theoretical\nanalyses and observations of the limitations of graph-based indexes, we propose\nseveral optimization methods. For the search logs, the conjugate graph stores\nthe edges from local optima to global optima to enhance routing to the nearest\nneighbor. For the construction logs, the conjugate graph stores the pruned\nedges from the proximity graph to enhance retrieving of k nearest neighbors.\nOur experimental results on several public and real-world industrial datasets\nshow that EnhanceGraph significantly improves search accuracy with the greatest\nimprovement on recall from 41.74% to 93.42%, but does not sacrifices search\nefficiency. In addition, our EnhanceGraph algorithm has been integrated into\nAnt Group's open-source vector library, VSAG.\n","authors":["Xiaoyao Zhong","Jiabao Jin","Peng Cheng","Mingyu Yang","Haoyang Li","Zhitao Shen","Heng Tao Shen","Jingkuan Song"],"pdf_url":"https://arxiv.org/pdf/2506.13144v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18499v1","updated":"2025-06-23T10:51:45Z","published":"2025-06-23T10:51:45Z","title":"PuckTrick: A Library for Making Synthetic Data More Realistic","summary":"  The increasing reliance on machine learning (ML) models for decision-making\nrequires high-quality training data. However, access to real-world datasets is\noften restricted due to privacy concerns, proprietary restrictions, and\nincomplete data availability. As a result, synthetic data generation (SDG) has\nemerged as a viable alternative, enabling the creation of artificial datasets\nthat preserve the statistical properties of real data while ensuring privacy\ncompliance. Despite its advantages, synthetic data is often overly clean and\nlacks real-world imperfections, such as missing values, noise, outliers, and\nmisclassified labels, which can significantly impact model generalization and\nrobustness. To address this limitation, we introduce Pucktrick, a Python\nlibrary designed to systematically contaminate synthetic datasets by\nintroducing controlled errors. The library supports multiple error types,\nincluding missing data, noisy values, outliers, label misclassification,\nduplication, and class imbalance, offering a structured approach to evaluating\nML model resilience under real-world data imperfections. Pucktrick provides two\ncontamination modes: one for injecting errors into clean datasets and another\nfor further corrupting already contaminated datasets. Through extensive\nexperiments on real-world financial datasets, we evaluate the impact of\nsystematic data contamination on model performance. Our findings demonstrate\nthat ML models trained on contaminated synthetic data outperform those trained\non purely synthetic, error-free data, particularly for tree-based and linear\nmodels such as SVMs and Extra Trees.\n","authors":["Alessandra Agostini","Andrea Maurino","Blerina Spahiu"],"pdf_url":"https://arxiv.org/pdf/2506.18499v1.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.18951v1","updated":"2025-06-23T09:41:37Z","published":"2025-06-23T09:41:37Z","title":"SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in\n  Real-World Applications","summary":"  Resolution of complex SQL issues persists as a significant bottleneck in\nreal-world database applications. Current Large Language Models (LLMs), while\nadept at text-to-SQL translation, have not been rigorously evaluated on the\nmore challenging task of debugging SQL issues. To address this gap, we\nintroduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530\nPostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks\n(BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within\nnew environments to facilitate rigorous evaluation. Baseline evaluations\nunderscore the task's complexity, with the leading reasoning model O3-Mini\nachieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on\nBIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks\nis crucial for empowering local development while safeguarding data privacy.\nTherefore, we present Six-Gym (Sql-fIX-Gym), a training environment for\nelevating open-source model capabilities for SQL issue debugging. This\nenvironment leverages SQL-Rewind strategy, which automatically generates\nexecutable issue-solution datasets by reverse-engineering issues from verified\nSQLs. However, popular trajectory-based fine-tuning methods do not explore\nsubstantial supervisory signals. We further propose f-Plan Boosting, which\nextracts high-level debugging plans from SQL solutions, enabling teacher LLMs\nto produce 73.7% more successful trajectories for training. We integrate these\ncomponents into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B,\nBird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on\nBIRD-CRITIC-Multi, surpassing leading proprietary models such as\nClaude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing\nsophisticated SQL-debugging capabilities. The leaderboard and source code are\navailable: https://bird-critic.github.io/\n","authors":["Jinyang Li","Xiaolong Li","Ge Qu","Per Jacobsson","Bowen Qin","Binyuan Hui","Shuzheng Si","Nan Huo","Xiaohan Xu","Yue Zhang","Ziwei Tang","Yuanshuai Li","Florensia Widjaja","Xintong Zhu","Feige Zhou","Yongfeng Huang","Yannis Papakonstantinou","Fatma Ozcan","Chenhao Ma","Reynold Cheng"],"pdf_url":"https://arxiv.org/pdf/2506.18951v1.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.22358v2","updated":"2025-06-23T05:31:32Z","published":"2025-03-28T11:52:26Z","title":"Shapley Revisited: Tractable Responsibility Measures for Query Answers","summary":"  The Shapley value, originating from cooperative game theory, has been\nemployed to define responsibility measures that quantify the contributions of\ndatabase facts to obtaining a given query answer. For non-numeric queries, this\nis done by considering a cooperative game whose players are the facts and whose\nwealth function assigns 1 or 0 to each subset of the database, depending on\nwhether the query answer holds in the given subset. While conceptually simple,\nthis approach suffers from a notable drawback: the problem of computing such\nShapley values is #P-hard in data complexity, even for simple conjunctive\nqueries. This motivates us to revisit the question of what constitutes a\nreasonable responsibility measure and to introduce a new family of\nresponsibility measures -- weighted sums of minimal supports (WSMS) -- which\nsatisfy intuitive properties. Interestingly, while the definition of WSMSs is\nsimple and bears no obvious resemblance to the Shapley value formula, we prove\nthat every WSMS measure can be equivalently seen as the Shapley value of a\nsuitably defined cooperative game. Moreover, WSMS measures enjoy tractable data\ncomplexity for a large class of queries, including all unions of conjunctive\nqueries. We further explore the combined complexity of WSMS computation and\nestablish (in)tractability results for various subclasses of conjunctive\nqueries.\n","authors":["Meghyn Bienvenu","Diego Figueira","Pierre Lafourcade"],"pdf_url":"https://arxiv.org/pdf/2503.22358v2.pdf","comment":"Long version of PODS'25 paper, with corrected error on Shapley\n  symmetry axiom statement"},{"id":"http://arxiv.org/abs/2402.01763v4","updated":"2025-06-23T04:05:15Z","published":"2024-01-30T23:35:28Z","title":"When Large Language Models Meet Vector Databases: A Survey","summary":"  This survey explores the synergistic potential of Large Language Models\n(LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving\nresearch area. With the proliferation of LLMs comes a host of challenges,\nincluding hallucinations, outdated knowledge, prohibitive commercial\napplication costs, and memory issues. VecDBs emerge as a compelling solution to\nthese issues by offering an efficient means to store, retrieve, and manage the\nhigh-dimensional vector representations intrinsic to LLM operations. Through\nthis nuanced review, we delineate the foundational principles of LLMs and\nVecDBs and critically analyze their integration's impact on enhancing LLM\nfunctionalities. This discourse extends into a discussion on the speculative\nfuture developments in this domain, aiming to catalyze further research into\noptimizing the confluence of LLMs and VecDBs for advanced data handling and\nknowledge extraction capabilities.\n","authors":["Zhi Jing","Yongye Su","Yikun Han","Bo Yuan","Haiyun Xu","Chunjiang Liu","Kehai Chen","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.01763v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18257v1","updated":"2025-06-23T03:05:31Z","published":"2025-06-23T03:05:31Z","title":"TableVault: Managing Dynamic Data Collections for LLM-Augmented\n  Workflows","summary":"  Large Language Models (LLMs) have emerged as powerful tools for automating\nand executing complex data tasks. However, their integration into more complex\ndata workflows introduces significant management challenges. In response, we\npresent TableVault - a data management system designed to handle dynamic data\ncollections in LLM-augmented environments. TableVault meets the demands of\nthese workflows by supporting concurrent execution, ensuring reproducibility,\nmaintaining robust data versioning, and enabling composable workflow design. By\nmerging established database methodologies with emerging LLM-driven\nrequirements, TableVault offers a transparent platform that efficiently manages\nboth structured data and associated data artifacts.\n","authors":["Jinjin Zhao","Sanjay Krishnan"],"pdf_url":"https://arxiv.org/pdf/2506.18257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18255v1","updated":"2025-06-23T02:56:39Z","published":"2025-06-23T02:56:39Z","title":"Fast Capture of Cell-Level Provenance in Numpy","summary":"  Effective provenance tracking enhances reproducibility, governance, and data\nquality in array workflows. However, significant challenges arise in capturing\nthis provenance, including: (1) rapidly evolving APIs, (2) diverse operation\ntypes, and (3) large-scale datasets. To address these challenges, this paper\npresents a prototype annotation system designed for arrays, which captures\ncell-level provenance specifically within the numpy library. With this\nprototype, we explore straightforward memory optimizations that substantially\nreduce annotation latency. We envision this provenance capture approach for\narrays as part of a broader governance system for tracking for structured data\nworkflows and diverse data science applications.\n","authors":["Jinjin Zhao","Sanjay Krishnan"],"pdf_url":"https://arxiv.org/pdf/2506.18255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18252v1","updated":"2025-06-23T02:45:43Z","published":"2025-06-23T02:45:43Z","title":"Learning Lineage Constraints for Data Science Operations","summary":"  Data science workflows often integrate functionalities from a diverse set of\nlibraries and frameworks. Tasks such as debugging require data lineage that\ncrosses library boundaries. The problem is that the way that \"lineage\" is\nrepresented is often intimately tied to particular data models and data\nmanipulation paradigms. Inspired by the use of intermediate representations\n(IRs) in cross-library performance optimizations, this vision paper proposes a\nsimilar architecture for lineage - how do we specify logical lineage across\nlibraries in a common parameterized way? In practice, cross-library workflows\nwill contain both known operations and unknown operations, so a key design of\nXProv to link both materialized lineage graphs of data transformations and the\naforementioned abstracted logical patterns. We further discuss early ideas on\nhow to infer logical patterns when only the materialized graphs are available.\n","authors":["Jinjin Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.18252v1.pdf","comment":null}]},"2025-06-22T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2407.17631v3","updated":"2025-06-22T23:41:34Z","published":"2024-07-24T20:44:36Z","title":"BLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic\n  Chunking and Hard Example Learning","summary":"  Software bugs require developers to exert significant effort to identify and\nresolve them, often consuming about one-third of their time. Bug localization,\nthe process of pinpointing the exact source code files that need modification,\nis crucial in reducing this effort. Existing bug localization tools, typically\nreliant on deep learning techniques, face limitations in cross-project\napplicability and effectiveness in multi-language environments. Recent\nadvancements with Large Language Models (LLMs) offer detailed representations\nfor bug localization. However, they encounter challenges with limited context\nwindows and mapping accuracy. To address these issues, we propose BLAZE, an\napproach that employs dynamic chunking and hard example learning. First, BLAZE\ndynamically segments source code to minimize continuity loss. Then, BLAZE\nfine-tunes a GPT-based model using challenging bug cases, in order to enhance\ncross-project and cross-language bug localization. To support the capability of\nBLAZE, we create the BEETLEBOX dataset, which comprises 26,321 bugs from 29\nlarge and thriving open-source projects across five different programming\nlanguages (Java, C++, Python, Go, and JavaScript). Our evaluations of BLAZE on\nthree benchmark datasets BEETLEBOX, SWE-Bench, and Ye et al. demonstrate\nsubstantial improvements compared to six state-of-the-art baselines.\nSpecifically, BLAZE achieves up to an increase of 120% in Top 1 accuracy, 144%\nin Mean Average Precision (MAP), and 100% in Mean Reciprocal Rank (MRR). An\nextensive ablation study confirms the contributions of our pipeline components\nto the overall performance enhancement.\n","authors":["Partha Chakraborty","Mahmoud Alfadel","Meiyappan Nagappan"],"pdf_url":"https://arxiv.org/pdf/2407.17631v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15576v2","updated":"2025-06-22T14:01:07Z","published":"2025-06-18T15:53:47Z","title":"DiscRec: Disentangled Semantic-Collaborative Modeling for Generative\n  Recommendation","summary":"  Generative recommendation is emerging as a powerful paradigm that directly\ngenerates item predictions, moving beyond traditional matching-based\napproaches. However, current methods face two key challenges: token-item\nmisalignment, where uniform token-level modeling ignores item-level granularity\nthat is critical for collaborative signal learning, and semantic-collaborative\nsignal entanglement, where collaborative and semantic signals exhibit distinct\ndistributions yet are fused in a unified embedding space, leading to\nconflicting optimization objectives that limit the recommendation performance.\nTo address these issues, we propose DiscRec, a novel framework that enables\nDisentangled Semantic-Collaborative signal modeling with flexible fusion for\ngenerative Recommendation. First, DiscRec introduces item-level position\nembeddings, assigned based on indices within each semantic ID, enabling\nexplicit modeling of item structure in input token sequences. Second, DiscRec\nemploys a dual-branch module to disentangle the two signals at the embedding\nlayer: a semantic branch encodes semantic signals using original token\nembeddings, while a collaborative branch applies localized attention restricted\nto tokens within the same item to effectively capture collaborative signals. A\ngating mechanism subsequently fuses both branches while preserving the model's\nability to model sequential dependencies. Extensive experiments on four\nreal-world datasets demonstrate that DiscRec effectively decouples these\nsignals and consistently outperforms state-of-the-art baselines. Our codes are\navailable on https://github.com/Ten-Mao/DiscRec.\n","authors":["Chang Liu","Yimeng Bai","Xiaoyan Zhao","Yang Zhang","Fuli Feng","Wenge Rong"],"pdf_url":"https://arxiv.org/pdf/2506.15576v2.pdf","comment":"Fixed the indentation issue in the abstract that caused rendering\n  errors on arXiv"},{"id":"http://arxiv.org/abs/2403.06567v4","updated":"2025-06-22T12:33:24Z","published":"2024-03-11T10:06:45Z","title":"Leveraging Foundation Models for Content-Based Image Retrieval in\n  Radiology","summary":"  Content-based image retrieval (CBIR) has the potential to significantly\nimprove diagnostic aid and medical research in radiology. However, current CBIR\nsystems face limitations due to their specialization to certain pathologies,\nlimiting their utility. On the other hand, several vision foundation models\nhave been shown to produce general-purpose visual features. Therefore, in this\nwork, we propose using vision foundation models as powerful and versatile\noff-the-shelf feature extractors for content-based image retrieval. Our\ncontributions include: (1) benchmarking a diverse set of vision foundation\nmodels on an extensive dataset comprising 1.6 million 2D radiological images\nacross four modalities and 161 pathologies; (2) identifying weakly-supervised\nmodels, particularly BiomedCLIP, as highly effective, achieving a achieving a\nP@1 of up to 0.594 (P@3: 0.590, P@5: 0.588, P@10: 0.583), comparable to\nspecialized CBIR systems but without additional training; (3) conducting an\nin-depth analysis of the impact of index size on retrieval performance; (4)\nevaluating the quality of embedding spaces generated by different models; and\n(5) investigating specific challenges associated with retrieving anatomical\nversus pathological structures. Despite these challenges, our research\nunderscores the vast potential of foundation models for CBIR in radiology,\nproposing a shift towards versatile, general-purpose medical image retrieval\nsystems that do not require specific tuning. Our code, dataset splits and\nembeddings are publicly available under\nhttps://github.com/MIC-DKFZ/foundation-models-for-cbmir.\n","authors":["Stefan Denner","David Zimmerer","Dimitrios Bounias","Markus Bujotzek","Shuhan Xiao","Raphael Stock","Lisa Kausch","Philipp Schader","Tobias Penzkofer","Paul F. Jäger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2403.06567v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18431v2","updated":"2025-06-22T12:13:24Z","published":"2024-12-24T13:45:22Z","title":"GeAR: Graph-enhanced Agent for Retrieval-augmented Generation","summary":"  Retrieval-augmented Generation (RAG) relies on effective retrieval\ncapabilities, yet traditional sparse and dense retrievers inherently struggle\nwith multi-hop retrieval scenarios. In this paper, we introduce GeAR, a system\nthat advances RAG performance through two key innovations: (i) an efficient\ngraph expansion mechanism that augments any conventional base retriever, such\nas BM25, and (ii) an agent framework that incorporates the resulting\ngraph-based retrieval into a multi-step retrieval framework. Our evaluation\ndemonstrates GeAR's superior retrieval capabilities across three multi-hop\nquestion answering datasets. Notably, our system achieves state-of-the-art\nresults with improvements exceeding 10% on the challenging MuSiQue dataset,\nwhile consuming fewer tokens and requiring fewer iterations than existing\nmulti-step retrieval systems. The project page is available at\nhttps://gear-rag.github.io.\n","authors":["Zhili Shen","Chenxin Diao","Pavlos Vougiouklis","Pascual Merita","Shriram Piramanayagam","Enting Chen","Damien Graux","Andre Melo","Ruofei Lai","Zeren Jiang","Zhongyang Li","YE QI","Yang Ren","Dandan Tu","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2412.18431v2.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2506.17966v1","updated":"2025-06-22T09:53:21Z","published":"2025-06-22T09:53:21Z","title":"LLM-Enhanced Multimodal Fusion for Cross-Domain Sequential\n  Recommendation","summary":"  Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by\nleveraging historical interactions across multiple domains, focusing on\nmodeling cross-domain preferences and capturing both intra- and inter-sequence\nitem relationships. We propose LLM-Enhanced Multimodal Fusion for Cross-Domain\nSequential Recommendation (LLM-EMF), a novel and advanced approach that\nenhances textual information with Large Language Models (LLM) knowledge and\nsignificantly improves recommendation performance through the fusion of visual\nand textual data. Using the frozen CLIP model, we generate image and text\nembeddings, thereby enriching item representations with multimodal data. A\nmultiple attention mechanism jointly learns both single-domain and cross-domain\npreferences, effectively capturing and understanding complex user interests\nacross diverse domains. Evaluations conducted on four e-commerce datasets\ndemonstrate that LLM-EMF consistently outperforms existing methods in modeling\ncross-domain user preferences, thereby highlighting the effectiveness of\nmultimodal data integration and its advantages in enhancing sequential\nrecommendation systems. Our source code will be released.\n","authors":["Wangyu Wu","Zhenhong Chen","Xianglin Qiu","Siqi Song","Xiaowei Huang","Fei Ma","Jimin Xiao"],"pdf_url":"https://arxiv.org/pdf/2506.17966v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2504.15085"},{"id":"http://arxiv.org/abs/2506.17934v1","updated":"2025-06-22T08:04:24Z","published":"2025-06-22T08:04:24Z","title":"A GenAI System for Improved FAIR Independent Biological Database\n  Integration","summary":"  Life sciences research increasingly requires identifying, accessing, and\neffectively processing data from an ever-evolving array of information sources\non the Linked Open Data (LOD) network. This dynamic landscape places a\nsignificant burden on researchers, as the quality of query responses depends\nheavily on the selection and semantic integration of data sources --processes\nthat are often labor-intensive, error-prone, and costly. While the adoption of\nFAIR (Findable, Accessible, Interoperable, and Reusable) data principles has\naimed to address these challenges, barriers to efficient and accurate\nscientific data processing persist.\n  In this paper, we introduce FAIRBridge, an experimental natural\nlanguage-based query processing system designed to empower scientists to\ndiscover, access, and query biological databases, even when they are not\nFAIR-compliant. FAIRBridge harnesses the capabilities of AI to interpret query\nintents, map them to relevant databases described in scientific literature, and\ngenerate executable queries via intelligent resource access plans. The system\nalso includes robust tools for mitigating low-quality query processing,\nensuring high fidelity and responsiveness in the information delivered.\n  FAIRBridge's autonomous query processing framework enables users to explore\nalternative data sources, make informed choices at every step, and leverage\ncommunity-driven crowd curation when needed. By providing a user-friendly,\nautomated hypothesis-testing platform in natural English, FAIRBridge\nsignificantly enhances the integration and processing of scientific data,\noffering researchers a powerful new tool for advancing their inquiries.\n","authors":["Syed N. Sakib","Kallol Naha","Sajratul Y. Rubaiat","Hasan M. Jamil"],"pdf_url":"https://arxiv.org/pdf/2506.17934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12260v2","updated":"2025-06-22T07:02:31Z","published":"2025-05-18T06:51:21Z","title":"LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x\n  Faster Query Inference","summary":"  Large Language Models (LLMs)-based hybrid retrieval uses LLMs to encode\nqueries and documents into low-dimensional dense or high-dimensional sparse\nvectors. It retrieves documents relevant to search queries based on vector\nsimilarities. Documents are pre-encoded offline, while queries arrive in\nreal-time, necessitating an efficient online query encoder. Although LLMs\nsignificantly enhance retrieval capabilities, serving deeply parameterized LLMs\nslows down query inference throughput and increases demands for online\ndeployment resources. In this paper, we propose LightRetriever, a novel\nLLM-based hybrid retriever with extremely lightweight query encoders. Our\nmethod retains a full-sized LLM for document encoding, but reduces the workload\nof query encoding to no more than an embedding lookup. Compared to serving a\nfull-sized LLM on an H800 GPU, our approach achieves over a 1000x speedup for\nquery inference with GPU acceleration, and even a 20x speedup without GPU.\nExperiments on large-scale retrieval benchmarks demonstrate that our method\ngeneralizes well across diverse retrieval tasks, retaining an average of 95%\nfull-sized performance.\n","authors":["Guangyuan Ma","Yongliang Ma","Xuanrui Gou","Zhenpeng Su","Ming Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2505.12260v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09044v4","updated":"2025-06-22T04:58:27Z","published":"2022-12-18T09:31:36Z","title":"Text2Struct: A Machine Learning Pipeline for Mining Structured Data from\n  Text","summary":"  Many analysis and prediction tasks require the extraction of structured data\nfrom unstructured texts. However, an annotation scheme and a training dataset\nhave not been available for training machine learning models to mine structured\ndata from text without special templates and patterns. To solve it, this paper\npresents an end-to-end machine learning pipeline, Text2Struct, including a text\nannotation scheme, training data processing, and machine learning\nimplementation. We formulated the mining problem as the extraction of metrics\nand units associated with numerals in the text. Text2Struct was trained and\nevaluated using an annotated text dataset collected from abstracts of medical\npublications regarding thrombectomy. In terms of prediction performance, a dice\ncoefficient of 0.82 was achieved on the test dataset. By random sampling, most\npredicted relations between numerals and entities were well matched to the\nground-truth annotations. These results show that Text2Struct is viable for the\nmining of structured data from text without special templates or patterns. It\nis anticipated to further improve the pipeline by expanding the dataset and\ninvestigating other machine learning models. A code demonstration can be found\nat: https://github.com/zcc861007/Text2Struct\n","authors":["Chaochao Zhou","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2212.09044v4.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.18062v1","updated":"2025-06-22T15:11:31Z","published":"2025-06-22T15:11:31Z","title":"Floating-Point Data Transformation for Lossless Compression","summary":"  Floating-point data is widely used across various domains. Depending on the\nrequired precision, each floating-point value can occupy several bytes.\nLossless storage of this information is crucial due to its critical accuracy,\nas seen in applications such as medical imaging and language model weights. In\nthese cases, data size is often significant, making lossless compression\nessential. Previous approaches either treat this data as raw byte streams for\ncompression or fail to leverage all patterns within the dataset. However,\nbecause multiple bytes represent a single value and due to inherent patterns in\nfloating-point representations, some of these bytes are correlated. To leverage\nthis property, we propose a novel data transformation method called Typed Data\nTransformation (\\DTT{}) that groups related bytes together to improve\ncompression. We implemented and tested our approach on various datasets across\nboth CPU and GPU. \\DTT{} achieves a geometric mean compression ratio\nimprovement of 1.16$\\times$ over state-of-the-art compression tools such as\nzstd, while also improving both compression and decompression throughput by\n1.18--3.79$\\times$.\n","authors":["Samirasadat Jamalidinan","Kazem Cheshmi"],"pdf_url":"https://arxiv.org/pdf/2506.18062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18013v1","updated":"2025-06-22T12:26:09Z","published":"2025-06-22T12:26:09Z","title":"Dual-Hierarchy Labelling: Scaling Up Distance Queries on Dynamic Road\n  Networks","summary":"  Computing the shortest-path distance between any two given vertices in road\nnetworks is an important problem. A tremendous amount of research has been\nconducted to address this problem, most of which are limited to static road\nnetworks. Since road networks undergo various real-time traffic conditions,\nthere is a pressing need to address this problem for dynamic road networks.\nExisting state-of-the-art methods incrementally maintain an indexing structure\nto reflect dynamic changes on road networks. However, these methods suffer from\neither slow query response time or poor maintenance performance, particularly\nwhen road networks are large. In this work, we propose an efficient solution\n\\emph{Dual-Hierarchy Labelling (DHL)} for distance querying on dynamic road\nnetworks from a novel perspective, which incorporates two hierarchies with\ndifferent but complementary data structures to support efficient query and\nupdate processing. Specifically, our proposed solution is comprised of three\nmain components: \\emph{query hierarchy}, \\emph{update hierarchy}, and\n\\emph{hierarchical labelling}, where \\emph{query hierarchy} enables efficient\nquery answering by exploring only a small subset of vertices in the labels of\ntwo query vertices and \\emph{update hierarchy} supports efficient maintenance\nof distance labelling under edge weight increase or decrease. We further\ndevelop dynamic algorithms to reflect dynamic changes by efficiently\nmaintaining the update hierarchy and hierarchical labelling. We also propose a\nparallel variant of our dynamic algorithms by exploiting labelling structure.\nWe evaluate our methods on 10 large road networks and it shows that our methods\nsignificantly outperform the state-of-the-art methods, i.e., achieving\nconsiderably faster construction and update time, while being consistently 2-4\ntimes faster in terms of query processing and consuming only 10\\%-20\\%\nlabelling space.\n","authors":["Muhammad Farhan","Henning Koehler","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2506.18013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17977v1","updated":"2025-06-22T10:28:46Z","published":"2025-06-22T10:28:46Z","title":"SliceGX: Layer-wise GNN Explanation with Model-slicing","summary":"  Ensuring the trustworthiness of graph neural networks (GNNs) as black-box\nmodels requires effective explanation methods. Existing GNN explanations\ntypically apply input perturbations to identify subgraphs that are responsible\nfor the occurrence of the final output of GNNs. However, such approaches lack\nfiner-grained, layer-wise analysis of how intermediate representations\ncontribute to the final result, capabilities that are crucial for model\ndiagnosis and architecture optimization. This paper introduces SliceGX, a novel\nGNN explanation approach that generates explanations at specific GNN layers in\na progressive manner. Given a GNN M, a set of selected intermediate layers, and\na target layer, SliceGX automatically segments M into layer blocks (\"model\nslice\") and discovers high-quality explanatory subgraphs in each layer block\nthat clarifies the occurrence of output of M at the targeted layer. Although\nfinding such layer-wise explanations is computationally challenging, we develop\nefficient algorithms and optimization techniques that incrementally generate\nand maintain these subgraphs with provable approximation guarantees.\nAdditionally, SliceGX offers a SPARQL-like query interface, providing\ndeclarative access and search capacities for the generated explanations.\nThrough experiments on large real-world graphs and representative GNN\narchitectures, we verify the effectiveness and efficiency of SliceGX, and\nillustrate its practical utility in supporting model debugging.\n","authors":["Tingting Zhu","Tingyang Chen","Yinghui Wu","Arijit Khan","Xiangyu Ke"],"pdf_url":"https://arxiv.org/pdf/2506.17977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20677v1","updated":"2025-06-22T03:13:08Z","published":"2025-06-22T03:13:08Z","title":"Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting\n  Across Diverse Data Distributions","summary":"  Sorting is an essential operation in computer science with direct\nconsequences on the performance of large scale data systems, real-time systems,\nand embedded computation. However, no sorting algorithm is optimal under all\ndistributions of data. The new adaptive hybrid sorting paradigm proposed in\nthis paper is the paradigm that automatically selects the most effective\nsorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time\nmonitoring of patterns in input data. The architecture begins by having a\nfeature extraction module to compute significant parameters such as data\nvolume, value range and entropy. These parameters are sent to a decision engine\ninvolving Finite State Machine and XGBoost classifier to aid smart and\neffective in choosing the optimal sorting strategy. It implements Counting Sort\non small key ranges, Radix Sort on large range structured input with\nlow-entropy keys and QuickSort on general purpose sorting. The experimental\nfindings of both synthetic and real life dataset confirm that the proposed\nsolution is actually inclined to excel significantly by comparison in execution\ntime, flexibility and the efficiency of conventional static sorting algorithms.\nThe proposed framework provides a scalable, high perhaps and applicable to a\nwide range of data processing operations like big data analytics, edge\ncomputing, and systems with hardware limitations.\n","authors":["Shrinivass Arunachalam Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2506.20677v1.pdf","comment":"11 Pages, 5 figures"}]},"2025-06-21T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.17782v1","updated":"2025-06-21T18:29:33Z","published":"2025-06-21T18:29:33Z","title":"Expanding Relevance Judgments for Medical Case-based Retrieval Task with\n  Multimodal LLMs","summary":"  Evaluating Information Retrieval (IR) systems relies on high-quality manual\nrelevance judgments (qrels), which are costly and time-consuming to obtain.\nWhile pooling reduces the annotation effort, it results in only partially\nlabeled datasets. Large Language Models (LLMs) offer a promising alternative to\nreducing reliance on manual judgments, particularly in complex domains like\nmedical case-based retrieval, where relevance assessment requires analyzing\nboth textual and visual information. In this work, we explore using a\nMultimodal Large Language Model (MLLM) to expand relevance judgments, creating\na new dataset of automated judgments. Specifically, we employ Gemini 1.5 Pro on\nthe ImageCLEFmed 2013 case-based retrieval task, simulating human assessment\nthrough an iteratively refined, structured prompting strategy that integrates\nbinary scoring, instruction-based evaluation, and few-shot learning. We\nsystematically experimented with various prompt configurations to maximize\nagreement with human judgments. To evaluate agreement between the MLLM and\nhuman judgments, we use Cohen's Kappa, achieving a substantial agreement score\nof 0.6, comparable to inter-annotator agreement typically observed in\nmultimodal retrieval tasks. Starting from the original 15,028 manual judgments\n(4.72% relevant) across 35 topics, our MLLM-based approach expanded the dataset\nby over 37x to 558,653 judgments, increasing relevant annotations to 5,950. On\naverage, each medical case query received 15,398 new annotations, with\napproximately 99% being non-relevant, reflecting the high sparsity typical in\nthis domain. Our results demonstrate the potential of MLLMs to scale relevance\njudgment collection, offering a promising direction for supporting retrieval\nevaluation in medical and multimodal IR tasks.\n","authors":["Catarina Pires","Sérgio Nunes","Luís Filipe Teixeira"],"pdf_url":"https://arxiv.org/pdf/2506.17782v1.pdf","comment":"To appear at the Third Workshop on Large Language Models for\n  Evaluation in Information Retrieval (LLM4Eval 2025), co-located with SIGIR\n  2025. 9 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2409.05401v3","updated":"2025-06-21T17:29:02Z","published":"2024-09-09T07:57:43Z","title":"Benchmarking and Building Zero-Shot Hindi Retrieval Model with\n  Hindi-BEIR and NLLB-E5","summary":"  Given the large number of Hindi speakers worldwide, there is a pressing need\nfor robust and efficient information retrieval systems for Hindi. Despite\nongoing research, comprehensive benchmarks for evaluating retrieval models in\nHindi are lacking. To address this gap, we introduce the Hindi-BEIR benchmark,\ncomprising 15 datasets across seven distinct tasks. We evaluate\nstate-of-the-art multilingual retrieval models on the Hindi-BEIR benchmark,\nidentifying task and domain-specific challenges that impact Hindi retrieval\nperformance. Building on the insights from these results, we introduce NLLB-E5,\na multilingual retrieval model that leverages a zero-shot approach to support\nHindi without the need for Hindi training data. We believe our contributions,\nwhich include the release of the Hindi-BEIR benchmark and the NLLB-E5 model,\nwill prove to be a valuable resource for researchers and promote advancements\nin multilingual retrieval models.\n","authors":["Arkadeep Acharya","Rudra Murthy","Vishwajeet Kumar","Jaydeep Sen"],"pdf_url":"https://arxiv.org/pdf/2409.05401v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2408.09437"},{"id":"http://arxiv.org/abs/2506.17765v1","updated":"2025-06-21T17:18:35Z","published":"2025-06-21T17:18:35Z","title":"CARTS: Collaborative Agents for Recommendation Textual Summarization","summary":"  Current recommendation systems often require some form of textual data\nsummarization, such as generating concise and coherent titles for product\ncarousels or other grouped item displays. While large language models have\nshown promise in NLP domains for textual summarization, these approaches do not\ndirectly apply to recommendation systems, where explanations must be highly\nrelevant to the core features of item sets, adhere to strict word limit\nconstraints. In this paper, we propose CARTS (Collaborative Agents for\nRecommendation Textual Summarization), a multi-agent LLM framework designed for\nstructured summarization in recommendation systems. CARTS decomposes the task\ninto three stages-Generation Augmented Generation (GAG), refinement circle, and\narbitration, where successive agent roles are responsible for extracting\nsalient item features, iteratively refining candidate titles based on relevance\nand length feedback, and selecting the final title through a collaborative\narbitration process. Experiments on large-scale e-commerce data and live A/B\ntesting show that CARTS significantly outperforms single-pass and\nchain-of-thought LLM baselines, delivering higher title relevance and improved\nuser engagement metrics.\n","authors":["Jiao Chen","Kehui Yao","Reza Yousefi Maragheh","Kai Zhao","Jianpeng Xu","Jason Cho","Evren Korpeoglu","Sushant Kumar","Kannan Achan"],"pdf_url":"https://arxiv.org/pdf/2506.17765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13597v3","updated":"2025-06-21T16:01:37Z","published":"2024-03-20T13:44:30Z","title":"LaPuda: LLM-Enabled Policy-Based Query Optimizer for Multi-modal Data","summary":"  Large language model (LLM) has marked a pivotal moment in the field of\nmachine learning and deep learning. Recently its capability for query planning\nhas been investigated, including both single-modal and multi-modal queries.\nHowever, there is no work on the query optimization capability of LLM. As a\ncritical (or could even be the most important) step that significantly impacts\nthe execution performance of the query plan, such analysis and attempts should\nnot be missed. From another aspect, existing query optimizers are usually\nrule-based or rule-based + cost-based, i.e., they are dependent on manually\ncreated rules to complete the query plan rewrite/transformation. Given the fact\nthat modern optimizers include hundreds to thousands of rules, designing a\nmulti-modal query optimizer following a similar way is significantly\ntime-consuming since we will have to enumerate as many multi-modal optimization\nrules as possible, which has not been well addressed today. In this paper, we\ninvestigate the query optimization ability of LLM and use LLM to design LaPuda,\na novel LLM and Policy based multi-modal query optimizer. Instead of\nenumerating specific and detailed rules, LaPuda only needs a few abstract\npolicies to guide LLM in the optimization, by which much time and human effort\nare saved. Furthermore, to prevent LLM from making mistakes or negative\noptimization, we borrow the idea of gradient descent and propose a guided cost\ndescent (GCD) algorithm to perform the optimization, such that the optimization\ncan be kept in the correct direction. In our evaluation, our methods\nconsistently outperform the baselines in most cases. For example, the optimized\nplans generated by our methods result in 1~3x higher execution speed than those\nby the baselines.\n","authors":["Yifan Wang","Haodi Ma","Daisy Zhe Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13597v3.pdf","comment":"Yifan and Haodi contributed equally to the work, accepted by PAKDD\n  2025"},{"id":"http://arxiv.org/abs/2506.17682v1","updated":"2025-06-21T11:27:53Z","published":"2025-06-21T11:27:53Z","title":"Reinforcing User Interest Evolution in Multi-Scenario Learning for\n  recommender systems","summary":"  In real-world recommendation systems, users would engage in variety\nscenarios, such as homepages, search pages, and related recommendation pages.\nEach of these scenarios would reflect different aspects users focus on.\nHowever, the user interests may be inconsistent in different scenarios, due to\ndifferences in decision-making processes and preference expression. This\nvariability complicates unified modeling, making multi-scenario learning a\nsignificant challenge. To address this, we propose a novel reinforcement\nlearning approach that models user preferences across scenarios by modeling\nuser interest evolution across multiple scenarios. Our method employs Double\nQ-learning to enhance next-item prediction accuracy and optimizes contrastive\nlearning loss using Q-value to make model performance better. Experimental\nresults demonstrate that our approach surpasses state-of-the-art methods in\nmulti-scenario recommendation tasks. Our work offers a fresh perspective on\nmulti-scenario modeling and highlights promising directions for future\nresearch.\n","authors":["Zhijian Feng","Wenhao Zheng","Xuanji Xiao"],"pdf_url":"https://arxiv.org/pdf/2506.17682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17600v1","updated":"2025-06-21T05:35:38Z","published":"2025-06-21T05:35:38Z","title":"A novel fast short-time root music method for vibration monitoring of\n  high-speed spindles","summary":"  Ultra-high-speed spindle bearings challenge traditional vibration monitoring\ndue to broadband noise, non-stationarity, and limited time-frequency\nresolution. We present a fast Short-Time Root-MUSIC (fSTrM) algorithm that\nexploits\n  FFT-accelerated Lanczos bidiagonalization to reduce computational complexity\nfrom $\\mathcal{O}(N^3)$ to $SN\\log_2N+S^2(N+S)+M^2(N+M)$\n  while preserving parametric super-resolution. The method constructs Hankel\nmatrices from 16 ms signal frames and extracts fault frequencies through\npolynomial rooting on the unit circle. Experimental validation on the\nPolitecnico di Torino bearing dataset demonstrates breakthrough micro-defect\ndetection capabilities. The algorithm reliably identifies 150 $\\mu$m defects --\npreviously undetectable by conventional methods -- providing 72+ hours\nadditional warning time. Compared to STFT and wavelet methods, fSTrM achieves\n1.2 Hz frequency resolution (vs. 12.5 Hz), 93\\% detection rate at $-$5 dB SNR,\nand quantifies defect severity through harmonic content analysis. Critically,\nthe algorithm processes each frame in 2.4 ms on embedded ARM Cortex-M7\nhardware, enabling real-time deployment. This advancement transforms bearing\nmonitoring from failure prevention to continuous degradation assessment,\nestablishing a new paradigm for predictive maintenance in aerospace and\nprecision machining.\n","authors":["Huiguang Zhang","Baoguo Liu","Wei Feng","Zongtang Li"],"pdf_url":"https://arxiv.org/pdf/2506.17600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17580v1","updated":"2025-06-21T04:22:34Z","published":"2025-06-21T04:22:34Z","title":"Context-Aware Scientific Knowledge Extraction on Linked Open Data using\n  Large Language Models","summary":"  The exponential growth of scientific literature challenges researchers\nextracting and synthesizing knowledge. Traditional search engines return many\nsources without direct, detailed answers, while general-purpose LLMs may offer\nconcise responses that lack depth or omit current information. LLMs with search\ncapabilities are also limited by context window, yielding short, incomplete\nanswers. This paper introduces WISE (Workflow for Intelligent Scientific\nKnowledge Extraction), a system addressing these limits by using a structured\nworkflow to extract, refine, and rank query-specific knowledge. WISE uses an\nLLM-powered, tree-based architecture to refine data, focusing on query-aligned,\ncontext-aware, and non-redundant information. Dynamic scoring and ranking\nprioritize unique contributions from each source, and adaptive stopping\ncriteria minimize processing overhead. WISE delivers detailed, organized\nanswers by systematically exploring and synthesizing knowledge from diverse\nsources. Experiments on HBB gene-associated diseases demonstrate WISE reduces\nprocessed text by over 80% while achieving significantly higher recall over\nbaselines like search engines and other LLM-based approaches. ROUGE and BLEU\nmetrics reveal WISE's output is more unique than other systems, and a novel\nlevel-based metric shows it provides more in-depth information. We also explore\nhow the WISE workflow can be adapted for diverse domains like drug discovery,\nmaterial science, and social science, enabling efficient knowledge extraction\nand synthesis from unstructured scientific papers and web sources.\n","authors":["Sajratul Y. Rubaiat","Hasan M. Jamil"],"pdf_url":"https://arxiv.org/pdf/2506.17580v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2403.13597v3","updated":"2025-06-21T16:01:37Z","published":"2024-03-20T13:44:30Z","title":"LaPuda: LLM-Enabled Policy-Based Query Optimizer for Multi-modal Data","summary":"  Large language model (LLM) has marked a pivotal moment in the field of\nmachine learning and deep learning. Recently its capability for query planning\nhas been investigated, including both single-modal and multi-modal queries.\nHowever, there is no work on the query optimization capability of LLM. As a\ncritical (or could even be the most important) step that significantly impacts\nthe execution performance of the query plan, such analysis and attempts should\nnot be missed. From another aspect, existing query optimizers are usually\nrule-based or rule-based + cost-based, i.e., they are dependent on manually\ncreated rules to complete the query plan rewrite/transformation. Given the fact\nthat modern optimizers include hundreds to thousands of rules, designing a\nmulti-modal query optimizer following a similar way is significantly\ntime-consuming since we will have to enumerate as many multi-modal optimization\nrules as possible, which has not been well addressed today. In this paper, we\ninvestigate the query optimization ability of LLM and use LLM to design LaPuda,\na novel LLM and Policy based multi-modal query optimizer. Instead of\nenumerating specific and detailed rules, LaPuda only needs a few abstract\npolicies to guide LLM in the optimization, by which much time and human effort\nare saved. Furthermore, to prevent LLM from making mistakes or negative\noptimization, we borrow the idea of gradient descent and propose a guided cost\ndescent (GCD) algorithm to perform the optimization, such that the optimization\ncan be kept in the correct direction. In our evaluation, our methods\nconsistently outperform the baselines in most cases. For example, the optimized\nplans generated by our methods result in 1~3x higher execution speed than those\nby the baselines.\n","authors":["Yifan Wang","Haodi Ma","Daisy Zhe Wang"],"pdf_url":"https://arxiv.org/pdf/2403.13597v3.pdf","comment":"Yifan and Haodi contributed equally to the work, accepted by PAKDD\n  2025"},{"id":"http://arxiv.org/abs/2506.17702v1","updated":"2025-06-21T12:29:29Z","published":"2025-06-21T12:29:29Z","title":"Lower Bounds for Conjunctive Query Evaluation","summary":"  In this tutorial, we will survey known results on the complexity of\nconjunctive query evaluation in different settings, ranging from Boolean\nqueries over counting to more complex models like enumeration and direct\naccess. A particular focus will be on showing how different relatively recent\nhypotheses from complexity theory connect to query answering and allow showing\nthat known algorithms in several cases can likely not be improved.\n","authors":["Stefan Mengel"],"pdf_url":"https://arxiv.org/pdf/2506.17702v1.pdf","comment":"paper for the tutorial at PODS 2025"},{"id":"http://arxiv.org/abs/2506.17613v1","updated":"2025-06-21T06:40:32Z","published":"2025-06-21T06:40:32Z","title":"Contextual Pattern Mining and Counting","summary":"  Given a string $P$ of length $m$, a longer string $T$ of length $n>m$, and\ntwo integers $l\\geq 0$ and $r\\geq 0$, the context of $P$ in $T$ is the set of\nall string pairs $(L,R)$, with $|L|=l$ and $|R|=r$, such that the string $LPR$\noccurs in $T$. We introduce two problems related to the notion of context: (1)\nthe Contextual Pattern Mining (CPM) problem, which given $T$, $(m,l,r)$, and an\ninteger $\\tau>0$, asks for outputting the context of each substring $P$ of\nlength $m$ of $T$, provided that the size of the context of $P$ is at least\n$\\tau$; and (2) the Contextual Pattern Counting (CPC) problem, which asks for\npreprocessing $T$ so that the size of the context of a given query string $P$\nof length $m$ can be found efficiently.\n  For CPM, we propose a linear-work algorithm that either uses only internal\nmemory, or a bounded amount of internal memory and external memory, which\nallows much larger datasets to be handled. For CPC, we propose an\n$\\widetilde{\\mathcal{O}}(n)$-space index that can be constructed in\n$\\widetilde{\\mathcal{O}}n)$ time and answers queries in\n$\\mathcal{O}(m)+\\widetilde{\\mathcal{O}}(1)$ time. We further improve the\npractical performance of the CPC index by optimizations that exploit the LZ77\nfactorization of $T$ and an upper bound on the query length. Using\nbillion-letter datasets from different domains, we show that the external\nmemory version of our CPM algorithm can deal with very large datasets using a\nsmall amount of internal memory while its runtime is comparable to that of the\ninternal memory version. Interestingly, we also show that our optimized index\nfor CPC outperforms an approach based on the state of the art for the reporting\nversion of CPC [Navarro, SPIRE 2020] in terms of query time, index size,\nconstruction time, and construction space, often by more than an order of\nmagnitude.\n","authors":["Ling Li","Daniel Gibney","Sharma V. Thankachan","Solon P. Pissis","Grigorios Loukides"],"pdf_url":"https://arxiv.org/pdf/2506.17613v1.pdf","comment":"27 pages, 15 figures"}]},"2025-06-20T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.17493v1","updated":"2025-06-20T22:02:05Z","published":"2025-06-20T22:02:05Z","title":"PreQRAG -- Classify and Rewrite for Enhanced RAG","summary":"  This paper presents the submission of the UDInfo team to the SIGIR 2025\nLiveRAG Challenge. We introduce PreQRAG, a Retrieval Augmented Generation (RAG)\narchitecture designed to improve retrieval and generation quality through\ntargeted question preprocessing. PreQRAG incorporates a pipeline that first\nclassifies each input question as either single-document or multi-document\ntype. For single-document questions, we employ question rewriting techniques to\nimprove retrieval precision and generation relevance. For multi-document\nquestions, we decompose complex queries into focused sub-questions that can be\nprocessed more effectively by downstream components. This classification and\nrewriting strategy improves the RAG performance. Experimental evaluation of the\nLiveRAG Challenge dataset demonstrates the effectiveness of our\nquestion-type-aware architecture, with PreQRAG achieving the preliminary second\nplace in Session 2 of the LiveRAG challenge.\n","authors":["Damian Martinez","Catalina Riano","Hui Fang"],"pdf_url":"https://arxiv.org/pdf/2506.17493v1.pdf","comment":"7 pages, SIGIR 2025 LiveRAG"},{"id":"http://arxiv.org/abs/2407.21515v2","updated":"2025-06-20T19:43:59Z","published":"2024-07-31T10:33:32Z","title":"Learning Effective Representations for Retrieval Using Self-Distillation\n  with Adaptive Relevance Margins","summary":"  Representation-based retrieval models, so-called bi-encoders, estimate the\nrelevance of a document to a query by calculating the similarity of their\nrespective embeddings. Current state-of-the-art bi-encoders are trained using\nan expensive training regime involving knowledge distillation from a teacher\nmodel and batch-sampling. Instead of relying on a teacher model, we contribute\na novel parameter-free loss function for self-supervision that exploits the\npre-trained language modeling capabilities of the encoder model as a training\nsignal, eliminating the need for batch sampling by performing implicit hard\nnegative mining. We investigate the capabilities of our proposed approach\nthrough extensive experiments, demonstrating that self-distillation can match\nthe effectiveness of teacher distillation using only 13.5% of the data, while\noffering a speedup in training time between 3x and 15x compared to parametrized\nlosses. All code and data is made openly available.\n","authors":["Lukas Gienapp","Niklas Deckers","Martin Potthast","Harrisen Scells"],"pdf_url":"https://arxiv.org/pdf/2407.21515v2.pdf","comment":"9 Pages, 5 Tables, 6 Figures; published at ICTIR'25"},{"id":"http://arxiv.org/abs/2506.17188v1","updated":"2025-06-20T17:42:13Z","published":"2025-06-20T17:42:13Z","title":"Towards AI Search Paradigm","summary":"  In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.\n","authors":["Yuchen Li","Hengyi Cai","Rui Kong","Xinran Chen","Jiamin Chen","Jun Yang","Haojie Zhang","Jiayi Li","Jiayi Wu","Yiqun Chen","Changle Qu","Keyi Kong","Wenwen Ye","Lixin Su","Xinyu Ma","Long Xia","Daiting Shi","Jiashu Zhao","Haoyi Xiong","Shuaiqiang Wang","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2506.17188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17374v1","updated":"2025-06-20T17:10:01Z","published":"2025-06-20T17:10:01Z","title":"From Drawings to Decisions: A Hybrid Vision-Language Framework for\n  Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge","summary":"  Efficient and accurate extraction of key information from 2D engineering\ndrawings is essential for advancing digital manufacturing workflows. Such\ninformation includes geometric dimensioning and tolerancing (GD&T), measures,\nmaterial specifications, and textual annotations. Manual extraction is slow and\nlabor-intensive, while generic OCR models often fail due to complex layouts,\nengineering symbols, and rotated text, leading to incomplete and unreliable\noutputs. These limitations result in incomplete and unreliable outputs. To\naddress these challenges, we propose a hybrid vision-language framework that\nintegrates a rotation-aware object detection model (YOLOv11-obb) with a\ntransformer-based vision-language parser. Our structured pipeline applies\nYOLOv11-OBB to localize annotations and extract oriented bounding box (OBB)\npatches, which are then parsed into structured outputs using a fine-tuned,\nlightweight vision-language model (VLM). We curate a dataset of 1,367 2D\nmechanical drawings annotated across nine key categories. YOLOv11-OBB is\ntrained on this dataset to detect OBBs and extract annotation patches. These\nare parsed using two open-source VLMs: Donut and Florence-2. Both models are\nlightweight and well-suited for specialized industrial tasks under limited\ncomputational overhead. Following fine-tuning of both models on the curated\ndataset of image patches paired with structured annotation labels, a\ncomparative experiment is conducted to evaluate parsing performance across four\nkey metrics. Donut outperforms Florence-2, achieving 88.5% precision, 99.2%\nrecall, and a 93.5% F1-score, with a hallucination rate of 11.5%. Finally, a\ncase study demonstrates how the extracted structured information supports\ndownstream manufacturing tasks such as process and tool selection, showcasing\nthe practical utility of the proposed framework in modernizing 2D drawing\ninterpretation.\n","authors":["Muhammad Tayyab Khan","Lequn Chen","Zane Yong","Jun Ming Tan","Wenhe Feng","Seung Ki Moon"],"pdf_url":"https://arxiv.org/pdf/2506.17374v1.pdf","comment":"Preprint submitted to Elsevier"},{"id":"http://arxiv.org/abs/2506.13784v2","updated":"2025-06-20T15:48:51Z","published":"2025-06-11T02:05:23Z","title":"ScholarSearch: Benchmarking Scholar Searching Ability of LLMs","summary":"  Large Language Models (LLMs)' search capabilities have garnered significant\nattention. Existing benchmarks, such as OpenAI's BrowseComp, primarily focus on\ngeneral search scenarios and fail to adequately address the specific demands of\nacademic search. These demands include deeper literature tracing and\norganization, professional support for academic databases, the ability to\nnavigate long-tail academic knowledge, and ensuring academic rigor. Here, we\nproposed ScholarSearch, the first dataset specifically designed to evaluate the\ncomplex information retrieval capabilities of Large Language Models (LLMs) in\nacademic research. ScholarSearch possesses the following key characteristics:\nAcademic Practicality, where question content closely mirrors real academic\nlearning and research environments, avoiding deliberately misleading models;\nHigh Difficulty, with answers that are challenging for single models (e.g.,\nGrok DeepSearch or Gemini Deep Research) to provide directly, often requiring\nat least three deep searches to derive; Concise Evaluation, where limiting\nconditions ensure answers are as unique as possible, accompanied by clear\nsources and brief solution explanations, greatly facilitating subsequent audit\nand verification, surpassing the current lack of analyzed search datasets both\ndomestically and internationally; and Broad Coverage, as the dataset spans at\nleast 15 different academic disciplines. Through ScholarSearch, we expect to\nmore precisely measure and promote the performance improvement of LLMs in\ncomplex academic information retrieval tasks. The data is available at:\nhttps://huggingface.co/datasets/PKU-DS-LAB/ScholarSearch\n","authors":["Junting Zhou","Wang Li","Yiyan Liao","Nengyuan Zhang","Tingjia Miao","Zhihui Qi","Yuhan Wu","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2506.13784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17055v1","updated":"2025-06-20T15:06:44Z","published":"2025-06-20T15:06:44Z","title":"Universal Music Representations? Evaluating Foundation Models on World\n  Music Corpora","summary":"  Foundation models have revolutionized music information retrieval, but\nquestions remain about their ability to generalize across diverse musical\ntraditions. This paper presents a comprehensive evaluation of five\nstate-of-the-art audio foundation models across six musical corpora spanning\nWestern popular, Greek, Turkish, and Indian classical traditions. We employ\nthree complementary methodologies to investigate these models' cross-cultural\ncapabilities: probing to assess inherent representations, targeted supervised\nfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource\nscenarios. Our analysis shows varying cross-cultural generalization, with\nlarger models typically outperforming on non-Western music, though results\ndecline for culturally distant traditions. Notably, our approaches achieve\nstate-of-the-art performance on five out of six evaluated datasets,\ndemonstrating the effectiveness of foundation models for world music\nunderstanding. We also find that our targeted fine-tuning approach does not\nconsistently outperform probing across all settings, suggesting foundation\nmodels already encode substantial musical knowledge. Our evaluation framework\nand benchmarking results contribute to understanding how far current models are\nfrom achieving universal music representations while establishing metrics for\nfuture progress.\n","authors":["Charilaos Papaioannou","Emmanouil Benetos","Alexandros Potamianos"],"pdf_url":"https://arxiv.org/pdf/2506.17055v1.pdf","comment":"Accepted at ISMIR 2025"},{"id":"http://arxiv.org/abs/2506.17001v1","updated":"2025-06-20T13:52:15Z","published":"2025-06-20T13:52:15Z","title":"PersonalAI: Towards digital twins in the graph form","summary":"  The challenge of personalizing language models, specifically the ability to\naccount for a user's history during interactions, is of significant interest.\nDespite recent advancements in large language models (LLMs) and Retrieval\nAugmented Generation that have enhanced the factual base of LLMs, the task of\nretaining extensive personal information and using it to generate personalized\nresponses remains pertinent. To address this, we propose utilizing external\nmemory in the form of knowledge graphs, which are constructed and updated by\nthe LLM itself. We have expanded upon ideas of AriGraph architecture and for\nthe first time introduced a combined graph featuring both standard edges and\ntwo types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and\nDiaASQ benchmarks indicates that this approach aids in making the process of\ngraph construction and knowledge extraction unified and robust. Furthermore, we\naugmented the DiaASQ benchmark by incorporating parameters such as time into\ndialogues and introducing contradictory statements made by the same speaker at\ndifferent times. Despite these modifications, the performance of the\nquestion-answering system remained robust, demonstrating the proposed\narchitecture's ability to maintain and utilize temporal dependencies.\n","authors":["Mikhail Menschikov","Dmitry Evseev","Ruslan Kostoev","Ilya Perepechkin","Ilnaz Salimov","Victoria Dochkina","Petr Anokhin","Evgeny Burnaev","Nikita Semenov"],"pdf_url":"https://arxiv.org/pdf/2506.17001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16988v1","updated":"2025-06-20T13:37:03Z","published":"2025-06-20T13:37:03Z","title":"RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed\n  Question Answering","summary":"  We present RAGentA, a multi-agent retrieval-augmented generation (RAG)\nframework for attributed question answering (QA). With the goal of trustworthy\nanswer generation, RAGentA focuses on optimizing answer correctness, defined by\ncoverage and relevance to the question and faithfulness, which measures the\nextent to which answers are grounded in retrieved documents. RAGentA uses a\nmulti-agent architecture that iteratively filters retrieved documents,\ngenerates attributed answers with in-line citations, and verifies completeness\nthrough dynamic refinement. Central to the framework is a hybrid retrieval\nstrategy that combines sparse and dense methods, improving Recall@20 by 12.5%\ncompared to the best single retrieval model, resulting in more correct and\nwell-supported answers. Evaluated on a synthetic QA dataset derived from the\nFineWeb index, RAGentA outperforms standard RAG baselines, achieving gains of\n1.09% in correctness and 10.72% in faithfulness. These results demonstrate the\neffectiveness of the multi-agent architecture and hybrid retrieval in advancing\ntrustworthy QA.\n","authors":["Ines Besrour","Jingbo He","Tobias Schreieder","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2506.16988v1.pdf","comment":"Accepted at SIGIR 2025"},{"id":"http://arxiv.org/abs/2406.12593v3","updated":"2025-06-20T12:59:40Z","published":"2024-06-18T13:25:18Z","title":"PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental\n  Learning for Document Retrieval","summary":"  Differentiable Search Index (DSI) utilizes pre-trained language models to\nperform indexing and document retrieval via end-to-end learning without relying\non external indexes. However, DSI requires full re-training to index new\ndocuments, causing significant computational inefficiencies. Continual learning\n(CL) offers a solution by enabling the model to incrementally update without\nfull re-training. Existing CL solutions in document retrieval rely on memory\nbuffers or generative models for rehearsal, which is infeasible when accessing\nprevious training data is restricted due to privacy concerns. To this end, we\nintroduce PromptDSI, a prompt-based, rehearsal-free continual learning approach\nfor document retrieval. PromptDSI follows the Prompt-based Continual Learning\n(PCL) framework, using learnable prompts to efficiently index new documents\nwithout accessing previous documents or queries. To improve retrieval latency,\nwe remove the initial forward pass of PCL, which otherwise greatly increases\ntraining and inference time, with a negligible trade-off in performance.\nAdditionally, we introduce a novel topic-aware prompt pool that employs neural\ntopic embeddings as fixed keys, eliminating the instability of prompt key\noptimization while maintaining competitive performance with existing PCL prompt\npools. In a challenging rehearsal-free continual learning setup, we demonstrate\nthat PromptDSI variants outperform rehearsal-based baselines, match the strong\ncache-based baseline in mitigating forgetting, and significantly improving\nretrieval performance on new corpora.\n","authors":["Tuan-Luc Huynh","Thuy-Trang Vu","Weiqing Wang","Yinwei Wei","Trung Le","Dragan Gasevic","Yuan-Fang Li","Thanh-Toan Do"],"pdf_url":"https://arxiv.org/pdf/2406.12593v3.pdf","comment":"ECML PKDD 2025 Research track. Camera-ready version. Code is\n  available at https://github.com/LouisDo2108/PromptDSI"},{"id":"http://arxiv.org/abs/2506.16942v1","updated":"2025-06-20T12:11:38Z","published":"2025-06-20T12:11:38Z","title":"Pyramid Mixer: Multi-dimensional Multi-period Interest Modeling for\n  Sequential Recommendation","summary":"  Sequential recommendation, a critical task in recommendation systems,\npredicts the next user action based on the understanding of the user's\nhistorical behaviors. Conventional studies mainly focus on cross-behavior\nmodeling with self-attention based methods while neglecting comprehensive user\ninterest modeling for more dimensions. In this study, we propose a novel\nsequential recommendation model, Pyramid Mixer, which leverages the MLP-Mixer\narchitecture to achieve efficient and complete modeling of user interests. Our\nmethod learns comprehensive user interests via cross-behavior and cross-feature\nuser sequence modeling. The mixer layers are stacked in a pyramid way for\ncross-period user temporal interest learning. Through extensive offline and\nonline experiments, we demonstrate the effectiveness and efficiency of our\nmethod, and we obtain a +0.106% improvement in user stay duration and a\n+0.0113% increase in user active days in the online A/B test. The Pyramid Mixer\nhas been successfully deployed on the industrial platform, demonstrating its\nscalability and impact in real-world applications.\n","authors":["Zhen Gong","Zhifang Fan","Hui Lu","Qiwei Chen","Chenbin Zhang","Lin Guan","Yuchao Zheng","Feng Zhang","Xiao Yang","Zuotao Liu"],"pdf_url":"https://arxiv.org/pdf/2506.16942v1.pdf","comment":"Accepted by SIGIR'25"},{"id":"http://arxiv.org/abs/2506.16893v1","updated":"2025-06-20T10:30:39Z","published":"2025-06-20T10:30:39Z","title":"Multi-Objective Recommendation in the Era of Generative AI: A Survey of\n  Recent Progress and Future Prospects","summary":"  With the recent progress in generative artificial intelligence (Generative\nAI), particularly in the development of large language models, recommendation\nsystems are evolving to become more versatile. Unlike traditional techniques,\ngenerative AI not only learns patterns and representations from complex data\nbut also enables content generation, data synthesis, and personalized\nexperiences. This generative capability plays a crucial role in the field of\nrecommendation systems, helping to address the issue of data sparsity and\nimproving the overall performance of recommendation systems. Numerous studies\non generative AI have already emerged in the field of recommendation systems.\nMeanwhile, the current requirements for recommendation systems have surpassed\nthe single utility of accuracy, leading to a proliferation of multi-objective\nresearch that considers various goals in recommendation systems. However, to\nthe best of our knowledge, there remains a lack of comprehensive studies on\nmulti-objective recommendation systems based on generative AI technologies,\nleaving a significant gap in the literature. Therefore, we investigate the\nexisting research on multi-objective recommendation systems involving\ngenerative AI to bridge this gap. We compile current research on\nmulti-objective recommendation systems based on generative techniques,\ncategorizing them by objectives. Additionally, we summarize relevant evaluation\nmetrics and commonly used datasets, concluding with an analysis of the\nchallenges and future directions in this domain.\n","authors":["Zihan Hong","Yushi Wu","Zhiting Zhao","Shanshan Feng","Jianghong Ma","Jiao Liu","Tianjun Wei"],"pdf_url":"https://arxiv.org/pdf/2506.16893v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2506.14684v2","updated":"2025-06-20T09:48:47Z","published":"2025-06-17T16:19:21Z","title":"Refining music sample identification with a self-supervised graph neural\n  network","summary":"  Automatic sample identification (ASID), the detection and identification of\nportions of audio recordings that have been reused in new musical works, is an\nessential but challenging task in the field of audio query-based retrieval.\nWhile a related task, audio fingerprinting, has made significant progress in\naccurately retrieving musical content under \"real world\" (noisy, reverberant)\nconditions, ASID systems struggle to identify samples that have undergone\nmusical modifications. Thus, a system robust to common music production\ntransformations such as time-stretching, pitch-shifting, effects processing,\nand underlying or overlaying music is an important open challenge.\n  In this work, we propose a lightweight and scalable encoding architecture\nemploying a Graph Neural Network within a contrastive learning framework. Our\nmodel uses only 9% of the trainable parameters compared to the current\nstate-of-the-art system while achieving comparable performance, reaching a mean\naverage precision (mAP) of 44.2%.\n  To enhance retrieval quality, we introduce a two-stage approach consisting of\nan initial coarse similarity search for candidate selection, followed by a\ncross-attention classifier that rejects irrelevant matches and refines the\nranking of retrieved candidates - an essential capability absent in prior\nmodels. In addition, because queries in real-world applications are often short\nin duration, we benchmark our system for short queries using new fine-grained\nannotations for the Sample100 dataset, which we publish as part of this work.\n","authors":["Aditya Bhattacharjee","Ivan Meresman Higgs","Mark Sandler","Emmanouil Benetos"],"pdf_url":"https://arxiv.org/pdf/2506.14684v2.pdf","comment":"Accepted at International Conference for Music Information Retrieval\n  (ISMIR) 2025"},{"id":"http://arxiv.org/abs/2403.04311v2","updated":"2025-06-20T07:03:22Z","published":"2024-03-07T08:30:26Z","title":"Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry","summary":"  Compound AI applications chain together subcomponents such as generative\nlanguage models, document retrievers, and embedding models. Applying\ntraditional systems optimizations such as parallelism and pipelining in\ncompound AI systems is difficult because each component has different\nconstraints in terms of the granularity and type of data that it ingests. New\ndata is often generated during intermediate computations, and text streams may\nbe split into smaller, independent fragments (such as documents to sentences)\nwhich may then be re-aggregated at later parts of the computation. Due to this\ncomplexity, existing systems to serve compound AI queries do not fully take\nadvantage of parallelism and pipelining opportunities.\n  We present Alto, a framework that automatically optimizes execution of\ncompound AI queries through streaming and parallelism. Bento introduces a new\nabstraction called nested ancestry, a metadata hierarchy that allows the system\nto correctly track partial outputs and aggregate data across the heterogeneous\nconstraints of the components of compound AI applications. This metadata is\nautomatically inferred from the programming model, allowing developers to\nexpress complex dataflow patterns without needing to reason manually about the\ndetails of routing and aggregation. Implementations of four applications in\nAlto outperform or match implementations in LangGraph, a popular existing AI\nprogramming framework. Alto implementations match or improve latency by between\n10-30%.\n","authors":["Deepti Raghavan","Keshav Santhanam","Muhammad Shahir Rahman","Nayani Modugula","Luis Gaspar Schroeder","Maximilien Cura","Houjun Liu","Pratiksha Thaker","Philip Levis","Matei Zaharia"],"pdf_url":"https://arxiv.org/pdf/2403.04311v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16122v2","updated":"2025-06-20T07:03:19Z","published":"2024-11-25T06:14:20Z","title":"From Collapse to Stability: A Knowledge-Driven Ensemble Framework for\n  Scaling Up Click-Through Rate Prediction Models","summary":"  Click-through rate (CTR) prediction plays a crucial role in modern\nrecommender systems. While many existing methods utilize ensemble networks to\nimprove CTR model performance, they typically restrict the ensemble to only two\nor three sub-networks. Whether increasing the number of sub-networks\nconsistently enhances CTR model performance to align with scaling laws remains\nunclear. In this paper, we investigate larger ensemble networks and find three\ninherent limitations in commonly used ensemble methods: (1) performance\ndegradation as the number of sub-networks increases; (2) sharp declines and\nhigh variance in sub-network performance; and (3) significant discrepancies\nbetween sub-network and ensemble predictions. Meanwhile, we analyze the\nunderlying causes of these limitations from the perspective of dimensional\ncollapse: the collapse within sub-networks becomes increasingly severe as the\nnumber of sub-networks grows, leading to a lower knowledge abundance. In this\npaper, we employ knowledge transfer methods, such as Knowledge Distillation\n(KD) and Deep Mutual Learning (DML), to address the aforementioned limitations.\nWe find that KD enables CTR models to better follow scaling laws, while DML\nreduces variance among sub-networks and minimizes discrepancies with ensemble\npredictions. Furthermore, by combining KD and DML, we propose a model-agnostic\nand hyperparameter-free Knowledge-Driven Ensemble Framework (KDEF) for CTR\nPrediction.\n","authors":["Honghao Li","Lei Sang","Yi Zhang","Guangming Cui","Yiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.16122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16768v1","updated":"2025-06-20T06:07:20Z","published":"2025-06-20T06:07:20Z","title":"eSapiens: A Real-World NLP Framework for Multimodal Document\n  Understanding and Enterprise Knowledge Processing","summary":"  We introduce eSapiens, a unified question-answering system designed for\nenterprise settings, which bridges structured databases and unstructured\ntextual corpora via a dual-module architecture. The system combines a\nText-to-SQL planner with a hybrid Retrieval-Augmented Generation (RAG)\npipeline, enabling natural language access to both relational data and\nfree-form documents. To enhance answer faithfulness, the RAG module integrates\ndense and sparse retrieval, commercial reranking, and a citation verification\nloop that ensures grounding consistency. We evaluate eSapiens on the RAGTruth\nbenchmark across five leading large language models (LLMs), analyzing\nperformance across key dimensions such as completeness, hallucination, and\ncontext utilization. Results demonstrate that eSapiens outperforms a FAISS\nbaseline in contextual relevance and generation quality, with optional\nstrict-grounding controls for high-stakes scenarios. This work provides a\ndeployable framework for robust, citation-aware question answering in\nreal-world enterprise applications.\n","authors":["Isaac Shi","Zeyuan Li","Wenli Wang","Lewei He","Yang Yang","Tianyu Shi"],"pdf_url":"https://arxiv.org/pdf/2506.16768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18654v3","updated":"2025-06-20T05:35:15Z","published":"2025-05-24T11:47:28Z","title":"MTGR: Industrial-Scale Generative Recommendation Framework in Meituan","summary":"  Scaling law has been extensively validated in many domains such as natural\nlanguage processing and computer vision. In the recommendation system, recent\nwork has adopted generative recommendations to achieve scalability, but their\ngenerative approaches require abandoning the carefully constructed cross\nfeatures of traditional recommendation models. We found that this approach\nsignificantly degrades model performance, and scaling up cannot compensate for\nit at all. In this paper, we propose MTGR (Meituan Generative Recommendation)\nto address this issue. MTGR is modeling based on the HSTU architecture and can\nretain the original deep learning recommendation model (DLRM) features,\nincluding cross features. Additionally, MTGR achieves training and inference\nacceleration through user-level compression to ensure efficient scaling. We\nalso propose Group-Layer Normalization (GLN) to enhance the performance of\nencoding within different semantic spaces and the dynamic masking strategy to\navoid information leakage. We further optimize the training frameworks,\nenabling support for our models with 10 to 100 times computational complexity\ncompared to the DLRM, without significant cost increases. MTGR achieved 65x\nFLOPs for single-sample forward inference compared to the DLRM model, resulting\nin the largest gain in nearly two years both offline and online. This\nbreakthrough was successfully deployed on Meituan, the world's largest food\ndelivery platform, where it has been handling the main traffic.\n","authors":["Ruidong Han","Bin Yin","Shangyu Chen","He Jiang","Fei Jiang","Xiang Li","Chi Ma","Mincong Huang","Xiaoguang Li","Chunzhen Jing","Yueming Han","Menglei Zhou","Lei Yu","Chuan Liu","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2505.18654v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20643v3","updated":"2025-06-20T04:55:47Z","published":"2024-10-28T00:39:22Z","title":"GenUP: Generative User Profilers as In-Context Learners for Next POI\n  Recommender Systems","summary":"  Traditional Point-of-Interest (POI) recommendation systems often lack\ntransparency, interpretability, and scrutability due to their reliance on dense\nvector-based user embeddings. Furthermore, the cold-start problem -- where\nsystems have insufficient data for new users -- limits their ability to\ngenerate accurate recommendations. Existing methods often address this by\nleveraging similar trajectories from other users, but this approach can be\ncomputationally expensive and increases the context length for LLM-based\nmethods, making them difficult to scale. To address these limitations, we\npropose a method that generates natural language (NL) user profiles from\nlarge-scale, location-based social network (LBSN) check-ins, utilizing robust\npersonality assessments and behavioral theories. These NL profiles capture user\npreferences, routines, and behaviors, improving POI prediction accuracy while\noffering enhanced transparency. By incorporating NL profiles as system prompts\nto LLMs, our approach reduces reliance on extensive historical data, while\nremaining flexible, easily updated, and computationally efficient. Our method\nis not only competitive with other LLM-based methods but is also more scalable\nfor real-world POI recommender systems. Results demonstrate that our approach\nconsistently outperforms baseline methods, offering a more interpretable and\nresource-efficient solution for POI recommendation systems. Our source code is\navailable at: https://github.com/w11wo/GenUP/.\n","authors":["Wilson Wongso","Hao Xue","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2410.20643v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16683v1","updated":"2025-06-20T01:54:32Z","published":"2025-06-20T01:54:32Z","title":"A Simple Contrastive Framework Of Item Tokenization For Generative\n  Recommendation","summary":"  Generative retrieval-based recommendation has emerged as a promising paradigm\naiming at directly generating the identifiers of the target candidates.\nHowever, in large-scale recommendation systems, this approach becomes\nincreasingly cumbersome due to the redundancy and sheer scale of the token\nspace. To overcome these limitations, recent research has explored the use of\nsemantic tokens as an alternative to ID tokens, which typically leveraged\nreconstruction-based strategies, like RQ-VAE, to quantize content embeddings\nand significantly reduce the embedding size. However, reconstructive\nquantization aims for the precise reconstruction of each item embedding\nindependently, which conflicts with the goal of generative retrieval tasks\nfocusing more on differentiating among items. Moreover, multi-modal side\ninformation of items, such as descriptive text and images, geographical\nknowledge in location-based recommendation services, has been shown to be\neffective in improving recommendations by providing richer contexts for\ninteractions. Nevertheless, effectively integrating such complementary\nknowledge into existing generative recommendation frameworks remains\nchallenging. To overcome these challenges, we propose a novel unsupervised deep\nquantization exclusively based on contrastive learning, named SimCIT (a Simple\nContrastive Item Tokenization framework). Specifically, different from existing\nreconstruction-based strategies, SimCIT propose to use a learnable residual\nquantization module to align with the signals from different modalities of the\nitems, which combines multi-modal knowledge alignment and semantic tokenization\nin a mutually beneficial contrastive learning framework. Extensive experiments\nacross public datasets and a large-scale industrial dataset from various\ndomains demonstrate SimCIT's effectiveness in LLM-based generative\nrecommendation.\n","authors":["Penglong Zhai","Yifang Yuan","Fanyi Di","Jie Li","Yue Liu","Chen Li","Jie Huang","Sicong Wang","Yao Xu","Xin Li"],"pdf_url":"https://arxiv.org/pdf/2506.16683v1.pdf","comment":"12 pages,7 figures"}],"Databases":[{"id":"http://arxiv.org/abs/2506.17451v1","updated":"2025-06-20T19:39:26Z","published":"2025-06-20T19:39:26Z","title":"Transient Concepts in Streaming Graphs","summary":"  Concept Drift (CD) occurs when a change in a hidden context can induce\nchanges in a target concept. CD is a natural phenomenon in non-stationary\nsettings such as data streams. Understanding, detection, and adaptation to CD\nin streaming data is (i) vital for effective and efficient analytics as\nreliable output depends on adaptation to fresh input, (ii) challenging as it\nrequires efficient operations as well as effective performance evaluations, and\n(iii) impactful as it applies to a variety of use cases and is a crucial\ninitial step for data management systems. Current works are mostly focused on\npassive CD detection as part of supervised adaptation, on independently\ngenerated data instances or graph snapshots, on target concepts as a function\nof data labels, on static data management, and on specific temporal order of\ndata record. These methods do not always work. We revisit CD for the streaming\ngraphs setting and introduce two first-of-its-kind frameworks SGDD and SGDP for\nstreaming graph CD detection and prediction. Both frameworks discern the change\nof generative source. SGDD detects the CDs due to the changes of generative\nparameters with significant delays such that it is difficult to evaluate the\nperformance, while SGDP predicts these CDs between 7374 to 0.19 milliseconds\nahead of their occurrence, without accessing the payloads of data records.\n","authors":["Aida Sheshbolouki","M. Tamer Ozsu"],"pdf_url":"https://arxiv.org/pdf/2506.17451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12911v2","updated":"2025-06-20T13:24:05Z","published":"2025-02-18T14:53:45Z","title":"Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL\n  Generation","summary":"  Generating SQLs from user queries is a long-standing challenge, where the\naccuracy of initial schema linking significantly impacts subsequent SQL\ngeneration performance. However, current schema linking models still struggle\nwith missing relevant schema elements or an excess of redundant ones. A crucial\nreason for this is that commonly used metrics, recall and precision, fail to\ncapture relevant element missing and thus cannot reflect actual schema linking\nperformance. Motivated by this, we propose enhanced schema linking metrics by\nintroducing a restricted missing indicator. Accordingly, we introduce Knapsack\noptimization-based Schema Linking Approach (KaSLA), a plug-in schema linking\nmethod designed to prevent the missing of relevant schema elements while\nminimizing the inclusion of redundant ones. KaSLA employs a hierarchical\nlinking strategy that first identifies the optimal table linking and\nsubsequently links columns within the selected table to reduce linking\ncandidate space. In each linking process, it utilizes a knapsack optimization\napproach to link potentially relevant elements while accounting for a limited\ntolerance of potentially redundant ones. With this optimization, KaSLA-1.6B\nachieves superior schema linking results compared to large-scale LLMs,\nincluding deepseek-v3 with the state-of-the-art (SOTA) schema linking method.\nExtensive experiments on Spider and BIRD benchmarks verify that KaSLA can\nsignificantly improve the SQL generation performance of SOTA Text2SQL models by\nsubstituting their schema linking processes.\n","authors":["Zheng Yuan","Hao Chen","Zijin Hong","Qinggang Zhang","Feiran Huang","Qing Li","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2502.12911v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09530v2","updated":"2025-06-20T13:13:47Z","published":"2025-06-11T09:00:52Z","title":"Linking Data Citation to Repository Visibility: An Empirical Study","summary":"  In today's data-driven research landscape, dataset visibility and\naccessibility play a crucial role in advancing scientific knowledge. At the\nsame time, data citation is essential for maintaining academic integrity,\nacknowledging contributions, validating research outcomes, and fostering\nscientific reproducibility. As a critical link, it connects scholarly\npublications with the datasets that drive scientific progress. This study\ninvestigates whether repository visibility influences data citation rates. We\nhypothesize that repositories with higher visibility, as measured by search\nengine metrics, are associated with increased dataset citations. Using OpenAlex\ndata and repository impact indicators (including the visibility index from\nSistrix, the h-index of repositories, and citation metrics such as mean and\nmedian citations), we analyze datasets in Social Sciences and Economics to\nexplore their relationship. Our findings suggest that datasets hosted on more\nvisible web domains tend to receive more citations, with a positive correlation\nobserved between web domain visibility and dataset citation counts,\nparticularly for datasets with at least one citation. However, when analyzing\ndomain-level citation metrics, such as the h-index, mean, and median citations,\nthe correlations are inconsistent and weaker. While higher visibility domains\ntend to host datasets with greater citation impact, the distribution of\ncitations across datasets varies significantly. These results suggest that\nwhile visibility plays a role in increasing citation counts, it is not the sole\nfactor influencing dataset citation impact. Other elements, such as dataset\nquality, research trends, and disciplinary norms, can also contribute to\ncitation patterns.\n","authors":["Fakhri Momeni","Janete Saldanha Bach","Brigitte Mathiak","Peter Mutschke"],"pdf_url":"https://arxiv.org/pdf/2506.09530v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16976v1","updated":"2025-06-20T13:09:26Z","published":"2025-06-20T13:09:26Z","title":"PUL: Pre-load in Software for Caches Wouldn't Always Play Along","summary":"  Memory latencies and bandwidth are major factors, limiting system performance\nand scalability. Modern CPUs aim at hiding latencies by employing large caches,\nout-of-order execution, or complex hardware prefetchers. However,\nsoftware-based prefetching exhibits higher efficiency, improving with newer CPU\ngenerations.\n  In this paper we investigate software-based, post-Moore systems that offload\noperations to intelligent memories. We show that software-based prefetching has\neven higher potential in near-data processing settings by maximizing compute\nutilization through compute/IO interleaving.\n","authors":["Arthur Bernhardt","Sajjad Tamimi","Florian Stock","Andreas Koch","Ilia Petrov"],"pdf_url":"https://arxiv.org/pdf/2506.16976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.11756v2","updated":"2025-06-20T12:54:46Z","published":"2025-04-16T04:18:25Z","title":"AQETuner: Reliable Query-level Configuration Tuning for Analytical Query\n  Engines","summary":"  Modern analytical query engines (AQEs) are essential for large-scale data\nanalysis and processing. These systems usually provide numerous query-level\ntunable knobs that significantly affect individual query performance. While\nseveral studies have explored automatic DBMS configuration tuning, they have\nseveral limitations to handle query-level tuning. Firstly, they fail to capture\nhow knobs influence query plans, which directly affect query performance.\nSecondly, they overlook query failures during the tuning processing, resulting\nin low tuning efficiency. Thirdly, they struggle with cold-start problems for\nnew queries, leading to prolonged tuning time. To address these challenges, we\npropose AQETuner, a novel Bayesian Optimization-based system tailored for\nreliable query-level knob tuning in AQEs. AQETuner first applies the attention\nmechanisms to jointly encode the knobs and plan query, effectively identifying\nthe impact of knobs on plan nodes. Then, AQETuner employs a dual-task Neural\nProcess to predict both query performance and failures, leveraging their\ninteractions to guide the tuning process. Furthermore, AQETuner utilizes\nParticle Swarm Optimization to efficiently generate high-quality samples in\nparallel during the initial tuning stage for the new queries. Experimental\nresults show that AQETuner significantly outperforms existing methods, reducing\nquery latency by up to 23.7% and query failures by up to 51.2%.\n","authors":["Lixiang Chen","Yuxing Han","Yu Chen","Xing Chen","Chengcheng Yang","Weining Qian"],"pdf_url":"https://arxiv.org/pdf/2504.11756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20233v2","updated":"2025-06-20T12:21:20Z","published":"2025-02-27T16:19:54Z","title":"Selective Use of Yannakakis' Algorithm to Improve Query Performance:\n  Machine Learning to the Rescue","summary":"  Query optimization has played a central role in database research for\ndecades. However, more often than not, the proposed optimization techniques\nlead to a performance improvement in some, but not in all, situations.\nTherefore, we urgently need a methodology for designing a decision procedure\nthat decides for a given query whether the optimization technique should be\napplied or not.\n  In this work, we propose such a methodology with a focus on Yannakakis-style\nquery evaluation as our optimization technique of interest. More specifically,\nwe formulate this decision problem as an algorithm selection problem and we\npresent a Machine Learning based approach for its solution. Empirical results\nwith several benchmarks on a variety of database systems show that our approach\nindeed leads to a statistically significant performance improvement.\n","authors":["Daniela Böhm","Georg Gottlob","Matthias Lanzinger","Davide Longo","Cem Okulmus","Reinhard Pichler","Alexander Selzer"],"pdf_url":"https://arxiv.org/pdf/2502.20233v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16923v1","updated":"2025-06-20T11:30:58Z","published":"2025-06-20T11:30:58Z","title":"Advancing Fact Attribution for Query Answering: Aggregate Queries and\n  Novel Algorithms","summary":"  In this paper, we introduce a novel approach to computing the contribution of\ninput tuples to the result of the query, quantified by the Banzhaf and Shapley\nvalues. In contrast to prior algorithmic work that focuses on\nSelect-Project-Join-Union queries, ours is the first practical approach for\nqueries with aggregates. It relies on two novel optimizations that are\nessential for its practicality and significantly improve the runtime\nperformance already for queries without aggregates. The first optimization\nexploits the observation that many input tuples have the same contribution to\nthe query result, so it is enough to compute the contribution of one of them.\nThe second optimization uses the gradient of the query lineage to compute the\ncontributions of all tuples with the same complexity as for one of them.\nExperiments with a million instances over 3 databases show that our approach\nachieves up to 3 orders of magnitude runtime improvements over the\nstate-of-the-art for queries without aggregates, and that it is practical for\naggregate queries.\n","authors":["Omer Abramovich","Daniel Deutch","Nave Frost","Ahmet Kara","Dan Olteanu"],"pdf_url":"https://arxiv.org/pdf/2506.16923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10601v2","updated":"2025-06-20T05:57:33Z","published":"2024-01-19T10:19:34Z","title":"Influential Slot and Tag Selection in Billboard Advertisement","summary":"  The selection of influential billboard slots remains an important problem in\nbillboard advertisements. Existing studies on this problem have not considered\nthe case of context-specific influence probability. To bridge this gap, in this\npaper, we introduce the Context Dependent Influential Billboard Slot Selection\nProblem. First, we show that the problem is NP-hard. We also show that the\ninfluence function holds the bi-monotonicity, bi-submodularity, and\nnon-negativity properties. We propose an orthant-wise Stochastic Greedy\napproach to solve this problem. We show that this method leads to a\nconstant-factor approximation guarantee. Subsequently, we propose an\northant-wise Incremental and Lazy Greedy approach. In a generic sense, this is\na method for maximizing a bi-submodular function under the cardinality\nconstraint, which may also be of independent interest. We analyze the\nperformance guarantee of this algorithm as well as time and space complexity.\nThe proposed solution approaches have been implemented with real-world\nbillboard and trajectory datasets. We compare the performance of our method\nwith several baseline methods, and the results are reported. Our proposed\northant-wise stochastic greedy approach leads to significant results when the\nparameters are set properly with reasonable computational overhead.\n","authors":["Dildar Ali","Suman Banerjee","Yamuna Prasad"],"pdf_url":"https://arxiv.org/pdf/2401.10601v2.pdf","comment":"15 pages"}]},"2025-06-19T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.16644v1","updated":"2025-06-19T23:06:12Z","published":"2025-06-19T23:06:12Z","title":"Semantic Outlier Removal with Embedding Models and LLMs","summary":"  Modern text processing pipelines demand robust methods to remove extraneous\ncontent while preserving a document's core message. Traditional approaches such\nas HTML boilerplate extraction or keyword filters often fail in multilingual\nsettings and struggle with context-sensitive nuances, whereas Large Language\nModels (LLMs) offer improved quality at high computational cost. We introduce\nSORE (Semantic Outlier Removal), a cost-effective, transparent method that\nleverages multilingual sentence embeddings and approximate nearest-neighbor\nsearch to identify and excise unwanted text segments. By first identifying core\ncontent via metadata embedding and then flagging segments that either closely\nmatch predefined outlier groups or deviate significantly from the core, SORE\nachieves near-LLM extraction precision at a fraction of the cost. Experiments\non HTML datasets demonstrate that SORE outperforms structural methods and yield\nhigh precision in diverse scenarios. Our system is currently deployed in\nproduction, processing millions of documents daily across multiple languages\nwhile maintaining both efficiency and accuracy. To facilitate reproducibility\nand further research, we release our implementation and evaluation datasets.\n","authors":["Eren Akbiyik","João Almeida","Rik Melis","Ritu Sriram","Viviana Petrescu","Vilhjálmur Vilhjálmsson"],"pdf_url":"https://arxiv.org/pdf/2506.16644v1.pdf","comment":"Accepted to the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025) Industry Track, 10 pages"},{"id":"http://arxiv.org/abs/2506.16552v1","updated":"2025-06-19T19:13:59Z","published":"2025-06-19T19:13:59Z","title":"Revela: Dense Retriever Learning via Language Modeling","summary":"  Dense retrievers play a vital role in accessing external and specialized\nknowledge to augment language models (LMs). Training dense retrievers typically\nrequires annotated query-document pairs, which are costly and hard to obtain in\nspecialized domains such as code-motivating growing interest in self-supervised\nretriever learning. Since LMs are trained to capture token-level dependencies\nthrough a self-supervised learning objective (i.e., next-token prediction), we\ncan analogously cast retrieval as learning dependencies among chunks of tokens.\nThis analogy naturally leads to the question: How can we adapt self-supervised\nlearning objectives in the spirit of language modeling to train retrievers?\n  To answer this question, we introduce Revela, a unified and scalable training\nframework for self-supervised retriever learning via language modeling. Revela\nmodels semantic dependencies among documents by conditioning next-token\nprediction on both local and cross-document context through an in-batch\nattention mechanism. This attention is weighted by retriever-computed\nsimilarity scores, enabling the retriever to be optimized as part of language\nmodeling. We evaluate Revela on both general-domain (BEIR) and domain-specific\n(CoIR) benchmarks across various retriever backbones. At a comparable parameter\nscale, Revela outperforms the previous best method with absolute improvements\nof 5.2 % (18.3 % relative) and 5.6 % (14.4 % relative) on NDCG@10,\nrespectively, underscoring its effectiveness. Performance increases with model\nsize, highlighting both the scalability of our approach and its promise for\nself-supervised retriever learning.\n","authors":["Fengyu Cai","Tong Chen","Xinran Zhao","Sihao Chen","Hongming Zhang","Sherry Tongshuang Wu","Iryna Gurevych","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2506.16552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16429v1","updated":"2025-06-19T16:07:31Z","published":"2025-06-19T16:07:31Z","title":"Agentic Personalisation of Cross-Channel Marketing Experiences","summary":"  Consumer applications provide ample opportunities to surface and communicate\nvarious forms of content to users. From promotional campaigns for new features\nor subscriptions, to evergreen nudges for engagement, or personalised\nrecommendations; across e-mails, push notifications, and in-app surfaces. The\nconventional approach to orchestration for communication relies heavily on\nlabour-intensive manual marketer work, and inhibits effective personalisation\nof content, timing, frequency, and copy-writing. We formulate this task under a\nsequential decision-making framework, where we aim to optimise a modular\ndecision-making policy that maximises incremental engagement for any funnel\nevent. Our approach leverages a Difference-in-Differences design for Individual\nTreatment Effect estimation, and Thompson sampling to balance the\nexplore-exploit trade-off. We present results from a multi-service application,\nwhere our methodology has resulted in significant increases to a variety of\ngoal events across several product features, and is currently deployed across\n150 million users.\n","authors":["Sami Abboud","Eleanor Hanna","Olivier Jeunen","Vineesha Raheja","Schaun Wheeler"],"pdf_url":"https://arxiv.org/pdf/2506.16429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16343v1","updated":"2025-06-19T14:21:08Z","published":"2025-06-19T14:21:08Z","title":"Analyzing the Influence of Knowledge Graph Information on Relation\n  Extraction","summary":"  We examine the impact of incorporating knowledge graph information on the\nperformance of relation extraction models across a range of datasets. Our\nhypothesis is that the positions of entities within a knowledge graph provide\nimportant insights for relation extraction tasks. We conduct experiments on\nmultiple datasets, each varying in the number of relations, training examples,\nand underlying knowledge graphs. Our results demonstrate that integrating\nknowledge graph information significantly enhances performance, especially when\ndealing with an imbalance in the number of training examples for each relation.\nWe evaluate the contribution of knowledge graph-based features by combining\nestablished relation extraction methods with graph-aware Neural Bellman-Ford\nnetworks. These features are tested in both supervised and zero-shot settings,\ndemonstrating consistent performance improvements across various datasets.\n","authors":["Cedric Möller","Ricardo Usbeck"],"pdf_url":"https://arxiv.org/pdf/2506.16343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13057v2","updated":"2025-06-19T12:53:17Z","published":"2024-11-20T06:10:06Z","title":"Learning Multi-Branch Cooperation for Enhanced Click-Through Rate\n  Prediction at Taobao","summary":"  Existing click-through rate (CTR) prediction works have studied the role of\nfeature interaction through a variety of techniques. Each interaction technique\nexhibits its own strength, and solely using one type usually constrains the\nmodel's capability to capture the complex feature relationships, especially for\nindustrial data with enormous input feature fields. Recent research shows that\neffective CTR models often combine an MLP network with a dedicated feature\ninteraction network in a two-parallel structure. However, the interplay and\ncooperative dynamics between different streams or branches remain\nunder-researched. In this work, we introduce a novel Multi-Branch Cooperation\nNetwork (MBCnet) which enables multiple branch networks to collaborate with\neach other for better complex feature interaction modeling. Specifically,\nMBCnet consists of three branches: the Extensible Feature Grouping and Crossing\n(EFGC) branch that promotes the model's memorization ability of specific\nfeature fields, the low rank Cross Net branch and Deep branch to enhance\nexplicit and implicit feature crossing for improved generalization. Among these\nbranches, a novel cooperation scheme is proposed based on two principles:\nBranch co-teaching and moderate differentiation. Branch co-teaching encourages\nwell-learned branches to support poorly-learned ones on specific training\nsamples. Moderate differentiation advocates branches to maintain a reasonable\nlevel of difference in their feature representations on the same inputs. This\ncooperation strategy improves learning through mutual knowledge sharing and\nboosts the discovery of diverse feature interactions across branches.\nExperiments on large-scale industrial datasets and online A/B test at Taobao\napp demonstrate MBCnet's superior performance, delivering a 0.09 point increase\nin CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available\nonline.\n","authors":["Xu Chen","Zida Cheng","Yuangang Pan","Shuai Xiao","Xiaoming Liu","Jinsong Lan","Xiaoyong Zhu","Bo Zheng","Ivor W. Tsang"],"pdf_url":"https://arxiv.org/pdf/2411.13057v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2506.13496v3","updated":"2025-06-19T10:08:49Z","published":"2025-06-16T13:53:02Z","title":"Hierarchical Multi-Positive Contrastive Learning for Patent Image\n  Retrieval","summary":"  Patent images are technical drawings that convey information about a patent's\ninnovation. Patent image retrieval systems aim to search in vast collections\nand retrieve the most relevant images. Despite recent advances in information\nretrieval, patent images still pose significant challenges due to their\ntechnical intricacies and complex semantic information, requiring efficient\nfine-tuning for domain adaptation. Current methods neglect patents'\nhierarchical relationships, such as those defined by the Locarno International\nClassification (LIC) system, which groups broad categories (e.g., \"furnishing\")\ninto subclasses (e.g., \"seats\" and \"beds\") and further into specific patent\ndesigns. In this work, we introduce a hierarchical multi-positive contrastive\nloss that leverages the LIC's taxonomy to induce such relations in the\nretrieval process. Our approach assigns multiple positive pairs to each patent\nimage within a batch, with varying similarity scores based on the hierarchical\ntaxonomy. Our experimental analysis with various vision and multimodal models\non the DeepPatent2 dataset shows that the proposed method enhances the\nretrieval results. Notably, our method is effective with low-parameter models,\nwhich require fewer computational resources and can be deployed on environments\nwith limited hardware.\n","authors":["Kshitij Kavimandan","Angelos Nalmpantis","Emma Beauxis-Aussalet","Robert-Jan Sips"],"pdf_url":"https://arxiv.org/pdf/2506.13496v3.pdf","comment":"5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on\n  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located\n  with SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.16146v1","updated":"2025-06-19T08:59:21Z","published":"2025-06-19T08:59:21Z","title":"Neural Prioritisation for Web Crawling","summary":"  Given the vast scale of the Web, crawling prioritisation techniques based on\nlink graph traversal, popularity, link analysis, and textual content are\nfrequently applied to surface documents that are most likely to be valuable.\nWhile existing techniques are effective for keyword-based search, both\nretrieval methods and user search behaviours are shifting from keyword-based\nmatching to natural language semantic matching. The remarkable success of\napplying semantic matching and quality signals during ranking leads us to\nhypothesize that crawling could be improved by prioritizing Web pages with high\nsemantic quality. To investigate this, we propose a semantic quality-driven\nprioritisation technique to enhance the effectiveness of crawling and align the\ncrawler behaviour with recent shift towards natural language search. We embed\nsemantic understanding directly into the crawling process -- leveraging recent\nneural semantic quality estimators to prioritise the crawling frontier -- with\nthe goal of surfacing content that is semantically rich and valuable for modern\nsearch needs. Our experiments on the English subset of ClueWeb22-B and the\nResearchy Questions query set show that, compared to existing crawling\ntechniques, neural crawling policies significantly improve harvest rate,\nmaxNDCG, and search effectiveness during the early stages of crawling.\nMeanwhile, crawlers based on our proposed neural policies maintain comparable\nsearch performance on keyword queries from the MS MARCO Web Search query set.\nWhile this work does not propose a definitive and complete solution, it\npresents a forward-looking perspective on Web crawling and opens the door to a\nnew line of research on leveraging semantic analysis to effectively align\ncrawlers with the ongoing shift toward natural language search.\n","authors":["Francesza Pezzuti","Sean MacAvaney","Nicola Tonellotto"],"pdf_url":"https://arxiv.org/pdf/2506.16146v1.pdf","comment":"Published at ACM ICTIR 2025"},{"id":"http://arxiv.org/abs/2506.16114v1","updated":"2025-06-19T08:04:31Z","published":"2025-06-19T08:04:31Z","title":"GFlowGR: Fine-tuning Generative Recommendation Frameworks with\n  Generative Flow Networks","summary":"  Generative recommendations (GR), which usually include item tokenizers and\ngenerative Large Language Models (LLMs), have demonstrated remarkable success\nacross a wide range of scenarios. The majority of existing research efforts\nprimarily concentrate on developing powerful item tokenizers or advancing LLM\ndecoding strategies to attain superior performance. However, the critical\nfine-tuning step in GR frameworks, which is essential for adapting LLMs to\nrecommendation data, remains largely unexplored. Current approaches\npredominantly rely on either the next-token prediction loss of supervised\nfine-tuning (SFT) or recommendationspecific direct preference optimization\n(DPO) strategies. Both methods ignore the exploration of possible positive\nunobserved samples, which is commonly referred to as the exposure bias problem.\nTo mitigate this problem, this paper treats the GR as a multi-step generation\ntask and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The\nproposed framework integrates collaborative knowledge from traditional\nrecommender systems to create an adaptive trajectory sampler and a\ncomprehensive reward model. Leveraging the diverse generation property of\nGFlowNets, along with sampling and heuristic weighting techniques, GFlowGR\nemerges as a promising approach to mitigate the exposure bias problem.\nExtensive empirical results on two real-world datasets and with two different\nGR backbones highlight the effectiveness and robustness of GFlowGR.\n","authors":["Yejing Wang","Shengyu Zhou","Jinyu Lu","Qidong Liu","Xinhang Li","Wenlin Zhang","Feng Li","Pengjie Wang","Jian Xu","Bo Zheng","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.16114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.23804v2","updated":"2025-06-19T08:01:46Z","published":"2025-03-31T07:35:40Z","title":"DrunkAgent: Stealthy Memory Corruption in LLM-Powered Recommender Agents","summary":"  Large language model (LLM)-powered agents are increasingly used in\nrecommender systems (RSs) to achieve personalized behavior modeling, where the\nmemory mechanism plays a pivotal role in enabling the agents to autonomously\nexplore, learn and self-evolve from real-world interactions. However, this very\nmechanism, serving as a contextual repository, inherently exposes an attack\nsurface for potential adversarial manipulations. Despite its central role, the\nrobustness of agentic RSs in the face of such threats remains largely\nunderexplored. Previous works suffer from semantic mismatches or rely on static\nembeddings or pre-defined prompts, all of which hinder their applicability to\nsystems with dynamic memory states. This challenge is exacerbated by the\nblack-box nature of commercial RSs.\n  To tackle the above problems, in this paper, we present the first systematic\ninvestigation of memory-based vulnerabilities in LLM-powered recommender\nagents, revealing their security limitations and guiding efforts to strengthen\nsystem resilience and trustworthiness. Specifically, we propose a novel\nblack-box attack framework named DrunkAgent. DrunkAgent crafts semantically\nmeaningful adversarial textual triggers for target item promotions and\nintroduces a series of strategies to maximize the trigger effect by corrupting\nthe memory updates during the interactions. The triggers and strategies are\noptimized on a surrogate model, enabling DrunkAgent transferable and stealthy.\nExtensive experiments on real-world datasets across diverse agentic RSs,\nincluding collaborative filtering, retrieval augmentation and sequential\nrecommendations, demonstrate the generalizability, transferability and\nstealthiness of DrunkAgent.\n","authors":["Shiyi Yang","Zhibo Hu","Xinshu Li","Chen Wang","Tong Yu","Xiwei Xu","Liming Zhu","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2503.23804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10545v3","updated":"2025-06-19T07:04:38Z","published":"2025-04-13T15:23:00Z","title":"HSTU-BLaIR: Lightweight Contrastive Text Embedding for Generative\n  Recommender","summary":"  Recent advances in recommender systems have underscored the complementary\nstrengths of generative modeling and pretrained language models. We propose\nHSTU-BLaIR, a hybrid framework that augments the Hierarchical Sequential\nTransduction Unit (HSTU)-based generative recommender with BLaIR, a lightweight\ncontrastive text embedding model. This integration enriches item\nrepresentations with semantic signals from textual metadata while preserving\nHSTU's powerful sequence modeling capabilities.\n  We evaluate HSTU-BLaIR on two e-commerce datasets: three subsets from the\nAmazon Reviews 2023 dataset and the Steam dataset. We compare its performance\nagainst both the original HSTU-based recommender and a variant augmented with\nembeddings from OpenAI's state-of-the-art \\texttt{text-embedding-3-large}\nmodel. Despite the latter being trained on a substantially larger corpus with\nsignificantly more parameters, our lightweight BLaIR-enhanced approach --\npretrained on domain-specific data -- achieves better performance in nearly all\ncases. Specifically, HSTU-BLaIR outperforms the OpenAI embedding-based variant\non all but one metric, where it is marginally lower, and matches it on another.\nThese findings highlight the effectiveness of contrastive text embeddings in\ncompute-efficient recommendation settings.\n","authors":["Yijun Liu"],"pdf_url":"https://arxiv.org/pdf/2504.10545v3.pdf","comment":"Accepted at the Workshop on Large Language Models for E-Commerce, KDD\n  2025. Code available at https://www.github.com/snapfinger/HSTU-BLaIR"},{"id":"http://arxiv.org/abs/2506.16035v1","updated":"2025-06-19T05:11:43Z","published":"2025-06-19T05:11:43Z","title":"Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal\n  Document Understanding","summary":"  Retrieval-Augmented Generation (RAG) systems have revolutionized information\nretrieval and question answering, but traditional text-based chunking methods\nstruggle with complex document structures, multi-page tables, embedded figures,\nand contextual dependencies across page boundaries. We present a novel\nmultimodal document chunking approach that leverages Large Multimodal Models\n(LMMs) to process PDF documents in batches while maintaining semantic coherence\nand structural integrity. Our method processes documents in configurable page\nbatches with cross-batch context preservation, enabling accurate handling of\ntables spanning multiple pages, embedded visual elements, and procedural\ncontent. We evaluate our approach on a curated dataset of PDF documents with\nmanually crafted queries, demonstrating improvements in chunk quality and\ndownstream RAG performance. Our vision-guided approach achieves better accuracy\ncompared to traditional vanilla RAG systems, with qualitative analysis showing\nsuperior preservation of document structure and semantic coherence.\n","authors":["Vishesh Tripathi","Tanmay Odapally","Indraneel Das","Uday Allu","Biddwan Ahmed"],"pdf_url":"https://arxiv.org/pdf/2506.16035v1.pdf","comment":"11 pages, 1 Figure, 1 Table"},{"id":"http://arxiv.org/abs/2506.16003v1","updated":"2025-06-19T03:48:30Z","published":"2025-06-19T03:48:30Z","title":"SEP-GCN: Leveraging Similar Edge Pairs with Temporal and Spatial\n  Contexts for Location-Based Recommender Systems","summary":"  Recommender systems play a crucial role in enabling personalized content\ndelivery amidst the challenges of information overload and human mobility.\nAlthough conventional methods often rely on interaction matrices or graph-based\nretrieval, recent approaches have sought to exploit contextual signals such as\ntime and location. However, most existing models focus on node-level\nrepresentation or isolated edge attributes, underutilizing the relational\nstructure between interactions. We propose SEP-GCN, a novel graph-based\nrecommendation framework that learns from pairs of contextually similar\ninteraction edges, each representing a user-item check-in event. By identifying\nedge pairs that occur within similar temporal windows or geographic proximity,\nSEP-GCN augments the user-item graph with contextual similarity links. These\nlinks bridge distant but semantically related interactions, enabling improved\nlong-range information propagation. The enriched graph is processed via an\nedge-aware convolutional mechanism that integrates contextual similarity into\nthe message-passing process. This allows SEP-GCN to model user preferences more\naccurately and robustly, especially in sparse or dynamic environments.\nExperiments on benchmark data sets show that SEP-GCN consistently outperforms\nstrong baselines in both predictive accuracy and robustness.\n","authors":["Tan Loc Nguyen","Tin T. Tran"],"pdf_url":"https://arxiv.org/pdf/2506.16003v1.pdf","comment":"Accepted for ACM SIGIR Conference on Innovative Concepts and Theories\n  in Information Retrieval (ICTIR) 2025, Padua, Itay"},{"id":"http://arxiv.org/abs/2506.15986v1","updated":"2025-06-19T03:07:12Z","published":"2025-06-19T03:07:12Z","title":"Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive\n  Awareness Capabilities","summary":"  Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces finds\nextensive applications in databases, information retrieval, recommender\nsystems, etc. While graph-based methods have emerged as the leading solution\nfor ANNS due to their superior query performance, they still face several\nchallenges, such as struggling with local optima and redundant computations.\nThese issues arise because existing methods (i) fail to fully exploit the\ntopological information underlying the proximity graph G, and (ii) suffer from\nsevere distribution mismatches between the base data and queries in practice.\n  To this end, this paper proposes GATE, high-tier proximity Graph with\nAdaptive Topology and Query AwarEness, as a lightweight and adaptive module\natop the graph-based indexes to accelerate ANNS. Specifically, GATE formulates\nthe critical problem to identify an optimal entry point in the proximity graph\nfor a given query, facilitating faster online search. By leveraging the\ninherent clusterability of high-dimensional data, GATE first extracts a small\nset of hub nodes V as candidate entry points. Then, resorting to a contrastive\nlearning-based two-tower model, GATE encodes both the structural semantics\nunderlying G and the query-relevant features into the latent representations of\nthese hub nodes V. A navigation graph index on V is further constructed to\nminimize the model inference overhead. Extensive experiments demonstrate that\nGATE achieves a 1.2-2.0X speed-up in query performance compared to\nstate-of-the-art graph-based indexes.\n","authors":["Jiancheng Ruan","Tingyang Chen","Renchi Yang","Xiangyu Ke","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2506.15986v1.pdf","comment":"Accecpted by KDD2025"}],"Databases":[{"id":"http://arxiv.org/abs/2506.16654v1","updated":"2025-06-19T23:51:38Z","published":"2025-06-19T23:51:38Z","title":"Relational Deep Learning: Challenges, Foundations and Next-Generation\n  Architectures","summary":"  Graph machine learning has led to a significant increase in the capabilities\nof models that learn on arbitrary graph-structured data and has been applied to\nmolecules, social networks, recommendation systems, and transportation, among\nother domains. Data in multi-tabular relational databases can also be\nconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -\na new blueprint that enables end-to-end representation learning without\ntraditional feature engineering. Compared to arbitrary graph-structured data,\nrelational entity graphs have key properties: (i) their structure is defined by\nprimary-foreign key relationships between entities in different tables, (ii)\nthe structural connectivity is a function of the relational schema defining a\ndatabase, and (iii) the graph connectivity is temporal and heterogeneous in\nnature. In this paper, we provide a comprehensive review of RDL by first\nintroducing the representation of relational databases as relational entity\ngraphs, and then reviewing public benchmark datasets that have been used to\ndevelop and evaluate recent GNN-based RDL models. We discuss key challenges\nincluding large-scale multi-table integration and the complexities of modeling\ntemporal dynamics and heterogeneous data, while also surveying foundational\nneural network methods and recent architectural advances specialized for\nrelational entity graphs. Finally, we explore opportunities to unify these\ndistinct modeling challenges, highlighting how RDL converges multiple\nsub-fields in graph machine learning towards the design of foundation models\nthat can transform the processing of relational data.\n","authors":["Vijay Prakash Dwivedi","Charilaos Kanatsoulis","Shenyang Huang","Jure Leskovec"],"pdf_url":"https://arxiv.org/pdf/2506.16654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16616v1","updated":"2025-06-19T21:27:03Z","published":"2025-06-19T21:27:03Z","title":"LDI: Localized Data Imputation","summary":"  Missing values are a common challenge in real-world tabular data and can\nsignificantly impair downstream analysis. While Large Language Models (LLMs)\nhave recently shown promise in data imputation, existing methods often rely on\nbroad, unfiltered prompts that compromise accuracy, scalability, and\nexplainability. We introduce LDI (Localized Data Imputation), a novel framework\nthat improves both the accuracy and transparency of LLM-based imputation by\nselecting a compact, contextually relevant subset of attributes and tuples for\neach missing value. This localized prompting reduces noise, enables\ntraceability by revealing which data influenced each prediction, and is\neffective across both hosted LLMs and lightweight local models. Our extensive\nexperiments on four real-world datasets show that LDI outperforms\nstate-of-the-art methods, achieving up to 8% higher accuracy when using hosted\nLLMs. The gains are more substantial with lightweight local models, reaching\nnearly 17% and 97% accuracy on some datasets when using 3 and 10 examples,\nrespectively. In addition to higher accuracy, LDI offers improved\ninterpretability and robustness to data inconsistencies, making it well-suited\nfor high-stakes and privacy-sensitive applications.\n","authors":["Soroush Omidvartehrani","Davood Rafiei"],"pdf_url":"https://arxiv.org/pdf/2506.16616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16444v1","updated":"2025-06-19T16:26:51Z","published":"2025-06-19T16:26:51Z","title":"REIS: A High-Performance and Energy-Efficient Retrieval System with\n  In-Storage Processing","summary":"  Large Language Models (LLMs) face an inherent challenge: their knowledge is\nconfined to the data that they have been trained on. To overcome this issue,\nRetrieval-Augmented Generation (RAG) complements the static training-derived\nknowledge of LLMs with an external knowledge repository. RAG consists of three\nstages: indexing, retrieval, and generation. The retrieval stage of RAG becomes\na significant bottleneck in inference pipelines. In this stage, a user query is\nmapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)\nalgorithm searches for similar vectors in the database to identify relevant\nitems. Due to the large database sizes, ANNS incurs significant data movement\noverheads between the host and the storage system. To alleviate these\noverheads, prior works propose In-Storage Processing (ISP) techniques that\naccelerate ANNS by performing computations inside storage. However, existing\nworks that leverage ISP for ANNS (i) employ algorithms that are not tailored to\nISP systems, (ii) do not accelerate data retrieval operations for data selected\nby ANNS, and (iii) introduce significant hardware modifications, limiting\nperformance and hindering their adoption. We propose REIS, the first ISP system\ntailored for RAG that addresses these limitations with three key mechanisms.\nFirst, REIS employs a database layout that links database embedding vectors to\ntheir associated documents, enabling efficient retrieval. Second, it enables\nefficient ANNS by introducing an ISP-tailored data placement technique that\ndistributes embeddings across the planes of the storage system and employs a\nlightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that\nuses the existing computational resources inside the storage system. Compared\nto a server-grade system, REIS improves the performance (energy efficiency) of\nretrieval by an average of 13x (55x).\n","authors":["Kangqi Chen","Andreas Kosmas Kakolyris","Rakesh Nadig","Manos Frouzakis","Nika Mansouri Ghiasi","Yu Liang","Haiyu Mao","Jisung Park","Mohammad Sadrosadati","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2506.16444v1.pdf","comment":"Extended version of our publication at the 52nd International\n  Symposium on Computer Architecture (ISCA-52), 2025"},{"id":"http://arxiv.org/abs/2506.16379v1","updated":"2025-06-19T14:59:01Z","published":"2025-06-19T14:59:01Z","title":"PBench: Workload Synthesizer with Real Statistics for Cloud Analytics\n  Benchmarking","summary":"  Cloud service providers commonly use standard benchmarks like TPC-H and\nTPC-DS to evaluate and optimize cloud data analytics systems. However, these\nbenchmarks rely on fixed query patterns and fail to capture the real execution\nstatistics of production cloud workloads. Although some cloud database vendors\nhave recently released real workload traces, these traces alone do not qualify\nas benchmarks, as they typically lack essential components like the original\nSQL queries and their underlying databases. To overcome this limitation, this\npaper introduces a new problem of workload synthesis with real statistics,\nwhich aims to generate synthetic workloads that closely approximate real\nexecution statistics, including key performance metrics and operator\ndistributions, in real cloud workloads. To address this problem, we propose\nPBench, a novel workload synthesizer that constructs synthetic workloads by\njudiciously selecting and combining workload components (i.e., queries and\ndatabases) from existing benchmarks. This paper studies the key challenges in\nPBench. First, we address the challenge of balancing performance metrics and\noperator distributions by introducing a multi-objective optimization-based\ncomponent selection method. Second, to capture the temporal dynamics of real\nworkloads, we design a timestamp assignment method that progressively refines\nworkload timestamps. Third, to handle the disparity between the original\nworkload and the candidate workload, we propose a component augmentation\napproach that leverages large language models (LLMs) to generate additional\nworkload components while maintaining statistical fidelity. We evaluate PBench\non real cloud workload traces, demonstrating that it reduces approximation\nerror by up to 6x compared to state-of-the-art methods.\n","authors":["Yan Zhou","Chunwei Liu","Bhuvan Urgaonkar","Zhengle Wang","Magnus Mueller","Chao Zhang","Songyue Zhang","Pascal Pfeil","Dominik Horn","Zhengchun Liu","Davide Pagano","Tim Kraska","Samuel Madden","Ju Fan"],"pdf_url":"https://arxiv.org/pdf/2506.16379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14772v2","updated":"2025-06-19T14:02:19Z","published":"2025-03-28T16:12:09Z","title":"SimBank: from Simulation to Solution in Prescriptive Process Monitoring","summary":"  Prescriptive Process Monitoring (PresPM) is an emerging area within Process\nMining, focused on optimizing processes through real-time interventions for\neffective decision-making. PresPM holds significant promise for organizations\nseeking enhanced operational performance. However, the current literature faces\ntwo key limitations: a lack of extensive comparisons between techniques and\ninsufficient evaluation approaches. To address these gaps, we introduce\nSimBank: a simulator designed for accurate benchmarking of PresPM methods.\nModeled after a bank's loan application process, SimBank enables extensive\ncomparisons of both online and offline PresPM methods. It incorporates a\nvariety of intervention optimization problems with differing levels of\ncomplexity and supports experiments on key causal machine learning challenges,\nsuch as assessing a method's robustness to confounding in data. SimBank\nadditionally offers a comprehensive evaluation capability: for each test case,\nit can generate the true outcome under each intervention action, which is not\npossible using recorded datasets. The simulator incorporates parallel\nactivities and loops, drawing from common logs to generate cases that closely\nresemble real-life process instances. Our proof of concept demonstrates\nSimBank's benchmarking capabilities through experiments with various PresPM\nmethods across different interventions, highlighting its value as a publicly\navailable simulator for advancing research and practice in PresPM.\n","authors":["Jakob De Moor","Hans Weytjens","Johannes De Smedt","Jochen De Weerdt"],"pdf_url":"https://arxiv.org/pdf/2506.14772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16087v1","updated":"2025-06-19T07:21:16Z","published":"2025-06-19T07:21:16Z","title":"Consistency Verification in Ontology-Based Process Models with Parameter\n  Interdependencies","summary":"  The formalization of process knowledge using ontologies enables consistent\nmodeling of parameter interdependencies in manufacturing. These\ninterdependencies are typically represented as mathematical expressions that\ndefine relations between process parameters, supporting tasks such as\ncalculation, validation, and simulation. To support cross-context application\nand knowledge reuse, such expressions are often defined in a generic form and\napplied across multiple process contexts. This highlights the necessity of a\nconsistent and semantically coherent model to ensure the correctness of data\nretrieval and interpretation. Consequently, dedicated mechanisms are required\nto address key challenges such as selecting context-relevant data, ensuring\nunit compatibility between variables and data elements, and verifying the\ncompleteness of input data required for evaluating mathematical expressions.\nThis paper presents a set of verification mechanisms for a previously developed\nontology-based process model that integrates standardized process semantics,\ndata element definitions, and formal mathematical constructs. The approach\nincludes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a\nunit consistency check based on expected-unit annotations and semantic\nclassification, and (iii) a data completeness check to validate the\nevaluability of interdependencies. The applicability of the approach is\ndemonstrated with a use case from Resin Transfer Molding (RTM), supporting the\ndevelopment of machine-interpretable and verifiable engineering models.\n","authors":["Tom Jeleniewski","Hamied Nabizada","Jonathan Reif","Felix Gehlhoff","Alexander Fay"],"pdf_url":"https://arxiv.org/pdf/2506.16087v1.pdf","comment":"This paper is accepted at IEEE ETFA 2025 and will be published in the\n  conference proceedings"},{"id":"http://arxiv.org/abs/2506.16051v1","updated":"2025-06-19T06:09:01Z","published":"2025-06-19T06:09:01Z","title":"From Data to Decision: Data-Centric Infrastructure for Reproducible ML\n  in Collaborative eScience","summary":"  Reproducibility remains a central challenge in machine learning (ML),\nespecially in collaborative eScience projects where teams iterate over data,\nfeatures, and models. Current ML workflows are often dynamic yet fragmented,\nrelying on informal data sharing, ad hoc scripts, and loosely connected tools.\nThis fragmentation impedes transparency, reproducibility, and the adaptability\nof experiments over time. This paper introduces a data-centric framework for\nlifecycle-aware reproducibility, centered around six structured artifacts:\nDataset, Feature, Workflow, Execution, Asset, and Controlled Vocabulary. These\nartifacts formalize the relationships between data, code, and decisions,\nenabling ML experiments to be versioned, interpretable, and traceable over\ntime. The approach is demonstrated through a clinical ML use case of glaucoma\ndetection, illustrating how the system supports iterative exploration, improves\nreproducibility, and preserves the provenance of collaborative decisions across\nthe ML lifecycle.\n","authors":["Zhiwei Li","Carl Kesselman","Tran Huy Nguyen","Benjamin Yixing Xu","Kyle Bolo","Kimberley Yu"],"pdf_url":"https://arxiv.org/pdf/2506.16051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.16015v1","updated":"2025-06-19T04:22:35Z","published":"2025-06-19T04:22:35Z","title":"Bayesian Epistemology with Weighted Authority: A Formal Architecture for\n  Truth-Promoting Autonomous Scientific Reasoning","summary":"  The exponential expansion of scientific literature has surpassed the\nepistemic processing capabilities of both human experts and current artificial\nintelligence systems. This paper introduces Bayesian Epistemology with Weighted\nAuthority (BEWA), a formally structured architecture that operationalises\nbelief as a dynamic, probabilistically coherent function over structured\nscientific claims. Each claim is contextualised, author-attributed, and\nevaluated through a system of replication scores, citation weighting, and\ntemporal decay. Belief updates are performed via evidence-conditioned Bayesian\ninference, contradiction processing, and epistemic decay mechanisms. The\narchitecture supports graph-based claim propagation, authorial credibility\nmodelling, cryptographic anchoring, and zero-knowledge audit verification. By\nformalising scientific reasoning into a computationally verifiable epistemic\nnetwork, BEWA advances the foundation for machine reasoning systems that\npromote truth utility, rational belief convergence, and audit-resilient\nintegrity across dynamic scientific domains.\n","authors":["Craig S. Wright"],"pdf_url":"https://arxiv.org/pdf/2506.16015v1.pdf","comment":"91 pages, 0 figures, includes mathematical appendix and formal\n  proofs. Designed as a foundational submission for a modular autonomous\n  epistemic reasoning system. Suitable for logic in computer science, AI\n  epistemology, and scientific informatics"},{"id":"http://arxiv.org/abs/2506.16007v1","updated":"2025-06-19T03:58:31Z","published":"2025-06-19T03:58:31Z","title":"Data-Agnostic Cardinality Learning from Imperfect Workloads","summary":"  Cardinality estimation (CardEst) is a critical aspect of query optimization.\nTraditionally, it leverages statistics built directly over the data. However,\norganizational policies (e.g., regulatory compliance) may restrict global data\naccess. Fortunately, query-driven cardinality estimation can learn CardEst\nmodels using query workloads. However, existing query-driven models often\nrequire access to data or summaries for best performance, and they assume\nperfect training workloads with complete and balanced join templates (or join\ngraphs). Such assumptions rarely hold in real-world scenarios, in which join\ntemplates are incomplete and imbalanced. We present GRASP, a data-agnostic\ncardinality learning system designed to work under these real-world\nconstraints. GRASP's compositional design generalizes to unseen join templates\nand is robust to join template imbalance. It also introduces a new per-table\nCardEst model that handles value distribution shifts for range predicates, and\na novel learned count sketch model that captures join correlations across base\nrelations. Across three database instances, we demonstrate that GRASP\nconsistently outperforms existing query-driven models on imperfect workloads,\nboth in terms of estimation accuracy and query latency. Remarkably, GRASP\nachieves performance comparable to, or even surpassing, traditional approaches\nbuilt over the underlying data on the complex CEB-IMDb-full benchmark --\ndespite operating without any data access and using only 10% of all possible\njoin templates.\n","authors":["Peizhi Wu","Rong Kang","Tieying Zhang","Jianjun Chen","Ryan Marcus","Zachary G. Ives"],"pdf_url":"https://arxiv.org/pdf/2506.16007v1.pdf","comment":"14 pages. Technical Report (Extended Version)"},{"id":"http://arxiv.org/abs/2506.15987v1","updated":"2025-06-19T03:16:25Z","published":"2025-06-19T03:16:25Z","title":"Filter-Centric Vector Indexing: Geometric Transformation for Efficient\n  Filtered Vector Search","summary":"  The explosive growth of vector search applications demands efficient handling\nof combined vector similarity and attribute filtering; a challenge where\ncurrent approaches force an unsatisfying choice between performance and\naccuracy. We introduce Filter-Centric Vector Indexing (FCVI), a novel framework\nthat transforms this fundamental trade-off by directly encoding filter\nconditions into the vector space through a mathematically principled\ntransformation $\\psi(v, f, \\alpha)$. Unlike specialized solutions, FCVI works\nwith any existing vector index (HNSW, FAISS, ANNOY) while providing theoretical\nguarantees on accuracy. Our comprehensive evaluation demonstrates that FCVI\nachieves 2.6-3.0 times higher throughput than state-of-the-art methods while\nmaintaining comparable recall. More remarkably, FCVI exhibits exceptional\nstability under distribution shifts; maintaining consistent performance when\nfilter patterns or vector distributions change, unlike traditional approaches\nthat degrade significantly. This combination of performance, compatibility, and\nresilience positions FCVI as an immediately applicable solution for production\nvector search systems requiring flexible filtering capabilities.\n","authors":["Alireza Heidari","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.15987v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2506.15986v1","updated":"2025-06-19T03:07:12Z","published":"2025-06-19T03:07:12Z","title":"Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive\n  Awareness Capabilities","summary":"  Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces finds\nextensive applications in databases, information retrieval, recommender\nsystems, etc. While graph-based methods have emerged as the leading solution\nfor ANNS due to their superior query performance, they still face several\nchallenges, such as struggling with local optima and redundant computations.\nThese issues arise because existing methods (i) fail to fully exploit the\ntopological information underlying the proximity graph G, and (ii) suffer from\nsevere distribution mismatches between the base data and queries in practice.\n  To this end, this paper proposes GATE, high-tier proximity Graph with\nAdaptive Topology and Query AwarEness, as a lightweight and adaptive module\natop the graph-based indexes to accelerate ANNS. Specifically, GATE formulates\nthe critical problem to identify an optimal entry point in the proximity graph\nfor a given query, facilitating faster online search. By leveraging the\ninherent clusterability of high-dimensional data, GATE first extracts a small\nset of hub nodes V as candidate entry points. Then, resorting to a contrastive\nlearning-based two-tower model, GATE encodes both the structural semantics\nunderlying G and the query-relevant features into the latent representations of\nthese hub nodes V. A navigation graph index on V is further constructed to\nminimize the model inference overhead. Extensive experiments demonstrate that\nGATE achieves a 1.2-2.0X speed-up in query performance compared to\nstate-of-the-art graph-based indexes.\n","authors":["Jiancheng Ruan","Tingyang Chen","Renchi Yang","Xiangyu Ke","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2506.15986v1.pdf","comment":"Accecpted by KDD2025"}]},"2025-06-18T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.15862v1","updated":"2025-06-18T20:15:23Z","published":"2025-06-18T20:15:23Z","title":"MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense,\n  and Human Retrievers","summary":"  Retrieval-augmented Generation (RAG) is powerful, but its effectiveness\nhinges on which retrievers we use and how. Different retrievers offer distinct,\noften complementary signals: BM25 captures lexical matches; dense retrievers,\nsemantic similarity. Yet in practice, we typically fix a single retriever based\non heuristics, which fails to generalize across diverse information needs. Can\nwe dynamically select and integrate multiple retrievers for each individual\nquery, without the need for manual selection? In our work, we validate this\nintuition with quantitative analysis and introduce mixture of retrievers: a\nzero-shot, weighted combination of heterogeneous retrievers. Extensive\nexperiments show that such mixtures are effective and efficient: Despite\ntotaling just 0.8B parameters, this mixture outperforms every individual\nretriever and even larger 7B models by +10.8% and +3.9% on average,\nrespectively. Further analysis also shows that this mixture framework can help\nincorporate specialized non-oracle human information sources as retrievers to\nachieve good collaboration, with a 58.9% relative performance improvement over\nsimulated humans alone.\n","authors":["Jushaan Singh Kalra","Xinran Zhao","To Eun Kim","Fengyu Cai","Fernando Diaz","Tongshuang Wu"],"pdf_url":"https://arxiv.org/pdf/2506.15862v1.pdf","comment":"19 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.15841v1","updated":"2025-06-18T19:44:46Z","published":"2025-06-18T19:44:46Z","title":"MEM1: Learning to Synergize Memory and Reasoning for Efficient\n  Long-Horizon Agents","summary":"  Modern language agents must operate over long-horizon, multi-turn\ninteractions, where they retrieve external information, adapt to observations,\nand answer interdependent queries. Yet, most LLM systems rely on full-context\nprompting, appending all past turns regardless of their relevance. This leads\nto unbounded memory growth, increased computational costs, and degraded\nreasoning performance on out-of-distribution input lengths. We introduce MEM1,\nan end-to-end reinforcement learning framework that enables agents to operate\nwith constant memory across long multi-turn tasks. At each turn, MEM1 updates a\ncompact shared internal state that jointly supports memory consolidation and\nreasoning. This state integrates prior memory with new observations from the\nenvironment while strategically discarding irrelevant or redundant information.\nTo support training in more realistic and compositional settings, we propose a\nsimple yet effective and scalable approach to constructing multi-turn\nenvironments by composing existing datasets into arbitrarily complex task\nsequences. Experiments across three domains, including internal retrieval QA,\nopen-domain web QA, and multi-turn web shopping, show that MEM1-7B improves\nperformance by 3.5x while reducing memory usage by 3.7x compared to\nQwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes\nbeyond the training horizon. Our results demonstrate the promise of\nreasoning-driven memory consolidation as a scalable alternative to existing\nsolutions for training long-horizon interactive agents, where both efficiency\nand performance are optimized.\n","authors":["Zijian Zhou","Ao Qu","Zhaoxuan Wu","Sunghwan Kim","Alok Prakash","Daniela Rus","Jinhua Zhao","Bryan Kian Hsiang Low","Paul Pu Liang"],"pdf_url":"https://arxiv.org/pdf/2506.15841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15833v1","updated":"2025-06-18T19:18:49Z","published":"2025-06-18T19:18:49Z","title":"Architecture is All You Need: Improving LLM Recommenders by Dropping the\n  Text","summary":"  In recent years, there has been an explosion of interest in the applications\nof large pre-trained language models (PLMs) to recommender systems, with many\nstudies showing strong performance of PLMs on common benchmark datasets.\nPLM-based recommender models benefit from flexible and customizable prompting,\nan unlimited vocabulary of recommendable items, and general ``world knowledge''\nacquired through pre-training on massive text corpora. While PLM-based\nrecommenders show promise in settings where data is limited, they are hard to\nimplement in practice due to their large size and computational cost.\nAdditionally, fine-tuning PLMs to improve performance on collaborative signals\nmay degrade the model's capacity for world knowledge and generalizability. We\npropose a recommender model that uses the architecture of large language models\n(LLMs) while reducing layer count and dimensions and replacing the text-based\nsubword tokenization of a typical LLM with discrete tokens that uniquely\nrepresent individual content items. We find that this simplified approach\nsubstantially outperforms both traditional sequential recommender models and\nPLM-based recommender models at a tiny fraction of the size and computational\ncomplexity of PLM-based models. Our results suggest that the principal benefit\nof LLMs in recommender systems is their architecture, rather than the world\nknowledge acquired during extensive pre-training.\n","authors":["Kevin Foley","Shaghayegh Agah","Kavya Priyanka Kakinada"],"pdf_url":"https://arxiv.org/pdf/2506.15833v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2506.15655v1","updated":"2025-06-18T17:31:51Z","published":"2025-06-18T17:31:51Z","title":"cAST: Enhancing Code Retrieval-Augmented Generation with Structural\n  Chunking via Abstract Syntax Tree","summary":"  Retrieval-Augmented Generation (RAG) has become essential for large-scale\ncode generation, grounding predictions in external code corpora to improve\nactuality. However, a critical yet underexplored aspect of RAG pipelines is\nchunking -- the process of dividing documents into retrievable units. Existing\nline-based chunking heuristics often break semantic structures, splitting\nfunctions or merging unrelated code, which can degrade generation quality. We\npropose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method\nthat recursively breaks large AST nodes into smaller chunks and merges sibling\nnodes while respecting size limits. This approach generates self-contained,\nsemantically coherent units across programming languages and tasks, improving\nperformance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3\npoints on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.\nOur work highlights the importance of structure-aware chunking for scaling\nretrieval-enhanced code intelligence.\n","authors":["Yilin Zhang","Xinran Zhao","Zora Zhiruo Wang","Chenyang Yang","Jiayi Wei","Tongshuang Wu"],"pdf_url":"https://arxiv.org/pdf/2506.15655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14651v3","updated":"2025-06-18T14:49:00Z","published":"2022-05-29T13:14:53Z","title":"Contributions to Representation Learning with Graph Autoencoders and\n  Applications to Music Recommendation","summary":"  Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as\ntwo powerful groups of unsupervised node embedding methods, with various\napplications to graph-based machine learning problems such as link prediction\nand community detection. Nonetheless, at the beginning of this Ph.D. project,\nGAE and VGAE models were also suffering from key limitations, preventing them\nfrom being adopted in the industry. In this thesis, we present several\ncontributions to improve these models, with the general aim of facilitating\ntheir use to address industrial-level problems involving graph representations.\nFirstly, we propose two strategies to overcome the scalability issues of\nprevious GAE and VGAE models, permitting to effectively train these models on\nlarge graphs with millions of nodes and edges. These strategies leverage graph\ndegeneracy and stochastic subgraph decoding techniques, respectively. Besides,\nwe introduce Gravity-Inspired GAE and VGAE, providing the first extensions of\nthese models for directed graphs, that are ubiquitous in industrial\napplications. We also consider extensions of GAE and VGAE models for dynamic\ngraphs. Furthermore, we argue that GAE and VGAE models are often unnecessarily\ncomplex, and we propose to simplify them by leveraging linear encoders. Lastly,\nwe introduce Modularity-Aware GAE and VGAE to improve community detection on\ngraphs, while jointly preserving good performances on link prediction. In the\nlast part of this thesis, we evaluate our methods on several graphs extracted\nfrom the music streaming service Deezer. We put the emphasis on graph-based\nmusic recommendation problems. In particular, we show that our methods can\nimprove the detection of communities of similar musical items to recommend to\nusers, that they can effectively rank similar artists in a cold start setting,\nand that they permit modeling the music genre perception across cultures.\n","authors":["Guillaume Salha-Galvan"],"pdf_url":"https://arxiv.org/pdf/2205.14651v3.pdf","comment":"Ph.D. thesis defended at \\'Ecole Polytechnique (IPP) in March 2022.\n  As mentioned in this thesis, several chapters present results also published\n  in scientific articles written with co-authors"},{"id":"http://arxiv.org/abs/2409.20302v3","updated":"2025-06-18T13:36:39Z","published":"2024-09-30T14:00:04Z","title":"OM4OV: Leveraging Ontology Matching for Ontology Versioning","summary":"  Due to the dynamic nature of the Semantic Web, version control is necessary\nto capture time-varying information, particularly for widely used ontologies.\nDespite the long-standing recognition of ontology versioning (OV) as a crucial\ncomponent for efficient ontology management, the growing size of ontologies and\naccumulating errors caused by manual labour overwhelm current OV approaches. In\nthis paper, we propose yet another approach to performing OV using existing\nontology matching (OM) techniques and systems. We introduce a unified OM4OV\npipeline. From an OM perspective, we reconstruct a new task formulation and\nmeasurement for OV tasks. Building upon the prior alignment(s) from OM, we\npropose a pipeline optimisation method called the cross-reference (CR)\nmechanism to enhance overall OV performance. We experimentally validate the\nOM4OV pipeline and the cross-reference mechanism in the OV tested originating\nfrom the Ontology Alignment Evaluation Initiative (OAEI) datasets. We also\ndiscuss insights into OM used for OV tasks, where some false mappings detected\nby OV systems are not actually untrue.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"https://arxiv.org/pdf/2409.20302v3.pdf","comment":"15 pages, 8 figures, 1 table"},{"id":"http://arxiv.org/abs/2506.15284v1","updated":"2025-06-18T09:05:32Z","published":"2025-06-18T09:05:32Z","title":"Multi-Interest Recommendation: A Survey","summary":"  Existing recommendation methods often struggle to model users' multifaceted\npreferences due to the diversity and volatility of user behavior, as well as\nthe inherent uncertainty and ambiguity of item attributes in practical\nscenarios. Multi-interest recommendation addresses this challenge by extracting\nmultiple interest representations from users' historical interactions, enabling\nfine-grained preference modeling and more accurate recommendations. It has\ndrawn broad interest in recommendation research. However, current\nrecommendation surveys have either specialized in frontier recommendation\nmethods or delved into specific tasks and downstream applications. In this\nwork, we systematically review the progress, solutions, challenges, and future\ndirections of multi-interest recommendation by answering the following three\nquestions: (1) Why is multi-interest modeling significantly important for\nrecommendation? (2) What aspects are focused on by multi-interest modeling in\nrecommendation? and (3) How can multi-interest modeling be applied, along with\nthe technical details of the representative modules? We hope that this survey\nestablishes a fundamental framework and delivers a preliminary overview for\nresearchers interested in this field and committed to further exploration. The\nimplementation of multi-interest recommendation summarized in this survey is\nmaintained at https://github.com/WHUIR/Multi-Interest-Recommendation-A-Survey.\n","authors":["Zihao Li","Qiang Chen","Lixin Zou","Aixin Sun","Chenliang Li"],"pdf_url":"https://arxiv.org/pdf/2506.15284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15267v1","updated":"2025-06-18T08:42:01Z","published":"2025-06-18T08:42:01Z","title":"Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative\n  Next-User Modeling","summary":"  The item cold-start problem is critical for online recommendation systems, as\nthe success of this phase determines whether high-quality new items can\ntransition to popular ones, receive essential feedback to inspire creators, and\nthus lead to the long-term retention of creators. However, modern\nrecommendation systems still struggle to address item cold-start challenges due\nto the heavy reliance on item and historical interactions, which are\nnon-trivial for cold-start items lacking sufficient exposure and feedback.\nLookalike algorithms provide a promising solution by extending feedback for new\nitems based on lookalike users. Traditional lookalike algorithms face such\nlimitations: (1) failing to effectively model the lookalike users and further\nimprove recommendations with the existing rule- or model-based methods; and (2)\nstruggling to utilize the interaction signals and incorporate diverse features\nin modern recommendation systems.\n  Inspired by lookalike algorithms, we propose Next-User Retrieval, a novel\nframework for enhancing cold-start recommendations via generative next-user\nmodeling. Specifically, we employ a transformer-based model to capture the\nunidirectional relationships among recently interacted users and utilize these\nsequences to generate the next potential user who is most likely to interact\nwith the item. The additional item features are also integrated as prefix\nprompt embeddings to assist the next-user generation. The effectiveness of\nNext-User Retrieval is evaluated through both offline experiments and online\nA/B tests. Our method achieves significant improvements with increases of\n0.0142% in daily active users and +0.1144% in publications in Douyin,\nshowcasing its practical applicability and scalability.\n","authors":["Yu-Ting Lan","Yang Huo","Yi Shen","Xiao Yang","Zuotao Liu"],"pdf_url":"https://arxiv.org/pdf/2506.15267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01375v2","updated":"2025-06-18T06:33:31Z","published":"2025-06-02T07:04:16Z","title":"Generative Next POI Recommendation with Semantic ID","summary":"  Point-of-interest (POI) recommendation systems aim to predict the next\ndestinations of user based on their preferences and historical check-ins.\nExisting generative POI recommendation methods usually employ random numeric\nIDs for POIs, limiting the ability to model semantic relationships between\nsimilar locations. In this paper, we propose Generative Next POI Recommendation\nwith Semantic ID (GNPR-SID), an LLM-based POI recommendation model with a novel\nsemantic POI ID (SID) representation method that enhances the semantic\nunderstanding of POI modeling. There are two key components in our GNPR-SID:\n(1) a Semantic ID Construction module that generates semantically rich POI IDs\nbased on semantic and collaborative features, and (2) a Generative POI\nRecommendation module that fine-tunes LLMs to predict the next POI using these\nsemantic IDs. By incorporating user interaction patterns and POI semantic\nfeatures into the semantic ID generation, our method improves the\nrecommendation accuracy and generalization of the model. To construct\nsemantically related SIDs, we propose a POI quantization method based on\nresidual quantized variational autoencoder, which maps POIs into a discrete\nsemantic space. We also propose a diversity loss to ensure that SIDs are\nuniformly distributed across the semantic space. Extensive experiments on three\nbenchmark datasets demonstrate that GNPR-SID substantially outperforms\nstate-of-the-art methods, achieving up to 16% improvement in recommendation\naccuracy.\n","authors":["Dongsheng Wang","Yuxi Huang","Shen Gao","Yifan Wang","Chengrui Huang","Shuo Shang"],"pdf_url":"https://arxiv.org/pdf/2506.01375v2.pdf","comment":"11 pages, 4 figures, the paper has been accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2506.15120v1","updated":"2025-06-18T03:39:13Z","published":"2025-06-18T03:39:13Z","title":"Advancing Loss Functions in Recommender Systems: A Comparative Study\n  with a Rényi Divergence-Based Solution","summary":"  Loss functions play a pivotal role in optimizing recommendation models. Among\nvarious loss functions, Softmax Loss (SL) and Cosine Contrastive Loss (CCL) are\nparticularly effective. Their theoretical connections and differences warrant\nin-depth exploration. This work conducts comprehensive analyses of these\nlosses, yielding significant insights: 1) Common strengths -- both can be\nviewed as augmentations of traditional losses with Distributional Robust\nOptimization (DRO), enhancing robustness to distributional shifts; 2)\nRespective limitations -- stemming from their use of different distribution\ndistance metrics in DRO optimization, SL exhibits high sensitivity to false\nnegative instances, whereas CCL suffers from low data utilization. To address\nthese limitations, this work proposes a new loss function, DrRL, which\ngeneralizes SL and CCL by leveraging R\\'enyi-divergence in DRO optimization.\nDrRL incorporates the advantageous structures of both SL and CCL, and can be\ndemonstrated to effectively mitigate their limitations. Extensive experiments\nhave been conducted to validate the superiority of DrRL on both recommendation\naccuracy and robustness.\n","authors":["Shengjia Zhang","Jiawei Chen","Changdong Li","Sheng Zhou","Qihao Shi","Yan Feng","Chun Chen","Can Wang"],"pdf_url":"https://arxiv.org/pdf/2506.15120v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2407.06060v3","updated":"2025-06-18T02:04:36Z","published":"2024-07-08T16:01:04Z","title":"MERGE -- A Bimodal Audio-Lyrics Dataset for Static Music Emotion\n  Recognition","summary":"  The Music Emotion Recognition (MER) field has seen steady developments in\nrecent years, with contributions from feature engineering, machine learning,\nand deep learning. The landscape has also shifted from audio-centric systems to\nbimodal ensembles that combine audio and lyrics. However, a lack of public,\nsizable and quality-controlled bimodal databases has hampered the development\nand improvement of bimodal audio-lyrics systems. This article proposes three\nnew audio, lyrics, and bimodal MER research datasets, collectively referred to\nas MERGE, which were created using a semi-automatic approach. To\ncomprehensively assess the proposed datasets and establish a baseline for\nbenchmarking, we conducted several experiments for each modality, using feature\nengineering, machine learning, and deep learning methodologies. Additionally,\nwe propose and validate fixed train-validation-test splits. The obtained\nresults confirm the viability of the proposed datasets, achieving the best\noverall result of 81.74\\% F1-score for bimodal classification.\n","authors":["Pedro Lima Louro","Hugo Redinho","Ricardo Santos","Ricardo Malheiro","Renato Panda","Rui Pedro Paiva"],"pdf_url":"https://arxiv.org/pdf/2407.06060v3.pdf","comment":"18 pages, 2 figures, 8 tables, submitted to IEEE Transactions on\n  Affective Computing"}],"Databases":[{"id":"http://arxiv.org/abs/2506.15848v1","updated":"2025-06-18T19:55:59Z","published":"2025-06-18T19:55:59Z","title":"Delta: A Learned Mixed Cost-based Query Optimization Framework","summary":"  Query optimizer is a crucial module for database management systems. Existing\noptimizers exhibit two flawed paradigms: (1) cost-based optimizers use dynamic\nprogramming with cost models but face search space explosion and heuristic\npruning constraints; (2) value-based ones train value networks to enable\nefficient beam search, but incur higher training costs and lower accuracy. They\nalso lack mechanisms to detect queries where they may perform poorly. To\ndetermine more efficient plans, we propose Delta, a mixed cost-based query\noptimization framework that consists of a compatible query detector and a\ntwo-stage planner. Delta first employs a Mahalanobis distancebased detector to\npreemptively filter out incompatible queries where the planner might perform\npoorly. For compatible queries, Delta activates its two-stage mixed cost-based\nplanner. Stage I serves as a coarse-grained filter to generate high-quality\ncandidate plans based on the value network via beam search, relaxing precision\nrequirements and narrowing the search space. Stage II employs a fine-grained\nranker to determine the best plan from the candidate plans based on a learned\ncost model. Moreover, to reduce training costs, we reuse and augment the\ntraining data from stage I to train the model in stage II. Experimental results\non three workloads demonstrate that Delta identifies higher-quality plans,\nachieving an average 2.34x speedup over PostgreSQL and outperforming the\nstate-of-the-art learned methods by 2.21x.\n","authors":["Jiazhen Peng","Zheng Qu","Xiaoye Miao","Rong Zhu"],"pdf_url":"https://arxiv.org/pdf/2506.15848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15831v1","updated":"2025-06-18T19:17:55Z","published":"2025-06-18T19:17:55Z","title":"Adaptive Anomaly Detection in the Presence of Concept Drift: Extended\n  Report","summary":"  Data changes to reflect evolving user behaviour, preferences, and changes in\nthe environment. Such changes may occur due to expected shifts in the data\ndistribution, i.e., concept drift, or unexpected anomalous changes. The\npresence of concept drift poses challenges for anomaly detection in time\nseries. While anomalies are caused by undesirable changes in the data,\ndifferentiating abnormal changes from varying normal behaviours is difficult\ndue to differing frequencies of occurrence, varying time intervals when normal\npatterns occur. Differentiating between concept drift and anomalies is critical\nfor accurate analysis as studies have shown that the compounding effects of\nerror propagation in downstream data analysis tasks lead to lower detection\naccuracy and increased overhead due to unnecessary model updates.\nUnfortunately, existing work has largely explored anomaly detection and concept\ndrift detection in isolation. We develop AnDri, a system for Anomaly detection\nin the presence of Drift, which adjusts the normal patterns temporally, and\ndistinguish abnormal subsequences and new concepts. Moreover, it introduces a\nnew clustering method, Adjacent Hierarchical Clustering (AHC), which groups\nsimilar subsequences while respecting their temporal locality.\n","authors":["Jongjun Park","Fei Chiang","Mostafa Milani"],"pdf_url":"https://arxiv.org/pdf/2506.15831v1.pdf","comment":"Extended version (to be updated)"},{"id":"http://arxiv.org/abs/2504.12058v2","updated":"2025-06-18T18:18:38Z","published":"2025-04-16T13:11:07Z","title":"ProvSQL: A General System for Keeping Track of the Provenance and\n  Probability of Data","summary":"  We present the data model, design choices, and performance of ProvSQL, a\ngeneral and easy-to-deploy provenance tracking and probabilistic database\nsystem implemented as a PostgreSQL extension. ProvSQL's data and query models\nclosely reflect that of a large core of SQL, including multiset semantics, the\nfull relational algebra, and aggregation. A key part of its implementation\nrelies on generic provenance circuits stored in memory-mapped files. We propose\nbenchmarks to measure the overhead of provenance and probabilistic evaluation\nand demonstrate its scalability and competitiveness with respect to other\nstate-of-the-art systems.\n","authors":["Aryak Sen","Silviu Maniu","Pierre Senellart"],"pdf_url":"https://arxiv.org/pdf/2504.12058v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03893v2","updated":"2025-06-18T12:32:18Z","published":"2025-06-04T12:42:36Z","title":"An Efficient Candidate-Free R-S Set Similarity Join Algorithm with the\n  Filter-and-Verification Tree and MapReduce","summary":"  Given two different collections of sets, the exact set similarity R-S Join\nfinds all set pairs with similarity no less than a given threshold, which has\nwidespread applications. While existing algorithms accelerate large-scale R-S\nJoins using a two-stage filter-and-verification framework along with the\nparallel and distributed MapReduce framework, they suffer from excessive\ncandidate set pairs, leading to significant I/O, data transfer, and\nverification overhead, and ultimately degrading the performance. This paper\nproposes novel candidate-free R-S Join (CF-RS-Join) algorithms that integrate\nfiltering and verification into a single stage through filter-and-verification\ntrees (FVTs) and their linear variants (LFVTs). First, CF-RS-Join with FVT\n(CF-RS-Join/FVT) is proposed to leverage an innovative FVT structure that\ncompresses elements and associated sets in memory, enabling single-stage\nprocessing that eliminates the candidate set generation, fast lookups, and\nreduced database scans. Correctness proofs are provided. Second, CF-RS-Join\nwith LFVT (CF-RS-Join/LFVT) is proposed to exploit a more compact Linear FVT,\nwhich compresses non-branching paths into single nodes and stores them in\nlinear arrays for optimized traversal. Third, MR-CF-RS-Join/FVT and\nMR-CF-RS-Join/LFVT have been proposed to extend our approaches using MapReduce\nfor parallel processing. Empirical studies on 7 real-world datasets have been\nconducted to evaluate the performance of the proposed algorithms against\nselected existing algorithms in terms of execution time, scalability, memory\nusage, and disk usage. Experimental results demonstrate that our algorithm\nusing MapReduce, i.e., MR-CF-RS-Join/LFVT, achieves the best performance.\n","authors":["Yuhong Feng","Fangcao Jian","Yixuan Cao","Xiaobin Jian","Jia Wang","Haiyue Feng","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2506.03893v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00031v4","updated":"2025-06-18T08:03:27Z","published":"2025-01-23T15:11:30Z","title":"GNN-based Anchor Embedding for Efficient Exact Subgraph Matching","summary":"  Subgraph matching query is a fundamental problem in graph data management and\nhas a variety of real-world applications. Several recent works utilize deep\nlearning (DL) techniques to process subgraph matching queries. Most of them\nfind approximate subgraph matching results without accuracy guarantees. Unlike\nthese DL-based inexact subgraph matching methods, we propose a learning-based\nexact subgraph matching framework, called \\textit{graph neural network\n(GNN)-based anchor embedding framework} (GNN-AE). In contrast to traditional\nexact subgraph matching methods that rely on creating auxiliary summary\nstructures online for each specific query, our method indexes small feature\nsubgraphs in the data graph offline and uses GNNs to perform graph isomorphism\ntests for these indexed feature subgraphs to efficiently obtain high-quality\ncandidates. To make a tradeoff between query efficiency and index storage cost,\nwe use two types of feature subgraphs, namely anchored subgraphs and anchored\npaths. Based on the proposed techniques, we transform the exact subgraph\nmatching problem into a search problem in the embedding space. Furthermore, to\nefficiently retrieve all matches, we develop a parallel matching growth\nalgorithm and design a cost-based DFS query planning method to further improve\nthe matching growth algorithm. Extensive experiments on 6 real-world and 3\nsynthetic datasets indicate that GNN-AE is more efficient than the baselines,\nespecially outperforming the exploration-based baseline methods by up to 1--2\norders of magnitude.\n","authors":["Bin Yang","Zhaonian Zou","Jianxiong Ye"],"pdf_url":"https://arxiv.org/pdf/2502.00031v4.pdf","comment":null}]},"2025-06-17T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.11421v2","updated":"2025-06-17T17:08:47Z","published":"2025-06-13T02:39:21Z","title":"Deep Learning Model Acceleration and Optimization Strategies for\n  Real-Time Recommendation Systems","summary":"  With the rapid growth of Internet services, recommendation systems play a\ncentral role in delivering personalized content. Faced with massive user\nrequests and complex model architectures, the key challenge for real-time\nrecommendation systems is how to reduce inference latency and increase system\nthroughput without sacrificing recommendation quality. This paper addresses the\nhigh computational cost and resource bottlenecks of deep learning models in\nreal-time settings by proposing a combined set of modeling- and system-level\nacceleration and optimization strategies. At the model level, we dramatically\nreduce parameter counts and compute requirements through lightweight network\ndesign, structured pruning, and weight quantization. At the system level, we\nintegrate multiple heterogeneous compute platforms and high-performance\ninference libraries, and we design elastic inference scheduling and\nload-balancing mechanisms based on real-time load characteristics. Experiments\nshow that, while maintaining the original recommendation accuracy, our methods\ncut latency to less than 30% of the baseline and more than double system\nthroughput, offering a practical solution for deploying large-scale online\nrecommendation services.\n","authors":["Junli Shao","Jing Dong","Dingzhou Wang","Kowei Shih","Dannier Li","Chengrui Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.11421v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14692v1","updated":"2025-06-17T16:29:55Z","published":"2025-06-17T16:29:55Z","title":"A Systematic Replicability and Comparative Study of BSARec and SASRec\n  for Sequential Recommendation","summary":"  This study aims at comparing two sequential recommender systems:\nSelf-Attention based Sequential Recommendation (SASRec), and Beyond\nSelf-Attention based Sequential Recommendation (BSARec) in order to check the\nimprovement frequency enhancement - the added element in BSARec - has on\nrecommendations. The models in the study, have been re-implemented with a\ncommon base-structure from EasyRec, with the aim of obtaining a fair and\nreproducible comparison. The results obtained displayed how BSARec, by\nincluding bias terms for frequency enhancement, does indeed outperform SASRec,\nalthough the increases in performance obtained, are not as high as those\npresented by the authors. This work aims at offering an overview on existing\nmethods, and most importantly at underlying the importance of implementation\ndetails for performance comparison.\n","authors":["Chiara D'Ercoli","Giulia Di Teodoro","Federico Siciliano"],"pdf_url":"https://arxiv.org/pdf/2506.14692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00039v3","updated":"2025-06-17T15:18:57Z","published":"2025-04-29T18:36:57Z","title":"Graph RAG for Legal Norms: A Hierarchical, Temporal and Deterministic\n  Approach","summary":"  This article proposes an adaptation of Graph Retrieval-Augmented Generation\n(Graph RAG) specifically designed for the analysis and comprehension of legal\nnorms. Legal texts are characterized by a predefined hierarchical structure, an\nextensive network of references and a continuous evolution through multiple\ntemporal versions. This temporal dynamism poses a significant challenge for\nstandard AI systems, demanding a deterministic representation of the law at any\ngiven point in time. To address this, our approach grounds the knowledge graph\nconstruction in a formal, FRBRoo-inspired model that distinguishes abstract\nlegal works from their concrete textual expressions. We introduce a\nmulti-layered representation of Temporal Versions (capturing date-specific\nchanges) and Language Versions (capturing linguistic variations). By modeling\nnormative evolution as a precise sequence of these versioned entities, we\nenable the construction of a knowledge graph that serves as a verifiable\n\"ground truth\". This allows Large Language Models to generate responses based\non accurate, context-aware, and point-in-time correct legal information,\novercoming the risk of temporal inaccuracies. Through a detailed analysis of\nthis formal Graph RAG approach and its application to legal norm datasets, this\narticle aims to advance the field of Artificial Intelligence applied to Law,\ncreating opportunities for more effective and reliable systems in legal\nresearch, legislative analysis, and decision support.\n","authors":["Hudson de Martim"],"pdf_url":"https://arxiv.org/pdf/2505.00039v3.pdf","comment":"This version enhances the theoretical underpinnings of the proposed\n  Graph RAG methodology, including the introduction of a formal, FRBRoo-based\n  model for versioning, and enabling multi-language support for both content\n  and metadata"},{"id":"http://arxiv.org/abs/2308.12420v4","updated":"2025-06-17T14:32:54Z","published":"2023-08-23T20:42:32Z","title":"Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature","summary":"  Distributed Ledger Technology (DLT) faces increasing environmental scrutiny,\nparticularly concerning the energy consumption of the Proof of Work (PoW)\nconsensus mechanism and broader Environmental, Social, and Governance (ESG)\nissues. However, existing systematic literature reviews of DLT rely on limited\nanalyses of citations, abstracts, and keywords, failing to fully capture the\nfield's complexity and ESG concerns. We address these challenges by analyzing\nthe full text of 24,539 publications using Natural Language Processing (NLP)\nwith our manually labeled Named Entity Recognition (NER) dataset of 39,427\nentities for DLT. This methodology identified 505 key publications at the\nDLT/ESG intersection, enabling comprehensive domain analysis. Our combined NLP\nand temporal graph analysis reveals critical trends in DLT evolution and ESG\nimpacts, including cryptography and peer-to-peer networks research's\nfoundational influence, Bitcoin's persistent impact on research and\nenvironmental concerns (a \"Lindy effect\"), Ethereum's catalytic role on Proof\nof Stake (PoS) and smart contract adoption, and the industry's progressive\nshift toward energy-efficient consensus mechanisms. Our contributions include\nthe first DLT-specific NER dataset addressing the scarcity of high-quality\nlabeled NLP data in blockchain research, a methodology integrating NLP and\ntemporal graph analysis for large-scale interdisciplinary literature reviews,\nand the first NLP-driven literature review focusing on DLT's ESG aspects.\n","authors":["Walter Hernandez Cruz","Kamil Tylinski","Alastair Moore","Niall Roche","Nikhil Vadgama","Horst Treiblmaier","Jiangbo Shangguan","Paolo Tasca","Jiahua Xu"],"pdf_url":"https://arxiv.org/pdf/2308.12420v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14516v1","updated":"2025-06-17T13:41:12Z","published":"2025-06-17T13:41:12Z","title":"RMIT-ADM+S at the SIGIR 2025 LiveRAG Challenge","summary":"  This paper presents the RMIT--ADM+S participation in the SIGIR 2025 LiveRAG\nChallenge. Our Generation-Retrieval-Augmented Generation (GRAG) approach relies\non generating a hypothetical answer that is used in the retrieval phase,\nalongside the original question. GRAG also incorporates a pointwise large\nlanguage model (LLM)-based re-ranking step prior to final answer generation. We\ndescribe the system architecture and the rationale behind our design choices.\nIn particular, a systematic evaluation using the Grid of Points (GoP) framework\nand N-way ANOVA enabled comparison across multiple configurations, including\nquery variant generation, question decomposition, rank fusion strategies, and\nprompting techniques for answer generation. Our system achieved a Relevance\nscore of 1.199 and a Faithfulness score of 0.477 on the private leaderboard,\nplacing among the top four finalists in the LiveRAG 2025 Challenge.\n","authors":["Kun Ran","Shuoqi Sun","Khoi Nguyen Dinh Anh","Damiano Spina","Oleg Zendel"],"pdf_url":"https://arxiv.org/pdf/2506.14516v1.pdf","comment":"Accepted for oral presentation at SIGIR 2025 LiveRAG"},{"id":"http://arxiv.org/abs/2506.10037v2","updated":"2025-06-17T13:13:31Z","published":"2025-06-10T21:38:26Z","title":"The Cell Ontology in the age of single-cell omics","summary":"  Single-cell omics technologies have transformed our understanding of cellular\ndiversity by enabling high-resolution profiling of individual cells. However,\nthe unprecedented scale and heterogeneity of these datasets demand robust\nframeworks for data integration and annotation. The Cell Ontology (CL) has\nemerged as a pivotal resource for achieving FAIR (Findable, Accessible,\nInteroperable, and Reusable) data principles by providing standardized,\nspecies-agnostic terms for canonical cell types - forming a core component of a\nwide range of platforms and tools. In this paper, we describe the wide variety\nof uses of CL in these platforms and tools and detail ongoing work to improve\nand extend CL content including the addition of transcriptomically defined\ntypes, working closely with major atlasing efforts including the Human Cell\nAtlas and the Brain Initiative Cell Atlas Network to support their needs. We\ncover the challenges and future plans for harmonising classical and\ntranscriptomic cell type definitions, integrating markers and using Large\nLanguage Models (LLMs) to improve content and efficiency of CL workflows.\n","authors":["Shawn Zheng Kai Tan","Aleix Puig-Barbe","Damien Goutte-Gattat","Caroline Eastwood","Brian Aevermann","Alida Avola","James P Balhoff","Ismail Ugur Bayindir","Jasmine Belfiore","Anita Reane Caron","David S Fischer","Nancy George","Benjamin M Gyori","Melissa A Haendel","Charles Tapley Hoyt","Huseyin Kir","Tiago Lubiana","Nicolas Matentzoglu","James A Overton","Beverly Peng","Bjoern Peters","Ellen M Quardokus","Patrick L Ray","Paola Roncaglia","Andrea D Rivera","Ray Stefancsik","Wei Kheng Teh","Sabrina Toro","Nicole Vasilevsky","Chuan Xu","Yun Zhang","Richard H Scheuermann","Chirstopher J Mungall","Alexander D Diehl","David Osumi-Sutherland"],"pdf_url":"https://arxiv.org/pdf/2506.10037v2.pdf","comment":"41 pages, 7 Figures"},{"id":"http://arxiv.org/abs/2506.14445v1","updated":"2025-06-17T12:10:19Z","published":"2025-06-17T12:10:19Z","title":"Vela: Scalable Embeddings with Voice Large Language Models for\n  Multimodal Retrieval","summary":"  Multimodal large language models (MLLMs) have seen substantial progress in\nrecent years. However, their ability to represent multimodal information in the\nacoustic domain remains underexplored. In this work, we introduce Vela, a novel\nframework designed to adapt MLLMs for the generation of universal multimodal\nembeddings. By leveraging MLLMs with specially crafted prompts and selected\nin-context learning examples, Vela effectively bridges the modality gap across\nvarious modalities. We then propose a single-modality training approach, where\nthe model is trained exclusively on text pairs. Our experiments show that Vela\noutperforms traditional CLAP models in standard text-audio retrieval tasks.\nFurthermore, we introduce new benchmarks that expose CLAP models' limitations\nin handling long texts and complex retrieval tasks. In contrast, Vela, by\nharnessing the capabilities of MLLMs, demonstrates robust performance in these\nscenarios. Our code will soon be available.\n","authors":["Ruofan Hu","Yan Xia","Minjie Hong","Jieming Zhu","Bo Chen","Xiaoda Yang","Minghui Fang","Tao Jin"],"pdf_url":"https://arxiv.org/pdf/2506.14445v1.pdf","comment":"Accepted by Interspeech 2025"},{"id":"http://arxiv.org/abs/2506.14437v1","updated":"2025-06-17T11:56:11Z","published":"2025-06-17T11:56:11Z","title":"Similarity = Value? Consultation Value Assessment and Alignment for\n  Personalized Search","summary":"  Personalized search systems in e-commerce platforms increasingly involve user\ninteractions with AI assistants, where users consult about products, usage\nscenarios, and more. Leveraging consultation to personalize search services is\ntrending. Existing methods typically rely on semantic similarity to align\nhistorical consultations with current queries due to the absence of 'value'\nlabels, but we observe that semantic similarity alone often fails to capture\nthe true value of consultation for personalization. To address this, we propose\na consultation value assessment framework that evaluates historical\nconsultations from three novel perspectives: (1) Scenario Scope Value, (2)\nPosterior Action Value, and (3) Time Decay Value. Based on this, we introduce\nVAPS, a value-aware personalized search model that selectively incorporates\nhigh-value consultations through a consultation-user action interaction module\nand an explicit objective that aligns consultations with user actions.\nExperiments on both public and commercial datasets show that VAPS consistently\noutperforms baselines in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Teng Shi","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2506.14437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14412v1","updated":"2025-06-17T11:14:22Z","published":"2025-06-17T11:14:22Z","title":"RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG\n  Systems for the SIGIR LiveRAG Competition","summary":"  Retrieval-Augmented Generation (RAG) enriches Large Language Models (LLMs) by\ncombining their internal, parametric knowledge with external, non-parametric\nsources, with the goal of improving factual correctness and minimizing\nhallucinations. The LiveRAG 2025 challenge explores RAG solutions to maximize\naccuracy on DataMorgana's QA pairs, which are composed of single-hop and\nmulti-hop questions. The challenge provides access to sparse OpenSearch and\ndense Pinecone indices of the Fineweb 10BT dataset. It restricts model use to\nLLMs with up to 10B parameters and final answer generation with Falcon-3-10B. A\njudge-LLM assesses the submitted answers along with human evaluators. By\nexploring distinct retriever combinations and RAG solutions under the challenge\nconditions, our final solution emerged using InstructRAG in combination with a\nPinecone retriever and a BGE reranker. Our solution achieved a correctness\nscore of 1.13 and a faithfulness score of 0.55, placing fourth in the SIGIR\n2025 LiveRAG Challenge.\n","authors":["Tim Cofala","Oleh Astappiev","William Xion","Hailay Teklehaymanot"],"pdf_url":"https://arxiv.org/pdf/2506.14412v1.pdf","comment":"4 pages, 5 figures. Report for SIGIR 2025 LiveRAG Challenge"},{"id":"http://arxiv.org/abs/2506.14349v1","updated":"2025-06-17T09:45:08Z","published":"2025-06-17T09:45:08Z","title":"hyperFA*IR: A hypergeometric approach to fair rankings with finite\n  candidate pool","summary":"  Ranking algorithms play a pivotal role in decision-making processes across\ndiverse domains, from search engines to job applications. When rankings\ndirectly impact individuals, ensuring fairness becomes essential, particularly\nfor groups that are marginalised or misrepresented in the data. Most of the\nexisting group fairness frameworks often rely on ensuring proportional\nrepresentation of protected groups. However, these approaches face limitations\nin accounting for the stochastic nature of ranking processes or the finite size\nof candidate pools. To this end, we present hyperFA*IR, a framework for\nassessing and enforcing fairness in rankings drawn from a finite set of\ncandidates. It relies on a generative process based on the hypergeometric\ndistribution, which models real-world scenarios by sampling without replacement\nfrom fixed group sizes. This approach improves fairness assessment when top-$k$\nselections are large relative to the pool or when protected groups are small.\nWe compare our approach to the widely used binomial model, which treats each\ndraw as independent with fixed probability, and demonstrate$-$both analytically\nand empirically$-$that our method more accurately reproduces the statistical\nproperties of sampling from a finite population. To operationalise this\nframework, we propose a Monte Carlo-based algorithm that efficiently detects\nunfair rankings by avoiding computationally expensive parameter tuning.\nFinally, we adapt our generative approach to define affirmative action policies\nby introducing weights into the sampling process.\n","authors":["Mauritz N. Cartier van Dissel","Samuel Martin-Gutierrez","Lisette Espín-Noboa","Ana María Jaramillo","Fariba Karimi"],"pdf_url":"https://arxiv.org/pdf/2506.14349v1.pdf","comment":"In Proceedings of the 2025 ACM Conference on Fairness,\n  Accountability, and Transparency (FAccT'25)"},{"id":"http://arxiv.org/abs/2506.14345v1","updated":"2025-06-17T09:38:45Z","published":"2025-06-17T09:38:45Z","title":"A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive,\n  Transparent, and Reproducible Geo-Temporal Information Synthesis","summary":"  The emergence of Large Language Models (LLMs) has transformed information\naccess, with current LLMs also powering deep research systems that can generate\ncomprehensive report-style answers, through planned iterative search,\nretrieval, and reasoning. Still, current deep research systems lack the\ngeo-temporal capabilities that are essential for answering context-rich\nquestions involving geographic and/or temporal constraints, frequently\noccurring in domains like public health, environmental science, or\nsocio-economic analysis. This paper reports our vision towards next generation\nsystems, identifying important technical, infrastructural, and evaluative\nchallenges in integrating geo-temporal reasoning into deep research pipelines.\nWe argue for augmenting retrieval and synthesis processes with the ability to\nhandle geo-temporal constraints, supported by open and reproducible\ninfrastructures and rigorous evaluation protocols. Our vision outlines a path\ntowards more advanced and geo-temporally aware deep research systems, of\npotential impact to the future of AI-driven information access.\n","authors":["Bruno Martins","Piotr Szymański","Piotr Gramacki"],"pdf_url":"https://arxiv.org/pdf/2506.14345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14231v1","updated":"2025-06-17T06:38:46Z","published":"2025-06-17T06:38:46Z","title":"ImpReSS: Implicit Recommender System for Support Conversations","summary":"  Following recent advancements in large language models (LLMs), LLM-based\nchatbots have transformed customer support by automating interactions and\nproviding consistent, scalable service. While LLM-based conversational\nrecommender systems (CRSs) have attracted attention for their ability to\nenhance the quality of recommendations, limited research has addressed the\nimplicit integration of recommendations within customer support interactions.\nIn this work, we introduce ImpReSS, an implicit recommender system designed for\ncustomer support conversations. ImpReSS operates alongside existing support\nchatbots, where users report issues and chatbots provide solutions. Based on a\ncustomer support conversation, ImpReSS identifies opportunities to recommend\nrelevant solution product categories (SPCs) that help resolve the issue or\nprevent its recurrence -- thereby also supporting business growth. Unlike\ntraditional CRSs, ImpReSS functions entirely implicitly and does not rely on\nany assumption of a user's purchasing intent. Our empirical evaluation of\nImpReSS's ability to recommend relevant SPCs that can help address issues\nraised in support conversations shows promising results, including an MRR@1\n(and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for\ninformation security support, and 0.85 (0.67) for cybersecurity\ntroubleshooting. To support future research, our data and code will be shared\nupon request.\n","authors":["Omri Haller","Yair Meidan","Dudu Mimran","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2506.14231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14086v1","updated":"2025-06-17T01:04:45Z","published":"2025-06-17T01:04:45Z","title":"InsertRank: LLMs can reason over BM25 scores to Improve Listwise\n  Reranking","summary":"  Large Language Models (LLMs) have demonstrated significant strides across\nvarious information retrieval tasks, particularly as rerankers, owing to their\nstrong generalization and knowledge-transfer capabilities acquired from\nextensive pretraining. In parallel, the rise of LLM-based chat interfaces has\nraised user expectations, encouraging users to pose more complex queries that\nnecessitate retrieval by ``reasoning'' over documents rather than through\nsimple keyword matching or semantic similarity. While some recent efforts have\nexploited reasoning abilities of LLMs for reranking such queries, considerable\npotential for improvement remains. In that regards, we introduce InsertRank, an\nLLM-based reranker that leverages lexical signals like BM25 scores during\nreranking to further improve retrieval performance. InsertRank demonstrates\nimproved retrieval effectiveness on -- BRIGHT, a reasoning benchmark spanning\n12 diverse domains, and R2MED, a specialized medical reasoning retrieval\nbenchmark spanning 8 different tasks. We conduct an exhaustive evaluation and\nseveral ablation studies and demonstrate that InsertRank consistently improves\nretrieval effectiveness across multiple families of LLMs, including GPT,\nGemini, and Deepseek models. %In addition, we also conduct ablation studies on\nnormalization by varying the scale of the BM25 scores, and positional bias by\nshuffling the order of the documents. With Deepseek-R1, InsertRank achieves a\nscore of 37.5 on the BRIGHT benchmark. and 51.1 on the R2MED benchmark,\nsurpassing previous methods.\n","authors":["Rahul Seetharaman","Kaustubh D. Dhole","Aman Bansal"],"pdf_url":"https://arxiv.org/pdf/2506.14086v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2504.17918v3","updated":"2025-06-17T21:43:18Z","published":"2025-04-24T20:19:07Z","title":"PHast -- Perfect Hashing with fast evaluation","summary":"  Perfect hash functions give unique \"names\" to arbitrary keys requiring only a\nfew bits per key. This is an essential building block in applications like\nstatic hash tables, databases, or bioinformatics. This paper introduces the\nPHast approach that has the currently fastest query time with competitive\nconstruction time and space consumption. PHast improves bucket-placement which\nfirst hashes each key k to a bucket, and then looks for the bucket seed s such\nthat a secondary hash function maps pairs (s,k) in a collision-free way. PHast\ncan use small-range primary hash functions with linear mapping, fixed-width\nencoding of seeds, and parallel construction. This is achieved using small\noverlapping slices of allowed values and bumping to handle unsuccessful seed\nassignment.\n","authors":["Piotr Beling","Peter Sanders"],"pdf_url":"https://arxiv.org/pdf/2504.17918v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14707v1","updated":"2025-06-17T16:45:42Z","published":"2025-06-17T16:45:42Z","title":"HARMONY: A Scalable Distributed Vector Database for High-Throughput\n  Approximate Nearest Neighbor Search","summary":"  Approximate Nearest Neighbor Search (ANNS) is essential for various\ndata-intensive applications, including recommendation systems, image retrieval,\nand machine learning. Scaling ANNS to handle billions of high-dimensional\nvectors on a single machine presents significant challenges in memory capacity\nand processing efficiency. To address these challenges, distributed vector\ndatabases leverage multiple nodes for the parallel storage and processing of\nvectors. However, existing solutions often suffer from load imbalance and high\ncommunication overhead, primarily due to traditional partition strategies that\nfail to effectively distribute the workload. In this paper, we introduce\nHarmony, a distributed ANNS system that employs a novel multi-granularity\npartition strategy, combining dimension-based and vector-based partition. This\nstrategy ensures a balanced distribution of computational load across all nodes\nwhile effectively minimizing communication costs. Furthermore, Harmony\nincorporates an early-stop pruning mechanism that leverages the monotonicity of\ndistance computations in dimension-based partition, resulting in significant\nreductions in both computational and communication overhead. We conducted\nextensive experiments on diverse real-world datasets, demonstrating that\nHarmony outperforms leading distributed vector databases, achieving 4.63 times\nthroughput on average in four nodes and 58% performance improvement over\ntraditional distribution for skewed workloads.\n","authors":["Qian Xu","Feng Zhang","Chengxi Li","Lei Cao","Zheng Chen","Jidong Zhai","Xiaoyong Du"],"pdf_url":"https://arxiv.org/pdf/2506.14707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.14661v2","updated":"2025-06-17T15:45:12Z","published":"2025-05-20T17:49:46Z","title":"Abacus: A Cost-Based Optimizer for Semantic Operator Systems","summary":"  LLMs enable an exciting new class of data processing applications over large\ncollections of unstructured documents. Several new programming frameworks have\nenabled developers to build these applications by composing them out of\nsemantic operators: a declarative set of AI-powered data transformations with\nnatural language specifications. These include LLM-powered maps, filters,\njoins, etc. used for document processing tasks such as information extraction,\nsummarization, and more. While systems of semantic operators have achieved\nstrong performance on benchmarks, they can be difficult to optimize. An\noptimizer for this setting must determine how to physically implement each\nsemantic operator in a way that optimizes the system globally. Existing\noptimizers are limited in the number of optimizations they can apply, and most\n(if not all) cannot optimize system quality, cost, or latency subject to\nconstraint(s) on the other dimensions. In this paper we present Abacus, an\nextensible, cost-based optimizer which searches for the best implementation of\na semantic operator system given a (possibly constrained) optimization\nobjective. Abacus estimates operator performance by leveraging a minimal set of\nvalidation examples and, if available, prior beliefs about operator\nperformance. We evaluate Abacus on document processing workloads in the\nbiomedical and legal domains (BioDEX; CUAD) and multi-modal question answering\n(MMQA). We demonstrate that systems optimized by Abacus achieve 18.7%-39.2%\nbetter quality and up to 23.6x lower cost and 4.2x lower latency than the next\nbest system.\n","authors":["Matthew Russo","Sivaprasad Sudhir","Gerardo Vitagliano","Chunwei Liu","Tim Kraska","Samuel Madden","Michael Cafarella"],"pdf_url":"https://arxiv.org/pdf/2505.14661v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.14630v1","updated":"2025-06-17T15:25:11Z","published":"2025-06-17T15:25:11Z","title":"Keigo: Co-designing Log-Structured Merge Key-Value Stores with a\n  Non-Volatile, Concurrency-aware Storage Hierarchy (Extended Version)","summary":"  We present Keigo, a concurrency- and workload-aware storage middleware that\nenhances the performance of log-structured merge key-value stores (LSM KVS)\nwhen they are deployed on a hierarchy of storage devices. The key observation\nbehind Keigo is that there is no one-size-fits-all placement of data across the\nstorage hierarchy that optimizes for all workloads. Hence, to leverage the\nbenefits of combining different storage devices, Keigo places files across\ndifferent devices based on their parallelism, I/O bandwidth, and capacity. We\nintroduce three techniques - concurrency-aware data placement, persistent\nread-only caching, and context-based I/O differentiation. Keigo is portable\nacross different LSMs, is adaptable to dynamic workloads, and does not require\nextensive profiling. Our system enables established production KVS such as\nRocksDB, LevelDB, and Speedb to benefit from heterogeneous storage setups. We\nevaluate Keigo using synthetic and realistic workloads, showing that it\nimproves the throughput of production-grade LSMs up to 4x for write- and 18x\nfor read-heavy workloads when compared to general-purpose storage systems and\nspecialized LSM KVS.\n","authors":["Rúben Adão","Zhongjie Wu","Changjun Zhou","Oana Balmau","João Paulo","Ricardo Macedo"],"pdf_url":"https://arxiv.org/pdf/2506.14630v1.pdf","comment":"This is an extended version of the full paper to appear in VLDB 2025"},{"id":"http://arxiv.org/abs/2412.02448v2","updated":"2025-06-17T09:24:55Z","published":"2024-12-03T13:32:11Z","title":"UNIFY: Unified Index for Range Filtered Approximate Nearest Neighbors\n  Search","summary":"  This paper presents an efficient and scalable framework for Range Filtered\nApproximate Nearest Neighbors Search (RF-ANNS) over high-dimensional vectors\nassociated with attribute values. Given a query vector $q$ and a range $[l,\nh]$, RF-ANNS aims to find the approximate $k$ nearest neighbors of $q$ among\ndata whose attribute values fall within $[l, h]$. Existing methods including\npre-, post-, and hybrid filtering strategies that perform attribute range\nfiltering before, after, or during the ANNS process, all suffer from\nsignificant performance degradation when query ranges shift. Though building\ndedicated indexes for each strategy and selecting the best one based on the\nquery range can address this problem, it leads to index consistency and\nmaintenance issues.\n  Our framework, called UNIFY, constructs a unified Proximity Graph-based\n(PG-based) index that seamlessly supports all three strategies. In UNIFY, we\nintroduce SIG, a novel Segmented Inclusive Graph, which segments the dataset by\nattribute values. It ensures the PG of objects from any segment combinations is\na sub-graph of SIG, thereby enabling efficient hybrid filtering by\nreconstructing and searching a PG from relevant segments. Moreover, we present\nHierarchical Segmented Inclusive Graph (HSIG), a variant of SIG which\nincorporates a hierarchical structure inspired by HNSW to achieve logarithmic\nhybrid filtering complexity. We also implement pre- and post-filtering for HSIG\nby fusing skip list connections and compressed HNSW edges into the hierarchical\ngraph. Experimental results show that UNIFY delivers state-of-the-art RF-ANNS\nperformance across small, mid, and large query ranges.\n","authors":["Anqi Liang","Pengcheng Zhang","Bin Yao","Zhongpu Chen","Yitong Song","Guangxu Cheng"],"pdf_url":"https://arxiv.org/pdf/2412.02448v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08194v2","updated":"2025-06-17T08:36:16Z","published":"2024-12-11T08:35:56Z","title":"Magneto: Combining Small and Large Language Models for Schema Matching","summary":"  Recent advances in language models opened new opportunities to address\ncomplex schema matching tasks. Schema matching approaches have been proposed\nthat demonstrate the usefulness of language models, but they have also\nuncovered important limitations: Small language models (SLMs) require training\ndata (which can be both expensive and challenging to obtain), and large\nlanguage models (LLMs) often incur high computational costs and must deal with\nconstraints imposed by context windows. We present Magneto, a cost-effective\nand accurate solution for schema matching that combines the advantages of SLMs\nand LLMs to address their limitations. By structuring the schema matching\npipeline in two phases, retrieval and reranking, Magneto can use\ncomputationally efficient SLM-based strategies to derive candidate matches\nwhich can then be reranked by LLMs, thus making it possible to reduce runtime\nwithout compromising matching accuracy. We propose a self-supervised approach\nto fine-tune SLMs which uses LLMs to generate syntactically diverse training\ndata, and prompting strategies that are effective for reranking. We also\nintroduce a new benchmark, developed in collaboration with domain experts,\nwhich includes real biomedical datasets and presents new challenges to schema\nmatching methods. Through a detailed experimental evaluation, using both our\nnew and existing benchmarks, we show that Magneto is scalable and attains high\naccuracy for datasets from different domains.\n","authors":["Yurong Liu","Eduardo Pena","Aecio Santos","Eden Wu","Juliana Freire"],"pdf_url":"https://arxiv.org/pdf/2412.08194v2.pdf","comment":null}]},"2025-06-16T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.13743v1","updated":"2025-06-16T17:53:18Z","published":"2025-06-16T17:53:18Z","title":"LTRR: Learning To Rank Retrievers for LLMs","summary":"  Retrieval-Augmented Generation (RAG) systems typically rely on a single fixed\nretriever, despite growing evidence that no single retriever performs optimally\nacross all query types. In this paper, we explore a query routing approach that\ndynamically selects from a pool of retrievers based on the query, using both\ntrain-free heuristics and learned routing models. We frame routing as a\nlearning-to-rank (LTR) problem and introduce LTRR, a framework that learns to\nrank retrievers by their expected utility gain to downstream LLM performance.\nOur experiments, conducted on synthetic QA data with controlled query type\nvariations, show that routing-based RAG systems can outperform the best\nsingle-retriever-based systems. Performance gains are especially pronounced in\nmodels trained with the Answer Correctness (AC) metric and with pairwise\nlearning approaches, especially with XGBoost. We also observe improvements in\ngeneralization to out-of-distribution queries. As part of the SIGIR 2025\nLiveRAG challenge, our submitted system demonstrated the practical viability of\nour approach, achieving competitive performance in both answer correctness and\nfaithfulness. These findings highlight the importance of both training\nmethodology and metric selection in query routing for RAG systems.\n","authors":["To Eun Kim","Fernando Diaz"],"pdf_url":"https://arxiv.org/pdf/2506.13743v1.pdf","comment":"SIGIR 2025 LiveRAG Spotlight"},{"id":"http://arxiv.org/abs/2506.13695v1","updated":"2025-06-16T16:58:55Z","published":"2025-06-16T16:58:55Z","title":"OneRec Technical Report","summary":"  Recommender systems have been widely used in various large-scale\nuser-oriented platforms for many years. However, compared to the rapid\ndevelopments in the AI community, recommendation systems have not achieved a\nbreakthrough in recent years. For instance, they still rely on a multi-stage\ncascaded architecture rather than an end-to-end approach, leading to\ncomputational fragmentation and optimization inconsistencies, and hindering the\neffective application of key breakthrough technologies from the AI community in\nrecommendation scenarios.\n  To address these issues, we propose OneRec, which reshapes the recommendation\nsystem through an end-to-end generative approach and achieves promising\nresults. Firstly, we have enhanced the computational FLOPs of the current\nrecommendation model by 10 $\\times$ and have identified the scaling laws for\nrecommendations within certain boundaries. Secondly, reinforcement learning\ntechniques, previously difficult to apply for optimizing recommendations, show\nsignificant potential in this framework. Lastly, through infrastructure\noptimizations, we have achieved 23.7% and 28.8% Model FLOPs Utilization (MFU)\non flagship GPUs during training and inference, respectively, aligning closely\nwith the LLM community. This architecture significantly reduces communication\nand storage overhead, resulting in operating expense that is only 10.6% of\ntraditional recommendation pipelines. Deployed in Kuaishou/Kuaishou Lite APP,\nit handles 25% of total queries per second, enhancing overall App Stay Time by\n0.54% and 1.24%, respectively. Additionally, we have observed significant\nincreases in metrics such as 7-day Lifetime, which is a crucial indicator of\nrecommendation experience. We also provide practical lessons and insights\nderived from developing, optimizing, and maintaining a production-scale\nrecommendation system with significant real-world impact.\n","authors":["Guorui Zhou","Jiaxin Deng","Jinghao Zhang","Kuo Cai","Lejian Ren","Qiang Luo","Qianqian Wang","Qigen Hu","Rui Huang","Shiyao Wang","Weifeng Ding","Wuchao Li","Xinchen Luo","Xingmei Wang","Zexuan Cheng","Zixing Zhang","Bin Zhang","Boxuan Wang","Chaoyi Ma","Chengru Song","Chenhui Wang","Di Wang","Dongxue Meng","Fan Yang","Fangyu Zhang","Feng Jiang","Fuxing Zhang","Gang Wang","Guowang Zhang","Han Li","Hengrui Hu","Hezheng Lin","Hongtao Cheng","Hongyang Cao","Huanjie Wang","Jiaming Huang","Jiapeng Chen","Jiaqiang Liu","Jinghui Jia","Kun Gai","Lantao Hu","Liang Zeng","Liao Yu","Qiang Wang","Qidong Zhou","Shengzhe Wang","Shihui He","Shuang Yang","Shujie Yang","Sui Huang","Tao Wu","Tiantian He","Tingting Gao","Wei Yuan","Xiao Liang","Xiaoxiao Xu","Xugang Liu","Yan Wang","Yi Wang","Yiwu Liu","Yue Song","Yufei Zhang","Yunfan Wu","Yunfeng Zhao","Zhanyu Liu"],"pdf_url":"https://arxiv.org/pdf/2506.13695v1.pdf","comment":"Authors are listed alphabetically by their first name"},{"id":"http://arxiv.org/abs/2504.05317v2","updated":"2025-06-16T16:22:39Z","published":"2025-02-21T09:43:18Z","title":"On Synthesizing Data for Context Attribution in Question Answering","summary":"  Question Answering (QA) accounts for a significant portion of LLM usage \"in\nthe wild\". However, LLMs sometimes produce false or misleading responses, also\nknown as \"hallucinations\". Therefore, grounding the generated answers in\ncontextually provided information -- i.e., providing evidence for the generated\ntext -- is paramount for LLMs' trustworthiness. Providing this information is\nthe task of context attribution. In this paper, we systematically study\nLLM-based approaches for this task, namely we investigate (i) zero-shot\ninference, (ii) LLM ensembling, and (iii) fine-tuning of small LMs on synthetic\ndata generated by larger LLMs. Our key contribution is SynQA: a novel\ngenerative strategy for synthesizing context attribution data. Given selected\ncontext sentences, an LLM generates QA pairs that are supported by these\nsentences. This leverages LLMs' natural strengths in text generation while\nensuring clear attribution paths in the synthetic training data. We show that\nthe attribution data synthesized via SynQA is highly effective for fine-tuning\nsmall LMs for context attribution in different QA tasks and domains. Finally,\nwith a user study, we validate the usefulness of small LMs (fine-tuned on\nsynthetic data from SynQA) in context attribution for QA.\n","authors":["Gorjan Radevski","Kiril Gashteovski","Shahbaz Syed","Christopher Malon","Sebastien Nicolas","Chia-Chien Hung","Timo Sztyler","Verena Heußer","Wiem Ben Rim","Masafumi Enomoto","Kunihiro Takeoka","Masafumi Oyamada","Goran Glavaš","Carolin Lawrence"],"pdf_url":"https://arxiv.org/pdf/2504.05317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13607v1","updated":"2025-06-16T15:34:29Z","published":"2025-06-16T15:34:29Z","title":"Tree-Based Text Retrieval via Hierarchical Clustering in RAGFrameworks:\n  Application on Taiwanese Regulations","summary":"  Traditional Retrieval-Augmented Generation (RAG) systems employ brute-force\ninner product search to retrieve the top-k most similar documents, then\ncombined with the user query and passed to a language model. This allows the\nmodel to access external knowledge and reduce hallucinations. However,\nselecting an appropriate k value remains a significant challenge in practical\napplications: a small k may fail to retrieve sufficient information, while a\nlarge k can introduce excessive and irrelevant content. To address this, we\npropose a hierarchical clustering-based retrieval method that eliminates the\nneed to predefine k. Our approach maintains the accuracy and relevance of\nsystem responses while adaptively selecting semantically relevant content. In\nthe experiment stage, we applied our method to a Taiwanese legal dataset with\nexpert-graded queries. The results show that our approach achieves superior\nperformance in expert evaluations and maintains high precision while\neliminating the need to predefine k, demonstrating improved accuracy and\ninterpretability in legal text retrieval tasks. Our framework is simple to\nimplement and easily integrates with existing RAG pipelines, making it a\npractical solution for real-world applications under limited resources.\n","authors":["Chia-Heng Yu","Yen-Lung Tsai"],"pdf_url":"https://arxiv.org/pdf/2506.13607v1.pdf","comment":"19 pages, 5 figures, Code available at\n  https://github.com/arthur422tp/hierachical"},{"id":"http://arxiv.org/abs/2506.11502v2","updated":"2025-06-16T14:36:50Z","published":"2025-06-13T06:58:25Z","title":"A Reference Model and Patterns for Production Event Data Enrichment","summary":"  With the advent of digital transformation, organisations are increasingly\ngenerating large volumes of data through the execution of various processes\nacross disparate systems. By integrating data from these heterogeneous sources,\nit becomes possible to derive new insights essential for tasks such as\nmonitoring and analysing process performance. Typically, this information is\nextracted during a data pre-processing or engineering phase. However, this step\nis often performed in an ad-hoc manner and is time-consuming and\nlabour-intensive. To streamline this process, we introduce a reference model\nand a collection of patterns designed to enrich production event data. The\nreference model provides a standard way for storing and extracting production\nevent data. The patterns describe common information extraction tasks and how\nsuch tasks can be automated effectively. The reference model is developed by\ncombining the ISA-95 industry standard with the Event Knowledge Graph\nformalism. The patterns are developed based on empirical observations from\nevent data sets originating in manufacturing processes and are formalised using\nthe reference model. We evaluate the relevance and applicability of these\npatterns by demonstrating their application to use cases.\n","authors":["Mark van der Pas","Remco Dijkman","Alp Akçay","Ivo Adan","John Walker"],"pdf_url":"https://arxiv.org/pdf/2506.11502v2.pdf","comment":"Extended version of the paper submitted to EDOC 2025"},{"id":"http://arxiv.org/abs/2502.19596v3","updated":"2025-06-16T14:27:30Z","published":"2025-02-26T22:20:08Z","title":"Reference-Aligned Retrieval-Augmented Question Answering over\n  Heterogeneous Proprietary Documents","summary":"  Proprietary corporate documents contain rich domain-specific knowledge, but\ntheir overwhelming volume and disorganized structure make it difficult even for\nemployees to access the right information when needed. For example, in the\nautomotive industry, vehicle crash-collision tests, each costing hundreds of\nthousands of dollars, produce highly detailed documentation. However,\nretrieving relevant content during decision-making remains time-consuming due\nto the scale and complexity of the material. While Retrieval-Augmented\nGeneration (RAG)-based Question Answering (QA) systems offer a promising\nsolution, building an internal RAG-QA system poses several challenges: (1)\nhandling heterogeneous multi-modal data sources, (2) preserving data\nconfidentiality, and (3) enabling traceability between each piece of\ninformation in the generated answer and its original source document. To\naddress these, we propose a RAG-QA framework for internal enterprise use,\nconsisting of: (1) a data pipeline that converts raw multi-modal documents into\na structured corpus and QA pairs, (2) a fully on-premise, privacy-preserving\narchitecture, and (3) a lightweight reference matcher that links answer\nsegments to supporting content. Applied to the automotive domain, our system\nimproves factual correctness (+1.79, +1.94), informativeness (+1.33, +1.16),\nand helpfulness (+1.08, +1.67) over a non-RAG baseline, based on 1-5 scale\nratings from both human and LLM judge.\n","authors":["Nayoung Choi","Grace Byun","Andrew Chung","Ellie S. Paek","Shinsun Lee","Jinho D. Choi"],"pdf_url":"https://arxiv.org/pdf/2502.19596v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10512v2","updated":"2025-06-16T14:08:36Z","published":"2025-04-10T01:31:11Z","title":"JEPA4Rec: Learning Effective Language Representations for Sequential\n  Recommendation via Joint Embedding Predictive Architecture","summary":"  Language representation learning has emerged as a promising approach for\nsequential recommendation, thanks to its ability to learn generalizable\nrepresentations. However, despite its advantages, this approach still struggles\nwith data sparsity and a limited understanding of common-sense user\npreferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a\nframework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding\n$\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item\ntextual descriptions. JEPA4Rec captures semantically rich and transferable\nrepresentations, improving recommendation performance and reducing reliance on\nlarge-scale pre-training data. Specifically, JEPA4Rec represents items as text\nsentences by flattening descriptive information such as $\\textit{title,\ncategory}$, and other attributes. To encode these sentences, we employ a\nbidirectional Transformer encoder with modified embedding layers tailored for\ncapturing item information in recommendation datasets. We apply masking to text\nsentences and use them to predict the representations of the unmasked\nsentences, helping the model learn generalizable item embeddings. To further\nimprove recommendation performance and language understanding, we employ a\ntwo-stage training strategy incorporating self-supervised learning losses.\nExperiments on six real-world datasets demonstrate that JEPA4Rec consistently\noutperforms state-of-the-art methods, particularly in cross-domain,\ncross-platform, and low-resource scenarios.\n","authors":["Minh-Anh Nguyen","Dung D. Le"],"pdf_url":"https://arxiv.org/pdf/2504.10512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13409v1","updated":"2025-06-16T12:23:17Z","published":"2025-06-16T12:23:17Z","title":"Beyond One-Size-Fits-All: A Study of Neural and Behavioural Variability\n  Across Different Recommendation Categories","summary":"  Traditionally, Recommender Systems (RS) have primarily measured performance\nbased on the accuracy and relevance of their recommendations. However, this\nalgorithmic-centric approach overlooks how different types of recommendations\nimpact user engagement and shape the overall quality of experience. In this\npaper, we shift the focus to the user and address for the first time the\nchallenge of decoding the neural and behavioural variability across distinct\nrecommendation categories, considering more than just relevance. Specifically,\nwe conducted a controlled study using a comprehensive e-commerce dataset\ncontaining various recommendation types, and collected Electroencephalography\nand behavioural data. We analysed both neural and behavioural responses to\nrecommendations that were categorised as Exact, Substitute, Complement, or\nIrrelevant products within search query results. Our findings offer novel\ninsights into user preferences and decision-making processes, revealing\nmeaningful relationships between behavioural and neural patterns for each\ncategory, but also indicate inter-subject variability.\n","authors":["Georgios Koutroumpas","Sebastian Idesis","Mireia Masias Bruns","Carlos Segura","Joemon M. Jose","Sergi Abadal","Ioannis Arapakis"],"pdf_url":"https://arxiv.org/pdf/2506.13409v1.pdf","comment":"11 pages, 7 figures, 5 tables"},{"id":"http://arxiv.org/abs/2506.13380v1","updated":"2025-06-16T11:44:28Z","published":"2025-06-16T11:44:28Z","title":"Decompositional Reasoning for Graph Retrieval with Large Language Models","summary":"  Large Language Models (LLMs) excel at many NLP tasks, but struggle with\nmulti-hop reasoning and factual consistency, limiting their effectiveness on\nknowledge-intensive tasks like complex question answering (QA). Linking\nKnowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally\nlack the ability to reason efficiently over graph-structured information. To\ntackle this problem, we propose a novel retrieval approach that integrates\ntextual knowledge graphs into the LLM reasoning process via query\ndecomposition. Our method decomposes complex questions into sub-questions,\nretrieves relevant textual subgraphs, and composes a question-specific\nknowledge graph to guide answer generation. For that, we use a weighted\nsimilarity function that focuses on both the complex question and the generated\nsubquestions to extract a relevant subgraph, which allows efficient and precise\nretrieval for complex questions and improves the performance of LLMs on\nmulti-hop QA tasks. This structured reasoning pipeline enhances factual\ngrounding and interpretability while leveraging the generative strengths of\nLLMs. We evaluate our method on standard multi-hop QA benchmarks and show that\nit achieves comparable or superior performance to competitive existing methods,\nusing smaller models and fewer LLM calls.\n","authors":["Valentin Six","Evan Dufraisse","Gaël de Chalendar"],"pdf_url":"https://arxiv.org/pdf/2506.13380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13333v1","updated":"2025-06-16T10:23:46Z","published":"2025-06-16T10:23:46Z","title":"Digital Transformation of Urban Planning in Australia: Influencing\n  Factors and Key Challenges","summary":"  Over the past two decades, several governments in developing and developed\ncountries have started their journey toward digital transformation. However,\nthe pace and maturity of digital technologies and strategies are different\nbetween public services. Current literature indicates that research on the\ndigital transformation of urban planning is still developing. Therefore, the\naim of this study is to understand the influencing factors and key challenges\nfor the digital transformation of urban planning in Australia. The study adopts\nthe inter-organisational theory and Planning Support Science (PSScience) under\nthe Technological, Organisational, and External Environmental (TOE) framework.\nIt involves a multiple case study, administered semi-structured interviews with\nthirteen IT and urban planning experts across Victoria and New South Wales\ngovernments and private industries. The study findings indicate that the main\nchallenges for digital transformation of the Australian urban planning system\nare related to organisational and external environmental factors. Furthermore,\na digital maturity model is absent in the Australian urban planning industry.\nThis study offers important implications to research and practice related to\ndigital transformation in urban planning.\n","authors":["Soheil Sabri","Sherah Kurnia"],"pdf_url":"https://arxiv.org/pdf/2506.13333v1.pdf","comment":"30 pages, 2 figures, Master's Thesis"},{"id":"http://arxiv.org/abs/2506.13315v1","updated":"2025-06-16T09:56:10Z","published":"2025-06-16T09:56:10Z","title":"Gated Rotary-Enhanced Linear Attention for Long-term Sequential\n  Recommendation","summary":"  In Sequential Recommendation Systems (SRSs), Transformer models show\nremarkable performance but face computation cost challenges when modeling\nlong-term user behavior sequences due to the quadratic complexity of the\ndot-product attention mechanism. By approximating the dot-product attention,\nlinear attention provides an efficient option with linear complexity. However,\nexisting linear attention methods face two limitations: 1) they often use\nlearnable position encodings, which incur extra computational costs in\nlong-term sequence scenarios, and 2) they may not consider the user's\nfine-grained local preferences and confuse these with the actual change of\nlong-term interests. To remedy these drawbacks, we propose a long-term\nsequential Recommendation model with Gated Rotary Enhanced Linear Attention\n(RecGRELA). Specifically, we first propose a Rotary-Enhanced Linear Attention\n(RELA) module to model long-range dependency within the user's historical\ninformation using rotary position encodings. We then introduce a local short\noperation to incorporate local preferences and demonstrate the theoretical\ninsight. We further introduce a SiLU-based Gated mechanism for RELA (GRELA) to\nhelp the model determine whether a user's behavior indicates local interest or\na genuine shift in long-term preferences. Experimental results on four public\ndatasets demonstrate that our RecGRELA achieves state-of-the-art performance\ncompared to existing SRSs while maintaining low memory overhead.\n","authors":["Juntao Hu","Wei Zhou","Huayi Shen","Xiao Du","Jie Liao","Junhao Wen","Min Gao"],"pdf_url":"https://arxiv.org/pdf/2506.13315v1.pdf","comment":"24 pages,9 figures"},{"id":"http://arxiv.org/abs/2506.13256v1","updated":"2025-06-16T08:52:58Z","published":"2025-06-16T08:52:58Z","title":"Accessibility Barriers in Multi-Terabyte Public Datasets: The Gap\n  Between Promise and Practice","summary":"  The promise of \"free and open\" multi-terabyte datasets often collides with\nharsh realities. While these datasets may be technically accessible, practical\nbarriers -- from processing complexity to hidden costs -- create a system that\nprimarily serves well-funded institutions. This study examines accessibility\nchallenges across web crawls, satellite imagery, scientific data, and\ncollaborative projects, revealing a consistent two-tier system where\ntheoretical openness masks practical exclusivity. Our analysis demonstrates\nthat datasets marketed as \"publicly accessible\" typically require minimum\ninvestments of \\$1,000+ for meaningful analysis, with complex processing\npipelines demanding \\$10,000-100,000+ in infrastructure costs. The\ninfrastructure requirements -- distributed computing knowledge, domain\nexpertise, and substantial budgets -- effectively gatekeep these datasets\ndespite their \"open\" status, limiting practical accessibility to those with\ninstitutional support or substantial resources.\n","authors":["Marc Bara"],"pdf_url":"https://arxiv.org/pdf/2506.13256v1.pdf","comment":"5 pages, 28 references. Analysis of practical barriers to accessing\n  multi-terabyte public datasets"},{"id":"http://arxiv.org/abs/2506.13252v1","updated":"2025-06-16T08:49:21Z","published":"2025-06-16T08:49:21Z","title":"Vector Ontologies as an LLM world view extraction method","summary":"  Large Language Models (LLMs) possess intricate internal representations of\nthe world, yet these latent structures are notoriously difficult to interpret\nor repurpose beyond the original prediction task. Building on our earlier work\n(Rothenfusser, 2025), which introduced the concept of vector ontologies as a\nframework for translating high-dimensional neural representations into\ninterpretable geometric structures, this paper provides the first empirical\nvalidation of that approach. A vector ontology defines a domain-specific vector\nspace spanned by ontologically meaningful dimensions, allowing geometric\nanalysis of concepts and relationships within a domain. We construct an\n8-dimensional vector ontology of musical genres based on Spotify audio features\nand test whether an LLM's internal world model of music can be consistently and\naccurately projected into this space. Using GPT-4o-mini, we extract genre\nrepresentations through multiple natural language prompts and analyze the\nconsistency of these projections across linguistic variations and their\nalignment with ground-truth data. Our results show (1) high spatial consistency\nof genre projections across 47 query formulations, (2) strong alignment between\nLLM-inferred genre locations and real-world audio feature distributions, and\n(3) evidence of a direct relationship between prompt phrasing and spatial\nshifts in the LLM's inferred vector ontology. These findings demonstrate that\nLLMs internalize structured, repurposable knowledge and that vector ontologies\noffer a promising method for extracting and analyzing this knowledge in a\ntransparent and verifiable way.\n","authors":["Kaspar Rothenfusser","Bekk Blando"],"pdf_url":"https://arxiv.org/pdf/2506.13252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13188v1","updated":"2025-06-16T07:55:44Z","published":"2025-06-16T07:55:44Z","title":"SPOT: Bridging Natural Language and Geospatial Search for Investigative\n  Journalists","summary":"  OpenStreetMap (OSM) is a vital resource for investigative journalists doing\ngeolocation verification. However, existing tools to query OSM data such as\nOverpass Turbo require familiarity with complex query languages, creating\nbarriers for non-technical users. We present SPOT, an open source natural\nlanguage interface that makes OSM's rich, tag-based geographic data more\naccessible through intuitive scene descriptions. SPOT interprets user inputs as\nstructured representations of geospatial object configurations using fine-tuned\nLarge Language Models (LLMs), with results being displayed in an interactive\nmap interface. While more general geospatial search tasks are conceivable, SPOT\nis specifically designed for use in investigative journalism, addressing\nreal-world challenges such as hallucinations in model output, inconsistencies\nin OSM tagging, and the noisy nature of user input. It combines a novel\nsynthetic data pipeline with a semantic bundling system to enable robust,\naccurate query generation. To our knowledge, SPOT is the first system to\nachieve reliable natural language access to OSM data at this level of accuracy.\nBy lowering the technical barrier to geolocation verification, SPOT contributes\na practical tool to the broader efforts to support fact-checking and combat\ndisinformation.\n","authors":["Lynn Khellaf","Ipek Baris Schlicht","Tilman Mirass","Julia Bayer","Tilman Wagner","Ruben Bouwmeester"],"pdf_url":"https://arxiv.org/pdf/2506.13188v1.pdf","comment":"Accepted to ACL 2025"},{"id":"http://arxiv.org/abs/2402.11827v2","updated":"2025-06-16T03:39:07Z","published":"2024-02-19T04:41:31Z","title":"Ask Optimal Questions: Aligning Large Language Models with Retriever's\n  Preference in Conversation","summary":"  Conversational search, unlike single-turn retrieval tasks, requires\nunderstanding the current question within a dialogue context. The common\napproach of rewrite-then-retrieve aims to decontextualize questions to be\nself-sufficient for off-the-shelf retrievers, but most existing methods produce\nsub-optimal query rewrites due to the limited ability to incorporate signals\nfrom the retrieval results. To overcome this limitation, we present a novel\nframework RetPO (Retriever's Preference Optimization), which is designed to\noptimize a language model (LM) for reformulating search queries in line with\nthe preferences of the target retrieval systems. The process begins by\nprompting a large LM to produce various potential rewrites and then collects\nretrieval performance for these rewrites as the retrievers' preferences.\nThrough the process, we construct a large-scale dataset called RF collection,\ncontaining Retrievers' Feedback on over 410K query rewrites across 12K\nconversations. Furthermore, we fine-tune a smaller LM on this dataset to align\nit with the retrievers' feedback. Our resulting model demonstrates superiority\non two benchmarks, surpassing the previous state-of-the-art performance of\nrewrite-then-retrieve approaches.\n","authors":["Chanwoong Yoon","Gangwoo Kim","Byeongguk Jeon","Sungdong Kim","Yohan Jo","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2402.11827v2.pdf","comment":"NAACL 2025 (findings)"},{"id":"http://arxiv.org/abs/2506.11603v2","updated":"2025-06-16T03:35:12Z","published":"2025-06-13T09:17:36Z","title":"TongSearch-QR: Reinforced Query Reasoning for Retrieval","summary":"  Traditional information retrieval (IR) methods excel at textual and semantic\nmatching but struggle in reasoning-intensive retrieval tasks that require\nmulti-hop inference or complex semantic understanding between queries and\ndocuments. One promising solution is to explicitly rewrite or augment queries\nusing large language models (LLMs) to elicit reasoning-relevant content prior\nto retrieval. However, the widespread use of large-scale language models like\nGPT-4 or LLaMA3-70B remains impractical due to their high inference cost and\nlimited deployability in real-world systems. In this work, we introduce\nTongSearch QR (Previously Known as \"TongSearch Reasoner\"), a family of\nsmall-scale language models for query reasoning and rewriting in\nreasoning-intensive retrieval. With a novel semi-rule-based reward function, we\nemploy reinforcement learning approaches enabling smaller language models, e,g,\nQwen2.5-7B-Instruct and Qwen2.5-1.5B-Instruct, to achieve query reasoning\nperformance rivaling large-scale language models without their prohibitive\ninference costs. Experiment results on BRIGHT benchmark show that with BM25 as\nretrievers, both TongSearch QR-7B and TongSearch QR-1.5B models significantly\noutperform existing baselines, including prompt-based query reasoners and some\nlatest dense retrievers trained for reasoning-intensive retrieval tasks,\noffering superior adaptability for real-world deployment.\n","authors":["Xubo Qin","Jun Bai","Jiaqi Li","Zixia Jia","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.11603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11999v2","updated":"2025-06-16T03:10:31Z","published":"2025-06-13T17:54:12Z","title":"Generative Representational Learning of Foundation Models for\n  Recommendation","summary":"  Developing a single foundation model with the capability to excel across\ndiverse tasks has been a long-standing objective in the field of artificial\nintelligence. As the wave of general-purpose foundation models sweeps across\nvarious domains, their influence has significantly extended to the field of\nrecommendation systems. While recent efforts have explored recommendation\nfoundation models for various generative tasks, they often overlook crucial\nembedding tasks and struggle with the complexities of multi-task learning,\nincluding knowledge sharing & conflict resolution, and convergence speed\ninconsistencies. To address these limitations, we introduce RecFound, a\ngenerative representational learning framework for recommendation foundation\nmodels. We construct the first comprehensive dataset for recommendation\nfoundation models covering both generative and embedding tasks across diverse\nscenarios. Based on this dataset, we propose a novel multi-task training scheme\nfeaturing a Task-wise Mixture of Low-rank Experts (TMoLE) to handle knowledge\nsharing & conflict, a Step-wise Convergence-oriented Sample Scheduler (S2Sched)\nto address inconsistent convergence, and a Model Merge module to balance the\nperformance across tasks. Experiments demonstrate that RecFound achieves\nstate-of-the-art performance across various recommendation tasks, outperforming\nexisting baselines.\n","authors":["Zheli Zhou","Chenxu Zhu","Jianghao Lin","Bo Chen","Ruiming Tang","Weinan Zhang","Yong Yu"],"pdf_url":"https://arxiv.org/pdf/2506.11999v2.pdf","comment":"Project page is available at https://junkfood436.github.io/RecFound/"}],"Databases":[{"id":"http://arxiv.org/abs/2506.14034v1","updated":"2025-06-16T22:13:48Z","published":"2025-06-16T22:13:48Z","title":"Sketched Sum-Product Networks for Joins","summary":"  Sketches have shown high accuracy in multi-way join cardinality estimation, a\ncritical problem in cost-based query optimization. Accurately estimating the\ncardinality of a join operation -- analogous to its computational cost --\nallows the optimization of query execution costs in relational database\nsystems. However, although sketches have shown high efficacy in query\noptimization, they are typically constructed specifically for predefined\nselections in queries that are assumed to be given a priori, hindering their\napplicability to new queries. As a more general solution, we propose for\nSum-Product Networks to dynamically approximate sketches on-the-fly.\nSum-Product Networks can decompose and model multivariate distributions, such\nas relations, as linear combinations of multiple univariate distributions. By\nrepresenting these univariate distributions as sketches, Sum-Product Networks\ncan combine them element-wise to efficiently approximate the sketch of any\nquery selection. These approximate sketches can then be applied to join\ncardinality estimation. In particular, we implement the Fast-AGMS and Bound\nSketch methods, which have successfully been used in prior work, despite their\ncostly construction. By accurately approximating them instead, our work\nprovides a practical alternative to apply these sketches to query optimization.\n","authors":["Brian Tsan","Abylay Amanbayev","Asoke Datta","Florin Rusu"],"pdf_url":"https://arxiv.org/pdf/2506.14034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13670v1","updated":"2025-06-16T16:29:29Z","published":"2025-06-16T16:29:29Z","title":"Parachute: Single-Pass Bi-Directional Information Passing","summary":"  Sideways information passing is a well-known technique for mitigating the\nimpact of large build sides in a database query plan. As currently implemented\nin production systems, sideways information passing enables only a\nuni-directional information flow, as opposed to instance-optimal algorithms,\nsuch as Yannakakis'. On the other hand, the latter require an additional pass\nover the input, which hinders adoption in production systems.\n  In this paper, we make a step towards enabling single-pass bi-directional\ninformation passing during query execution. We achieve this by statically\nanalyzing between which tables the information flow is blocked and by\nleveraging precomputed join-induced fingerprint columns on FK-tables. On the\nJOB benchmark, Parachute improves DuckDB v1.2's end-to-end execution time\nwithout and with semi-join filtering by 1.54x and 1.24x, respectively, when\nallowed to use 15% extra space.\n","authors":["Mihail Stoian","Andreas Zimmerer","Skander Krid","Amadou Latyr Ngom","Jialin Ding","Tim Kraska","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2506.13670v1.pdf","comment":"To appear at VLDB 2025"},{"id":"http://arxiv.org/abs/2411.17603v2","updated":"2025-06-16T15:46:33Z","published":"2024-11-26T17:11:10Z","title":"Is Integer Linear Programming All You Need for Deletion Propagation? A\n  Unified and Practical Approach for Generalized Deletion Propagation","summary":"  Deletion Propagation (DP) refers to a family of database problems rooted in\nthe classical view-update problem: how to propagate intended deletions in a\nview (query output) back to the source database while satisfying constraints\nand minimizing side effects. Although studied for over 40 years, DP variants,\ntheir complexities, and practical algorithms have been typically explored in\nisolation.\n  This work presents a unified and generalized framework for DP with several\nkey benefits: (1) It unifies and generalizes all previously known DP variants,\neffectively subsuming them within a broader class of problems, including new,\nwell-motivated variants. (2) It comes with a practical and general-purpose\nalgorithm that is ``coarse-grained instance-optimal'': it runs in PTIME for all\nknown PTIME cases and can automatically exploit structural regularities in the\ndata, i.e. it does not rely on hints about such regularities as part of the\ninput. (3) It is complete: our framework handles all known DP variants in all\nsettings (including those involving self-joins, unions, and bag semantics), and\nallows us to provide new complexity results. (4) It is easy to implement and,\nin many cases, outperforms prior variant-specific solutions, sometimes by\norders of magnitude. We provide the first experimental results for several DP\nvariants previously studied only in theory.\n","authors":["Neha Makhija","Wolfgang Gatterbauer"],"pdf_url":"https://arxiv.org/pdf/2411.17603v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2310.11703v2","updated":"2025-06-16T07:42:11Z","published":"2023-10-18T04:31:06Z","title":"A Comprehensive Survey on Vector Database: Storage and Retrieval\n  Technique, Challenge","summary":"  Vector databases (VDBs) have emerged to manage high-dimensional data that\nexceed the capabilities of traditional database management systems, and are now\ntightly integrated with large language models as well as widely applied in\nmodern artificial intelligence systems. Although relatively few studies\ndescribe existing or introduce new vector database architectures, the core\ntechnologies underlying VDBs, such as approximate nearest neighbor search, have\nbeen extensively studied and are well documented in the literature. In this\nwork, we present a comprehensive review of the relevant algorithms to provide a\ngeneral understanding of this booming research area. Specifically, we first\nprovide a review of storage and retrieval techniques in VDBs, with detailed\ndesign principles and technological evolution. Then, we conduct an in-depth\ncomparison of several advanced VDB solutions with their strengths, limitations,\nand typical application scenarios. Finally, we also outline emerging\nopportunities for coupling VDBs with large language models, including open\nresearch problems and trends, such as novel indexing strategies. This survey\naims to serve as a practical resource, enabling readers to quickly gain an\noverall understanding of the current knowledge landscape in this rapidly\ndeveloping area.\n","authors":["Le Ma","Ran Zhang","Yikun Han","Shirui Yu","Zaitian Wang","Zhiyuan Ning","Jinghan Zhang","Ping Xu","Pengjiang Li","Wei Ju","Chong Chen","Dongjie Wang","Kunpeng Liu","Pengyang Wang","Pengfei Wang","Yanjie Fu","Chunjiang Liu","Yuanchun Zhou","Chang-Tien Lu"],"pdf_url":"https://arxiv.org/pdf/2310.11703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10422v2","updated":"2025-06-16T02:33:57Z","published":"2025-06-12T07:21:54Z","title":"A Hybrid Heuristic Framework for Resource-Efficient Querying of\n  Scientific Experiments Data","summary":"  Scientific experiments and modern applications are generating large amounts\nof data every day. Most organizations utilize In-house servers or Cloud\nresources to manage application data and workload. The traditional database\nmanagement system (DBMS) and HTAP systems spend significant time & resources to\nload the entire dataset into DBMS before starting query execution. On the other\nhand, in-situ engines may reparse required data multiple times, increasing\nresource utilization and data processing costs. Additionally, over or\nunder-allocation of resources also increases application running costs. This\npaper proposes a lightweight Resource Availability &Workload aware Hybrid\nFramework (RAW-HF) to optimize querying raw data by utilizing existing finite\nresources efficiently. RAW-HF includes modules that help optimize the resources\nrequired to execute a given workload and maximize the utilization of existing\nresources. The impact of applying RAW-HF to real-world scientific dataset\nworkloads like Sloan Digital Sky Survey (SDSS) and Linked Observation Data\n(LOD) presented over 90% and 85% reduction in workload execution time (WET)\ncompared to widely used traditional DBMS PostgreSQL. The overall CPU, IO\nresource utilization, and WET have been reduced by 26%, 25%, and 26%,\nrespectively, while improving memory utilization by 33%, compared to the\nstate-of-the-art workload-aware partial loading technique (WA) proposed for\nhybrid systems. A comparison of MUAR technique used by RAW-HF with machine\nlearning based resource allocation techniques like PCC is also presented.\n","authors":["Mayank Patel","Minal Bhise"],"pdf_url":"https://arxiv.org/pdf/2506.10422v2.pdf","comment":null}]},"2025-06-15T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.12981v1","updated":"2025-06-15T22:35:43Z","published":"2025-06-15T22:35:43Z","title":"Efficient Neuro-Symbolic Retrieval-Augmented Generation through Adaptive\n  Query Routing","summary":"  Retrieval-Augmented Generation (RAG) systems address factual inconsistencies\nin Large Language Models by grounding generation in external knowledge, yet\nthey face a fundamental efficiency problem: simple queries consume\ncomputational resources equivalent to complex multi-hop reasoning tasks. We\npresent SymRAG, a neuro-symbolic framework that introduces adaptive query\nrouting based on real-time complexity and system load assessments. SymRAG\ndynamically selects symbolic, neural, or hybrid processing paths to align\nresource use with query demands. Evaluated on 2,000 queries from HotpotQA and\nDROP using Llama-3.2-3B and Mistral-7B models, SymRAG achieves 97.6--100.0%\nexact match accuracy with significantly lower CPU utilization (3.6--6.2%) and\nprocessing time (0.985--3.165s). Disabling adaptive logic results in 169--1151%\nincrease in processing time, highlighting the framework's impact. These results\nunderscore the potential of adaptive neuro-symbolic routing for scalable,\nsustainable AI systems.\n","authors":["Safayat Bin Hakim","Muhammad Adil","Alvaro Velasquez","Houbing Herbert Song"],"pdf_url":"https://arxiv.org/pdf/2506.12981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12925v1","updated":"2025-06-15T17:50:08Z","published":"2025-06-15T17:50:08Z","title":"Identifying and Investigating Global News Coverage of Critical Events\n  Such as Disasters and Terrorist Attacks","summary":"  Comparative studies of news coverage are challenging to conduct because\nmethods to identify news articles about the same event in different languages\nrequire expertise that is difficult to scale. We introduce an AI-powered method\nfor identifying news articles based on an event FINGERPRINT, which is a minimal\nset of metadata required to identify critical events. Our event coverage\nidentification method, FINGERPRINT TO ARTICLE MATCHING FOR EVENTS (FAME),\nefficiently identifies news articles about critical world events, specifically\nterrorist attacks and several types of natural disasters. FAME does not require\ntraining data and is able to automatically and efficiently identify news\narticles that discuss an event given its fingerprint: time, location, and class\n(such as storm or flood). The method achieves state-of-the-art performance and\nscales to massive databases of tens of millions of news articles and hundreds\nof events happening globally. We use FAME to identify 27,441 articles that\ncover 470 natural disaster and terrorist attack events that happened in 2020.\nTo this end, we use a massive database of news articles in three languages from\nMediaCloud, and three widely used, expert-curated databases of critical events:\nEM-DAT, USGS, and GTD. Our case study reveals patterns consistent with prior\nliterature: coverage of disasters and terrorist attacks correlates to death\ncounts, to the GDP of a country where the event occurs, and to trade volume\nbetween the reporting country and the country where the event occurred. We\nshare our NLP annotations and cross-country media attention data to support the\nefforts of researchers and media monitoring organizations.\n","authors":["Erica Cai","Xi Chen","Reagan Grey Keeney","Ethan Zuckerman","Brendan O'Connor","Przemyslaw A. Grabowicz"],"pdf_url":"https://arxiv.org/pdf/2506.12925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12895v1","updated":"2025-06-15T15:53:38Z","published":"2025-06-15T15:53:38Z","title":"Assessing the Performance Gap Between Lexical and Semantic Models for\n  Information Retrieval With Formulaic Legal Language","summary":"  Legal passage retrieval is an important task that assists legal practitioners\nin the time-intensive process of finding relevant precedents to support legal\narguments. This study investigates the task of retrieving legal passages or\nparagraphs from decisions of the Court of Justice of the European Union (CJEU),\nwhose language is highly structured and formulaic, leading to repetitive\npatterns. Understanding when lexical or semantic models are more effective at\nhandling the repetitive nature of legal language is key to developing retrieval\nsystems that are more accurate, efficient, and transparent for specific legal\ndomains. To this end, we explore when this routinized legal language is better\nsuited for retrieval using methods that rely on lexical and statistical\nfeatures, such as BM25, or dense retrieval models trained to capture semantic\nand contextual information. A qualitative and quantitative analysis with three\ncomplementary metrics shows that both lexical and dense models perform well in\nscenarios with more repetitive usage of language, whereas BM25 performs better\nthan the dense models in more nuanced scenarios where repetition and\nverbatim~quotes are less prevalent and in longer queries. Our experiments also\nshow that BM25 is a strong baseline, surpassing off-the-shelf dense models in 4\nout of 7 performance metrics. However, fine-tuning a dense model on\ndomain-specific data led to improved performance, surpassing BM25 in most\nmetrics, and we analyze the effect of the amount of data used in fine-tuning on\nthe model's performance and temporal robustness. The code, dataset and appendix\nrelated to this work are available on:\nhttps://github.com/larimo/lexsem-legal-ir.\n","authors":["Larissa Mori","Carlos Sousa de Oliveira","Yuehwern Yih","Mario Ventresca"],"pdf_url":"https://arxiv.org/pdf/2506.12895v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17288v1","updated":"2025-06-15T15:36:17Z","published":"2025-06-15T15:36:17Z","title":"SlimRAG: Retrieval without Graphs via Entity-Aware Context Selection","summary":"  Retrieval-Augmented Generation (RAG) enhances language models by\nincorporating external knowledge at inference time. However, graph-based RAG\nsystems often suffer from structural overhead and imprecise retrieval: they\nrequire costly pipelines for entity linking and relation extraction, yet\nfrequently return subgraphs filled with loosely related or tangential content.\nThis stems from a fundamental flaw -- semantic similarity does not imply\nsemantic relevance. We introduce SlimRAG, a lightweight framework for retrieval\nwithout graphs. SlimRAG replaces structure-heavy components with a simple yet\neffective entity-aware mechanism. At indexing time, it constructs a compact\nentity-to-chunk table based on semantic embeddings. At query time, it\nidentifies salient entities, retrieves and scores associated chunks, and\nassembles a concise, contextually relevant input -- without graph traversal or\nedge construction. To quantify retrieval efficiency, we propose Relative Index\nToken Utilization (RITU), a metric measuring the compactness of retrieved\ncontent. Experiments across multiple QA benchmarks show that SlimRAG\noutperforms strong flat and graph-based baselines in accuracy while reducing\nindex size and RITU (e.g., 16.31 vs. 56+), highlighting the value of\nstructure-free, entity-centric context selection. The code will be released\nsoon. https://github.com/continue-ai-company/SlimRAG\n","authors":["Jiale Zhang","Jiaxiang Chen","Zhucong Li","Jie Ding","Kui Zhao","Zenglin Xu","Xin Pang","Yinghui Xu"],"pdf_url":"https://arxiv.org/pdf/2506.17288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14256v2","updated":"2025-06-15T11:16:43Z","published":"2025-01-24T05:44:04Z","title":"DKT2: Revisiting Applicable and Comprehensive Knowledge Tracing in\n  Large-Scale Data","summary":"  Knowledge Tracing (KT) is a fundamental component of Intelligent Tutoring\nSystems (ITS), enabling the modeling of students' knowledge states to predict\nfuture performance. The introduction of Deep Knowledge Tracing (DKT), the first\ndeep learning-based KT (DLKT) model, has brought significant advantages in\nterms of applicability and comprehensiveness. However, recent DLKT models, such\nas Attentive Knowledge Tracing (AKT), have often prioritized predictive\nperformance at the expense of these benefits. While deep sequential models like\nDKT have shown potential, they face challenges related to parallel computing,\nstorage decision modification, and limited storage capacity. To address these\nlimitations, we propose DKT2, a novel KT model that leverages the recently\ndeveloped xLSTM architecture. DKT2 enhances applicable input representation\nusing the Rasch model and incorporates Item Response Theory (IRT) for output\ninterpretability, allowing for the decomposition of learned knowledge into\nfamiliar and unfamiliar knowledge. By integrating this knowledge with predicted\nquestions, DKT2 generates comprehensive knowledge states. Extensive experiments\nconducted across three large-scale datasets demonstrate that DKT2 consistently\noutperforms 18 baseline models in various prediction tasks, underscoring its\npotential for real-world educational applications. This work bridges the gap\nbetween theoretical advancements and practical implementation in KT. Our code\nand datasets are fully available at https://github.com/zyy-2001/DKT2.\n","authors":["Yiyun Zhou","Wenkang Han","Jingyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2501.14256v2.pdf","comment":"Accepted by ECML-PKDD 2025"},{"id":"http://arxiv.org/abs/2506.17287v1","updated":"2025-06-15T10:51:01Z","published":"2025-06-15T10:51:01Z","title":"Recommendation systems in e-commerce applications with machine learning\n  methods","summary":"  E-commerce platforms are increasingly reliant on recommendation systems to\nenhance user experience, retain customers, and, in most cases, drive sales. The\nintegration of machine learning methods into these systems has significantly\nimproved their efficiency, personalization, and scalability. This paper aims to\nhighlight the current trends in e-commerce recommendation systems, identify\nchallenges, and evaluate the effectiveness of various machine learning methods\nused, including collaborative filtering, content-based filtering, and hybrid\nmodels. A systematic literature review (SLR) was conducted, analyzing 38\npublications from 2013 to 2025. The methods used were evaluated and compared to\ndetermine their performance and effectiveness in addressing e-commerce\nchallenges.\n","authors":["Aneta Poniszewska-Maranda","Magdalena Pakula","Bozena Borowska"],"pdf_url":"https://arxiv.org/pdf/2506.17287v1.pdf","comment":"29th International Conference on Evaluation and Assessment in\n  Software Engineering, 17-20 June, 2025, Istanbul, Turkey"},{"id":"http://arxiv.org/abs/2506.12761v1","updated":"2025-06-15T08:01:35Z","published":"2025-06-15T08:01:35Z","title":"Versatile and Fast Location-Based Private Information Retrieval with\n  Fully Homomorphic Encryption over the Torus","summary":"  Location-based services often require users to share sensitive locational\ndata, raising privacy concerns due to potential misuse or exploitation by\nuntrusted servers. In response, we present VeLoPIR, a versatile location-based\nprivate information retrieval (PIR) system designed to preserve user privacy\nwhile enabling efficient and scalable query processing. VeLoPIR introduces\nthree operational modes-interval validation, coordinate validation, and\nidentifier matching-that support a broad range of real-world applications,\nincluding information and emergency alerts. To enhance performance, VeLoPIR\nincorporates multi-level algorithmic optimizations with parallel structures,\nachieving significant scalability across both CPU and GPU platforms. We also\nprovide formal security and privacy proofs, confirming the system's robustness\nunder standard cryptographic assumptions. Extensive experiments on real-world\ndatasets demonstrate that VeLoPIR achieves up to 11.55 times speed-up over a\nprior baseline. The implementation of VeLoPIR is publicly available at\nhttps://github.com/PrivStatBool/VeLoPIR.\n","authors":["Joon Soo Yoo","Taeho Kim","Ji Won Yoon"],"pdf_url":"https://arxiv.org/pdf/2506.12761v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12756v1","updated":"2025-06-15T07:47:26Z","published":"2025-06-15T07:47:26Z","title":"Hierarchical Group-wise Ranking Framework for Recommendation Models","summary":"  In modern recommender systems, CTR/CVR models are increasingly trained with\nranking objectives to improve item ranking quality. While this shift aligns\ntraining more closely with serving goals, most existing methods rely on\nin-batch negative sampling, which predominantly surfaces easy negatives. This\nlimits the model's ability to capture fine-grained user preferences and weakens\noverall ranking performance. To address this, we propose a Hierarchical\nGroup-wise Ranking Framework with two key components. First, we apply residual\nvector quantization to user embeddings to generate hierarchical user codes that\npartition users into hierarchical, trie-structured clusters. Second, we apply\nlistwise ranking losses to user-item pairs at each level of the hierarchy,\nwhere shallow levels group loosely similar users and deeper levels group highly\nsimilar users, reinforcing learning-to-rank signals through progressively\nharder negatives. Since users with similar preferences and content exposure\ntend to yield more informative negatives, applying ranking losses within these\nhierarchical user groups serves as an effective approximation of hard negative\nmining. Our approach improves ranking performance without requiring complex\nreal-time context collection or retrieval infrastructure. Extensive experiments\ndemonstrate that the proposed framework consistently enhances both model\ncalibration and ranking accuracy, offering a scalable and practical solution\nfor industrial recommender systems.\n","authors":["YaChen Yan","Liubo Li","Ravi Choudhary"],"pdf_url":"https://arxiv.org/pdf/2506.12756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12689v1","updated":"2025-06-15T02:23:47Z","published":"2025-06-15T02:23:47Z","title":"SciSage: A Multi-Agent Framework for High-Quality Scientific Survey\n  Generation","summary":"  The rapid growth of scientific literature demands robust tools for automated\nsurvey-generation. However, current large language model (LLM)-based methods\noften lack in-depth analysis, structural coherence, and reliable citations. To\naddress these limitations, we introduce SciSage, a multi-agent framework\nemploying a reflect-when-you-write paradigm. SciSage features a hierarchical\nReflector agent that critically evaluates drafts at outline, section, and\ndocument levels, collaborating with specialized agents for query\ninterpretation, content retrieval, and refinement. We also release SurveyScope,\na rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11\ncomputer science domains, with strict recency and citation-based quality\ncontrols. Evaluations demonstrate that SciSage outperforms state-of-the-art\nbaselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document\ncoherence and +32% in citation F1 scores. Human evaluations reveal mixed\noutcomes (3 wins vs. 7 losses against human-written surveys), but highlight\nSciSage's strengths in topical breadth and retrieval efficiency. Overall,\nSciSage offers a promising foundation for research-assistive writing tools.\n","authors":["Xiaofeng Shi","Qian Kou","Yuduo Li","Ning Tang","Jinxin Xie","Longbin Yu","Songjing Wang","Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12687v1","updated":"2025-06-15T02:20:18Z","published":"2025-06-15T02:20:18Z","title":"Device-Cloud Collaborative Correction for On-Device Recommendation","summary":"  With the rapid development of recommendation models and device computing\npower, device-based recommendation has become an important research area due to\nits better real-time performance and privacy protection. Previously,\nTransformer-based sequential recommendation models have been widely applied in\nthis field because they outperform Recurrent Neural Network (RNN)-based\nrecommendation models in terms of performance. However, as the length of\ninteraction sequences increases, Transformer-based models introduce\nsignificantly more space and computational overhead compared to RNN-based\nmodels, posing challenges for device-based recommendation. To balance real-time\nperformance and high performance on devices, we propose Device-Cloud\n\\underline{Co}llaborative \\underline{Corr}ection Framework for On-Device\n\\underline{Rec}ommendation (CoCorrRec). CoCorrRec uses a self-correction\nnetwork (SCN) to correct parameters with extremely low time cost. By updating\nmodel parameters during testing based on the input token, it achieves\nperformance comparable to current optimal but more complex Transformer-based\nmodels. Furthermore, to prevent SCN from overfitting, we design a global\ncorrection network (GCN) that processes hidden states uploaded from devices and\nprovides a global correction solution. Extensive experiments on multiple\ndatasets show that CoCorrRec outperforms existing Transformer-based and\nRNN-based device recommendation models in terms of performance, with fewer\nparameters and lower FLOPs, thereby achieving a balance between real-time\nperformance and high efficiency.\n","authors":["Tianyu Zhan","Shengyu Zhang","Zheqi Lv","Jieming Zhu","Jiwei Li","Fan Wu","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2506.12687v1.pdf","comment":"To be published in IJCAI-2025"}],"Databases":[{"id":"http://arxiv.org/abs/2506.12990v1","updated":"2025-06-15T23:13:20Z","published":"2025-06-15T23:13:20Z","title":"Humans, Machine Learning, and Language Models in Union: A Cognitive\n  Study on Table Unionability","summary":"  Data discovery and table unionability in particular became key tasks in\nmodern Data Science. However, the human perspective for these tasks is still\nunder-explored. Thus, this research investigates the human behavior in\ndetermining table unionability within data discovery. We have designed an\nexperimental survey and conducted a comprehensive analysis, in which we assess\nhuman decision-making for table unionability. We use the observations from the\nanalysis to develop a machine learning framework to boost the (raw) performance\nof humans. Furthermore, we perform a preliminary study on how LLM performance\nis compared to humans indicating that it is typically better to consider a\ncombination of both. We believe that this work lays the foundations for\ndeveloping future Human-in-the-Loop systems for efficient data discovery.\n","authors":["Sreeram Marimuthu","Nina Klimenkova","Roee Shraga"],"pdf_url":"https://arxiv.org/pdf/2506.12990v1.pdf","comment":"6 Pages, 4 figures, ACM SIGMOD HILDA '25 (Status-Accepted)"},{"id":"http://arxiv.org/abs/2502.17248v2","updated":"2025-06-15T16:16:30Z","published":"2025-02-24T15:26:22Z","title":"Alpha-SQL: Zero-Shot Text-to-SQL using Monte Carlo Tree Search","summary":"  Text-to-SQL, which enables natural language interaction with databases,\nserves as a pivotal method across diverse industries. With new, more powerful\nlarge language models (LLMs) emerging every few months, fine-tuning has become\nincredibly costly, labor-intensive, and error-prone. As an alternative,\nzero-shot Text-to-SQL, which leverages the growing knowledge and reasoning\ncapabilities encoded in LLMs without task-specific fine-tuning, presents a\npromising and more challenging direction. To address this challenge, we propose\nAlpha-SQL, a novel approach that leverages a Monte Carlo Tree Search (MCTS)\nframework to iteratively infer SQL construction actions based on partial\nreasoning states. To enhance the framework's reasoning capabilities, we\nintroduce LLM-as-Action-Model to dynamically generate SQL construction actions\nduring the MCTS process, steering the search toward more promising SQL queries.\nMoreover, Alpha-SQL employs a self-supervised reward function to evaluate the\nquality of candidate SQL queries, ensuring more accurate and efficient query\ngeneration. Experimental results show that Alpha-SQL achieves 69.7% execution\naccuracy on the BIRD development set, using a 32B open-source LLM without\nfine-tuning. Alpha-SQL outperforms the best previous zero-shot approach based\non GPT-4o by 2.5% on the BIRD development set.\n","authors":["Boyan Li","Jiayi Zhang","Ju Fan","Yanwei Xu","Chong Chen","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2502.17248v2.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2408.05109v5","updated":"2025-06-15T15:53:09Z","published":"2024-08-09T14:59:36Z","title":"A Survey of Text-to-SQL in the Era of LLMs: Where are we, and where are\n  we going?","summary":"  Translating users' natural language queries (NL) into SQL queries (i.e.,\nText-to-SQL, a.k.a. NL2SQL) can significantly reduce barriers to accessing\nrelational databases and support various commercial applications. The\nperformance of Text-to-SQL has been greatly enhanced with the emergence of\nLarge Language Models (LLMs). In this survey, we provide a comprehensive review\nof Text-to-SQL techniques powered by LLMs, covering its entire lifecycle from\nthe following four aspects: (1) Model: Text-to-SQL translation techniques that\ntackle not only NL ambiguity and under-specification, but also properly map NL\nwith database schema and instances; (2) Data: From the collection of training\ndata, data synthesis due to training data scarcity, to Text-to-SQL benchmarks;\n(3) Evaluation: Evaluating Text-to-SQL methods from multiple angles using\ndifferent metrics and granularities; and (4) Error Analysis: analyzing\nText-to-SQL errors to find the root cause and guiding Text-to-SQL models to\nevolve. Moreover, we offer a rule of thumb for developing Text-to-SQL\nsolutions. Finally, we discuss the research challenges and open problems of\nText-to-SQL in the LLMs era.\n","authors":["Xinyu Liu","Shuyu Shen","Boyan Li","Peixian Ma","Runzhi Jiang","Yuxin Zhang","Ju Fan","Guoliang Li","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2408.05109v5.pdf","comment":"20 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.11984v2","updated":"2025-06-15T15:17:10Z","published":"2025-03-15T03:54:10Z","title":"NL2SQL-BUGs: A Benchmark for Detecting Semantic Errors in NL2SQL\n  Translation","summary":"  Natural Language to SQL (i.e., NL2SQL) translation is crucial for\ndemocratizing database access, but even state-of-the-art models frequently\ngenerate semantically incorrect SQL queries, hindering the widespread adoption\nof these techniques by database vendors. While existing NL2SQL benchmarks\nprimarily focus on correct query translation, we argue that a benchmark\ndedicated to identifying common errors in NL2SQL translations is equally\nimportant, as accurately detecting these errors is a prerequisite for any\nsubsequent correction-whether performed by humans or models. To address this\ngap, we propose NL2SQL-BUGs, the first benchmark dedicated to detecting and\ncategorizing semantic errors in NL2SQL translation. NL2SQL-BUGs adopts a\ntwo-level taxonomy to systematically classify semantic errors, covering 9 main\ncategories and 31 subcategories. The benchmark consists of 2,018\nexpert-annotated instances, each containing a natural language query, database\nschema, and SQL query, with detailed error annotations for semantically\nincorrect queries. Through comprehensive experiments, we demonstrate that\ncurrent large language models exhibit significant limitations in semantic error\ndetection, achieving an average detection accuracy of 75.16%. Specifically, our\nmethod successfully detected 106 errors (accounting for 6.91%) in BIRD, a\nwidely-used NL2SQL dataset, which were previously undetected annotation errors.\nThis highlights the importance of semantic error detection in NL2SQL systems.\nThe benchmark is publicly available at https://nl2sql-bugs.github.io/.\n","authors":["Xinyu Liu","Shuyu Shen","Boyan Li","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2503.11984v2.pdf","comment":"12 pages, 6 figures, 4 tables, KDD 2025"},{"id":"http://arxiv.org/abs/2506.12837v1","updated":"2025-06-15T13:15:28Z","published":"2025-06-15T13:15:28Z","title":"Towards Visualizing Electronic Medical Records via Natural Language\n  Queries","summary":"  Electronic medical records (EMRs) contain essential data for patient care and\nclinical research. With the diversity of structured and unstructured data in\nEHR, data visualization is an invaluable tool for managing and explaining these\ncomplexities. However, the scarcity of relevant medical visualization data and\nthe high cost of manual annotation required to develop such datasets pose\nsignificant challenges to advancing medical visualization techniques. To\naddress this issue, we propose an innovative approach using large language\nmodels (LLMs) for generating visualization data without labor-intensive manual\nannotation. We introduce a new pipeline for building text-to-visualization\nbenchmarks suitable for EMRs, enabling users to visualize EMR statistics\nthrough natural language queries (NLQs). The dataset presented in this paper\nprimarily consists of paired text medical records, NLQs, and corresponding\nvisualizations, forming the first large-scale text-to-visual dataset for\nelectronic medical record information called MedicalVis with 35,374 examples.\nAdditionally, we introduce an LLM-based approach called MedCodeT5, showcasing\nits viability in generating EMR visualizations from NLQs, outperforming various\nstrong text-to-visualization baselines. Our work facilitates standardized\nevaluation of EMR visualization methods while providing researchers with tools\nto advance this influential field of application. In a nutshell, this study and\ndataset have the potential to promote advancements in eliciting medical\ninsights through visualization.\n","authors":["Haodi Zhang","Siqi Ning","Qiyong Zheng","Jinyin Nie","Liangjie Zhang","Weicheng Wang","Yuanfeng Song"],"pdf_url":"https://arxiv.org/pdf/2506.12837v1.pdf","comment":null}]},"2025-06-14T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.12661v1","updated":"2025-06-14T23:40:49Z","published":"2025-06-14T23:40:49Z","title":"INTERPOS: Interaction Rhythm Guided Positional Morphing for Mobile App\n  Recommender Systems","summary":"  The mobile app market has expanded exponentially, offering millions of apps\nwith diverse functionalities, yet research in mobile app recommendation remains\nlimited. Traditional sequential recommender systems utilize the order of items\nin users' historical interactions to predict the next item for the users.\nPosition embeddings, well-established in transformer-based architectures for\nnatural language processing tasks, effectively distinguish token positions in\nsequences. In sequential recommendation systems, position embeddings can\ncapture the order of items in a user's historical interaction sequence.\nNevertheless, this ordering does not consider the time elapsed between two\ninteractions of the same user (e.g., 1 day, 1 week, 1 month), referred to as\n\"user rhythm\". In mobile app recommendation datasets, the time between\nconsecutive user interactions is notably longer compared to other domains like\nmovies, posing significant challenges for sequential recommender systems. To\naddress this phenomenon in the mobile app domain, we introduce INTERPOS, an\nInteraction Rhythm Guided Positional Morphing strategy for autoregressive\nmobile app recommender systems. INTERPOS incorporates rhythm-guided position\nembeddings, providing a more comprehensive representation that considers both\nthe sequential order of interactions and the temporal gaps between them. This\napproach enables a deep understanding of users' rhythms at a fine-grained\nlevel, capturing the intricacies of their interaction patterns over time. We\npropose three strategies to incorporate the morphed positional embeddings in\ntwo transformer-based sequential recommendation system architectures. Our\nextensive evaluations show that INTERPOS outperforms state-of-the-art models\nusing 7 mobile app recommendation datasets on NDCG@K and HIT@K metrics. The\nsource code of INTERPOS is available at https://github.com/dlgrad/INTERPOS.\n","authors":["M. H. Maqbool","Moghis Fereidouni","Umar Farooq","A. B. Siddique","Hassan Foroosh"],"pdf_url":"https://arxiv.org/pdf/2506.12661v1.pdf","comment":"10 pages, 8 tables, 3 figures"},{"id":"http://arxiv.org/abs/2506.17285v1","updated":"2025-06-14T22:58:48Z","published":"2025-06-14T22:58:48Z","title":"A Framework for Generating Conversational Recommendation Datasets from\n  Behavioral Interactions","summary":"  Modern recommendation systems typically follow two complementary paradigms:\ncollaborative filtering, which models long-term user preferences from\nhistorical interactions, and conversational recommendation systems (CRS), which\ninteract with users in natural language to uncover immediate needs. Each\ncaptures a different dimension of user intent. While CRS models lack\ncollaborative signals, leading to generic or poorly personalized suggestions,\ntraditional recommenders lack mechanisms to interactively elicit immediate\nneeds. Unifying these paradigms promises richer personalization but remains\nchallenging due to the lack of large-scale conversational datasets grounded in\nreal user behavior. We present ConvRecStudio, a framework that uses large\nlanguage models (LLMs) to simulate realistic, multi-turn dialogs grounded in\ntimestamped user-item interactions and reviews. ConvRecStudio follows a\nthree-stage pipeline: (1) Temporal Profiling, which constructs user profiles\nand community-level item sentiment trajectories over fine-grained aspects; (2)\nSemantic Dialog Planning, which generates a structured plan using a DAG of\nflexible super-nodes; and (3) Multi-Turn Simulation, which instantiates the\nplan using paired LLM agents for the user and system, constrained by\nexecutional and behavioral fidelity checks. We apply ConvRecStudio to three\ndomains -- MobileRec, Yelp, and Amazon Electronics -- producing over 12K\nmulti-turn dialogs per dataset. Human and automatic evaluations confirm the\nnaturalness, coherence, and behavioral grounding of the generated\nconversations. To demonstrate utility, we build a cross-attention transformer\nmodel that jointly encodes user history and dialog context, achieving gains in\nHit@K and NDCG@K over baselines using either signal alone or naive fusion.\nNotably, our model achieves a 10.9% improvement in Hit@1 on Yelp over the\nstrongest baseline.\n","authors":["Vinaik Chhetri","Yousaf Reza","Moghis Fereidouni","Srijata Maji","Umar Farooq","AB Siddique"],"pdf_url":"https://arxiv.org/pdf/2506.17285v1.pdf","comment":"12 pages, 6 tables,4 figures"},{"id":"http://arxiv.org/abs/2506.12583v1","updated":"2025-06-14T17:35:27Z","published":"2025-06-14T17:35:27Z","title":"A Gradient Meta-Learning Joint Optimization for Beamforming and Antenna\n  Position in Pinching-Antenna Systems","summary":"  In this paper, we consider a novel optimization design for multi-waveguide\npinching-antenna systems, aiming to maximize the weighted sum rate (WSR) by\njointly optimizing beamforming coefficients and antenna position. To handle the\nformulated non-convex problem, a gradient-based meta-learning joint\noptimization (GML-JO) algorithm is proposed. Specifically, the original problem\nis initially decomposed into two sub-problems of beamforming optimization and\nantenna position optimization through equivalent substitution. Then, the convex\napproximation methods are used to deal with the nonconvex constraints of\nsub-problems, and two sub-neural networks are constructed to calculate the\nsub-problems separately. Different from alternating optimization (AO), where\ntwo sub-problems are solved alternately and the solutions are influenced by the\ninitial values, two sub-neural networks of proposed GML-JO with fixed channel\ncoefficients are considered as local sub-tasks and the computation results are\nused to calculate the loss function of joint optimization. Finally, the\nparameters of sub-networks are updated using the average loss function over\ndifferent sub-tasks and the solution that is robust to the initial value is\nobtained. Simulation results demonstrate that the proposed GML-JO algorithm\nachieves 5.6 bits/s/Hz WSR within 100 iterations, yielding a 32.7\\% performance\nenhancement over conventional AO with substantially reduced computational\ncomplexity. Moreover, the proposed GML-JO algorithm is robust to different\nchoices of initialization and yields better performance compared with the\nexisting optimization methods.\n","authors":["Kang Zhou","Weixi Zhou","Donghong Cai","Xianfu Lei","Yanqing Xu","Zhiguo Ding","Pingzhi Fan"],"pdf_url":"https://arxiv.org/pdf/2506.12583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17282v1","updated":"2025-06-14T17:07:06Z","published":"2025-06-14T17:07:06Z","title":"Automating Financial Statement Audits with Large Language Models","summary":"  Financial statement auditing is essential for stakeholders to understand a\ncompany's financial health, yet current manual processes are inefficient and\nerror-prone. Even with extensive verification procedures, auditors frequently\nmiss errors, leading to inaccurate financial statements that fail to meet\nstakeholder expectations for transparency and reliability. To this end, we\nharness large language models (LLMs) to automate financial statement auditing\nand rigorously assess their capabilities, providing insights on their\nperformance boundaries in the scenario of automated auditing. Our work\nintroduces a comprehensive benchmark using a curated dataset combining\nreal-world financial tables with synthesized transaction data. In the\nbenchmark, we developed a rigorous five-stage evaluation framework to assess\nLLMs' auditing capabilities. The benchmark also challenges models to map\nspecific financial statement errors to corresponding violations of accounting\nstandards, simulating real-world auditing scenarios through test cases. Our\ntesting reveals that current state-of-the-art LLMs successfully identify\nfinancial statement errors when given historical transaction data. However,\nthese models demonstrate significant limitations in explaining detected errors\nand citing relevant accounting standards. Furthermore, LLMs struggle to execute\ncomplete audits and make necessary financial statement revisions. These\nfindings highlight a critical gap in LLMs' domain-specific accounting\nknowledge. Future research must focus on enhancing LLMs' understanding of\nauditing principles and procedures. Our benchmark and evaluation framework\nestablish a foundation for developing more effective automated auditing tools\nthat will substantially improve the accuracy and efficiency of real-world\nfinancial statement auditing.\n","authors":["Rushi Wang","Jiateng Liu","Weijie Zhao","Shenglan Li","Denghui Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.17282v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2506.12571v1","updated":"2025-06-14T16:56:00Z","published":"2025-06-14T16:56:00Z","title":"DoTA-RAG: Dynamic of Thought Aggregation RAG","summary":"  In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a\nretrieval-augmented generation system optimized for high-throughput,\nlarge-scale web knowledge indexes. Traditional RAG pipelines often suffer from\nhigh latency and limited accuracy over massive, diverse datasets. DoTA-RAG\naddresses these challenges with a three-stage pipeline: query rewriting,\ndynamic routing to specialized sub-indexes, and multi-stage retrieval and\nranking. We further enhance retrieval by evaluating and selecting a superior\nembedding model, re-embedding the large FineWeb-10BT corpus. Moreover, we\ncreate a diverse Q&A dataset of 500 questions generated via the DataMorgana\nsetup across a broad range of WebOrganizer topics and formats. DoTA-RAG\nimproves the answer correctness score from 0.752 (baseline, using LiveRAG\npre-built vector store) to 1.478 while maintaining low latency, and it achieves\na 0.929 correctness score on the Live Challenge Day. These results highlight\nDoTA-RAG's potential for practical deployment in domains requiring fast,\nreliable access to large and evolving knowledge sources.\n","authors":["Saksorn Ruangtanusak","Natthapath Rungseesiripak","Peerawat Rojratchadakorn","Monthol Charattrakool","Natapong Nitarach"],"pdf_url":"https://arxiv.org/pdf/2506.12571v1.pdf","comment":"SIGIR LiveRAG 2025 (oral presentation)"},{"id":"http://arxiv.org/abs/2504.08385v2","updated":"2025-06-14T16:27:19Z","published":"2025-04-11T09:37:48Z","title":"Scholar Inbox: Personalized Paper Recommendations for Scientists","summary":"  Scholar Inbox is a new open-access platform designed to address the\nchallenges researchers face in staying current with the rapidly expanding\nvolume of scientific literature. We provide personalized recommendations,\ncontinuous updates from open-access archives (arXiv, bioRxiv, etc.), visual\npaper summaries, semantic search, and a range of tools to streamline research\nworkflows and promote open research access. The platform's personalized\nrecommendation system is trained on user ratings, ensuring that recommendations\nare tailored to individual researchers' interests. To further enhance the user\nexperience, Scholar Inbox also offers a map of science that provides an\noverview of research across domains, enabling users to easily explore specific\ntopics. We use this map to address the cold start problem common in recommender\nsystems, as well as an active learning strategy that iteratively prompts users\nto rate a selection of papers, allowing the system to learn user preferences\nquickly. We evaluate the quality of our recommendation system on a novel\ndataset of 800k user ratings, which we make publicly available, as well as via\nan extensive user study. https://www.scholar-inbox.com/\n","authors":["Markus Flicke","Glenn Angrabeit","Madhav Iyengar","Vitalii Protsenko","Illia Shakun","Jovan Cicvaric","Bora Kargi","Haoyu He","Lukas Schuler","Lewin Scholz","Kavyanjali Agnihotri","Yong Cao","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2504.08385v2.pdf","comment":"https://www.scholar-inbox.com/"},{"id":"http://arxiv.org/abs/2310.19488v3","updated":"2025-06-14T15:45:48Z","published":"2023-10-30T12:25:00Z","title":"CoLLM: Integrating Collaborative Embeddings into Large Language Models\n  for Recommendation","summary":"  Leveraging Large Language Models as Recommenders (LLMRec) has gained\nsignificant attention and introduced fresh perspectives in user preference\nmodeling. Existing LLMRec approaches prioritize text semantics, usually\nneglecting the valuable collaborative information from user-item interactions\nin recommendations. While these text-emphasizing approaches excel in cold-start\nscenarios, they may yield sub-optimal performance in warm-start situations. In\npursuit of superior recommendations for both cold and warm start scenarios, we\nintroduce CoLLM, an innovative LLMRec methodology that seamlessly incorporates\ncollaborative information into LLMs for recommendation. CoLLM captures\ncollaborative information through an external traditional model and maps it to\nthe input token embedding space of LLM, forming collaborative embeddings for\nLLM usage. Through this external integration of collaborative information,\nCoLLM ensures effective modeling of collaborative information without modifying\nthe LLM itself, providing the flexibility to employ various collaborative\ninformation modeling techniques. Extensive experiments validate that CoLLM\nadeptly integrates collaborative information into LLMs, resulting in enhanced\nrecommendation performance. We release the code and data at\nhttps://github.com/zyang1580/CoLLM.\n","authors":["Yang Zhang","Fuli Feng","Jizhi Zhang","Keqin Bao","Qifan Wang","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2310.19488v3.pdf","comment":"Accepted by IEEE TKDE 2025 (add new LLM backbone Qwen2-1.5B and NDCG\n  metric)"},{"id":"http://arxiv.org/abs/2412.18396v3","updated":"2025-06-14T15:20:18Z","published":"2024-12-24T12:39:23Z","title":"Contrastive Representation for Interactive Recommendation","summary":"  Interactive Recommendation (IR) has gained significant attention recently for\nits capability to quickly capture dynamic interest and optimize both short and\nlong term objectives. IR agents are typically implemented through Deep\nReinforcement Learning (DRL), because DRL is inherently compatible with the\ndynamic nature of IR. However, DRL is currently not perfect for IR. Due to the\nlarge action space and sample inefficiency problem, training DRL recommender\nagents is challenging. The key point is that useful features cannot be\nextracted as high-quality representations for the recommender agent to optimize\nits policy. To tackle this problem, we propose Contrastive Representation for\nInteractive Recommendation (CRIR). CRIR efficiently extracts latent, high-level\npreference ranking features from explicit interaction, and leverages the\nfeatures to enhance users' representation. Specifically, the CRIR provides\nrepresentation through one representation network, and refines it through our\nproposed Preference Ranking Contrastive Learning (PRCL). The key insight of\nPRCL is that it can perform contrastive learning without relying on\ncomputations involving high-level representations or large potential action\nsets. Furthermore, we also propose a data exploiting mechanism and an agent\ntraining mechanism to better adapt CRIR to the DRL backbone. Extensive\nexperiments have been carried out to show our method's superior improvement on\nthe sample efficiency while training an DRL-based IR agent.\n","authors":["Jingyu Li","Zhiyong Feng","Dongxiao He","Hongqi Chen","Qinghang Gao","Guoli Wu"],"pdf_url":"https://arxiv.org/pdf/2412.18396v3.pdf","comment":"AAAI-2025 Accepted paper"},{"id":"http://arxiv.org/abs/2506.12494v1","updated":"2025-06-14T13:16:31Z","published":"2025-06-14T13:16:31Z","title":"FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented\n  Generation","summary":"  Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large\nlanguage model applications, with numerous existing frameworks offering a wide\nrange of functionalities to facilitate the development of RAG systems. However,\nwe have identified several persistent challenges in these frameworks, including\ndifficulties in algorithm reproduction and sharing, lack of new techniques, and\nhigh system overhead. To address these limitations, we introduce\n\\textbf{FlexRAG}, an open-source framework specifically designed for research\nand prototyping. FlexRAG supports text-based, multimodal, and network-based\nRAG, providing comprehensive lifecycle support alongside efficient asynchronous\nprocessing and persistent caching capabilities. By offering a robust and\nflexible solution, FlexRAG enables researchers to rapidly develop, deploy, and\nshare advanced RAG systems. Our toolkit and resources are available at\n\\href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.\n","authors":["Zhuocheng Zhang","Yang Feng","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.12494v1.pdf","comment":"Accepted by ACL 2025 Demo"},{"id":"http://arxiv.org/abs/2506.17281v1","updated":"2025-06-14T08:20:15Z","published":"2025-06-14T08:20:15Z","title":"CORONA: A Coarse-to-Fine Framework for Graph-based Recommendation with\n  Large Language Models","summary":"  Recommender systems (RSs) are designed to retrieve candidate items a user\nmight be interested in from a large pool. A common approach is using graph\nneural networks (GNNs) to capture high-order interaction relationships. As\nlarge language models (LLMs) have shown strong capabilities across domains,\nresearchers are exploring their use to enhance recommendation. However, prior\nwork limits LLMs to re-ranking results or dataset augmentation, failing to\nutilize their power during candidate filtering - which may lead to suboptimal\nperformance. Instead, we propose to leverage LLMs' reasoning abilities during\nthe candidate filtering process, and introduce Chain Of Retrieval ON grAphs\n(CORONA) to progressively narrow down the range of candidate items on\ninteraction graphs with the help of LLMs: (1) First, LLM performs preference\nreasoning based on user profiles, with the response serving as a query to\nextract relevant users and items from the interaction graph as\npreference-assisted retrieval; (2) Then, using the information retrieved in the\nprevious step along with the purchase history of target user, LLM conducts\nintent reasoning to help refine an even smaller interaction subgraph as\nintent-assisted retrieval; (3) Finally, we employ a GNN to capture high-order\ncollaborative filtering information from the extracted subgraph, performing\nGNN-enhanced retrieval to generate the final recommendation results. The\nproposed framework leverages the reasoning capabilities of LLMs during the\nretrieval process, while seamlessly integrating GNNs to enhance overall\nrecommendation performance. Extensive experiments on various datasets and\nsettings demonstrate that our proposed CORONA achieves state-of-the-art\nperformance with an 18.6% relative improvement in recall and an 18.4% relative\nimprovement in NDCG on average.\n","authors":["Junze Chen","Xinjie Yang","Cheng Yang","Junfei Bao","Zeyuan Guo","Yawen Li","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2506.17281v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.12488v1","updated":"2025-06-14T12:58:02Z","published":"2025-06-14T12:58:02Z","title":"Redbench: A Benchmark Reflecting Real Workloads","summary":"  Instance-optimized components have made their way into production systems. To\nsome extent, this adoption is due to the characteristics of customer workloads,\nwhich can be individually leveraged during the model training phase. However,\nthere is a gap between research and industry that impedes the development of\nrealistic learned components: the lack of suitable workloads. Existing ones,\nsuch as TPC-H and TPC-DS, and even more recent ones, such as DSB and CAB, fail\nto exhibit real workload patterns, particularly distribution shifts.\n  In this paper, we introduce Redbench, a collection of 30 workloads that\nreflect query patterns observed in the real world. The workloads were obtained\nby sampling queries from support benchmarks and aligning them with workload\ncharacteristics observed in Redset.\n","authors":["Skander Krid","Mihail Stoian","Andreas Kipf"],"pdf_url":"https://arxiv.org/pdf/2506.12488v1.pdf","comment":"Eighth International Workshop on Exploiting Artificial Intelligence\n  Techniques for Data Management (aiDM 2025)"},{"id":"http://arxiv.org/abs/2506.12365v1","updated":"2025-06-14T05:55:19Z","published":"2025-06-14T05:55:19Z","title":"Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and\n  Ethics","summary":"  This survey paper outlines the key developments in the field of Large\nLanguage Models (LLMs), such as enhancing their reasoning skills, adaptability\nto various tasks, increased computational efficiency, and ability to make\nethical decisions. The techniques that have been most effective in bridging the\ngap between human and machine communications include the Chain-of-Thought\nprompting, Instruction Tuning, and Reinforcement Learning from Human Feedback.\nThe improvements in multimodal learning and few-shot or zero-shot techniques\nhave further empowered LLMs to handle complex jobs with minor input. They also\nmanage to do more with less by applying scaling and optimization tricks for\ncomputing power conservation. This survey also offers a broader perspective on\nrecent advancements in LLMs going beyond isolated aspects such as model\narchitecture or ethical concerns. It categorizes emerging methods that enhance\nLLM reasoning, efficiency, and ethical alignment. It also identifies\nunderexplored areas such as interpretability, cross-modal integration and\nsustainability. With recent progress, challenges like huge computational costs,\nbiases, and ethical risks remain constant. Addressing these requires bias\nmitigation, transparent decision-making, and clear ethical guidelines. Future\nresearch will focus on enhancing models ability to handle multiple input,\nthereby making them more intelligent, safe, and reliable.\n","authors":["Asifullah khan","Muhammad Zaeem Khan","Saleha Jamshed","Sadia Ahmad","Aleesha Zainab","Kaynat Khatib","Faria Bibi","Abdul Rehman"],"pdf_url":"https://arxiv.org/pdf/2506.12365v1.pdf","comment":null}]},"2025-06-13T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.18251v2","updated":"2025-06-13T21:35:13Z","published":"2024-10-09T16:35:41Z","title":"Context-Augmented Code Generation Using Programming Knowledge Graphs","summary":"  Large Language Models (LLMs) and Code-LLMs (CLLMs) have significantly\nimproved code generation, but, they frequently face difficulties when dealing\nwith challenging and complex problems. Retrieval-Augmented Generation (RAG)\naddresses this issue by retrieving and integrating external knowledge at the\ninference time. However, retrieval models often fail to find most relevant\ncontext, and generation models, with limited context capacity, can hallucinate\nwhen given irrelevant data. We present a novel framework that leverages a\nProgramming Knowledge Graph (PKG) to semantically represent and retrieve code.\nThis approach enables fine-grained code retrieval by focusing on the most\nrelevant segments while reducing irrelevant context through a tree-pruning\ntechnique. PKG is coupled with a re-ranking mechanism to reduce even more\nhallucinations by selectively integrating non-RAG solutions. We propose two\nretrieval approaches-block-wise and function-wise-based on the PKG, optimizing\ncontext granularity. Evaluations on the HumanEval and MBPP benchmarks show our\nmethod improves pass@1 accuracy by up to 20%, and outperforms state-of-the-art\nmodels by up to 34% on MBPP. Our contributions include PKG-based retrieval,\ntree pruning to enhance retrieval precision, a re-ranking method for robust\nsolution selection and a Fill-in-the-Middle (FIM) enhancer module for automatic\ncode augmentation with relevant comments and docstrings.\n","authors":["Iman Saberi","Fatemeh Fard"],"pdf_url":"https://arxiv.org/pdf/2410.18251v2.pdf","comment":"20 pages, Conference"},{"id":"http://arxiv.org/abs/2405.19164v2","updated":"2025-06-13T14:26:31Z","published":"2024-05-29T15:08:55Z","title":"Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in\n  eDiscovery","summary":"  Electronic Discovery (eDiscovery) requires identifying relevant documents\nfrom vast collections for legal production requests. While artificial\nintelligence (AI) and natural language processing (NLP) have improved document\nreview efficiency, current methods still struggle with legal entities,\ncitations, and complex legal artifacts. To address these challenges, we\nintroduce DISCOvery Graph (DISCOG), an emerging system that integrates\nknowledge graphs for enhanced document ranking and classification, augmented by\nLLM-driven reasoning. DISCOG outperforms strong baselines in F1-score,\nprecision, and recall across both balanced and imbalanced datasets. In\nreal-world deployments, it has reduced litigation-related document review costs\nby approximately 98\\%, demonstrating significant business impact.\n","authors":["Sounak Lahiri","Sumit Pai","Tim Weninger","Sanmitra Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2405.19164v2.pdf","comment":"Updated with Camera Ready Copy for ACL 2025"},{"id":"http://arxiv.org/abs/2506.11763v1","updated":"2025-06-13T13:17:32Z","published":"2025-06-13T13:17:32Z","title":"DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents","summary":"  Deep Research Agents are a prominent category of LLM-based agents. By\nautonomously orchestrating multistep web exploration, targeted retrieval, and\nhigher-order synthesis, they transform vast amounts of online information into\nanalyst-grade, citation-rich reports--compressing hours of manual desk research\ninto minutes. However, a comprehensive benchmark for systematically evaluating\nthe capabilities of these agents remains absent. To bridge this gap, we present\nDeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,\neach meticulously crafted by domain experts across 22 distinct fields.\nEvaluating DRAs is inherently complex and labor-intensive. We therefore propose\ntwo novel methodologies that achieve strong alignment with human judgment. The\nfirst is a reference-based method with adaptive criteria to assess the quality\nof generated research reports. The other framework is introduced to evaluate\nDRA's information retrieval and collection capabilities by assessing its\neffective citation count and overall citation accuracy. We have open-sourced\nDeepResearch Bench and key components of these frameworks at\nhttps://github.com/Ayanami0730/deep_research_bench to accelerate the\ndevelopment of practical LLM-based agents.\n","authors":["Mingxuan Du","Benfeng Xu","Chiwei Zhu","Xiaorui Wang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2506.11763v1.pdf","comment":"31 pages, 5 figures"},{"id":"http://arxiv.org/abs/2504.08754v4","updated":"2025-06-13T11:19:12Z","published":"2025-03-28T15:49:52Z","title":"Towards Personalized Conversational Sales Agents: Contextual User\n  Profiling for Strategic Action","summary":"  Conversational Recommender Systems (CRSs)aim to engage users in dialogue to\nprovide tailored recommendations. While traditional CRSs focus on eliciting\npreferences and retrieving items, real-world e-commerce interactions involve\nmore complex decision-making, where users consider multiple factors beyond\nsimple attributes. To capture this complexity, we introduce Conversational\nSales (CSALES), a novel task that integrates preference elicitation,\nrecommendation, and persuasion within a unified conversational framework. To\nsupport realistic and systematic evaluation, we present CSUSER, an evaluation\nprotocol with LLM-based user simulator grounded in real-world behavioral data\nby modeling fine-grained user profiles for personalized interaction. We also\npropose CSI, a conversational sales agent that proactively infers contextual\nuser profiles and strategically selects actions through conversation.\nComprehensive experiments show that CSI significantly improves both\nrecommendation success and persuasive effectiveness across diverse user\nprofiles.\n","authors":["Tongyoung Kim","Jeongeun Lee","Soojin Yoon","Sunghwan Kim","Dongha Lee"],"pdf_url":"https://arxiv.org/pdf/2504.08754v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11600v1","updated":"2025-06-13T09:09:08Z","published":"2025-06-13T09:09:08Z","title":"GraphRAG-Causal: A novel graph-augmented framework for causal reasoning\n  and annotation in news","summary":"  GraphRAG-Causal introduces an innovative framework that combines graph-based\nretrieval with large language models to enhance causal reasoning in news\nanalysis. Traditional NLP approaches often struggle with identifying complex,\nimplicit causal links, especially in low-data scenarios. Our approach addresses\nthese challenges by transforming annotated news headlines into structured\ncausal knowledge graphs. It then employs a hybrid retrieval system that merges\nsemantic embeddings with graph-based structural cues leveraging Neo4j to\naccurately match and retrieve relevant events. The framework is built on a\nthree-stage pipeline: First, during Data Preparation, news sentences are\nmeticulously annotated and converted into causal graphs capturing cause,\neffect, and trigger relationships. Next, the Graph Retrieval stage stores these\ngraphs along with their embeddings in a Neo4j database and utilizes hybrid\nCypher queries to efficiently identify events that share both semantic and\nstructural similarities with a given query. Finally, the LLM Inference stage\nutilizes these retrieved causal graphs in a few-shot learning setup with\nXML-based prompting, enabling robust classification and tagging of causal\nrelationships. Experimental evaluations demonstrate that GraphRAG-Causal\nachieves an impressive F1-score of 82.1% on causal classification using just 20\nfew-shot examples. This approach significantly boosts accuracy and consistency,\nmaking it highly suitable for real-time applications in news reliability\nassessment, misinformation detection, and policy analysis.\n","authors":["Abdul Haque","Umm e Hani","Ahmad Din","Muhammad Babar","Ali Abbas","Insaf Ullah"],"pdf_url":"https://arxiv.org/pdf/2506.11600v1.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.05161v2","updated":"2025-06-13T07:47:04Z","published":"2024-07-06T19:38:41Z","title":"A Survey of Datasets for Information Diffusion Tasks","summary":"  Information diffusion across various new media platforms gradually influences\nperceptions, decisions, and social behaviors of individual users. In\ncommunication studies, the famous Five W's of Communication model (5W Model)\nhas displayed the process of information diffusion clearly. At present,\nalthough plenty of studies and corresponding datasets about information\ndiffusion have emerged, a systematic categorization of tasks and an integration\nof datasets are still lacking. To address this gap, we survey a systematic\ntaxonomy of information diffusion tasks and datasets based on the \"5W Model\"\nframework. We first categorize the information diffusion tasks into ten\nsubtasks with definitions and datasets analysis, from three main tasks of\ninformation diffusion prediction, social bot detection, and misinformation\ndetection. We also collect the publicly available dataset repository of\ninformation diffusion tasks with the available links and compare them based on\nsix attributes affiliated to users and content: user information, social\nnetwork, bot label, propagation content, propagation network, and veracity\nlabel. In addition, we discuss the limitations and future directions of current\ndatasets and research topics to advance the future development of information\ndiffusion. The dataset repository can be accessed at our website\nhttps://github.com/fuxiaG/Information-Diffusion-Datasets.\n","authors":["Fuxia Guo","Xiaowen Wang","Yanwei Xie","Zehao Wang","Jingqiu Li","Lanjun Wang"],"pdf_url":"https://arxiv.org/pdf/2407.05161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.17277v1","updated":"2025-06-13T07:44:53Z","published":"2025-06-13T07:44:53Z","title":"Chunk Twice, Embed Once: A Systematic Study of Segmentation and\n  Representation Trade-offs in Chemistry-Aware Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) systems are increasingly vital for\nnavigating the ever-expanding body of scientific literature, particularly in\nhigh-stakes domains such as chemistry. Despite the promise of RAG, foundational\ndesign choices -- such as how documents are segmented and represented -- remain\nunderexplored in domain-specific contexts. This study presents the first\nlarge-scale, systematic evaluation of chunking strategies and embedding models\ntailored to chemistry-focused RAG systems. We investigate 25 chunking\nconfigurations across five method families and evaluate 48 embedding models on\nthree chemistry-specific benchmarks, including the newly introduced\nQuestChemRetrieval dataset. Our results reveal that recursive token-based\nchunking (specifically R100-0) consistently outperforms other approaches,\noffering strong performance with minimal resource overhead. We also find that\nretrieval-optimized embeddings -- such as Nomic and Intfloat E5 variants --\nsubstantially outperform domain-specialized models like SciBERT. By releasing\nour datasets, evaluation framework, and empirical benchmarks, we provide\nactionable guidelines for building effective and efficient chemistry-aware RAG\nsystems.\n","authors":["Mahmoud Amiri","Thomas Bocklitz"],"pdf_url":"https://arxiv.org/pdf/2506.17277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11538v1","updated":"2025-06-13T07:44:42Z","published":"2025-06-13T07:44:42Z","title":"Dual-View Disentangled Multi-Intent Learning for Enhanced Collaborative\n  Filtering","summary":"  Disentangling user intentions from implicit feedback has become a promising\nstrategy to enhance recommendation accuracy and interpretability. Prior methods\noften model intentions independently and lack explicit supervision, thus\nfailing to capture the joint semantics that drive user-item interactions. To\naddress these limitations, we propose DMICF, a unified framework that\nexplicitly models interaction-level intent alignment while leveraging\nstructural signals from both user and item perspectives. DMICF adopts a\ndual-view architecture that jointly encodes user-item interaction graphs from\nboth sides, enabling bidirectional information fusion. This design enhances\nrobustness under data sparsity by allowing the structural redundancy of one\nview to compensate for the limitations of the other. To model fine-grained\nuser-item compatibility, DMICF introduces an intent interaction encoder that\nperforms sub-intent alignment within each view, uncovering shared semantic\nstructures that underlie user decisions. This localized alignment enables\nadaptive refinement of intent embeddings based on interaction context, thus\nimproving the model's generalization and expressiveness, particularly in\nlong-tail scenarios. Furthermore, DMICF integrates an intent-aware scoring\nmechanism that aggregates compatibility signals from matched intent pairs\nacross user and item subspaces, enabling personalized prediction grounded in\nsemantic congruence rather than entangled representations. To facilitate\nsemantic disentanglement, we design a discriminative training signal via\nmulti-negative sampling and softmax normalization, which pulls together\nsemantically aligned intent pairs while pushing apart irrelevant or noisy ones.\nExtensive experiments demonstrate that DMICF consistently delivers robust\nperformance across datasets with diverse interaction distributions.\n","authors":["Shanfan Zhang","Yongyi Lin","Yuan Rao","Chenlong Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.11538v1.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2506.10488v2","updated":"2025-06-13T07:32:56Z","published":"2025-06-12T08:42:19Z","title":"Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation","summary":"  In this work, we introduce the Sheet Music Benchmark (SMB), a dataset of six\nhundred and eighty-five pages specifically designed to benchmark Optical Music\nRecognition (OMR) research. SMB encompasses a diverse array of musical\ntextures, including monophony, pianoform, quartet, and others, all encoded in\nCommon Western Modern Notation using the Humdrum **kern format. Alongside SMB,\nwe introduce the OMR Normalized Edit Distance (OMR-NED), a new metric tailored\nexplicitly for evaluating OMR performance. OMR-NED builds upon the widely-used\nSymbol Error Rate (SER), offering a fine-grained and detailed error analysis\nthat covers individual musical elements such as note heads, beams, pitches,\naccidentals, and other critical notation features. The resulting numeric score\nprovided by OMR-NED facilitates clear comparisons, enabling researchers and\nend-users alike to identify optimal OMR approaches. Our work thus addresses a\nlong-standing gap in OMR evaluation, and we support our contributions with\nbaseline experiments using standardized SMB dataset splits for training and\nassessing state-of-the-art methods.\n","authors":["Juan C. Martinez-Sevilla","Joan Cerveto-Serrano","Noelia Luna","Greg Chapman","Craig Sapp","David Rizo","Jorge Calvo-Zaragoza"],"pdf_url":"https://arxiv.org/pdf/2506.10488v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06877v4","updated":"2025-06-13T06:52:31Z","published":"2024-11-11T11:17:35Z","title":"LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?","summary":"  Test collections are information-retrieval tools that allow researchers to\nquickly and easily evaluate ranking algorithms. While test collections have\nbecome an integral part of IR research, the process of data creation involves\nsignificant manual-annotation effort, which often makes it very expensive and\ntime-consuming. Consequently, test collections can become too small when the\nbudget is limited, which may lead to unstable evaluations. As a cheaper\nalternative, recent studies have proposed using large language models (LLMs) to\ncompletely replace human assessors. However, while LLMs correlate to some\nextent with human judgments, their predictions are not perfect and often show\nbias. Thus, a complete replacement with LLMs is considered too risky and not\nfully reliable.\n  In this paper, we propose LLM-Assisted Relevance Assessments (LARA), an\neffective method to balance manual annotations with LLM annotations, helping\nbuild a rich and reliable test collection even under a low budget. We use the\nLLM's predicted relevance probabilities to select the most profitable documents\nfor manual annotation under a budget constraint. Guided by theoretical\nreasoning, LARA actively learns to calibrate the LLM's predicted relevance\nprobabilities, directing the human-annotation process. Then, using the\ncalibration model learned from the limited manual annotations, LARA debiases\nthe LLM predictions to annotate the remaining non-assessed data. Experiments on\nTREC-7 Ad Hoc, TREC-8 Ad Hoc, TREC Robust 2004, and TREC-COVID datasets show\nthat LARA outperforms alternative solutions under almost any budget constraint.\nWhile the community debates humans versus LLMs in relevance assessments, we\ncontend that, given the same amount of human effort, it is reasonable to\nleverage LLMs.\n","authors":["Rikiya Takehi","Ellen M. Voorhees","Tetsuya Sakai","Ian Soboroff"],"pdf_url":"https://arxiv.org/pdf/2411.06877v4.pdf","comment":"11 pages. Accepted at SIGIR 2025 (48th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval)"},{"id":"http://arxiv.org/abs/2506.11452v1","updated":"2025-06-13T04:03:09Z","published":"2025-06-13T04:03:09Z","title":"Leveraging Reference Documents for Zero-Shot Ranking via Large Language\n  Models","summary":"  Large Language Models (LLMs) have demonstrated exceptional performance in the\ntask of text ranking for information retrieval. While Pointwise ranking\napproaches offer computational efficiency by scoring documents independently,\nthey often yield biased relevance estimates due to the lack of inter-document\ncomparisons. In contrast, Pairwise methods improve ranking accuracy by\nexplicitly comparing document pairs, but suffer from substantial computational\noverhead with quadratic complexity ($O(n^2)$). To address this tradeoff, we\npropose \\textbf{RefRank}, a simple and effective comparative ranking method\nbased on a fixed reference document. Instead of comparing all document pairs,\nRefRank prompts the LLM to evaluate each candidate relative to a shared\nreference anchor. By selecting the reference anchor that encapsulates the core\nquery intent, RefRank implicitly captures relevance cues, enabling indirect\ncomparison between documents via this common anchor. This reduces computational\ncost to linear time ($O(n)$) while importantly, preserving the advantages of\ncomparative evaluation. To further enhance robustness, we aggregate multiple\nRefRank outputs using a weighted averaging scheme across different reference\nchoices. Experiments on several benchmark datasets and with various LLMs show\nthat RefRank significantly outperforms Pointwise baselines and could achieve\nperformance at least on par with Pairwise approaches with a significantly lower\ncomputational cost.\n","authors":["Jieran Li","Xiuyuan Hu","Yang Zhao","Shengyao Zhuang","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.11452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17844v3","updated":"2025-06-13T01:36:23Z","published":"2024-04-27T09:44:56Z","title":"Towards Robust Recommendation: A Review and an Adversarial Robustness\n  Evaluation Library","summary":"  Recently, recommender system has achieved significant success. However, due\nto the openness of recommender systems, they remain vulnerable to malicious\nattacks. Additionally, natural noise in training data and issues such as data\nsparsity can also degrade the performance of recommender systems. Therefore,\nenhancing the robustness of recommender systems has become an increasingly\nimportant research topic. In this survey, we provide a comprehensive overview\nof the robustness of recommender systems. Based on our investigation, we\ncategorize the robustness of recommender systems into adversarial robustness\nand non-adversarial robustness. In the adversarial robustness, we introduce the\nfundamental principles and classical methods of recommender system adversarial\nattacks and defenses. In the non-adversarial robustness, we analyze\nnon-adversarial robustness from the perspectives of data sparsity, natural\nnoise, and data imbalance. Additionally, we summarize commonly used datasets\nand evaluation metrics for evaluating the robustness of recommender systems.\nFinally, we also discuss the current challenges in the field of recommender\nsystem robustness and potential future research directions. Additionally, to\nfacilitate fair and efficient evaluation of attack and defense methods in\nadversarial robustness, we propose an adversarial robustness evaluation\nlibrary--ShillingREC, and we conduct evaluations of basic attack models and\nrecommendation models. ShillingREC project is released at\nhttps://github.com/chengleileilei/ShillingREC.\n","authors":["Lei Cheng","Xiaowen Huang","Jitao Sang","Jian Yu"],"pdf_url":"https://arxiv.org/pdf/2404.17844v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.13128v2","updated":"2025-06-13T00:25:54Z","published":"2025-04-17T17:44:06Z","title":"FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on\n  Technical Documents","summary":"  We introduce FreshStack, a holistic framework for automatically building\ninformation retrieval (IR) evaluation benchmarks by incorporating challenging\nquestions and answers. FreshStack conducts the following steps: (1) automatic\ncorpus collection from code and technical documentation, (2) nugget generation\nfrom community-asked questions and answers, and (3) nugget-level support,\nretrieving documents using a fusion of retrieval techniques and hybrid\narchitectures. We use FreshStack to build five datasets on fast-growing,\nrecent, and niche topics to ensure the tasks are sufficiently challenging. On\nFreshStack, existing retrieval models, when applied out-of-the-box,\nsignificantly underperform oracle approaches on all five topics, denoting\nplenty of headroom to improve IR quality. In addition, we identify cases where\nrerankers do not improve first-stage retrieval accuracy (two out of five\ntopics) and oracle context helps an LLM generator generate a high-quality RAG\nanswer. We hope FreshStack will facilitate future work toward constructing\nrealistic, scalable, and uncontaminated IR and RAG evaluation benchmarks.\n","authors":["Nandan Thakur","Jimmy Lin","Sam Havens","Michael Carbin","Omar Khattab","Andrew Drozdov"],"pdf_url":"https://arxiv.org/pdf/2504.13128v2.pdf","comment":"21 pages, 4 figures, 8 tables"}],"Databases":[{"id":"http://arxiv.org/abs/2506.11986v1","updated":"2025-06-13T17:46:02Z","published":"2025-06-13T17:46:02Z","title":"Schema-R1: A reasoning training approach for schema linking in\n  Text-to-SQL Task","summary":"  Schema linking is a critical step in Text-to-SQL task, aiming to accurately\npredict the table names and column names required for the SQL query based on\nthe given question. However, current fine-tuning approaches for schema linking\nmodels employ a rote-learning paradigm, excessively optimizing for ground truth\nschema linking outcomes while compromising reasoning ability. This limitation\narises because of the difficulty in acquiring a high-quality reasoning sample\nfor downstream tasks. To address this, we propose Schema-R1, a reasoning schema\nlinking model trained using reinforcement learning. Specifically, Schema-R1\nconsists of three key steps: constructing small batches of high-quality\nreasoning samples, supervised fine-tuning for cold-start initialization, and\nrule-based reinforcement learning training. The final results demonstrate that\nour method effectively enhances the reasoning ability of the schema linking\nmodel, achieving a 10\\% improvement in filter accuracy compared to the existing\nmethod. Our code is available at https://github.com/hongWin/Schema-R1/.\n","authors":["Wuzhenghong Wen","Su Pan","yuwei Sun"],"pdf_url":"https://arxiv.org/pdf/2506.11986v1.pdf","comment":"11 pages, 3 figures, conference"},{"id":"http://arxiv.org/abs/2506.11870v1","updated":"2025-06-13T15:23:07Z","published":"2025-06-13T15:23:07Z","title":"LLM-based Dynamic Differential Testing for Database Connectors with\n  Reinforcement Learning-Guided Prompt Selection","summary":"  Database connectors are critical components enabling applications to interact\nwith underlying database management systems (DBMS), yet their security\nvulnerabilities often remain overlooked. Unlike traditional software defects,\nconnector vulnerabilities exhibit subtle behavioral patterns and are inherently\nchallenging to detect. Besides, nonstandardized implementation of connectors\nleaves potential risks (a.k.a. unsafe implementations) but is more elusive. As\na result, traditional fuzzing methods are incapable of finding such\nvulnerabilities. Even for LLM-enable test case generation, due to a lack of\ndomain knowledge, they are also incapable of generating test cases that invoke\nall interface and internal logic of connectors. In this paper, we propose\nreinforcement learning (RL)-guided LLM test-case generation for database\nconnector testing. Specifically, to equip the LLM with sufficient and\nappropriate domain knowledge, a parameterized prompt template is composed which\ncan be utilized to generate numerous prompts. Test cases are generated via LLM\nwith a prompt, and are dynamically evaluated through differential testing\nacross multiple connectors. The testing is iteratively conducted, with each\nround RL is adopted to select optimal prompt based on prior-round behavioral\nfeedback, so as to maximize control flow coverage. We implement aforementioned\nmethodology in a practical tool and evaluate it on two widely used JDBC\nconnectors: MySQL Connector/J and OceanBase Connector/J. In total, we reported\n16 bugs, among them 10 are officially confirmed and the rest are acknowledged\nas unsafe implementations.\n","authors":["Ce Lyu","Minghao Zhao","Yanhao Wang","Liang Jie"],"pdf_url":"https://arxiv.org/pdf/2506.11870v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2206.09032v8","updated":"2025-06-13T10:02:41Z","published":"2022-06-17T22:18:02Z","title":"Conjunctive Queries with Free Access Patterns under Updates","summary":"  We study the problem of answering conjunctive queries with free access\npatterns (CQAPs) under updates. A free access pattern is a partition of the\nfree variables of the query into input and output. The query returns tuples\nover the output variables given a tuple of values over the input variables.\n  We introduce a fully dynamic evaluation approach that works for all CQAPs and\nis optimal for two classes of CQAPs. This approach recovers prior work on the\ndynamic evaluation of conjunctive queries without access patterns.\n  We first give a syntactic characterisation of all CQAPs that admit constant\ntime per single-tuple update and whose output tuples can be enumerated with\nconstant delay given a tuple of values over the input variables.\n  We further chart the complexity trade-off between the preprocessing time,\nupdate time and enumeration delay for a class of CQAPs. For some of these\nCQAPs, our approach achieves optimal, albeit non-constant, update time and\ndelay. This optimality is predicated on the Online Matrix-Vector Multiplication\nconjecture.\n  We finally adapt our approach to the dynamic evaluation of tractable CQAPs\nover probabilistic databases under updates.\n","authors":["Ahmet Kara","Milos Nikolic","Dan Olteanu","Haozhe Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.09032v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11541v1","updated":"2025-06-13T07:52:09Z","published":"2025-06-13T07:52:09Z","title":"OCPQ: Object-Centric Process Querying & Constraints","summary":"  Process querying is used to extract information and insights from process\nexecution data. Similarly, process constraints can be checked against input\ndata, yielding information on which process instances violate them.\nTraditionally, such process mining techniques use case-centric event data as\ninput. However, with the uptake of Object-Centric Process Mining (OCPM),\nexisting querying and constraint checking techniques are no longer applicable.\nObject-Centric Event Data (OCED) removes the requirement to pick a single case\nnotion (i.e., requiring that events belong to exactly one case) and can thus\nrepresent many real-life processes much more accurately. In this paper, we\npresent a novel highly-expressive approach for object-centric process querying,\ncalled OCPQ. It supports a wide variety of applications, including OCED-based\nconstraint checking and filtering. The visual representation of nested queries\nin OCPQ allows users to intuitively read and create queries and constraints. We\nimplemented our approach using (1) a high-performance execution engine backend\nand (2) an easy-to-use editor frontend. Additionally, we evaluated our approach\non a real-life dataset, showing the lack in expressiveness of prior work and\nruntime performance significantly better than the general querying solutions\nSQLite and Neo4j, as well as comparable to the performance-focused DuckDB.\n","authors":["Aaron Küsters","Wil M. P. van der Aalst"],"pdf_url":"https://arxiv.org/pdf/2506.11541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04713v3","updated":"2025-06-13T06:20:03Z","published":"2024-04-06T19:25:00Z","title":"Faster Algorithms for Fair Max-Min Diversification in $\\mathbb{R}^d$","summary":"  The task of extracting a diverse subset from a dataset, often referred to as\nmaximum diversification, plays a pivotal role in various real-world\napplications that have far-reaching consequences. In this work, we delve into\nthe realm of fairness-aware data subset selection, specifically focusing on the\nproblem of selecting a diverse set of size $k$ from a large collection of $n$\ndata points (FairDiv).\n  The FairDiv problem is well-studied in the data management and theory\ncommunity. In this work, we develop the first constant approximation algorithm\nfor FairDiv that runs in near-linear time using only linear space. In contrast,\nall previously known constant approximation algorithms run in super-linear time\n(with respect to $n$ or $k$) and use super-linear space. Our approach achieves\nthis efficiency by employing a novel combination of the Multiplicative Weight\nUpdate method and advanced geometric data structures to implicitly and\napproximately solve a linear program. Furthermore, we improve the efficiency of\nour techniques by constructing a coreset. Using our coreset, we also propose\nthe first efficient streaming algorithm for the FairDiv problem whose\nefficiency does not depend on the distribution of data points. Empirical\nevaluation on million-sized datasets demonstrates that our algorithm achieves\nthe best diversity within a minute. All prior techniques are either highly\ninefficient or do not generate a good solution.\n","authors":["Yash Kurkure","Miles Shamo","Joseph Wiseman","Sainyam Galhotra","Stavros Sintos"],"pdf_url":"https://arxiv.org/pdf/2404.04713v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10886v2","updated":"2025-06-13T01:44:10Z","published":"2025-06-12T16:50:04Z","title":"S3Mirror: Making Genomic Data Transfers Fast, Reliable, and Observable\n  with DBOS","summary":"  To meet the needs of a large pharmaceutical organization, we set out to\ncreate S3Mirror - an application for transferring large genomic sequencing\ndatasets between S3 buckets quickly, reliably, and observably. We used the DBOS\nTransact durable execution framework to achieve these goals and benchmarked the\nperformance and cost of the application. S3Mirror is an open source DBOS Python\napplication that can run in a variety of environments, including DBOS Cloud\nPro, where it runs as much as 40x faster than AWS DataSync at a fraction of the\ncost. Moreover, S3Mirror is resilient to failures and allows for real-time\nfilewise observability of ongoing and past transfers.\n","authors":["Steven Vasquez-Grinnell","Alex Poliakov"],"pdf_url":"https://arxiv.org/pdf/2506.10886v2.pdf","comment":null}]},"2025-06-12T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2501.10548v3","updated":"2025-06-12T20:01:38Z","published":"2025-01-17T20:43:47Z","title":"Diffusion Models in Recommendation Systems: A Survey","summary":"  Recommender systems remain an essential topic due to its wide application in\nvarious domains and the business potential behind them. Given the great\ngeneration capability exhibited by diffusion models in computer vision\nrecently, many recommender systems have adopted diffusion models and found\nimprovements in performance for various tasks. Research in this domain has been\ngrowing rapidly and calling for a systematic survey. In this survey paper, we\npresent and propose a taxonomy in recommender systems that utilize diffusion\nmodels. Distinct from a prior survey paper that categorizes based on the role\nof the diffusion model, we categorize based on the recommendation task at hand.\nThe decision originates from the rationale that after all, the adoption of\ndiffusion models is to enhance the recommendation performance, not vice versa:\nadapting the recommendation task to enable diffusion models. Nonetheless, we\noffer a unique perspective for diffusion models in recommender systems\ncomplementary to existing surveys. We present the foundational algorithms in\ndiffusion models and their applications in recommender systems to summarize the\nrapid development in this field. Finally, we discuss open research directions\nto prepare and encourage further efforts to advance the field. We compile the\nrelevant papers in a public GitHub repository.\n","authors":["Ting-Ruen Wei","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2501.10548v3.pdf","comment":"38 pages"},{"id":"http://arxiv.org/abs/2506.06270v2","updated":"2025-06-12T20:00:31Z","published":"2025-06-06T17:53:02Z","title":"RecGPT: A Foundation Model for Sequential Recommendation","summary":"  This work addresses a fundamental barrier in recommender systems: the\ninability to generalize across domains without extensive retraining.\nTraditional ID-based approaches fail entirely in cold-start and cross-domain\nscenarios where new users or items lack sufficient interaction history.\nInspired by foundation models' cross-domain success, we develop a foundation\nmodel for sequential recommendation that achieves genuine zero-shot\ngeneralization capabilities. Our approach fundamentally departs from existing\nID-based methods by deriving item representations exclusively from textual\nfeatures. This enables immediate embedding of any new item without model\nretraining. We introduce unified item tokenization with Finite Scalar\nQuantization that transforms heterogeneous textual descriptions into\nstandardized discrete tokens. This eliminates domain barriers that plague\nexisting systems. Additionally, the framework features hybrid\nbidirectional-causal attention that captures both intra-item token coherence\nand inter-item sequential dependencies. An efficient catalog-aware beam search\ndecoder enables real-time token-to-item mapping. Unlike conventional approaches\nconfined to their training domains, RecGPT naturally bridges diverse\nrecommendation contexts through its domain-invariant tokenization mechanism.\nComprehensive evaluations across six datasets and industrial scenarios\ndemonstrate consistent performance advantages.\n","authors":["Yangqin Jiang","Xubin Ren","Lianghao Xia","Da Luo","Kangyi Lin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2506.06270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10960v1","updated":"2025-06-12T17:57:05Z","published":"2025-06-12T17:57:05Z","title":"ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark","summary":"  Large language models (LLMs) have been increasingly applied to automated\nharmful content detection tasks, assisting moderators in identifying policy\nviolations and improving the overall efficiency and accuracy of content review.\nHowever, existing resources for harmful content detection are predominantly\nfocused on English, with Chinese datasets remaining scarce and often limited in\nscope. We present a comprehensive, professionally annotated benchmark for\nChinese content harm detection, which covers six representative categories and\nis constructed entirely from real-world data. Our annotation process further\nyields a knowledge rule base that provides explicit expert knowledge to assist\nLLMs in Chinese harmful content detection. In addition, we propose a\nknowledge-augmented baseline that integrates both human-annotated knowledge\nrules and implicit knowledge from large language models, enabling smaller\nmodels to achieve performance comparable to state-of-the-art LLMs. Code and\ndata are available at https://github.com/zjunlp/ChineseHarm-bench.\n","authors":["Kangwei Liu","Siyuan Cheng","Bozhong Tian","Xiaozhuan Liang","Yuyang Yin","Meng Han","Ningyu Zhang","Bryan Hooi","Xi Chen","Shumin Deng"],"pdf_url":"https://arxiv.org/pdf/2506.10960v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2409.15724v2","updated":"2025-06-12T17:40:54Z","published":"2024-09-24T04:17:21Z","title":"LLM-Cure: LLM-based Competitor User Review Analysis for Feature\n  Enhancement","summary":"  The exponential growth of the mobile app market underscores the importance of\nconstant innovation and rapid response to user demands. As user satisfaction is\nparamount to the success of a mobile application (app), developers typically\nrely on user reviews, which represent user feedback that includes ratings and\ncomments to identify areas for improvement. However, the sheer volume of user\nreviews poses challenges in manual analysis, necessitating automated\napproaches. Existing automated approaches either analyze only the target apps\nreviews, neglecting the comparison of similar features to competitors or fail\nto provide suggestions for feature enhancement. To address these gaps, we\npropose a Large Language Model (LLM)-based Competitive User Review Analysis for\nFeature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically\ngenerate suggestion s for mobile app feature improvements. More specifically,\nLLM-Cure identifies and categorizes features within reviews by applying LLMs.\nWhen provided with a complaint in a user review, LLM-Cure curates highly rated\n(4 and 5 stars) reviews in competing apps related to the complaint and proposes\npotential improvements tailored to the target application. We evaluate LLM-Cure\non 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates\nthat LLM-Cure significantly outperforms the state-of-the-art approaches in\nassigning features to reviews by up to 13% in F1-score, up to 16% in recall and\nup to 11% in precision. Additionally, LLM-Cure demonstrates its capability to\nprovide suggestions for resolving user complaints. We verify the suggestions\nusing the release notes that reflect the changes of features in the target\nmobile app. LLM-Cure achieves a promising average of 73% of the implementation\nof the provided suggestions.\n","authors":["Maram Assi","Safwat Hassan","Ying Zou"],"pdf_url":"https://arxiv.org/pdf/2409.15724v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2506.10859v1","updated":"2025-06-12T16:20:40Z","published":"2025-06-12T16:20:40Z","title":"Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated\n  Global Context Information","summary":"  Recent advancements have successfully harnessed the power of Large Language\nModels (LLMs) for zero-shot document ranking, exploring a variety of prompting\nstrategies. Comparative approaches like pairwise and listwise achieve high\neffectiveness but are computationally intensive and thus less practical for\nlarger-scale applications. Scoring-based pointwise approaches exhibit superior\nefficiency by independently and simultaneously generating the relevance scores\nfor each candidate document. However, this independence ignores critical\ncomparative insights between documents, resulting in inconsistent scoring and\nsuboptimal performance. In this paper, we aim to improve the effectiveness of\npointwise methods while preserving their efficiency through two key\ninnovations: (1) We propose a novel Global-Consistent Comparative Pointwise\nRanking (GCCP) strategy that incorporates global reference comparisons between\neach candidate and an anchor document to generate contrastive relevance scores.\nWe strategically design the anchor document as a query-focused summary of\npseudo-relevant candidates, which serves as an effective reference point by\ncapturing the global context for document comparison. (2) These contrastive\nrelevance scores can be efficiently Post-Aggregated with existing pointwise\nmethods, seamlessly integrating essential Global Context information in a\ntraining-free manner (PAGC). Extensive experiments on the TREC DL and BEIR\nbenchmark demonstrate that our approach significantly outperforms previous\npointwise methods while maintaining comparable efficiency. Our method also\nachieves competitive performance against comparative methods that require\nsubstantially more computational resources. More analyses further validate the\nefficacy of our anchor construction strategy.\n","authors":["Kehan Long","Shasha Li","Chen Xu","Jintao Tang","Ting Wang"],"pdf_url":"https://arxiv.org/pdf/2506.10859v1.pdf","comment":"Accepted by SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.10844v1","updated":"2025-06-12T16:02:29Z","published":"2025-06-12T16:02:29Z","title":"CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation\n  through Self-Training","summary":"  This paper presents mRAG, a multi-agent retrieval-augmented generation (RAG)\nframework composed of specialized agents for subtasks such as planning,\nsearching, reasoning, and coordination. Our system uses a self-training\nparadigm with reward-guided trajectory sampling to optimize inter-agent\ncollaboration and enhance response generation. Evaluated on DataMorgana-derived\ndatasets during the SIGIR 2025 LiveRAG competition, mRAG outperforms\nconventional RAG baselines. We further analyze competition outcomes and\nshowcase the framework's strengths with case studies, demonstrating its\nefficacy for complex, real-world RAG tasks.\n","authors":["Alireza Salemi","Mukta Maddipatla","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2506.10844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10802v1","updated":"2025-06-12T15:16:34Z","published":"2025-06-12T15:16:34Z","title":"Constructing and Evaluating Declarative RAG Pipelines in PyTerrier","summary":"  Search engines often follow a pipeline architecture, where complex but\neffective reranking components are used to refine the results of an initial\nretrieval. Retrieval augmented generation (RAG) is an exciting application of\nthe pipeline architecture, where the final component generates a coherent\nanswer for the users from the retrieved documents. In this demo paper, we\ndescribe how such RAG pipelines can be formulated in the declarative PyTerrier\narchitecture, and the advantages of doing so. Our PyTerrier-RAG extension for\nPyTerrier provides easy access to standard RAG datasets and evaluation\nmeasures, state-of-the-art LLM readers, and using PyTerrier's unique operator\nnotation, easy-to-build pipelines. We demonstrate the succinctness of indexing\nand RAG pipelines on standard datasets (including Natural Questions) and how to\nbuild on the larger PyTerrier ecosystem with state-of-the-art sparse,\nlearned-sparse, and dense retrievers, and other neural rankers.\n","authors":["Craig Macdonald","Jinyuan Fang","Andrew Parry","Zaiqiao Meng"],"pdf_url":"https://arxiv.org/pdf/2506.10802v1.pdf","comment":"4 pages, 3 tables, Accepted to SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.10737v1","updated":"2025-06-12T14:26:28Z","published":"2025-06-12T14:26:28Z","title":"TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to\n  Evolving Research Corpora","summary":"  The rapid evolution of scientific fields introduces challenges in organizing\nand retrieving scientific literature. While expert-curated taxonomies have\ntraditionally addressed this need, the process is time-consuming and expensive.\nFurthermore, recent automatic taxonomy construction methods either (1)\nover-rely on a specific corpus, sacrificing generalizability, or (2) depend\nheavily on the general knowledge of large language models (LLMs) contained\nwithin their pre-training datasets, often overlooking the dynamic nature of\nevolving scientific domains. Additionally, these approaches fail to account for\nthe multi-faceted nature of scientific literature, where a single research\npaper may contribute to multiple dimensions (e.g., methodology, new tasks,\nevaluation metrics, benchmarks). To address these gaps, we propose TaxoAdapt, a\nframework that dynamically adapts an LLM-generated taxonomy to a given corpus\nacross multiple dimensions. TaxoAdapt performs iterative hierarchical\nclassification, expanding both the taxonomy width and depth based on corpus'\ntopical distribution. We demonstrate its state-of-the-art performance across a\ndiverse set of computer science conferences over the years to showcase its\nability to structure and capture the evolution of scientific fields. As a\nmultidimensional method, TaxoAdapt generates taxonomies that are 26.51% more\ngranularity-preserving and 50.41% more coherent than the most competitive\nbaselines judged by LLMs.\n","authors":["Priyanka Kargupta","Nan Zhang","Yunyi Zhang","Rui Zhang","Prasenjit Mitra","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2506.10737v1.pdf","comment":"Accepted to ACL 2025 Main Conference. Code available at:\n  https://github.com/pkargupta/taxoadapt"},{"id":"http://arxiv.org/abs/2506.10728v1","updated":"2025-06-12T14:17:45Z","published":"2025-06-12T14:17:45Z","title":"Beyond True or False: Retrieval-Augmented Hierarchical Analysis of\n  Nuanced Claims","summary":"  Claims made by individuals or entities are oftentimes nuanced and cannot be\nclearly labeled as entirely \"true\" or \"false\" -- as is frequently the case with\nscientific and political claims. However, a claim (e.g., \"vaccine A is better\nthan vaccine B\") can be dissected into its integral aspects and sub-aspects\n(e.g., efficacy, safety, distribution), which are individually easier to\nvalidate. This enables a more comprehensive, structured response that provides\na well-rounded perspective on a given problem while also allowing the reader to\nprioritize specific angles of interest within the claim (e.g., safety towards\nchildren). Thus, we propose ClaimSpect, a retrieval-augmented generation-based\nframework for automatically constructing a hierarchy of aspects typically\nconsidered when addressing a claim and enriching them with corpus-specific\nperspectives. This structure hierarchically partitions an input corpus to\nretrieve relevant segments, which assist in discovering new sub-aspects.\nMoreover, these segments enable the discovery of varying perspectives towards\nan aspect of the claim (e.g., support, neutral, or oppose) and their respective\nprevalence (e.g., \"how many biomedical papers believe vaccine A is more\ntransportable than B?\"). We apply ClaimSpect to a wide variety of real-world\nscientific and political claims featured in our constructed dataset, showcasing\nits robustness and accuracy in deconstructing a nuanced claim and representing\nperspectives within a corpus. Through real-world case studies and human\nevaluation, we validate its effectiveness over multiple baselines.\n","authors":["Priyanka Kargupta","Runchu Tian","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2506.10728v1.pdf","comment":"Accepted to ACL 2025 Main Conference. Code available at:\n  https://github.com/pkargupta/claimspect"},{"id":"http://arxiv.org/abs/2504.08768v2","updated":"2025-06-12T13:56:30Z","published":"2025-04-01T22:15:17Z","title":"Accelerating Causal Network Discovery of Alzheimer Disease Biomarkers\n  via Scientific Literature-based Retrieval Augmented Generation","summary":"  The causal relationships between biomarkers are essential for disease\ndiagnosis and medical treatment planning. One notable application is\nAlzheimer's disease (AD) diagnosis, where certain biomarkers may influence the\npresence of others, enabling early detection, precise disease staging, targeted\ntreatments, and improved monitoring of disease progression. However,\nunderstanding these causal relationships is complex and requires extensive\nresearch. Constructing a comprehensive causal network of biomarkers demands\nsignificant effort from human experts, who must analyze a vast number of\nresearch papers, and have bias in understanding diseases' biomarkers and their\nrelation. This raises an important question: Can advanced large language models\n(LLMs), such as those utilizing retrieval-augmented generation (RAG), assist in\nbuilding causal networks of biomarkers for further medical analysis? To explore\nthis, we collected 200 AD-related research papers published over the past 25\nyears and then integrated scientific literature with RAG to extract AD\nbiomarkers and generate causal relations among them. Given the high-risk nature\nof the medical diagnosis, we applied uncertainty estimation to assess the\nreliability of the generated causal edges and examined the faithfulness and\nscientificness of LLM reasoning using both automatic and human evaluation. We\nfind that RAG enhances the ability of LLMs to generate more accurate causal\nnetworks from scientific papers. However, the overall performance of LLMs in\nidentifying causal relations of AD biomarkers is still limited. We hope this\nstudy will inspire further foundational research on AI-driven analysis of AD\nbiomarkers causal network discovery.\n","authors":["Xiaofan Zhou","Liangjie Huang","Pinyang Cheng","Wenpen Yin","Rui Zhang","Wenrui Hao","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2504.08768v2.pdf","comment":"9 pages, under review"},{"id":"http://arxiv.org/abs/2506.10658v1","updated":"2025-06-12T12:47:35Z","published":"2025-06-12T12:47:35Z","title":"Contrastive Matrix Completion with Denoising and Augmented Graph Views\n  for Robust Recommendation","summary":"  Matrix completion is a widely adopted framework in recommender systems, as\npredicting the missing entries in the user-item rating matrix enables a\ncomprehensive understanding of user preferences. However, current graph neural\nnetwork (GNN)-based approaches are highly sensitive to noisy or irrelevant\nedges--due to their inherent message-passing mechanisms--and are prone to\noverfitting, which limits their generalizability. To overcome these challenges,\nwe propose a novel method called Matrix Completion using Contrastive Learning\n(MCCL). Our approach begins by extracting local neighborhood subgraphs for each\ninteraction and subsequently generates two distinct graph representations. The\nfirst representation emphasizes denoising by integrating GNN layers with an\nattention mechanism, while the second is obtained via a graph variational\nautoencoder that aligns the feature distribution with a standard prior. A\nmutual learning loss function is employed during training to gradually\nharmonize these representations, enabling the model to capture common patterns\nand significantly enhance its generalizability. Extensive experiments on\nseveral real-world datasets demonstrate that our approach not only improves the\nnumerical accuracy of the predicted scores--achieving up to a 0.8% improvement\nin RMSE--but also produces superior rankings with improvements of up to 36% in\nranking metrics.\n","authors":["Narges Nemati","Mostafa Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2506.10658v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2506.10635v1","updated":"2025-06-12T12:19:57Z","published":"2025-06-12T12:19:57Z","title":"Conversational Search: From Fundamentals to Frontiers in the LLM Era","summary":"  Conversational search enables multi-turn interactions between users and\nsystems to fulfill users' complex information needs. During this interaction,\nthe system should understand the users' search intent within the conversational\ncontext and then return the relevant information through a flexible,\ndialogue-based interface. The recent powerful large language models (LLMs) with\ncapacities of instruction following, content generation, and reasoning, attract\nsignificant attention and advancements, providing new opportunities and\nchallenges for building up intelligent conversational search systems. This\ntutorial aims to introduce the connection between fundamentals and the emerging\ntopics revolutionized by LLMs in the context of conversational search. It is\ndesigned for students, researchers, and practitioners from both academia and\nindustry. Participants will gain a comprehensive understanding of both the core\nprinciples and cutting-edge developments driven by LLMs in conversational\nsearch, equipping them with the knowledge needed to contribute to the\ndevelopment of next-generation conversational search systems.\n","authors":["Fengran Mo","Chuan Meng","Mohammad Aliannejadi","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2506.10635v1.pdf","comment":"Accepted by Tutorial Track in SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.10520v1","updated":"2025-06-12T09:28:43Z","published":"2025-06-12T09:28:43Z","title":"Macro Graph of Experts for Billion-Scale Multi-Task Recommendation","summary":"  Graph-based multi-task learning at billion-scale presents a significant\nchallenge, as different tasks correspond to distinct billion-scale graphs.\nTraditional multi-task learning methods often neglect these graph structures,\nrelying solely on individual user and item embeddings. However, disregarding\ngraph structures overlooks substantial potential for improving performance. In\nthis paper, we introduce the Macro Graph of Expert (MGOE) framework, the first\napproach capable of leveraging macro graph embeddings to capture task-specific\nmacro features while modeling the correlations between task-specific experts.\nSpecifically, we propose the concept of a Macro Graph Bottom, which, for the\nfirst time, enables multi-task learning models to incorporate graph information\neffectively. We design the Macro Prediction Tower to dynamically integrate\nmacro knowledge across tasks. MGOE has been deployed at scale, powering\nmulti-task learning for the homepage of a leading billion-scale recommender\nsystem. Extensive offline experiments conducted on three public benchmark\ndatasets demonstrate its superiority over state-of-the-art multi-task learning\nmethods, establishing MGOE as a breakthrough in multi-task graph-based\nrecommendation. Furthermore, online A/B tests confirm the superiority of MGOE\nin billion-scale recommender systems.\n","authors":["Hongyu Yao","Zijin Hong","Hao Chen","Yuanchen Bei","Zhiqing Li","Qijie Shen","Zuobin Ying","Huan Gong","Feiran Huang"],"pdf_url":"https://arxiv.org/pdf/2506.10520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10487v1","updated":"2025-06-12T08:42:11Z","published":"2025-06-12T08:42:11Z","title":"SHORE: A Long-term User Lifetime Value Prediction Model in Digital Games","summary":"  In digital gaming, long-term user lifetime value (LTV) prediction is\nessential for monetization strategy, yet presents major challenges due to\ndelayed payment behavior, sparse early user data, and the presence of\nhigh-value outliers. While existing models typically rely on either short-cycle\nobservations or strong distributional assumptions, such approaches often\nunderestimate long-term value or suffer from poor robustness. To address these\nissues, we propose SHort-cycle auxiliary with Order-preserving REgression\n(SHORE), a novel LTV prediction framework that integrates short-horizon\npredictions (e.g., LTV-15 and LTV-30) as auxiliary tasks to enhance long-cycle\ntargets (e.g., LTV-60). SHORE also introduces a hybrid loss function combining\norder-preserving multi-class classification and a dynamic Huber loss to\nmitigate the influence of zero-inflation and outlier payment behavior.\nExtensive offline and online experiments on real-world datasets demonstrate\nthat SHORE significantly outperforms existing baselines, achieving a 47.91\\%\nrelative reduction in prediction error in online deployment. These results\nhighlight SHORE's practical effectiveness and robustness in industrial-scale\nLTV prediction for digital games.\n","authors":["Congde Yuan"],"pdf_url":"https://arxiv.org/pdf/2506.10487v1.pdf","comment":"This version has been removed by arXiv administrators as the\n  submitter did not have the right to agree to the license at the time of\n  submission"},{"id":"http://arxiv.org/abs/2408.17309v2","updated":"2025-06-12T08:35:26Z","published":"2024-08-30T14:12:31Z","title":"Metadata practices for simulation workflows","summary":"  Computer simulations are an essential pillar of knowledge generation in\nscience. Exploring, understanding, reproducing, and sharing the results of\nsimulations relies on tracking and organizing the metadata describing the\nnumerical experiments. The models used to understand real-world systems, and\nthe computational machinery required to simulate them, are typically complex,\nand produce large amounts of heterogeneous metadata. Here, we present general\npractices for acquiring and handling metadata that are agnostic to software and\nhardware, and highly flexible for the user. These consist of two steps: 1)\nrecording and storing raw metadata, and 2) selecting and structuring metadata.\nAs a proof of concept, we develop the Archivist, a Python tool to help with the\nsecond step, and use it to apply our practices to distinct high-performance\ncomputing use cases from neuroscience and hydrology. Our practices and the\nArchivist can readily be applied to existing workflows without the need for\nsubstantial restructuring. They support sustainable numerical workflows,\nfostering replicability, reproducibility, data exploration, and data sharing in\nsimulation-based research.\n","authors":["José Villamar","Matthias Kelbling","Heather L. More","Michael Denker","Tom Tetzlaff","Johanna Senk","Stephan Thober"],"pdf_url":"https://arxiv.org/pdf/2408.17309v2.pdf","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2506.17272v1","updated":"2025-06-12T07:06:40Z","published":"2025-06-12T07:06:40Z","title":"QUST_NLP at SemEval-2025 Task 7: A Three-Stage Retrieval Framework for\n  Monolingual and Crosslingual Fact-Checked Claim Retrieval","summary":"  This paper describes the participation of QUST_NLP in the SemEval-2025 Task\n7. We propose a three-stage retrieval framework specifically designed for\nfact-checked claim retrieval. Initially, we evaluate the performance of several\nretrieval models and select the one that yields the best results for candidate\nretrieval. Next, we employ multiple re-ranking models to enhance the candidate\nresults, with each model selecting the Top-10 outcomes. In the final stage, we\nutilize weighted voting to determine the final retrieval outcomes. Our approach\nachieved 5th place in the monolingual track and 7th place in the crosslingual\ntrack. We release our system code at:\nhttps://github.com/warmth27/SemEval2025_Task7\n","authors":["Youzheng Liu","Jiyan Liu","Xiaoman Xu","Taihang Wang","Yimin Wang","Ye Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.17272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10408v1","updated":"2025-06-12T07:01:56Z","published":"2025-06-12T07:01:56Z","title":"Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic\n  Retrieval-Augmented Generation for Industry Challenges","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to\novercome the knowledge limitations of Large Language Models (LLMs) by\nintegrating external retrieval with language generation. While early RAG\nsystems based on static pipelines have shown effectiveness in well-structured\ntasks, they struggle in real-world scenarios requiring complex reasoning,\ndynamic retrieval, and multi-modal integration. To address these challenges,\nthe field has shifted toward Reasoning Agentic RAG, a paradigm that embeds\ndecision-making and adaptive tool use directly into the retrieval process. In\nthis paper, we present a comprehensive review of Reasoning Agentic RAG methods,\ncategorizing them into two primary systems: predefined reasoning, which follows\nfixed modular pipelines to boost reasoning, and agentic reasoning, where the\nmodel autonomously orchestrates tool interaction during inference. We analyze\nrepresentative techniques under both paradigms, covering architectural design,\nreasoning strategies, and tool coordination. Finally, we discuss key research\nchallenges and propose future directions to advance the flexibility,\nrobustness, and applicability of reasoning agentic RAG systems. Our collection\nof the relevant research has been organized into a\nhttps://github.com/ByebyeMonica/Reasoning-Agentic-RAG.\n","authors":["Jintao Liang","Gang Su","Huifeng Lin","You Wu","Rui Zhao","Ziyue Li"],"pdf_url":"https://arxiv.org/pdf/2506.10408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.10380v1","updated":"2025-06-12T06:16:49Z","published":"2025-06-12T06:16:49Z","title":"TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous\n  Document Reasoning","summary":"  Retrieval-Augmented Generation (RAG) has demonstrated considerable\neffectiveness in open-domain question answering. However, when applied to\nheterogeneous documents, comprising both textual and tabular components,\nexisting RAG approaches exhibit critical limitations. The prevailing practice\nof flattening tables and chunking strategies disrupts the intrinsic tabular\nstructure, leads to information loss, and undermines the reasoning capabilities\nof LLMs in multi-hop, global queries. To address these challenges, we propose\nTableRAG, an hybrid framework that unifies textual understanding and complex\nmanipulations over tabular data. TableRAG iteratively operates in four steps:\ncontext-sensitive query decomposition, text retrieval, SQL programming and\nexecution, and compositional intermediate answer generation. We also develop\nHeteQA, a novel benchmark designed to evaluate the multi-hop heterogeneous\nreasoning capabilities. Experimental results demonstrate that TableRAG\nconsistently outperforms existing baselines on both public datasets and our\nHeteQA, establishing a new state-of-the-art for heterogeneous document question\nanswering. We release TableRAG at https://github.com/yxh-y/TableRAG/tree/main.\n","authors":["Xiaohan Yu","Pu Jian","Chong Chen"],"pdf_url":"https://arxiv.org/pdf/2506.10380v1.pdf","comment":"Under review. Codes are available at\n  https://github.com/yxh-y/TableRAG/tree/main"},{"id":"http://arxiv.org/abs/2506.10347v1","updated":"2025-06-12T04:56:10Z","published":"2025-06-12T04:56:10Z","title":"LightKG: Efficient Knowledge-Aware Recommendations with Simplified GNN\n  Architecture","summary":"  Recently, Graph Neural Networks (GNNs) have become the dominant approach for\nKnowledge Graph-aware Recommender Systems (KGRSs) due to their proven\neffectiveness. Building upon GNN-based KGRSs, Self-Supervised Learning (SSL)\nhas been incorporated to address the sparity issue, leading to longer training\ntime. However, through extensive experiments, we reveal that: (1)compared to\nother KGRSs, the existing GNN-based KGRSs fail to keep their superior\nperformance under sparse interactions even with SSL. (2) More complex models\ntend to perform worse in sparse interaction scenarios and complex mechanisms,\nlike attention mechanism, can be detrimental as they often increase learning\ndifficulty. Inspired by these findings, we propose LightKG, a simple yet\npowerful GNN-based KGRS to address sparsity issues. LightKG includes a\nsimplified GNN layer that encodes directed relations as scalar pairs rather\nthan dense embeddings and employs a linear aggregation framework, greatly\nreducing the complexity of GNNs. Additionally, LightKG incorporates an\nefficient contrastive layer to implement SSL. It directly minimizes the node\nsimilarity in original graph, avoiding the time-consuming subgraph generation\nand comparison required in previous SSL methods. Experiments on four benchmark\ndatasets show that LightKG outperforms 12 competitive KGRSs in both sparse and\ndense scenarios while significantly reducing training time. Specifically, it\nsurpasses the best baselines by an average of 5.8\\% in recommendation accuracy\nand saves 84.3\\% of training time compared to KGRSs with SSL. Our code is\navailable at https://github.com/1371149/LightKG.\n","authors":["Yanhui Li","Dongxia Wang","Zhu Sun","Haonan Zhang","Huizhong Guo"],"pdf_url":"https://arxiv.org/pdf/2506.10347v1.pdf","comment":"Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining"},{"id":"http://arxiv.org/abs/2506.10346v1","updated":"2025-06-12T04:54:44Z","published":"2025-06-12T04:54:44Z","title":"An Analysis of Datasets, Metrics and Models in Keyphrase Generation","summary":"  Keyphrase generation refers to the task of producing a set of words or\nphrases that summarises the content of a document. Continuous efforts have been\ndedicated to this task over the past few years, spreading across multiple lines\nof research, such as model architectures, data resources, and use-case\nscenarios. Yet, the current state of keyphrase generation remains unknown as\nthere has been no attempt to review and analyse previous work. In this paper,\nwe bridge this gap by presenting an analysis of over 50 research papers on\nkeyphrase generation, offering a comprehensive overview of recent progress,\nlimitations, and open challenges. Our findings highlight several critical\nissues in current evaluation practices, such as the concerning similarity among\ncommonly-used benchmark datasets and inconsistencies in metric calculations\nleading to overestimated performances. Additionally, we address the limited\navailability of pre-trained models by releasing a strong PLM-based model for\nkeyphrase generation as an effort to facilitate future research.\n","authors":["Florian Boudin","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2506.10346v1.pdf","comment":"GEM^2 paper @ ACL 2025"},{"id":"http://arxiv.org/abs/2506.10329v1","updated":"2025-06-12T03:33:58Z","published":"2025-06-12T03:33:58Z","title":"Context-Adaptive Graph Neural Networks for Next POI Recommendation","summary":"  Next Point-of-Interest (POI) recommendation is a critical task in\nlocation-based services, aiming to predict users' next visits based on their\ncheck-in histories. While many existing methods leverage Graph Neural Networks\n(GNNs) to incorporate collaborative information and improve recommendation\naccuracy, most of them model each type of context using separate graphs,\ntreating different factors in isolation. This limits their ability to model the\nco-influence of multiple contextual factors on user transitions during message\npropagation, resulting in suboptimal attention weights and recommendation\nperformance. Furthermore, they often prioritize sequential components as the\nprimary predictor, potentially undermining the semantic and structural\ninformation encoded in the POI embeddings learned by GNNs. To address these\nlimitations, we propose a Context-Adaptive Graph Neural Networks (CAGNN) for\nnext POI recommendation, which dynamically adjusts attention weights using\nedge-specific contextual factors and enables mutual enhancement between\ngraph-based and sequential components. Specifically, CAGNN introduces (1) a\ncontext-adaptive attention mechanism that jointly incorporates different types\nof contextual factors into the attention computation during graph propagation,\nenabling the model to dynamically capture collaborative and context-dependent\ntransition patterns; (2) a graph-sequential mutual enhancement module, which\naligns the outputs of the graph- and sequential-based modules via the KL\ndivergence, enabling mutual enhancement of both components. Experimental\nresults on three real-world datasets demonstrate that CAGNN consistently\noutperforms state-of-the-art methods. Meanwhile, theoretical guarantees are\nprovided that our context-adaptive attention mechanism improves the\nexpressiveness of POI representations.\n","authors":["Yu Lei","Limin Shen","Zhu Sun","Tiantian He","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2506.10329v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2506.10301v1","updated":"2025-06-12T02:25:42Z","published":"2025-06-12T02:25:42Z","title":"Towards Understanding Bias in Synthetic Data for Evaluation","summary":"  Test collections are crucial for evaluating Information Retrieval (IR)\nsystems. Creating a diverse set of user queries for these collections can be\nchallenging, and obtaining relevance judgments, which indicate how well\nretrieved documents match a query, is often costly and resource-intensive.\nRecently, generating synthetic datasets using Large Language Models (LLMs) has\ngained attention in various applications. While previous work has used LLMs to\ngenerate synthetic queries or documents to improve ranking models, using LLMs\nto create synthetic test collections is still relatively unexplored. Previous\nwork~\\cite{rahmani2024synthetic} showed that synthetic test collections have\nthe potential to be used for system evaluation, however, more analysis is\nneeded to validate this claim. In this paper, we thoroughly investigate the\nreliability of synthetic test collections constructed using LLMs, where LLMs\nare used to generate synthetic queries, labels, or both. In particular, we\nexamine the potential biases that might occur when such test collections are\nused for evaluation. We first empirically show the presence of such bias in\nevaluation results and analyse the effects it might have on system evaluation.\nWe further validate the presence of such bias using a linear mixed-effects\nmodel. Our analysis shows that while the effect of bias present in evaluation\nresults obtained using synthetic test collections could be significant, for\ne.g.~computing absolute system performance, its effect may not be as\nsignificant in comparing relative system performance. Codes and data are\navailable at: https://github.com/rahmanidashti/BiasSyntheticData.\n","authors":["Hossein A. Rahmani","Varsha Ramineni","Nick Craswell","Bhaskar Mitra","Emine Yilmaz"],"pdf_url":"https://arxiv.org/pdf/2506.10301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04907v4","updated":"2025-06-12T02:06:29Z","published":"2025-06-05T11:41:05Z","title":"Context Is Not Comprehension","summary":"  The dominant way of judging Large Language Models (LLMs) has been to ask how\nwell they can recall explicit facts from very long inputs. While today's best\nmodels achieve near perfect recall, this masks a harder skill: performing\nmulti-step reasoning and tracking intermediate state that never appears\nverbatim. We introduce Verbose ListOps (VLO), a benchmark that embeds\ndeterministic ListOps computations inside narrative camouflage and, crucially,\nallows step-level evaluation of every intermediate result. Experiments show\nthat models which solve raw ListOps with approximately 100% accuracy collapse\non VLO after only 10,000 tokens. By exposing where a model's reasoning chain\nfirst diverges, VLO moves assessment beyond sheer context length and toward\ngenuine comprehension. VLO's generation pipeline is task-agnostic: it can weave\nany deterministically verifiable reasoning schema -- arithmetic, symbolic,\nabductive, inductive or defeasible -- into narrative form. This makes VLO a\nreusable test-bed for the next wave of reasoning-centric model designs, not\nmerely those with step-explicit scaffolds.\n","authors":["Alex Pan","Mary-Anne Williams"],"pdf_url":"https://arxiv.org/pdf/2506.04907v4.pdf","comment":"24 pages, 2 figures, 4 tables; under review"},{"id":"http://arxiv.org/abs/2504.17811v3","updated":"2025-06-12T00:31:21Z","published":"2025-04-22T18:07:45Z","title":"OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation\n  Learning","summary":"  Representation learning, a task of learning latent vectors to represent\nentities, is a key task in improving search and recommender systems in web\napplications. Various representation learning methods have been developed,\nincluding graph-based approaches for relationships among entities,\nsequence-based methods for capturing the temporal evolution of user activities,\nand content-based models for leveraging text and visual content. However, the\ndevelopment of a unifying framework that integrates these diverse techniques to\nsupport multiple applications remains a significant challenge.\n  This paper presents OmniSage, a large-scale representation framework that\nlearns universal representations for a variety of applications at Pinterest.\nOmniSage integrates graph neural networks with content-based models and user\nsequence models by employing multiple contrastive learning tasks to effectively\nprocess graph data, user sequence data, and content signals. To support the\ntraining and inference of OmniSage, we developed an efficient infrastructure\ncapable of supporting Pinterest graphs with billions of nodes. The universal\nrepresentations generated by OmniSage have significantly enhanced user\nexperiences on Pinterest, leading to an approximate 2.5% increase in sitewide\nrepins (saves) across five applications. This paper highlights the impact of\nunifying representation learning methods, and we make the model code publicly\navailable at https://github.com/pinterest/atg-research/tree/main/omnisage.\n","authors":["Anirudhan Badrinath","Alex Yang","Kousik Rajesh","Prabhat Agarwal","Jaewon Yang","Haoyu Chen","Jiajing Xu","Charles Rosenberg"],"pdf_url":"https://arxiv.org/pdf/2504.17811v3.pdf","comment":"To appear in Proceedings of KDD 2025 Industry Track"}],"Databases":[{"id":"http://arxiv.org/abs/2506.11298v1","updated":"2025-06-12T20:58:39Z","published":"2025-06-12T20:58:39Z","title":"Jelly: a fast and convenient RDF serialization format","summary":"  Existing RDF serialization formats such as Turtle, N-Triples, and JSON-LD are\nwidely used for communication and storage in knowledge graph and Semantic Web\napplications. However, they suffer from limitations in performance, compression\nratio, and lack of native support for RDF streams. To address these\nshortcomings, we introduce Jelly, a fast and convenient binary serialization\nformat for RDF data that supports both batch and streaming use cases. Jelly is\ndesigned to maximize serialization throughput, reduce file size with\nlightweight streaming compression, and minimize compute resource usage. Built\non Protocol Buffers, Jelly is easy to integrate with modern programming\nlanguages and RDF libraries. To maximize reusability, Jelly has an open\nprotocol specification, open-source implementations in Java and Python\nintegrated with popular RDF libraries, and a versatile command-line tool. To\nillustrate its usefulness, we outline concrete use cases where Jelly can\nprovide tangible benefits. By combining practical usability with\nstate-of-the-art efficiency, Jelly is an important contribution to the Semantic\nWeb tool stack.\n","authors":["Piotr Sowinski","Karolina Bogacka","Anastasiya Danilenka","Nikita Kozlov"],"pdf_url":"https://arxiv.org/pdf/2506.11298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04286v2","updated":"2025-06-12T12:48:02Z","published":"2025-06-04T08:46:33Z","title":"OxO2 -- A SSSOM mapping browser for logically sound crosswalks","summary":"  EMBL-EBI created OxO to enable users to map between datasets that are\nannotated with different ontologies. Mappings identified by the first version\nof OxO were not necessarily logically sound, lacked important provenance\ninformation such as author and reviewer, and could timeout or crash for certain\nrequests. In this paper we introduce OxO2 to address these concerns. Provenance\nis addressed by implementing SSSOM, a mapping standard that defines provenance\nfor mappings. SSSOM defines the conditions under which logical sound mappings\ncan be derived and is implemented in OxO2 using Nemo, a Datalog rule engine. To\nensure reasoning is performant and memory efficient, Nemo implements a number\nof strategies that ensures OxO2 will be stable for all requests. Due to these\nchanges, OxO2 users will be able to integrate between disparate datasets with\ngreater confidence.\n","authors":["Henriette Harmse","Haider Iqbal","Helen Parkinson","James McLaughlin"],"pdf_url":"https://arxiv.org/pdf/2506.04286v2.pdf","comment":"12 pages, 2 figures and 2 tables. Also submitted to FOIS\n  Demonstration track and awaiting feedback"},{"id":"http://arxiv.org/abs/2503.17911v2","updated":"2025-06-12T11:26:10Z","published":"2025-03-23T03:16:50Z","title":"VSAG: An Optimized Search Framework for Graph-based Approximate Nearest\n  Neighbor Search","summary":"  Approximate nearest neighbor search (ANNS) is a fundamental problem in vector\ndatabases and AI infrastructures. Recent graph-based ANNS algorithms have\nachieved high search accuracy with practical efficiency. Despite the\nadvancements, these algorithms still face performance bottlenecks in\nproduction, due to the random memory access patterns of graph-based search and\nthe high computational overheads of vector distance. In addition, the\nperformance of a graph-based ANNS algorithm is highly sensitive to parameters,\nwhile selecting the optimal parameters is cost-prohibitive, e.g., manual tuning\nrequires repeatedly re-building the index.\n  This paper introduces VSAG, an open-source framework that aims to enhance the\nin production performance of graph-based ANNS algorithms. VSAG has been\ndeployed at scale in the services of Ant Group, and it incorporates three key\noptimizations: (i) efficient memory access: it reduces L3 cache misses with\npre-fetching and cache-friendly vector organization; (ii) automated parameter\ntuning: it automatically selects performance-optimal parameters without\nrequiring index rebuilding; (iii) efficient distance computation: it leverages\nmodern hardware, scalar quantization, and smartly switches to low-precision\nrepresentation to dramatically reduce the distance computation costs. We\nevaluate VSAG on real-world datasets. The experimental results show that VSAG\nachieves the state-of-the-art performance and provides up to 4x speedup over\nHNSWlib (an industry-standard library) while ensuring the same accuracy.\n","authors":["Xiaoyao Zhong","Haotian Li","Jiabao Jin","Mingyu Yang","Deming Chu","Xiangyu Wang","Zhitao Shen","Wei Jia","George Gu","Yi Xie","Xuemin Lin","Heng Tao Shen","Jingkuan Song","Peng Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.17911v2.pdf","comment":"the report of open-source library VSAG\n  (https://github.com/antgroup/vsag)"}]},"2025-06-11T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.10077v1","updated":"2025-06-11T18:00:30Z","published":"2025-06-11T18:00:30Z","title":"A quantum semantic framework for natural language processing","summary":"  Semantic degeneracy represents a fundamental property of natural language\nthat extends beyond simple polysemy to encompass the combinatorial explosion of\npotential interpretations that emerges as semantic expressions increase in\ncomplexity. Large Language Models (LLMs) and other modern NLP systems face\ninherent limitations precisely because they operate within natural language\nitself, making them subject to the same interpretive constraints imposed by\nsemantic degeneracy. In this work, we argue using Kolmogorov complexity that as\nan expression's complexity grows, the likelihood of any interpreting agent\n(human or LLM-powered AI) recovering the single intended meaning vanishes. This\ncomputational intractability suggests the classical view that linguistic forms\npossess meaning in and of themselves is flawed. We alternatively posit that\nmeaning is instead actualized through an observer-dependent interpretive act.\nTo test this, we conducted a semantic Bell inequality test using diverse LLM\nagents as ``computational cognitive systems'' to interpret ambiguous word pairs\nunder varied contextual settings. Across several independent experiments, we\nfound average CHSH expectation values ranging from 1.2 to 2.8, with several\nruns yielding values (e.g., 2.3-2.4) that significantly violate the classical\nboundary ($|S|\\leq2$). This demonstrates that linguistic interpretation under\nambiguity can exhibit non-classical contextuality, consistent with results from\nhuman cognition experiments. These results inherently imply that classical\nfrequentist-based analytical approaches for natural language are necessarily\nlossy. Instead, we propose that Bayesian-style repeated sampling approaches can\nprovide more practically useful and appropriate characterizations of linguistic\nmeaning in context.\n","authors":["Christopher J. Agostino","Quan Le Thien","Molly Apsel","Denizhan Pak","Elina Lesyk","Ashabari Majumdar"],"pdf_url":"https://arxiv.org/pdf/2506.10077v1.pdf","comment":"12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025"},{"id":"http://arxiv.org/abs/2502.13909v4","updated":"2025-06-11T17:41:16Z","published":"2025-02-19T17:41:09Z","title":"Lost in Sequence: Do Large Language Models Understand Sequential\n  Recommendation?","summary":"  Large Language Models (LLMs) have recently emerged as promising tools for\nrecommendation thanks to their advanced textual understanding ability and\ncontext-awareness. Despite the current practice of training and evaluating\nLLM-based recommendation (LLM4Rec) models under a sequential recommendation\nscenario, we found that whether these models understand the sequential\ninformation inherent in users' item interaction sequences has been largely\noverlooked. In this paper, we first demonstrate through a series of experiments\nthat existing LLM4Rec models do not fully capture sequential information both\nduring training and inference. Then, we propose a simple yet effective\nLLM-based sequential recommender, called LLM-SRec, a method that enhances the\nintegration of sequential information into LLMs by distilling the user\nrepresentations extracted from a pre-trained CF-SRec model into LLMs. Our\nextensive experiments show that LLM-SRec enhances LLMs' ability to understand\nusers' item interaction sequences, ultimately leading to improved\nrecommendation performance. Furthermore, unlike existing LLM4Rec models that\nrequire fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by\ntraining only a few lightweight MLPs, highlighting its practicality in\nreal-world applications. Our code is available at\nhttps://github.com/Sein-Kim/LLM-SRec.\n","authors":["Sein Kim","Hongseok Kang","Kibum Kim","Jiwan Kim","Donghyun Kim","Minchul Yang","Kwangjin Oh","Julian McAuley","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2502.13909v4.pdf","comment":"KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2506.09898v1","updated":"2025-06-11T16:13:52Z","published":"2025-06-11T16:13:52Z","title":"Discrete Scale-invariant Metric Learning for Efficient Collaborative\n  Filtering","summary":"  Metric learning has attracted extensive interest for its ability to provide\npersonalized recommendations based on the importance of observed user-item\ninteractions. Current metric learning methods aim to push negative items away\nfrom the corresponding users and positive items by an absolute geometrical\ndistance margin. However, items may come from imbalanced categories with\ndifferent intra-class variations. Thus, the absolute distance margin may not be\nideal for estimating the difference between user preferences over imbalanced\nitems. To this end, we propose a new method, named discrete scale-invariant\nmetric learning (DSIML), by adding binary constraints to users and items, which\nmaps users and items into binary codes of a shared Hamming subspace to speed up\nthe online recommendation. Specifically, we firstly propose a scale-invariant\nmargin based on angles at the negative item points in the shared Hamming\nsubspace. Then, we derive a scale-invariant triple hinge loss based on the\nmargin. To capture more preference difference information, we integrate a\npairwise ranking loss into the scale-invariant loss in the proposed model. Due\nto the difficulty of directly optimizing the mixed integer optimization problem\nformulated with \\textit{log-sum-exp} functions, we seek to optimize its\nvariational quadratic upper bound and learn hash codes with an alternating\noptimization strategy. Experiments on benchmark datasets clearly show that our\nproposed method is superior to competitive metric learning and hashing-based\nbaselines for recommender systems. The implementation code is available at\nhttps://github.com/AnonyFeb/dsml.\n","authors":["Yan Zhang","Li Deng","Lixin Duan","Sami Azam"],"pdf_url":"https://arxiv.org/pdf/2506.09898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11156v1","updated":"2025-06-11T16:03:01Z","published":"2025-06-11T16:03:01Z","title":"Digitization of Document and Information Extraction using OCR","summary":"  Retrieving accurate details from documents is a crucial task, especially when\nhandling a combination of scanned images and native digital formats. This\ndocument presents a combined framework for text extraction that merges Optical\nCharacter Recognition (OCR) techniques with Large Language Models (LLMs) to\ndeliver structured outputs enriched by contextual understanding and confidence\nindicators. Scanned files are processed using OCR engines, while digital files\nare interpreted through layout-aware libraries. The extracted raw text is\nsubsequently analyzed by an LLM to identify key-value pairs and resolve\nambiguities. A comparative analysis of different OCR tools is presented to\nevaluate their effectiveness concerning accuracy, layout recognition, and\nprocessing speed. The approach demonstrates significant improvements over\ntraditional rule-based and template-based methods, offering enhanced\nflexibility and semantic precision across different document categories\n","authors":["Rasha Sinha","Rekha B S"],"pdf_url":"https://arxiv.org/pdf/2506.11156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.02132v2","updated":"2025-06-11T15:07:55Z","published":"2025-04-02T21:08:33Z","title":"One Pic is All it Takes: Poisoning Visual Document Retrieval Augmented\n  Generation with a Single Image","summary":"  Multi-modal retrieval augmented generation (M-RAG) is instrumental for\ninhibiting hallucinations in large multi-modal models (LMMs) through the use of\na factual knowledge base (KB). However, M-RAG introduces new attack vectors for\nadversaries that aim to disrupt the system by injecting malicious entries into\nthe KB. In this paper, we present the first poisoning attack against M-RAG\ntargeting visual document retrieval applications where the KB contains images\nof document pages. We propose two attacks, each of which require injecting only\na single adversarial image into the KB. Firstly, we propose a universal attack\nthat, for any potential user query, influences the response to cause a\ndenial-of-service (DoS) in the M-RAG system. Secondly, we present a targeted\nattack against one or a group of user queries, with the goal of spreading\ntargeted misinformation. For both attacks, we use a multi-objective\ngradient-based adversarial approach to craft the injected image while\noptimizing for both retrieval and generation. We evaluate our attacks against\nseveral visual document retrieval datasets, a diverse set of state-of-the-art\nretrievers (embedding models) and generators (LMMs), demonstrating the attack\neffectiveness in both the universal and targeted settings. We additionally\npresent results including commonly used defenses, various attack\nhyper-parameter settings, ablations, and attack transferability.\n","authors":["Ezzeldin Shereen","Dan Ristea","Shae McFadden","Burak Hasircioglu","Vasilios Mavroudis","Chris Hicks"],"pdf_url":"https://arxiv.org/pdf/2504.02132v2.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.06591v2","updated":"2025-06-11T15:02:20Z","published":"2024-04-09T19:39:27Z","title":"Milgram's experiment in the knowledge space: Individual navigation\n  strategies","summary":"  Data deluge characteristic for our times has led to information overload,\nposing a significant challenge to effectively finding our way through the\ndigital landscape. Addressing this issue requires an in-depth understanding of\nhow we navigate through the abundance of information. Previous research has\ndiscovered multiple patterns in how individuals navigate in the geographic,\nsocial, and information spaces, yet individual differences in strategies for\nnavigation in the knowledge space has remained largely unexplored. To bridge\nthe gap, we conducted an online experiment where participants played a\nnavigation game on Wikipedia and completed questionnaires about their personal\ninformation. Utilizing the hierarchical structure of the English Wikipedia and\na graph embedding trained on it, we identified two navigation strategies and\nfound that there are significant individual differences in the choices of them.\nOlder, white and female participants tend to adopt a proximity-driven strategy,\nwhile younger participants prefer a hub-driven strategy. Our study connects\nsocial navigation to knowledge navigation: individuals' differing tendencies to\nuse geographical and occupational information about the target person to\nnavigate in the social space can be understood as different choices between the\nhub-driven and proximity-driven strategies in the knowledge space.\n","authors":["Manran Zhu","János Kertész"],"pdf_url":"https://arxiv.org/pdf/2404.06591v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.17834v3","updated":"2025-06-11T14:58:32Z","published":"2025-04-24T15:34:35Z","title":"Unveiling the Hidden: Movie Genre and User Bias in Spoiler Detection","summary":"  Spoilers in movie reviews are important on platforms like IMDb and Rotten\nTomatoes, offering benefits and drawbacks. They can guide some viewers' choices\nbut also affect those who prefer no plot details in advance, making effective\nspoiler detection essential. Existing spoiler detection methods mainly analyze\nreview text, often overlooking the impact of movie genres and user bias,\nlimiting their effectiveness. To address this, we analyze movie review data,\nfinding genre-specific variations in spoiler rates and identifying that certain\nusers are more likely to post spoilers. Based on these findings, we introduce a\nnew spoiler detection framework called GUSD (The code is available at\nhttps://github.com/AI-explorer-123/GUSD) (Genre-aware and User-specific Spoiler\nDetection), which incorporates genre-specific data and user behavior bias. User\nbias is calculated through dynamic graph modeling of review history.\nAdditionally, the R2GFormer module combines RetGAT (Retentive Graph Attention\nNetwork) for graph information and GenreFormer for genre-specific aggregation.\nThe GMoE (Genre-Aware Mixture of Experts) model further assigns reviews to\nspecialized experts based on genre. Extensive testing on benchmark datasets\nshows that GUSD achieves state-of-the-art results. This approach advances\nspoiler detection by addressing genre and user-specific patterns, enhancing\nuser experience on movie review platforms.\n","authors":["Haokai Zhang","Shengtao Zhang","Zijian Cai","Heng Wang","Ruixuan Zhu","Zinan Zeng","Minnan Luo"],"pdf_url":"https://arxiv.org/pdf/2504.17834v3.pdf","comment":"ECML PKDD 2025"},{"id":"http://arxiv.org/abs/2505.21165v2","updated":"2025-06-11T13:27:06Z","published":"2025-05-27T13:21:39Z","title":"Counterfactual Multi-player Bandits for Explainable Recommendation\n  Diversification","summary":"  Existing recommender systems tend to prioritize items closely aligned with\nusers' historical interactions, inevitably trapping users in the dilemma of\n``filter bubble''. Recent efforts are dedicated to improving the diversity of\nrecommendations. However, they mainly suffer from two major issues: 1) a lack\nof explainability, making it difficult for the system designers to understand\nhow diverse recommendations are generated, and 2) limitations to specific\nmetrics, with difficulty in enhancing non-differentiable diversity metrics. To\nthis end, we propose a \\textbf{C}ounterfactual \\textbf{M}ulti-player\n\\textbf{B}andits (CMB) method to deliver explainable recommendation\ndiversification across a wide range of diversity metrics. Leveraging a\ncounterfactual framework, our method identifies the factors influencing\ndiversity outcomes. Meanwhile, we adopt the multi-player bandits to optimize\nthe counterfactual optimization objective, making it adaptable to both\ndifferentiable and non-differentiable diversity metrics. Extensive experiments\nconducted on three real-world datasets demonstrate the applicability,\neffectiveness, and explainability of the proposed CMB.\n","authors":["Yansen Zhang","Bowei He","Xiaokun Zhang","Haolun Wu","Zexu Sun","Chen Ma"],"pdf_url":"https://arxiv.org/pdf/2505.21165v2.pdf","comment":"Accepted in ECML PKDD 2025"},{"id":"http://arxiv.org/abs/2506.09645v1","updated":"2025-06-11T12:03:52Z","published":"2025-06-11T12:03:52Z","title":"Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph\n  Question Answering","summary":"  Large Language Models (LLMs) have shown strong inductive reasoning ability\nacross various domains, but their reliability is hindered by the outdated\nknowledge and hallucinations. Retrieval-Augmented Generation mitigates these\nissues by grounding LLMs with external knowledge; however, most existing RAG\npipelines rely on unstructured text, limiting interpretability and structured\nreasoning. Knowledge graphs, which represent facts as relational triples, offer\na more structured and compact alternative. Recent studies have explored\nintegrating knowledge graphs with LLMs for knowledge graph question answering\n(KGQA), with a significant proportion adopting the retrieve-then-reasoning\nparadigm. In this framework, graph-based retrievers have demonstrated strong\nempirical performance, yet they still face challenges in generalization\nability. In this work, we propose RAPL, a novel framework for efficient and\neffective graph retrieval in KGQA. RAPL addresses these limitations through\nthree aspects: (1) a two-stage labeling strategy that combines heuristic\nsignals with parametric models to provide causally grounded supervision; (2) a\nmodel-agnostic graph transformation approach to capture both intra- and\ninter-triple interactions, thereby enhancing representational capacity; and (3)\na path-based reasoning strategy that facilitates learning from the injected\nrational knowledge, and supports downstream reasoner through structured inputs.\nEmpirically, RAPL outperforms state-of-the-art methods by $2.66\\%-20.34\\%$, and\nsignificantly reduces the performance gap between smaller and more powerful\nLLM-based reasoners, as well as the gap under cross-dataset settings,\nhighlighting its superior retrieval capability and generalizability. Codes are\navailable at: https://github.com/tianyao-aka/RAPL.\n","authors":["Tianjun Yao","Haoxuan Li","Zhiqiang Shen","Pan Li","Tongliang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.09645v1.pdf","comment":"32 pages, 28 figures"},{"id":"http://arxiv.org/abs/2310.17373v3","updated":"2025-06-11T09:28:52Z","published":"2023-10-26T13:10:59Z","title":"Causality-Inspired Fair Representation Learning for Multimodal\n  Recommendation","summary":"  Recently, multimodal recommendations (MMR) have gained increasing attention\nfor alleviating the data sparsity problem of traditional recommender systems by\nincorporating modality-based representations. Although MMR exhibits notable\nimprovement in recommendation accuracy, we empirically validate that an\nincrease in the quantity or variety of modalities leads to a higher degree of\nusers' sensitive information leakage due to entangled causal relationships,\nrisking fair representation learning. On the other hand, existing fair\nrepresentation learning approaches are mostly based on the assumption that\nsensitive information is solely leaked from users' interaction data and do not\nexplicitly model the causal relationships introduced by multimodal data, which\nlimits their applicability in multimodal scenarios. To address this limitation,\nwe propose a novel fair multimodal recommendation approach (dubbed FMMRec)\nthrough causality-inspired fairness-oriented modal disentanglement and\nrelation-aware fairness learning. Particularly, we disentangle biased and\nfiltered modal embeddings inspired by causal inference techniques, enabling the\nmining of modality-based unfair and fair user-user relations, thereby enhancing\nthe fairness and informativeness of user representations. By addressing the\ncausal effects of sensitive attributes on user preferences, our approach aims\nto achieve counterfactual fairness in multimodal recommendations. Experiments\non two public datasets demonstrate the superiority of our FMMRec relative to\nthe state-of-the-art baselines. Our source code is available at\nhttps://github.com/WeixinChen98/FMMRec.\n","authors":["Weixin Chen","Li Chen","Yongxin Ni","Yuhan Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.17373v3.pdf","comment":"In ACM Transactions on Information Systems (TOIS), 2025 (just\n  accepted)"},{"id":"http://arxiv.org/abs/2409.04432v3","updated":"2025-06-11T09:15:33Z","published":"2024-09-06T17:54:43Z","title":"A Survey on Knowledge Organization Systems of Research Fields: Resources\n  and Challenges","summary":"  Knowledge Organization Systems (KOSs), such as term lists, thesauri,\ntaxonomies, and ontologies, play a fundamental role in categorising, managing,\nand retrieving information. In the academic domain, KOSs are often adopted for\nrepresenting research areas and their relationships, primarily aiming to\nclassify research articles, academic courses, patents, books, scientific\nvenues, domain experts, grants, software, experiment materials, and several\nother relevant products and agents. These structured representations of\nresearch areas, widely embraced by many academic fields, have proven effective\nin empowering AI-based systems to i) enhance retrievability of relevant\ndocuments, ii) enable advanced analytic solutions to quantify the impact of\nacademic research, and iii) analyse and forecast research dynamics. This paper\naims to present a comprehensive survey of the current KOS for academic\ndisciplines. We analysed and compared 45 KOSs according to five main\ndimensions: scope, structure, curation, usage, and links to other KOSs. Our\nresults reveal a very heterogeneous scenario in terms of scope, scale, quality,\nand usage, highlighting the need for more integrated solutions for representing\nresearch knowledge across academic fields. We conclude by discussing the main\nchallenges and the most promising future directions.\n","authors":["Angelo Salatino","Tanay Aggarwal","Andrea Mannocci","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2409.04432v3.pdf","comment":"Published at Quantitative Science Studies"},{"id":"http://arxiv.org/abs/2412.08258v2","updated":"2025-06-11T08:58:18Z","published":"2024-12-11T10:11:41Z","title":"Large Language Models for Scholarly Ontology Generation: An Extensive\n  Analysis in the Engineering Field","summary":"  Ontologies of research topics are crucial for structuring scientific\nknowledge, enabling scientists to navigate vast amounts of research, and\nforming the backbone of intelligent systems such as search engines and\nrecommendation systems. However, manual creation of these ontologies is\nexpensive, slow, and often results in outdated and overly general\nrepresentations. As a solution, researchers have been investigating ways to\nautomate or semi-automate the process of generating these ontologies. This\npaper offers a comprehensive analysis of the ability of large language models\n(LLMs) to identify semantic relationships between different research topics,\nwhich is a critical step in the development of such ontologies. To this end, we\ndeveloped a gold standard based on the IEEE Thesaurus to evaluate the task of\nidentifying four types of relationships between pairs of topics: broader,\nnarrower, same-as, and other. Our study evaluates the performance of seventeen\nLLMs, which differ in scale, accessibility (open vs. proprietary), and model\ntype (full vs. quantised), while also assessing four zero-shot reasoning\nstrategies. Several models have achieved outstanding results, including\nMixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,\n0.920, and 0.967, respectively. Furthermore, our findings demonstrate that\nsmaller, quantised models, when optimised through prompt engineering, can\ndeliver performance comparable to much larger proprietary models, while\nrequiring significantly fewer computational resources.\n","authors":["Tanay Aggarwal","Angelo Salatino","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2412.08258v2.pdf","comment":"Now accepted to Information Processing & Management. this is the\n  camera ready"},{"id":"http://arxiv.org/abs/2504.15629v2","updated":"2025-06-11T07:56:14Z","published":"2025-04-22T06:41:25Z","title":"CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation\n  Correction","summary":"  Retrieval Augmented Generation (RAG) has emerged as a powerful application of\nLarge Language Models (LLMs), revolutionizing information search and\nconsumption. RAG systems combine traditional search capabilities with LLMs to\ngenerate comprehensive answers to user queries, ideally with accurate\ncitations. However, in our experience of developing a RAG product, LLMs often\nstruggle with source attribution, aligning with other industry studies\nreporting citation accuracy rates of only about 74% for popular generative\nsearch engines. To address this, we present efficient post-processing\nalgorithms to improve citation accuracy in LLM-generated responses, with\nminimal impact on latency and cost. Our approaches cross-check generated\ncitations against retrieved articles using methods including keyword + semantic\nmatching, fine tuned model with BERTScore, and a lightweight LLM-based\ntechnique. Our experimental results demonstrate a relative improvement of\n15.46% in the overall accuracy metrics of our RAG system. This significant\nenhancement potentially enables a shift from our current larger language model\nto a relatively smaller model that is approximately 12x more cost-effective and\n3x faster in inference time, while maintaining comparable performance. This\nresearch contributes to enhancing the reliability and trustworthiness of\nAI-generated content in information retrieval and summarization tasks which is\ncritical to gain customer trust especially in commercial products.\n","authors":["Harsh Maheshwari","Srikanth Tenneti","Alwarappan Nakkiran"],"pdf_url":"https://arxiv.org/pdf/2504.15629v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07563v3","updated":"2025-06-11T07:55:32Z","published":"2025-06-09T09:03:05Z","title":"MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with\n  Expert Specialization","summary":"  Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.\n","authors":["Ken Yaggel","Eyal German","Aviel Ben Siman Tov"],"pdf_url":"https://arxiv.org/pdf/2506.07563v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09414v1","updated":"2025-06-11T05:56:03Z","published":"2025-06-11T05:56:03Z","title":"PGDA-KGQA: A Prompt-Guided Generative Framework with Multiple Data\n  Augmentation Strategies for Knowledge Graph Question Answering","summary":"  Knowledge Graph Question Answering (KGQA) is a crucial task in natural\nlanguage processing that requires reasoning over knowledge graphs (KGs) to\nanswer natural language questions. Recent methods utilizing large language\nmodels (LLMs) have shown remarkable semantic parsing capabilities but are\nlimited by the scarcity of diverse annotated data and multi-hop reasoning\nsamples. Traditional data augmentation approaches are focus mainly on\nsingle-hop questions and prone to semantic distortion, while LLM-based methods\nprimarily address semantic distortion but usually neglect multi-hop reasoning,\nthus limiting data diversity. The scarcity of multi-hop samples further weakens\nmodels' generalization. To address these issues, we propose PGDA-KGQA, a\nprompt-guided generative framework with multiple data augmentation strategies\nfor KGQA. At its core, PGDA-KGQA employs a unified prompt-design paradigm: by\ncrafting meticulously engineered prompts that integrate the provided textual\ncontent, it leverages LLMs to generate large-scale (question, logical form)\npairs for model training. Specifically, PGDA-KGQA enriches its training set by:\n(1) generating single-hop pseudo questions to improve the alignment of question\nsemantics with KG relations; (2) applying semantic-preserving question\nrewriting to improve robustness against linguistic variations; (3) employing\nanswer-guided reverse path exploration to create realistic multi-hop questions.\nBy adopting an augment-generate-retrieve semantic parsing pipeline, PGDA-KGQA\nutilizes the augmented data to enhance the accuracy of logical form generation\nand thus improve answer retrieval performance. Experiments demonstrate that\noutperforms state-of-the-art methods on standard KGQA datasets, achieving\nimprovements on WebQSP by 2.8%, 1.2%, and 3.1% and on ComplexWebQuestions by\n1.8%, 1.1%, and 2.4% in F1, Hits@1, and Accuracy, respectively.\n","authors":["Xiujun Zhou","Pingjian Zhang","Deyou Tang"],"pdf_url":"https://arxiv.org/pdf/2506.09414v1.pdf","comment":"13 pages, 7 figures, 5 tables"},{"id":"http://arxiv.org/abs/2506.09409v1","updated":"2025-06-11T05:40:26Z","published":"2025-06-11T05:40:26Z","title":"MAGMaR Shared Task System Description: Video Retrieval with OmniEmbed","summary":"  Effective video retrieval remains challenging due to the complexity of\nintegrating visual, auditory, and textual modalities. In this paper, we explore\nunified retrieval methods using OmniEmbed, a powerful multimodal embedding\nmodel from the Tevatron 2.0 toolkit, in the context of the MAGMaR shared task.\nEvaluated on the comprehensive MultiVENT 2.0 dataset, OmniEmbed generates\nunified embeddings for text, images, audio, and video, enabling robust\nmultimodal retrieval. By finetuning OmniEmbed with the combined multimodal\ndata--visual frames, audio tracks, and textual descriptions provided in\nMultiVENT 2.0, we achieve substantial improvements in complex, multilingual\nvideo retrieval tasks. Our submission achieved the highest score on the MAGMaR\nshared task leaderboard among public submissions as of May 20th, 2025,\nhighlighting the practical effectiveness of our unified multimodal retrieval\napproach. Model checkpoint in this work is opensourced.\n","authors":["Jiaqi Samantha Zhan","Crystina Zhang","Shengyao Zhuang","Xueguang Ma","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2506.09409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18470v5","updated":"2025-06-11T04:41:29Z","published":"2025-02-04T01:30:06Z","title":"Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World\n  Geospatial Reasoning Questions","summary":"  Answering real-world geospatial questions--such as finding restaurants along\na travel route or amenities near a landmark--requires reasoning over both\ngeographic relationships and semantic user intent. However, existing large\nlanguage models (LLMs) lack spatial computing capabilities and access to\nup-to-date, ubiquitous real-world geospatial data, while traditional geospatial\nsystems fall short in interpreting natural language. To bridge this gap, we\nintroduce Spatial-RAG, a Retrieval-Augmented Generation (RAG) framework\ndesigned for geospatial question answering. Spatial-RAG integrates structured\nspatial databases with LLMs via a hybrid spatial retriever that combines sparse\nspatial filtering and dense semantic matching. It formulates the answering\nprocess as a multi-objective optimization over spatial and semantic relevance,\nidentifying Pareto-optimal candidates and dynamically selecting the best\nresponse based on user intent. Experiments across multiple tourism and\nmap-based QA datasets show that Spatial-RAG significantly improves accuracy,\nprecision, and ranking performance over strong baselines.\n","authors":["Dazhou Yu","Riyang Bao","Ruiyu Ning","Jinghong Peng","Gengchen Mai","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.18470v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13787v1","updated":"2025-06-11T04:40:24Z","published":"2025-06-11T04:40:24Z","title":"Analysis of Anonymous User Interaction Relationships and Prediction of\n  Advertising Feedback Based on Graph Neural Network","summary":"  While online advertising is highly dependent on implicit interaction networks\nof anonymous users for engagement inference, and for the selection and\noptimization of delivery strategies, existing graph models seldom can capture\nthe multi-scale temporal, semantic and higher-order dependency features of\nthese interaction networks, thus it's hard to describe the complicated patterns\nof the anonymous behavior. In this paper, we propose Decoupled\nTemporal-Hierarchical Graph Neural Network (DTH-GNN), which achieves three main\ncontributions. Above all, we introduce temporal edge decomposition, which\ndivides each interaction into three types of channels: short-term burst,\ndiurnal cycle and long-range memory, and conducts feature extraction using the\nconvolution kernel of parallel dilated residuals; Furthermore, our model builds\na hierarchical heterogeneous aggregation, where user-user, user-advertisement,\nadvertisement-advertisement subgraphs are combined through the meta-path\nconditional Transformer encoder, where the noise structure is dynamically\ntamped down via the synergy of cross-channel self-attention and gating\nrelationship selector. Thirdly, the contrast regularity of feedback perception\nis formulated, the consistency of various time slices is maximized, the entropy\nof control exposure information with dual-view target is maximized, the global\nprototype of dual-momentum queue distillation is presented, and the strategy\ngradient layer with light weight is combined with delaying transformation\nsignal to fine-tune the node representation for benefit-oriented. The AUC of\nDTH-GNN improved by 8.2% and the logarithmic loss improved by 5.7% in\ncomparison with the best baseline model.\n","authors":["Yanjun Dai","Haoyang Feng","Yuan Gao"],"pdf_url":"https://arxiv.org/pdf/2506.13787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04211v2","updated":"2025-06-11T04:27:29Z","published":"2024-08-08T04:31:29Z","title":"MMREC: LLM Based Multi-Modal Recommender System","summary":"  The importance of recommender systems is growing rapidly due to the\nexponential increase in the volume of content generated daily. This surge in\ncontent presents unique challenges for designing effective recommender systems.\nKey among these challenges is the need to effectively leverage the vast amounts\nof natural language data and images that represent user preferences. This paper\npresents a novel approach to enhancing recommender systems by leveraging Large\nLanguage Models (LLMs) and deep learning techniques. The proposed framework\naims to improve the accuracy and relevance of recommendations by incorporating\nmulti-modal information processing and by the use of unified latent space\nrepresentation. The study explores the potential of LLMs to better understand\nand utilize natural language data in recommendation contexts, addressing the\nlimitations of previous methods. The framework efficiently extracts and\nintegrates text and image information through LLMs, unifying diverse modalities\nin a latent space to simplify the learning process for the ranking model.\nExperimental results demonstrate the enhanced discriminative power of the model\nwhen utilizing multi-modal information. This research contributes to the\nevolving field of recommender systems by showcasing the potential of LLMs and\nmulti-modal data integration to create more personalized and contextually\nrelevant recommendations.\n","authors":["Jiahao Tian","Jinman Zhao","Zhenkai Wang","Zhicheng Ding"],"pdf_url":"https://arxiv.org/pdf/2408.04211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13785v1","updated":"2025-06-11T04:04:13Z","published":"2025-06-11T04:04:13Z","title":"LLM-Driven Data Generation and a Novel Soft Metric for Evaluating\n  Text-to-SQL in Aviation MRO","summary":"  The application of Large Language Models (LLMs) to text-to-SQL tasks promises\nto democratize data access, particularly in critical industries like aviation\nMaintenance, Repair, and Operation (MRO). However, progress is hindered by two\nkey challenges: the rigidity of conventional evaluation metrics such as\nexecution accuracy, which offer coarse, binary feedback, and the scarcity of\ndomain-specific evaluation datasets. This paper addresses these gaps. To enable\nmore nuanced assessment, we introduce a novel F1-score-based 'soft' metric that\nquantifies the informational overlap between generated and ground-truth SQL\nresults. To address data scarcity, we propose an LLM-driven pipeline that\nsynthesizes realistic question-SQL pairs from database schemas. We demonstrate\nour contributions through an empirical evaluation on an authentic MRO database.\nOur experiments show that the proposed soft metric provides more insightful\nperformance analysis than strict accuracy, and our data generation technique is\neffective in creating a domain-specific benchmark. Together, these\ncontributions offer a robust framework for evaluating and advancing text-to-SQL\nsystems in specialized environments.\n","authors":["Patrick Sutanto","Jonathan Kenrick","Max Lorenz","Joan Santoso"],"pdf_url":"https://arxiv.org/pdf/2506.13785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08626v2","updated":"2025-06-11T03:47:20Z","published":"2025-06-10T09:44:03Z","title":"Leveraging LLMs to Evaluate Usefulness of Document","summary":"  The conventional Cranfield paradigm struggles to effectively capture user\nsatisfaction due to its weak correlation between relevance and satisfaction,\nalongside the high costs of relevance annotation in building test collections.\nTo tackle these issues, our research explores the potential of leveraging large\nlanguage models (LLMs) to generate multilevel usefulness labels for evaluation.\nWe introduce a new user-centric evaluation framework that integrates users'\nsearch context and behavioral data into LLMs. This framework uses a cascading\njudgment structure designed for multilevel usefulness assessments, drawing\ninspiration from ordinal regression techniques. Our study demonstrates that\nwhen well-guided with context and behavioral information, LLMs can accurately\nevaluate usefulness, allowing our approach to surpass third-party labeling\nmethods. Furthermore, we conduct ablation studies to investigate the influence\nof key components within the framework. We also apply the labels produced by\nour method to predict user satisfaction, with real-world experiments indicating\nthat these labels substantially improve the performance of satisfaction\nprediction models.\n","authors":["Xingzhu Wang","Erhan Zhang","Yiqun Chen","Jinghan Xuan","Yucheng Hou","Yitong Xu","Ying Nie","Shuaiqiang Wang","Dawei Yin","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2506.08626v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.10238v1","updated":"2025-06-11T23:43:58Z","published":"2025-06-11T23:43:58Z","title":"A Unifying Algorithm for Hierarchical Queries","summary":"  The class of hierarchical queries is known to define the boundary of the\ndichotomy between tractability and intractability for the following two\nextensively studied problems about self-join free Boolean conjunctive queries\n(SJF-BCQ): (i) evaluating a SJF-BCQ on a tuple-independent probabilistic\ndatabase; (ii) computing the Shapley value of a fact in a database on which a\nSJF-BCQ evaluates to true. Here, we establish that hierarchical queries define\nalso the boundary of the dichotomy between tractability and intractability for\na different natural algorithmic problem, which we call the \"bag-set\nmaximization\" problem. The bag-set maximization problem associated with a\nSJF-BCQ $Q$ asks: given a database $\\cal D$, find the biggest value that $Q$\ntakes under bag semantics on a database $\\cal D'$ obtained from $\\cal D$ by\nadding at most $\\theta$ facts from another given database $\\cal D^r$.\n  For non-hierarchical queries, we show that the bag-set maximization problem\nis an NP-complete optimization problem. More significantly, for hierarchical\nqueries, we show that all three aforementioned problems (probabilistic query\nevaluation, Shapley value computation, and bag-set maximization) admit a single\nunifying polynomial-time algorithm that operates on an abstract algebraic\nstructure, called a \"2-monoid\". Each of the three problems requires a different\ninstantiation of the 2-monoid tailored for the problem at hand.\n","authors":["Mahmoud Abo Khamis","Jesse Comer","Phokion Kolaitis","Sudeepa Roy","Val Tannen"],"pdf_url":"https://arxiv.org/pdf/2506.10238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.11575v2","updated":"2025-06-11T20:39:41Z","published":"2025-03-14T16:40:36Z","title":"Finding a Fair Scoring Function for Top-$k$ Selection: From Hardness to\n  Practice","summary":"  Selecting a subset of the $k$ \"best\" items from a dataset of $n$ items, based\non a scoring function, is a key task in decision-making. Given the rise of\nautomated decision-making software, it is important that the outcome of this\nprocess, called top-$k$ selection, is fair. Here we consider the problem of\nidentifying a fair linear scoring function for top-$k$ selection. The function\ncomputes a score for each item as a weighted sum of its (numerical) attribute\nvalues, and must ensure that the selected subset includes adequate\nrepresentation of a minority or historically disadvantaged group. Existing\nalgorithms do not scale efficiently, particularly in higher dimensions. Our\nhardness analysis shows that in more than two dimensions, no algorithm is\nlikely to achieve good scalability with respect to dataset size, and the\ncomputational complexity is likely to increase rapidly with dimensionality.\nHowever, the hardness results also provide key insights guiding algorithm\ndesign, leading to our dual-algorithm solution: (1) For small values of $k$,\nour hardness analysis reveals a gap in the hardness barrier. By addressing\nvarious engineering challenges, including achieving efficient parallelism, we\nturn this potential of efficiency into an optimized algorithm delivering\nsubstantial practical performance gains. (2) For large values of $k$, where the\nhardness is robust, we employ a practically efficient algorithm which, despite\nbeing theoretically worse, achieves superior real-world performance.\nExperimental evaluations on real-world datasets then explore scenarios where\nworst-case behavior does not manifest, identifying areas critical to practical\nperformance. Our solution achieves speed-ups of up to several orders of\nmagnitude compared to SOTA, an efficiency made possible through a tight\nintegration of hardness analysis, algorithm design, practical engineering, and\nempirical evaluation.\n","authors":["Guangya Cai"],"pdf_url":"https://arxiv.org/pdf/2503.11575v2.pdf","comment":"Abstract shortened to meet Arxiv requirements"},{"id":"http://arxiv.org/abs/2506.10092v1","updated":"2025-06-11T18:24:11Z","published":"2025-06-11T18:24:11Z","title":"GPU Acceleration of SQL Analytics on Compressed Data","summary":"  GPUs are uniquely suited to accelerate (SQL) analytics workloads thanks to\ntheir massive compute parallelism and High Bandwidth Memory (HBM) -- when\ndatasets fit in the GPU HBM, performance is unparalleled. Unfortunately, GPU\nHBMs remain typically small when compared with lower-bandwidth CPU main memory.\nBesides brute-force scaling across many GPUs, current solutions to accelerate\nqueries on large datasets include leveraging data partitioning and loading\nsmaller data batches in GPU HBM, and hybrid execution with a connected device\n(e.g., CPUs). Unfortunately, these approaches are exposed to the limitations of\nlower main memory and host-to-device interconnect bandwidths, introduce\nadditional I/O overheads, or incur higher costs. This is a substantial problem\nwhen trying to scale adoption of GPUs on larger datasets. Data compression can\nalleviate this bottleneck, but to avoid paying for costly\ndecompression/decoding, an ideal solution must include computation primitives\nto operate directly on data in compressed form.\n  This is the focus of our paper: a set of new methods for running queries\ndirectly on light-weight compressed data using schemes such as Run-Length\nEncoding (RLE), index encoding, bit-width reductions, and dictionary encoding.\nOur novelty includes operating on multiple RLE columns without decompression,\nhandling heterogeneous column encodings, and leveraging PyTorch tensor\noperations for portability across devices. Experimental evaluations show\nspeedups of an order of magnitude compared to state-of-the-art commercial\nCPU-only analytics systems, for real-world queries on a production dataset that\nwould not fit into GPU memory uncompressed. This work paves the road for GPU\nadoption in a much broader set of use cases, and it is complementary to most\nother scale-out or fallback mechanisms.\n","authors":["Zezhou Huang","Krystian Sakowski","Hans Lehnert","Wei Cui","Carlo Curino","Matteo Interlandi","Marius Dumitru","Rathijit Sen"],"pdf_url":"https://arxiv.org/pdf/2506.10092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12372v6","updated":"2025-06-11T17:49:37Z","published":"2025-01-21T18:52:15Z","title":"Is Long Context All You Need? Leveraging LLM's Extended Context for\n  NL2SQL","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of natural language processing tasks. In particular, improvements in\nreasoning abilities and the expansion of context windows have opened new\navenues for leveraging these powerful models. NL2SQL is challenging in that the\nnatural language question is inherently ambiguous, while the SQL generation\nrequires a precise understanding of complex data schema and semantics. One\napproach to this semantic ambiguous problem is to provide more and sufficient\ncontextual information.\n  In this work, we explore the performance and the latency trade-offs of the\nextended context window (a.k.a., long context) offered by Google's\nstate-of-the-art LLM (\\textit{gemini-1.5-pro}). We study the impact of various\ncontextual information, including column example values, question and SQL query\npairs, user-provided hints, SQL documentation, and schema. To the best of our\nknowledge, this is the first work to study how the extended context window and\nextra contextual information can help NL2SQL generation with respect to both\naccuracy and latency cost. We show that long context LLMs are robust and do not\nget lost in the extended contextual information. Additionally, our long-context\nNL2SQL pipeline based on Google's \\textit{gemini-pro-1.5} achieve strong\nperformances on various benchmark datasets without finetuning and expensive\nself-consistency based techniques.\n","authors":["Yeounoh Chung","Gaurav T. Kakkar","Yu Gan","Brenton Milne","Fatma Ozcan"],"pdf_url":"https://arxiv.org/pdf/2501.12372v6.pdf","comment":"13 pages, 6 figures, VLDB 2025"},{"id":"http://arxiv.org/abs/2505.05568v2","updated":"2025-06-11T17:37:10Z","published":"2025-05-08T18:03:43Z","title":"Griffin: Towards a Graph-Centric Relational Database Foundation Model","summary":"  We introduce Griffin, the first foundation model attemptation designed\nspecifically for Relational Databases (RDBs). Unlike previous smaller models\nfocused on single RDB tasks, Griffin unifies the data encoder and task decoder\nto handle diverse tasks. Additionally, we enhance the architecture by\nincorporating a cross-attention module and a novel aggregator. Griffin utilizes\npretraining on both single-table and RDB datasets, employing advanced encoders\nfor categorical, numerical, and metadata features, along with innovative\ncomponents such as cross-attention modules and enhanced message-passing neural\nnetworks (MPNNs) to capture the complexities of relational data. Evaluated on\nlarge-scale, heterogeneous, and temporal graphs extracted from RDBs across\nvarious domains (spanning over 150 million nodes), Griffin demonstrates\nsuperior or comparable performance to individually trained models, excels in\nlow-data scenarios, and shows strong transferability with similarity and\ndiversity in pretraining across new datasets and tasks, highlighting its\npotential as a universally applicable foundation model for RDBs. Code available\nat https://github.com/yanxwb/Griffin.\n","authors":["Yanbo Wang","Xiyuan Wang","Quan Gan","Minjie Wang","Qibin Yang","David Wipf","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2505.05568v2.pdf","comment":"Published at ICML 2025"},{"id":"http://arxiv.org/abs/2506.09938v1","updated":"2025-06-11T17:02:12Z","published":"2025-06-11T17:02:12Z","title":"Microservices and Real-Time Processing in Retail IT: A Review of\n  Open-Source Toolchains and Deployment Strategies","summary":"  With the rapid pace of digital transformation, the retail industry is\nincreasingly depending on real-time, scalable, and resilient systems to manage\nfinancial transactions, analyze customer behavior, and streamline order\nprocessing. This literature review explores how modern event-driven and\nmicroservices-based architectures, particularly those leveraging Apache Kafka,\nSpring Boot, MongoDB, and Kubernetes are transforming retail and financial\nsystems. By systematically reviewing academic publications, technical white\npapers, and industry reports from recent years, this study synthesizes key\nthemes and implementation strategies. The analysis reveals that technologies\nlike Kafka and Spring Boot are instrumental in building low-latency,\nevent-driven applications that support real-time analytics and fraud detection,\nwhile MongoDB, when deployed on Kubernetes, ensures fault tolerance and high\navailability in inventory and transaction systems. Kubernetes itself plays a\ncrucial role in automating deployment and scaling of microservices. These\nfindings provide valuable insights for industry practitioners aiming to design\nscalable infrastructures, identify research opportunities in hybrid deployment\nmodels, and offer educators a foundation to integrate modern system\narchitectures into professional and technical communication training.\n","authors":["Aaditaa Vashisht","Rekha B S"],"pdf_url":"https://arxiv.org/pdf/2506.09938v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.18916v1","updated":"2025-06-11T12:07:55Z","published":"2025-06-11T12:07:55Z","title":"HI-SQL: Optimizing Text-to-SQL Systems through Dynamic Hint Integration","summary":"  Text-to-SQL generation bridges the gap between natural language and\ndatabases, enabling users to query data without requiring SQL expertise. While\nlarge language models (LLMs) have significantly advanced the field, challenges\nremain in handling complex queries that involve multi-table joins, nested\nconditions, and intricate operations. Existing methods often rely on multi-step\npipelines that incur high computational costs, increase latency, and are prone\nto error propagation. To address these limitations, we propose HI-SQL, a\npipeline that incorporates a novel hint generation mechanism utilizing\nhistorical query logs to guide SQL generation. By analyzing prior queries, our\nmethod generates contextual hints that focus on handling the complexities of\nmulti-table and nested operations. These hints are seamlessly integrated into\nthe SQL generation process, eliminating the need for costly multi-step\napproaches and reducing reliance on human-crafted prompts. Experimental\nevaluations on multiple benchmark datasets demonstrate that our approach\nsignificantly improves query accuracy of LLM-generated queries while ensuring\nefficiency in terms of LLM calls and latency, offering a robust and practical\nsolution for enhancing Text-to-SQL systems.\n","authors":["Ganesh Parab","Zishan Ahmad","Dagnachew Birru"],"pdf_url":"https://arxiv.org/pdf/2506.18916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10362v3","updated":"2025-06-11T08:54:54Z","published":"2024-12-06T15:54:36Z","title":"Reviewing Uses of Regulatory Compliance Monitoring","summary":"  Organizations need to manage numerous business processes for delivering their\nservices and products to customers. One important consideration thereby lies in\nthe adherence to regulations such as laws, guidelines, or industry standards.\nIn order to monitor adherence of their business processes to regulations -- in\nother words, their regulatory compliance -- organizations make use of various\ntechniques that draw on process execution data of IT systems that support these\nprocesses. Previous research has investigated conformance checking, an\noperation of process mining, for the domains in which it is applied, its\noperationalization of regulations, the techniques being used, and the\npresentation of results produced. However, other techniques for regulatory\ncompliance monitoring, which we summarize as compliance checking techniques,\nhave not yet been investigated regarding these aspects in a structural manner.\nTo this end, this work presents a systematic literature review on uses of\nregulatory compliance monitoring of business processes, thereby offering\ninsights into the various techniques being used, their application and the\nresults they generate. We highlight commonalities and differences between the\napproaches and find that various steps are performed manually; we also provide\nfurther impulses for research on compliance monitoring and its use in practice.\n","authors":["Finn Klessascheck","Luise Pufahl"],"pdf_url":"https://arxiv.org/pdf/2501.10362v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09467v1","updated":"2025-06-11T07:16:29Z","published":"2025-06-11T07:16:29Z","title":"ArcNeural: A Multi-Modal Database for the Gen-AI Era","summary":"  ArcNeural introduces a novel multimodal database tailored for the demands of\nGenerative AI and Large Language Models, enabling efficient management of\ndiverse data types such as graphs, vectors, and documents. Its storage-compute\nseparated architecture integrates graph technology, advanced vector indexing,\nand transaction processing to support real-time analytics and AI-driven\napplications. Key features include a unified storage layer, adaptive edge\ncollection in MemEngine, and seamless integration of transaction and analytical\nprocessing. Experimental evaluations demonstrate ArcNeural's superior\nperformance and scalability compared to state-of-the-art systems. This system\nbridges structured and unstructured data management, offering a versatile\nsolution for enterprise-grade AI applications.\n  ArcNeural's design addresses the challenges of multimodal data processing,\nproviding a robust framework for intelligent, data-driven solutions in the Gen\nAI era.\n","authors":["Wu Min","Qiao Yuncong","Yu Tan","Chenghu Yang"],"pdf_url":"https://arxiv.org/pdf/2506.09467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13785v1","updated":"2025-06-11T04:04:13Z","published":"2025-06-11T04:04:13Z","title":"LLM-Driven Data Generation and a Novel Soft Metric for Evaluating\n  Text-to-SQL in Aviation MRO","summary":"  The application of Large Language Models (LLMs) to text-to-SQL tasks promises\nto democratize data access, particularly in critical industries like aviation\nMaintenance, Repair, and Operation (MRO). However, progress is hindered by two\nkey challenges: the rigidity of conventional evaluation metrics such as\nexecution accuracy, which offer coarse, binary feedback, and the scarcity of\ndomain-specific evaluation datasets. This paper addresses these gaps. To enable\nmore nuanced assessment, we introduce a novel F1-score-based 'soft' metric that\nquantifies the informational overlap between generated and ground-truth SQL\nresults. To address data scarcity, we propose an LLM-driven pipeline that\nsynthesizes realistic question-SQL pairs from database schemas. We demonstrate\nour contributions through an empirical evaluation on an authentic MRO database.\nOur experiments show that the proposed soft metric provides more insightful\nperformance analysis than strict accuracy, and our data generation technique is\neffective in creating a domain-specific benchmark. Together, these\ncontributions offer a robust framework for evaluating and advancing text-to-SQL\nsystems in specialized environments.\n","authors":["Patrick Sutanto","Jonathan Kenrick","Max Lorenz","Joan Santoso"],"pdf_url":"https://arxiv.org/pdf/2506.13785v1.pdf","comment":null}]},"2025-06-10T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.09279v1","updated":"2025-06-10T22:35:49Z","published":"2025-06-10T22:35:49Z","title":"A Topic Modeling Analysis of Stigma Dimensions, Social, and Related\n  Behavioral Circumstances in Clinical Notes Among Patients with HIV","summary":"  Objective: To characterize stigma dimensions, social, and related behavioral\ncircumstances in people living with HIV (PLWHs) seeking care, using natural\nlanguage processing methods applied to a large collection of electronic health\nrecord (EHR) clinical notes from a large integrated health system in the\nsoutheast United States. Methods: We identified 9,140 cohort of PLWHs from the\nUF Health IDR and performed topic modeling analysis using Latent Dirichlet\nAllocation (LDA) to uncover stigma dimensions, social, and related behavioral\ncircumstances. Domain experts created a seed list of HIV-related stigma\nkeywords, then applied a snowball strategy to iteratively review notes for\nadditional terms until saturation was reached. To identify more target topics,\nwe tested three keyword-based filtering strategies. Domain experts manually\nreviewed the detected topics using the prevalent terms and key discussion\ntopics. Word frequency analysis was used to highlight the prevalent terms\nassociated with each topic. In addition, we conducted topic variation analysis\namong subgroups to examine differences across age and sex-specific\ndemographics. Results and Conclusion: Topic modeling on sentences containing at\nleast one keyword uncovered a wide range of topic themes associated with\nHIV-related stigma, social, and related behaviors circumstances, including\n\"Mental Health Concern and Stigma\", \"Social Support and Engagement\", \"Limited\nHealthcare Access and Severe Illness\", \"Treatment Refusal and Isolation\" and so\non. Topic variation analysis across age subgroups revealed differences.\nExtracting and understanding the HIV-related stigma dimensions, social, and\nrelated behavioral circumstances from EHR clinical notes enables scalable,\ntime-efficient assessment, overcoming the limitations of traditional\nquestionnaires and improving patient outcomes.\n","authors":["Ziyi Chen","Yiyang Liu","Mattia Prosperi","Krishna Vaddiparti","Robert L Cook","Jiang Bian","Yi Guo","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2506.09279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09260v1","updated":"2025-06-10T21:41:01Z","published":"2025-06-10T21:41:01Z","title":"ThinkQE: Query Expansion via an Evolving Thinking Process","summary":"  Effective query expansion for web search benefits from promoting both\nexploration and result diversity to capture multiple interpretations and facets\nof a query. While recent LLM-based methods have improved retrieval performance\nand demonstrate strong domain generalization without additional training, they\noften generate narrowly focused expansions that overlook these desiderata. We\npropose ThinkQE, a test-time query expansion framework addressing this\nlimitation through two key components: a thinking-based expansion process that\nencourages deeper and comprehensive semantic exploration, and a\ncorpus-interaction strategy that iteratively refines expansions using retrieval\nfeedback from the corpus. Experiments on diverse web search benchmarks (DL19,\nDL20, and BRIGHT) show ThinkQE consistently outperforms prior approaches,\nincluding training-intensive dense retrievers and rerankers.\n","authors":["Yibin Lei","Tao Shen","Andrew Yates"],"pdf_url":"https://arxiv.org/pdf/2506.09260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09221v1","updated":"2025-06-10T20:25:10Z","published":"2025-06-10T20:25:10Z","title":"In Crowd Veritas: Leveraging Human Intelligence To Fight Misinformation","summary":"  The spread of online misinformation poses serious threats to democratic\nsocieties. Traditionally, expert fact-checkers verify the truthfulness of\ninformation through investigative processes. However, the volume and immediacy\nof online content present major scalability challenges. Crowdsourcing offers a\npromising alternative by leveraging non-expert judgments, but it introduces\nconcerns about bias, accuracy, and interpretability. This thesis investigates\nhow human intelligence can be harnessed to assess the truthfulness of online\ninformation, focusing on three areas: misinformation assessment, cognitive\nbiases, and automated fact-checking systems. Through large-scale crowdsourcing\nexperiments and statistical modeling, it identifies key factors influencing\nhuman judgments and introduces a model for the joint prediction and explanation\nof truthfulness. The findings show that non-expert judgments often align with\nexpert assessments, particularly when factors such as timing and experience are\nconsidered. By deepening our understanding of human judgment and bias in\ntruthfulness assessment, this thesis contributes to the development of more\ntransparent, trustworthy, and interpretable systems for combating\nmisinformation.\n","authors":["Michael Soprano"],"pdf_url":"https://arxiv.org/pdf/2506.09221v1.pdf","comment":"PhD thesis, University of Udine, defended May 2023, 458 pages"},{"id":"http://arxiv.org/abs/2506.09209v1","updated":"2025-06-10T19:59:49Z","published":"2025-06-10T19:59:49Z","title":"Revisiting Graph Projections for Effective Complementary Product\n  Recommendation","summary":"  Complementary product recommendation is a powerful strategy to improve\ncustomer experience and retail sales. However, recommending the right product\nis not a simple task because of the noisy and sparse nature of user-item\ninteractions. In this work, we propose a simple yet effective method to predict\na list of complementary products given a query item, based on the structure of\na directed weighted graph projected from the user-item bipartite graph. We\nrevisit bipartite graph projections for recommender systems and propose a novel\napproach for inferring complementarity relationships from historical user-item\ninteractions. We compare our model with recent methods from the literature and\nshow, despite the simplicity of our approach, an average improvement of +43%\nand +38% over sequential and graph-based recommenders, respectively, over\ndifferent benchmarks.\n","authors":["Leandro Anghinoni","Pablo Zivic","Jorge Adrian Sanchez"],"pdf_url":"https://arxiv.org/pdf/2506.09209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05582v3","updated":"2025-06-10T15:26:36Z","published":"2023-03-09T21:13:32Z","title":"Generalization analysis of an unfolding network for analysis-based\n  Compressed Sensing","summary":"  Unfolding networks have shown promising results in the Compressed Sensing\n(CS) field. Yet, the investigation of their generalization ability is still in\nits infancy. In this paper, we perform a generalization analysis of a\nstate-of-the-art ADMM-based unfolding network, which jointly learns a decoder\nfor CS and a sparsifying redundant analysis operator. To this end, we first\nimpose a structural constraint on the learnable sparsifier, which parametrizes\nthe network's hypothesis class. For the latter, we estimate its Rademacher\ncomplexity. With this estimate in hand, we deliver generalization error bounds\n-- which scale like the square root of the number of layers -- for the examined\nnetwork. Finally, the validity of our theory is assessed and numerical\ncomparisons to a state-of-the-art unfolding network are made, on synthetic and\nreal-world datasets. Our experimental results demonstrate that our proposed\nframework complies with our theoretical findings and outperforms the baseline,\nconsistently for all datasets.\n","authors":["Vicky Kouni","Yannis Panagakis"],"pdf_url":"https://arxiv.org/pdf/2303.05582v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19356v2","updated":"2025-06-10T13:33:12Z","published":"2025-05-25T23:06:20Z","title":"Optimized Text Embedding Models and Benchmarks for Amharic Passage\n  Retrieval","summary":"  Neural retrieval methods using transformer-based pre-trained language models\nhave advanced multilingual and cross-lingual retrieval. However, their\neffectiveness for low-resource, morphologically rich languages such as Amharic\nremains underexplored due to data scarcity and suboptimal tokenization. We\naddress this gap by introducing Amharic-specific dense retrieval models based\non pre-trained Amharic BERT and RoBERTa backbones. Our proposed\nRoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative\nimprovement in MRR@10 and a 9.86% gain in Recall@10 over the strongest\nmultilingual baseline, Arctic Embed 2.0 (568M parameters). More compact\nvariants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while\nbeing over 13x smaller. Additionally, we train a ColBERT-based late interaction\nretrieval model that achieves the highest MRR@10 score (0.843) among all\nevaluated models. We benchmark our proposed models against both sparse and\ndense retrieval baselines to systematically assess retrieval effectiveness in\nAmharic. Our analysis highlights key challenges in low-resource settings and\nunderscores the importance of language-specific adaptation. To foster future\nresearch in low-resource IR, we publicly release our dataset, codebase, and\ntrained models at https://github.com/kidist-amde/amharic-ir-benchmarks.\n","authors":["Kidist Amde Mekonnen","Yosef Worku Alemneh","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2505.19356v2.pdf","comment":"10 pages (excl. refs/appendix), 10 figures. Accepted to ACL 2025\n  Findings. Kidist and Yosef contributed equally to this work. Public\n  resources: https://github.com/kidist-amde/amharic-ir-benchmarks"},{"id":"http://arxiv.org/abs/2506.08774v1","updated":"2025-06-10T13:16:26Z","published":"2025-06-10T13:16:26Z","title":"Multimodal Representation Alignment for Cross-modal Information\n  Retrieval","summary":"  Different machine learning models can represent the same underlying concept\nin different ways. This variability is particularly valuable for in-the-wild\nmultimodal retrieval, where the objective is to identify the corresponding\nrepresentation in one modality given another modality as input. This challenge\ncan be effectively framed as a feature alignment problem. For example, given a\nsentence encoded by a language model, retrieve the most semantically aligned\nimage based on features produced by an image encoder, or vice versa. In this\nwork, we first investigate the geometric relationships between visual and\ntextual embeddings derived from both vision-language models and combined\nunimodal models. We then align these representations using four standard\nsimilarity metrics as well as two learned ones, implemented via neural\nnetworks. Our findings indicate that the Wasserstein distance can serve as an\ninformative measure of the modality gap, while cosine similarity consistently\noutperforms alternative metrics in feature alignment tasks. Furthermore, we\nobserve that conventional architectures such as multilayer perceptrons are\ninsufficient for capturing the complex interactions between image and text\nrepresentations. Our study offers novel insights and practical considerations\nfor researchers working in multimodal information retrieval, particularly in\nreal-world, cross-modal applications.\n","authors":["Fan Xu","Luis A. Leiva"],"pdf_url":"https://arxiv.org/pdf/2506.08774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08771v1","updated":"2025-06-10T13:13:55Z","published":"2025-06-10T13:13:55Z","title":"Paths to Causality: Finding Informative Subgraphs Within Knowledge\n  Graphs for Knowledge-Based Causal Discovery","summary":"  Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality\n","authors":["Yuni Susanti","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2506.08771v1.pdf","comment":"Accepted at KDD 2025 (full research paper)"},{"id":"http://arxiv.org/abs/2501.18056v2","updated":"2025-06-10T13:00:17Z","published":"2025-01-29T23:41:12Z","title":"RL-based Query Rewriting with Distilled LLM for online E-Commerce\n  Systems","summary":"  Query rewriting (QR) is a critical technique in e-commerce search, addressing\nthe lexical gap between user queries and product descriptions to enhance search\nperformance. Existing QR approaches typically fall into two categories:\ndiscriminative models and generative methods leveraging large language models\n(LLMs). Discriminative models often struggle with natural language\nunderstanding and offer limited flexibility in rewriting, while generative\nLLMs, despite producing high-quality rewrites, face high inference latency and\ncost in online settings. These limitations force offline deployment, making\nthem vulnerable to issues like information staleness and semantic drift. To\novercome these challenges, we propose a novel hybrid pipeline for QR that\nbalances efficiency and effectiveness. Our approach combines offline knowledge\ndistillation to create a lightweight but efficient student model with online\nreinforcement learning (RL) to refine query rewriting dynamically using\nreal-time feedback. A key innovation is the use of LLMs as simulated human\nfeedback, enabling scalable reward signals and cost-effective evaluation\nwithout manual annotations. Experimental results on Amazon ESCI dataset\ndemonstrate significant improvements in query relevance, diversity, and\nadaptability, as well as positive feedback from the LLM simulation. This work\ncontributes to advancing LLM capabilities for domain-specific applications,\noffering a robust solution for dynamic and complex e-commerce search\nenvironments.\n","authors":["Duy A. Nguyen","Rishi Kesav Mohan","Van Yang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2501.18056v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08743v1","updated":"2025-06-10T12:38:24Z","published":"2025-06-10T12:38:24Z","title":"Bridging RDF Knowledge Graphs with Graph Neural Networks for\n  Semantically-Rich Recommender Systems","summary":"  Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation\n","authors":["Michael Färber","David Lamprecht","Yuni Susanti"],"pdf_url":"https://arxiv.org/pdf/2506.08743v1.pdf","comment":"Accepted at DASFAA 2025"},{"id":"http://arxiv.org/abs/2505.07459v2","updated":"2025-06-10T09:54:11Z","published":"2025-05-12T11:47:42Z","title":"Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic\n  Analysis","summary":"  Large Language Models (LLMs) are valued for their strong performance across\nvarious tasks, but they also produce inaccurate or misleading outputs.\nUncertainty Estimation (UE) quantifies the model's confidence and helps users\nassess response reliability. However, existing UE methods have not been\nthoroughly examined in scenarios like Retrieval-Augmented Generation (RAG),\nwhere the input prompt includes non-parametric knowledge. This paper shows that\ncurrent UE methods cannot reliably assess correctness in the RAG setting. We\nfurther propose an axiomatic framework to identify deficiencies in existing\nmethods and guide the development of improved approaches. Our framework\nintroduces five constraints that an effective UE method should meet after\nincorporating retrieved documents into the LLM's prompt. Experimental results\nreveal that no existing UE method fully satisfies all the axioms, explaining\ntheir suboptimal performance in RAG. We further introduce a simple yet\neffective calibration function based on our framework, which not only satisfies\nmore axioms than baseline methods but also improves the correlation between\nuncertainty estimates and correctness.\n","authors":["Heydar Soudani","Evangelos Kanoulas","Faegheh Hasibi"],"pdf_url":"https://arxiv.org/pdf/2505.07459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.07112v3","updated":"2025-06-10T09:17:48Z","published":"2025-03-20T08:38:57Z","title":"Are AI Agents interacting with Online Ads?","summary":"  As AI-driven agents become increasingly integrated into the digital\necosystem, they reshape how online advertising is perceived and processed.\nParticularly in the travel and hotel booking sector, these autonomous systems\ninfluence the effectiveness of traditional advertising formats. While visual\ncues and emotional appeals sway human users, AI agents prioritize structured\ndata such as price, availability, and specifications. This study examines how\ndifferent AI agents interact with online advertising, whether they incorporate\nads into their decision-making processes, and which ad formats prove most\neffective. We analyze interaction patterns, click behavior, and decision-making\nstrategies through experiments with multimodal language models such as OpenAI\nGPT-4o, Anthropic Claude, and Google Gemini 2.0 Flash. Our findings reveal that\nAI agents neither ignore nor systematically avoid advertisements but instead\nfavor certain features-particularly keywords and structured data. These\ninsights have significant implications for the future design of advertising\nstrategies in AI-dominated digital environments.\n","authors":["Andreas Stöckl","Joel Nitu"],"pdf_url":"https://arxiv.org/pdf/2504.07112v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13782v1","updated":"2025-06-10T09:14:30Z","published":"2025-06-10T09:14:30Z","title":"XGraphRAG: Interactive Visual Analysis for Graph-based\n  Retrieval-Augmented Generation","summary":"  Graph-based Retrieval-Augmented Generation (RAG) has shown great capability\nin enhancing Large Language Model (LLM)'s answer with an external knowledge\nbase. Compared to traditional RAG, it introduces a graph as an intermediate\nrepresentation to capture better structured relational knowledge in the corpus,\nelevating the precision and comprehensiveness of generation results. However,\ndevelopers usually face challenges in analyzing the effectiveness of GraphRAG\non their dataset due to GraphRAG's complex information processing pipeline and\nthe overwhelming amount of LLM invocations involved during graph construction\nand query, which limits GraphRAG interpretability and accessibility. This\nresearch proposes a visual analysis framework that helps RAG developers\nidentify critical recalls of GraphRAG and trace these recalls through the\nGraphRAG pipeline. Based on this framework, we develop XGraphRAG, a prototype\nsystem incorporating a set of interactive visualizations to facilitate users'\nanalysis process, boosting failure cases collection and improvement\nopportunities identification. Our evaluation demonstrates the effectiveness and\nusability of our approach. Our work is open-sourced and available at\nhttps://github.com/Gk0Wk/XGraphRAG.\n","authors":["Ke Wang","Bo Pan","Yingchaojie Feng","Yuwei Wu","Jieyi Chen","Minfeng Zhu","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2506.13782v1.pdf","comment":"Accepted to IEEE Pacific Visualization Conference 2025"},{"id":"http://arxiv.org/abs/2506.08531v1","updated":"2025-06-10T07:50:19Z","published":"2025-06-10T07:50:19Z","title":"TSRec: Enhancing Repeat-Aware Recommendation from a Temporal-Sequential\n  Perspective","summary":"  Repeat consumption, such as repurchasing items and relistening songs, is a\ncommon scenario in daily life. To model repeat consumption, the repeat-aware\nrecommendation has been proposed to predict which item will be re-interacted\nbased on the user-item interactions. In this paper, we investigate various\ninherent characteristics to enhance the repeat-aware recommendation.\nSpecifically, we explore these characteristics from two aspects: one is from\nthe temporal aspect where we consider the time interval relationship in the\nuser behavior sequence; the other is from the sequential aspect where we\nconsider the sequential-level relationship in the user behavior sequence. And\nour intuition is that both the temporal pattern and sequential pattern will\nreflect users' intentions of repeat consumption. By utilizing these two\npatterns, a novel model called Temporal and Sequential repeat-aware\nRecommendation(TSRec for short) is proposed to enhance repeat-aware\nrecommendation. TSRec has three main components: 1) User-specific Temporal\nRepresentation Module (UTRM), which encodes and extracts user historical repeat\ntemporal information. 2)Item-specific Temporal Representation Module (ITRM),\nwhich incorporates item time interval information as side information to\nalleviate the data sparsity problem of user repeat behavior sequence. 3)\nSequential Repeat-Aware Module (SRAM), which represents the similarity between\nthe user's current and the last repeat sequences. Extensive experimental\nresults on three public benchmarks demonstrate the superiority of TSRec over\nstate-of-the-art methods. The implementation code is available\nhttps://anonymous.4open.science/r/TSRec-2306/.\n","authors":["Shigang Quan","Shui Liu","Zhenzhe Zheng","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2506.08531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17998v2","updated":"2025-06-10T07:35:41Z","published":"2024-05-28T09:34:50Z","title":"Exploring the Escalation of Source Bias in User, Data, and Recommender\n  System Feedback Loop","summary":"  Recommender systems are essential for information access, allowing users to\npresent their content for recommendation. With the rise of large language\nmodels (LLMs), AI-generated content (AIGC), primarily in the form of text, has\nbecome a central part of the content ecosystem. As AIGC becomes increasingly\nprevalent, it is important to understand how it affects the performance and\ndynamics of recommender systems. To this end, we construct an environment that\nincorporates AIGC to explore its short-term impact. The results from popular\nsequential recommendation models reveal that AIGC are ranked higher in the\nrecommender system, reflecting the phenomenon of source bias. To further\nexplore the long-term impact of AIGC, we introduce a feedback loop with\nrealistic simulators. The results show that the model's preference for AIGC\nincreases as the user clicks on AIGC rises and the model trains on simulated\nclick data. This leads to two issues: In the short term, bias toward AIGC\nencourages LLM-based content creation, increasing AIGC content, and causing\nunfair traffic distribution. From a long-term perspective, our experiments also\nshow that when AIGC dominates the content ecosystem after a feedback loop, it\ncan lead to a decline in recommendation performance. To address these issues,\nwe propose a debiasing method based on L1-loss optimization to maintain\nlong-term content ecosystem balance. In a real-world environment with AIGC\ngenerated by mainstream LLMs, our method ensures a balance between AIGC and\nhuman-generated content in the ecosystem. The code and dataset are available at\nhttps://github.com/Yuqi-Zhou/Rec_SourceBias.\n","authors":["Yuqi Zhou","Sunhao Dai","Liang Pang","Gang Wang","Zhenhua Dong","Jun Xu","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2405.17998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24200v2","updated":"2025-06-10T07:26:49Z","published":"2024-10-31T17:55:36Z","title":"Length-Induced Embedding Collapse in PLM-based Models","summary":"  Text embeddings from PLM-based models enable a wide range of applications,\nyet their performance often degrades on longer texts. In this paper, we\nintroduce a phenomenon we call Length Collapse, where embeddings of longer\ntexts tend to cluster together. This clustering results in a distributional\ninconsistency between the embeddings of short and long texts. We further\ninvestigate how these differences contribute to the performance decline\nobserved with longer texts across various downstream tasks. Through a rigorous\ntheoretical analysis of the self-attention mechanism, which acts as a low-pass\nfilter in PLM-based models, we demonstrate that as text length increases, the\nstrength of low-pass filtering intensifies, causing embeddings to retain more\nlow-frequency components. As a result, input token features become more\nsimilar, leading to clustering and ultimately the collapse of embeddings for\nlonger texts. To address this issue, we propose a simple method, TempScale,\nwhich mitigates the Length Collapse phenomenon. By narrowing the gap in\nlow-pass filtering rates between long and short texts, TempScale ensures more\nconsistent embeddings across different text lengths. This approach leads to\nperformance improvements of 0.94% on MTEB and 1.10% on LongEmbed, which focuses\nspecifically on long-context retrieval, providing strong evidence for the\nvalidity of our analysis. The source code is available at\nhttps://github.com/Yuqi-Zhou/Length_Collapse.\n","authors":["Yuqi Zhou","Sunhao Dai","Zhanshuo Cao","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.24200v2.pdf","comment":"Accepted by ACL 2025"},{"id":"http://arxiv.org/abs/2506.08479v1","updated":"2025-06-10T06:11:01Z","published":"2025-06-10T06:11:01Z","title":"Efficient Context Selection for Long-Context QA: No Tuning, No\n  Iteration, Just Adaptive-$k$","summary":"  Retrieval-augmented generation (RAG) and long-context language models (LCLMs)\nboth address context limitations of LLMs in open-domain question answering\n(QA). However, optimal external context to retrieve remains an open problem:\nfixing the retrieval size risks either wasting tokens or omitting key evidence.\nExisting adaptive methods like Self-RAG and Self-Route rely on iterative LLM\nprompting and perform well on factoid QA, but struggle with aggregation QA,\nwhere the optimal context size is both unknown and variable. We present\nAdaptive-$k$ retrieval, a simple and effective single-pass method that\nadaptively selects the number of passages based on the distribution of the\nsimilarity scores between the query and the candidate passages. It does not\nrequire model fine-tuning, extra LLM inferences or changes to existing\nretriever-reader pipelines. On both factoid and aggregation QA benchmarks,\nAdaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x\nfewer tokens than full-context input, yet still retrieves 70% of relevant\npassages. It improves accuracy across five LCLMs and two embedding models,\nhighlighting that dynamically adjusting context size leads to more efficient\nand accurate QA.\n","authors":["Chihiro Taguchi","Seiji Maekawa","Nikita Bhutani"],"pdf_url":"https://arxiv.org/pdf/2506.08479v1.pdf","comment":"26 pages, 16 tables, 5 figures"},{"id":"http://arxiv.org/abs/2506.08442v1","updated":"2025-06-10T04:33:44Z","published":"2025-06-10T04:33:44Z","title":"MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking","summary":"  Online Travel Platforms (OTPs) have been working on improving their hotel\nSearch & Ranking (S&R) systems that facilitate efficient matching between\nconsumers and hotels. Existing OTPs focus almost exclusively on improving\nplatform revenue. In this work, we take a first step in incorporating hotel\nmerchants' objectives into the design of hotel S&R systems to achieve an\nincentive loop: the OTP tilts impressions and better-ranked positions to\nmerchants with high quality, and in return, the merchants provide better\nservice to consumers. Three critical design challenges need to be resolved to\nachieve this incentive loop: Matthew Effect in the consumer feedback-loop,\nunclear relation between hotel quality and performance, and conflicts between\nshort-term and long-term revenue. To address these challenges, we propose\nMERIT, a MERchant IncenTive ranking model, which can simultaneously take the\ninterests of merchants and consumers into account. We define a new Merchant\nCompetitiveness Index (MCI) to represent hotel merchant quality and propose a\nnew Merchant Tower to model the relation between MCI and ranking scores. Also,\nwe design a monotonic structure for Merchant Tower to provide a clear relation\nbetween hotel quality and performance. Finally, we propose a Multi-objective\nStratified Pairwise Loss, which can mitigate the conflicts between OTP's\nshort-term and long-term revenue. The offline experiment results indicate that\nMERIT outperforms these methods in optimizing the demands of consumers and\nmerchants. Furthermore, we conduct an online A/B test and obtain an improvement\nof 3.02% for the MCI score.\n","authors":["Shigang Quan","Hailong Tan","Shui Liu","Zhenzhe zheng","Ruihao Zhu","Liangyue Li","Quan Lu","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2506.08442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08382v1","updated":"2025-06-10T02:46:05Z","published":"2025-06-10T02:46:05Z","title":"NAM: A Normalization Attention Model for Personalized Product Search In\n  Fliggy","summary":"  Personalized product search provides significant benefits to e-commerce\nplatforms by extracting more accurate user preferences from historical\nbehaviors. Previous studies largely focused on the user factors when\npersonalizing the search query, while ignoring the item perspective, which\nleads to the following two challenges that we summarize in this paper: First,\nprevious approaches relying only on co-occurrence frequency tend to\noverestimate the conversion rates for popular items and underestimate those for\nlong-tail items, resulting in inaccurate item similarities; Second, user\npurchasing propensity is highly heterogeneous according to the popularity of\nthe target item: it is less correlated with the user's historical behavior for\na popular item and more correlated for a long-tail item. To address these\nchallenges, in this paper we propose NAM, a Normalization Attention Model,\nwhich optimizes ''when to personalize'' by utilizing Inverse Item Frequency\n(IIF) and employing a gating mechanism, as well as optimizes ''how to\npersonalize'' by normalizing the attention mechanism from a global perspective.\nThrough comprehensive experiments, we demonstrate that our proposed NAM model\nsignificantly outperforms state-of-the-art baseline models. Furthermore, we\nconducted an online A/B test at Fliggy, and obtained a significant improvement\nof 0.8% over the latest production system in conversion rate.\n","authors":["Shui Liu","Mingyuan Tao","Maofei Que","Pan Li","Dong Li","Shenghua Ni","Zhuoran Zhuang"],"pdf_url":"https://arxiv.org/pdf/2506.08382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08354v1","updated":"2025-06-10T02:11:42Z","published":"2025-06-10T02:11:42Z","title":"Text Embeddings Should Capture Implicit Semantics, Not Just Surface\n  Meaning","summary":"  This position paper argues that the text embedding research community should\nmove beyond surface meaning and embrace implicit semantics as a central\nmodeling goal. Text embedding models have become foundational in modern NLP,\npowering a wide range of applications and drawing increasing research\nattention. Yet, much of this progress remains narrowly focused on surface-level\nsemantics. In contrast, linguistic theory emphasizes that meaning is often\nimplicit, shaped by pragmatics, speaker intent, and sociocultural context.\nCurrent embedding models are typically trained on data that lacks such depth\nand evaluated on benchmarks that reward the capture of surface meaning. As a\nresult, they struggle with tasks requiring interpretive reasoning, speaker\nstance, or social meaning. Our pilot study highlights this gap, showing that\neven state-of-the-art models perform only marginally better than simplistic\nbaselines on implicit semantics tasks. To address this, we call for a paradigm\nshift: embedding research should prioritize more diverse and linguistically\ngrounded training data, design benchmarks that evaluate deeper semantic\nunderstanding, and explicitly frame implicit meaning as a core modeling\nobjective, better aligning embeddings with real-world language complexity.\n","authors":["Yiqun Sun","Qiang Huang","Anthony K. H. Tung","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2506.08354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08352v1","updated":"2025-06-10T02:09:57Z","published":"2025-06-10T02:09:57Z","title":"Reinforcement Fine-Tuning for Reasoning towards Multi-Step Multi-Source\n  Search in Large Language Models","summary":"  Large language models (LLMs) can face factual limitations when responding to\ntime-sensitive queries about recent events that arise after their knowledge\nthresholds in the training corpus. Existing search-augmented approaches fall\ninto two categories, each with distinct limitations: multi-agent search\nframeworks incur substantial computational overhead by separating search\nplanning and response synthesis across multiple LLMs, while single-LLM\ntool-calling methods restrict themselves to sequential planned, single-query\nsearches from sole search sources. We present Reasoning-Search (R-Search), a\nsingle-LLM search framework that unifies multi-step planning, multi-source\nsearch execution, and answer synthesis within one coherent inference process.\nInnovatively, it structure the output into four explicitly defined components,\nincluding reasoning steps that guide the search process (<think>), a\nnatural-language directed acyclic graph that represents the search plans with\nrespect to diverse sources (<search>), retrieved results from executing the\nsearch plans (<result>), and synthesized final answers (<answer>). To enable\neffective generation of these structured outputs, we propose a specialized\nReinforcement Fine-Tuning (ReFT) method based on GRPO, together with a\nmulti-component reward function that optimizes LLM's answer correctness,\nstructural validity of the generated DAG, and adherence to the defined output\nformat. Experimental evaluation on FinSearchBench-24, SearchExpertBench-25, and\nseven Q and A benchmarks demonstrates that R-Search outperforms\nstate-of-the-art methods, while achieving substantial efficiency gains through\n70% reduction in context token usage and approximately 50% decrease in\nexecution latency. Code is available at\nhttps://github.com/wentao0429/Reasoning-search.\n","authors":["Wentao Shi","Yiqing Shen"],"pdf_url":"https://arxiv.org/pdf/2506.08352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.17294v3","updated":"2025-06-10T01:13:55Z","published":"2023-12-28T15:47:30Z","title":"Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous\n  Tool Integration from GitHub","summary":"  Large Language Models (LLMs) excel in traditional natural language processing\ntasks but struggle with problems that require complex domain-specific\ncalculations or simulations. While equipping LLMs with external tools to build\nLLM-based agents can enhance their capabilities, existing approaches lack the\nflexibility to address diverse and ever-evolving user queries in open domains.\nCurrently, there is also no existing dataset that evaluates LLMs on open-domain\nknowledge that requires tools to solve. To this end, we introduce OpenAct\nbenchmark to evaluate the open-domain task-solving capability, which is built\non human expert consultation and repositories in GitHub. It comprises 339\nquestions spanning 7 diverse domains that need to be solved with\ndomain-specific methods. In our experiments, even state-of-the-art LLMs and\nLLM-based agents demonstrate unsatisfactory success rates, underscoring the\nneed for a novel approach. Furthermore, we present OpenAgent, a novel LLM-based\nagent system that can tackle evolving queries in open domains through\nautonomously integrating specialized tools from GitHub. OpenAgent employs 1) a\nhierarchical framework where specialized agents handle specific tasks and can\nassign tasks to inferior agents, 2) a bi-level experience learning mechanism to\nlearn from both humans' and its own experiences to tackle tool flaws.\nExperiments demonstrate its superior effectiveness and efficiency, which\nsignificantly outperforms baselines. Our data and code are open-source at\nhttps://github.com/OpenBMB/OpenAct.\n","authors":["Bohan Lyu","Xin Cong","Heyang Yu","Pan Yang","Yujia Qin","Yining Ye","Yaxi Lu","Zhong Zhang","Yukun Yan","Yankai Lin","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2312.17294v3.pdf","comment":"Accepted by ACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2506.08314v1","updated":"2025-06-10T00:51:03Z","published":"2025-06-10T00:51:03Z","title":"Rule-Assisted Attribute Embedding","summary":"  Recommendation systems often overlook the rich attribute information embedded\nin property graphs, limiting their effectiveness. Existing graph convolutional\nnetwork (GCN) models either ignore attributes or rely on simplistic <user,\nitem, attribute> triples, failing to capture deeper semantic structures. We\npropose RAE (Rule- Assisted Approach for Attribute Embedding), a novel method\nthat improves recommendations by mining semantic rules from property graphs to\nguide attribute embedding. RAE performs rule-based random walks to generate\nenriched attribute representations, which are integrated into GCNs. Experiments\non real-world datasets (BlogCatalog, Flickr) show that RAE outperforms\nstate-of-the-art baselines by 10.6% on average in Recall@20 and NDCG@20. RAE\nalso demonstrates greater robustness to sparse data and missing attributes,\nhighlighting the value of leveraging structured attribute information in\nrecommendation tasks.\n","authors":["Sibo Zhao","Michael Bewong","Selasi Kwashie","Junwei Hu","Zaiwen Feng"],"pdf_url":"https://arxiv.org/pdf/2506.08314v1.pdf","comment":"ECML-PKDD2025"}],"Databases":[{"id":"http://arxiv.org/abs/2411.04525v2","updated":"2025-06-10T20:40:35Z","published":"2024-11-07T08:31:01Z","title":"GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns\n  from Subplan Hints","summary":"  Query optimization has become a research area where classical algorithms are\nbeing challenged by machine learning algorithms. At the same time, recent\ntrends in learned query optimizers have shown that it is prudent to take\nadvantage of decades of database research and augment classical query\noptimizers by shrinking the plan search space through different types of hints\n(e.g. by specifying the join type, scan type or the order of joins) rather than\ncompletely replacing the classical query optimizer with machine learning\nmodels. It is especially relevant for cases when classical optimizers cannot\nfully enumerate all logical and physical plans and, as an alternative, need to\nrely on less robust approaches like genetic algorithms. However, even\nsymbiotically learned query optimizers are hampered by the need for vast\namounts of training data, slow plan generation during inference and unstable\nresults across various workload conditions. In this paper, we present GenJoin -\na novel learned query optimizer that considers the query optimization problem\nas a generative task and is capable of learning from a random set of subplan\nhints to produce query plans that outperform the classical optimizer. GenJoin\nis the first learned query optimizer that significantly and consistently\noutperforms PostgreSQL as well as state-of-the-art methods on two well-known\nreal-world benchmarks across a variety of workloads using rigorous machine\nlearning evaluations.\n","authors":["Pavel Sulimov","Claude Lehmann","Kurt Stockinger"],"pdf_url":"https://arxiv.org/pdf/2411.04525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09226v1","updated":"2025-06-10T20:30:31Z","published":"2025-06-10T20:30:31Z","title":"Terabyte-Scale Analytics in the Blink of an Eye","summary":"  For the past two decades, the DB community has devoted substantial research\nto take advantage of cheap clusters of machines for distributed data analytics\n-- we believe that we are at the beginning of a paradigm shift. The scaling\nlaws and popularity of AI models lead to the deployment of incredibly powerful\nGPU clusters in commercial data centers. Compared to CPU-only solutions, these\nclusters deliver impressive improvements in per-node compute, memory bandwidth,\nand inter-node interconnect performance. In this paper, we study the problem of\nscaling analytical SQL queries on distributed clusters of GPUs, with the stated\ngoal of establishing an upper bound on the likely performance gains. To do so,\nwe build a prototype designed to maximize performance by leveraging ML/HPC best\npractices, such as group communication primitives for cross-device data\nmovements. This allows us to conduct thorough performance experimentation to\npoint our community towards a massive performance opportunity of at least\n60$\\times$. To make these gains more relatable, before you can blink twice, our\nsystem can run all 22 queries of TPC-H at a 1TB scale factor!\n","authors":["Bowen Wu","Wei Cui","Carlo Curino","Matteo Interlandi","Rathijit Sen"],"pdf_url":"https://arxiv.org/pdf/2506.09226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09186v1","updated":"2025-06-10T19:04:19Z","published":"2025-06-10T19:04:19Z","title":"Not all those who drift are lost: Drift correction and calibration\n  scheduling for the IoT","summary":"  Sensors provide a vital source of data that link digital systems with the\nphysical world. However, as sensors age, the relationship between what they\nmeasure and what they output changes. This is known as sensor drift and poses a\nsignificant challenge that, combined with limited opportunity for\nre-calibration, can severely limit data quality over time. Previous approaches\nto drift correction typically require large volumes of ground truth data and do\nnot consider measurement or prediction uncertainty. In this paper, we propose a\nprobabilistic sensor drift correction method that takes a fundamental approach\nto modelling the sensor response using Gaussian Process Regression. Tested\nusing dissolved oxygen sensors, our method delivers mean squared error (MSE)\nreductions of up to 90% and more than 20% on average. We also propose a novel\nuncertainty-driven calibration schedule optimisation approach that builds on\ntop of drift correction and further reduces MSE by up to 15.7%.\n","authors":["Aaron Hurst","Andrey V. Kalinichev","Klaus Koren","Daniel E. Lucani"],"pdf_url":"https://arxiv.org/pdf/2506.09186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.08600v3","updated":"2025-06-10T13:59:46Z","published":"2025-04-11T15:01:30Z","title":"SQL-R1: Training Natural Language to SQL Reasoning Model By\n  Reinforcement Learning","summary":"  Natural Language to SQL (NL2SQL) enables intuitive interactions with\ndatabases by transforming natural language queries into structured SQL\nstatements. Despite recent advancements in enhancing human-computer interaction\nwithin database applications, significant challenges persist, particularly\nregarding the inference performance in complex scenarios involving multi-table\njoins and nested queries. Current methodologies primarily utilize supervised\nfine-tuning (SFT) to train the NL2SQL model, which may limit adaptability and\ninterpretability in new environments (e.g., finance and healthcare). In order\nto enhance the reasoning performance of the NL2SQL model in the above complex\nsituations, we introduce SQL-R1, a novel NL2SQL reasoning model trained by the\nreinforcement learning (RL) algorithms. We design a specialized RL-based reward\nfunction tailored for NL2SQL tasks and discussed the impact of cold start on\nthe effectiveness of intensive training. In addition, we achieve competitive\naccuracy using only a tiny amount of synthetic NL2SQL data for augmented\ntraining and further explore data engineering for RL. In existing experiments,\nSQL-R1 achieves execution accuracy of 88.6% and 66.6% on the benchmark Spider\nand BIRD, respectively, only using the 7B base model.\n","authors":["Peixian Ma","Xialie Zhuang","Chengjin Xu","Xuhui Jiang","Ran Chen","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2504.08600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08759v1","updated":"2025-06-10T12:56:06Z","published":"2025-06-10T12:56:06Z","title":"Qymera: Simulating Quantum Circuits using RDBMS","summary":"  Quantum circuit simulation is crucial for quantum computing such as\nvalidating quantum algorithms. We present Qymera, a system that repurposes\nrelational database management systems (RDBMSs) for simulation by translating\ncircuits into SQL queries, allowing quantum operations to run natively within\nan RDBMS. Qymera supports a wide range of quantum circuits, offering a\ngraphical circuit builder and code-based interfaces to input circuits. With a\nbenchmarking framework, Qymera facilitates comparison of RDBMS-based simulation\nagainst state-of-the-art simulation methods. Our demonstration showcases\nQymera's end-to-end SQL-based execution, seamless integration with classical\nworkflows, and its utility for development, benchmarking, and education in\nquantum computing and data management.\n","authors":["Tim Littau","Rihan Hai"],"pdf_url":"https://arxiv.org/pdf/2506.08759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08743v1","updated":"2025-06-10T12:38:24Z","published":"2025-06-10T12:38:24Z","title":"Bridging RDF Knowledge Graphs with Graph Neural Networks for\n  Semantically-Rich Recommender Systems","summary":"  Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation\n","authors":["Michael Färber","David Lamprecht","Yuni Susanti"],"pdf_url":"https://arxiv.org/pdf/2506.08743v1.pdf","comment":"Accepted at DASFAA 2025"},{"id":"http://arxiv.org/abs/2506.08671v1","updated":"2025-06-10T10:31:09Z","published":"2025-06-10T10:31:09Z","title":"Evaluating Learned Indexes in LSM-tree Systems: Benchmarks,Insights and\n  Design Choices","summary":"  LSM-tree-based data stores are widely used in industry due to their\nexceptional performance. However, as data volumes grow, efficiently querying\nlarge-scale databases becomes increasingly challenging. To address this, recent\nstudies attempted to integrate learned indexes into LSM-trees to enhance lookup\nperformance, which has demonstrated promising improvements. Despite this, only\na limited range of learned index types has been considered, and the strengths\nand weaknesses of different learned indexes remain unclear, making them\ndifficult for practical use. To fill this gap, we provide a comprehensive and\nsystematic benchmark to pursue an in-depth understanding of learned indexes in\nLSM-tree systems. In this work, we summarize the workflow of 8 existing learned\nindexes and analyze the associated theoretical cost. We also identify several\nkey factors that significantly influence the performance of learned indexes and\nconclude them with a novel configuration space, including various index types,\nboundary positions, and granularity. Moreover, we implement different learned\nindex designs on a unified platform to evaluate across various configurations.\nSurprisingly, our experiments reveal several unexpected insights, such as the\nmarginal lookup enhancement when allocating a large memory budget to learned\nindexes and modest retraining overhead of learned indexes. Besides, we also\noffer practical guidelines to help developers intelligently select and tune\nlearned indexes for custom use cases.\n","authors":["Junfeng Liu","Jiarui Ye","Mengshi Chen","Meng Li","Siqiang Luo"],"pdf_url":"https://arxiv.org/pdf/2506.08671v1.pdf","comment":"14 pages,12 figures"},{"id":"http://arxiv.org/abs/2502.12918v3","updated":"2025-06-10T07:40:49Z","published":"2025-02-18T14:59:37Z","title":"Query Rewriting via LLMs","summary":"  When complex SQL queries suffer slow executions despite query optimization,\nDBAs typically invoke automated query rewriting tools to recommend ``lean''\nequivalents that are conducive to faster execution. The rewritings are usually\nachieved via transformation rules, but these rules are limited in scope and\ndifficult to update in a production system. Recently, LLM-based techniques have\nalso been suggested, but they are prone to semantic and syntactic errors.\n  We investigate here how the remarkable cognitive capabilities of LLMs can be\nleveraged for performant query rewriting while incorporating safeguards and\noptimizations to ensure correctness and efficiency. Our study shows that these\ngoals can be progressively achieved through incorporation of (a) an ensemble\nsuite of basic prompts, (b) database-sensitive prompts via redundancy removal\nand selectivity-based rewriting rules, and (c) LLM token probability-guided\nrewrite paths. Further, a suite of logic-based and statistical tools can be\nused to check for semantic violations in the rewrites prior to DBA\nconsideration.\n  We have implemented the above LLM-infused techniques in the LITHE system, and\nevaluated complex analytic queries from standard benchmarks on contemporary\ndatabase platforms. The results show significant performance improvements for\nslow queries, with regard to both abstract costing and actual execution, over\nboth SOTA techniques and the native query optimizer. For instance, with TPC-DS\non PostgreSQL, the geometric mean of the runtime speedups for slow queries was\nas high as 13.2 over the native optimizer, whereas SOTA delivered 4.9 in\ncomparison.\n  Overall, LITHE is a promising step toward viable LLM-based advisory tools for\nameliorating enterprise query performance.\n","authors":["Sriram Dharwada","Himanshu Devrani","Jayant Haritsa","Harish Doraiswamy"],"pdf_url":"https://arxiv.org/pdf/2502.12918v3.pdf","comment":null}]},"2025-06-09T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.01910v2","updated":"2025-06-09T23:45:38Z","published":"2025-06-02T17:31:42Z","title":"GLoSS: Generative Language Models with Semantic Search for Sequential\n  Recommendation","summary":"  We propose Generative Low-rank language model with Semantic Search (GLoSS), a\ngenerative recommendation framework that combines large language models with\ndense retrieval for sequential recommendation. Unlike prior methods such as\nGPT4Rec, which rely on lexical matching via BM25, GLoSS uses semantic search to\nretrieve relevant items beyond lexical matching. For query generation, we\nemploy 4-bit quantized LlaMA-3 models fine-tuned with low-rank adaptation\n(LoRA), enabling efficient training and inference on modest hardware. We\nevaluate GLoSS on three real-world Amazon review datasets: Beauty, Toys, and\nSports, and find that it achieves state-of-the-art performance. Compared to\ntraditional ID-based baselines, GLoSS improves Recall@5 by 33.3%, 52.8%, and\n15.2%, and NDCG@5 by 30.0%, 42.6%, and 16.1%, respectively. It also outperforms\nLLM-based recommenders such as P5, GPT4Rec, LlamaRec and E4SRec with Recall@5\ngains of 4.3%, 22.8%, and 29.5%. Additionally, user segment evaluations show\nthat GLoSS performs particularly well for cold-start users in the Amazon Toys\nand Sports datasets, and benefits from longer user histories in Amazon Beauty\ndataset, demonstrating robustness across different levels of interaction\nlengths.\n","authors":["Krishna Acharya","Aleksandr V. Petrov","Juba Ziani"],"pdf_url":"https://arxiv.org/pdf/2506.01910v2.pdf","comment":"Our code and model checkpoints are publicly available\n  at:https://github.com/krishnacharya/GLoSS"},{"id":"http://arxiv.org/abs/2506.08283v1","updated":"2025-06-09T23:13:22Z","published":"2025-06-09T23:13:22Z","title":"Serendipitous Recommendation with Multimodal LLM","summary":"  Conventional recommendation systems succeed in identifying relevant content\nbut often fail to provide users with surprising or novel items. Multimodal\nLarge Language Models (MLLMs) possess the world knowledge and multimodal\nunderstanding needed for serendipity, but their integration into\nbillion-item-scale platforms presents significant challenges. In this paper, we\npropose a novel hierarchical framework where fine-tuned MLLMs provide\nhigh-level guidance to conventional recommendation models, steering them\ntowards more serendipitous suggestions. This approach leverages MLLM strengths\nin understanding multimodal content and user interests while retaining the\nefficiency of traditional models for item-level recommendation. This mitigates\nthe complexity of applying MLLMs directly to vast action spaces. We also\ndemonstrate a chain-of-thought strategy enabling MLLMs to discover novel user\ninterests by first understanding video content and then identifying relevant\nyet unexplored interest clusters. Through live experiments within a commercial\nshort-form video platform serving billions of users, we show that our\nMLLM-powered approach significantly improves both recommendation serendipity\nand user satisfaction.\n","authors":["Haoting Wang","Jianling Wang","Hao Li","Fangjun Yi","Mengyu Fu","Youwei Zhang","Yifan Liu","Liang Liu","Minmin Chen","Ed H. Chi","Lichan Hong","Haokai Lu"],"pdf_url":"https://arxiv.org/pdf/2506.08283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14898v2","updated":"2025-06-09T22:13:58Z","published":"2025-02-18T01:57:02Z","title":"Retrieval-augmented systems can be dangerous medical communicators","summary":"  Patients have long sought health information online, and increasingly, they\nare turning to generative AI to answer their health-related queries. Given the\nhigh stakes of the medical domain, techniques like retrieval-augmented\ngeneration and citation grounding have been widely promoted as methods to\nreduce hallucinations and improve the accuracy of AI-generated responses and\nhave been widely adopted into search engines. This paper argues that even when\nthese methods produce literally accurate content drawn from source documents\nsans hallucinations, they can still be highly misleading. Patients may derive\nsignificantly different interpretations from AI-generated outputs than they\nwould from reading the original source material, let alone consulting a\nknowledgeable clinician. Through a large-scale query analysis on topics\nincluding disputed diagnoses and procedure safety, we support our argument with\nquantitative and qualitative evidence of the suboptimal answers resulting from\ncurrent systems. In particular, we highlight how these models tend to\ndecontextualize facts, omit critical relevant sources, and reinforce patient\nmisconceptions or biases. We propose a series of recommendations -- such as the\nincorporation of communication pragmatics and enhanced comprehension of source\ndocuments -- that could help mitigate these issues and extend beyond the\nmedical domain.\n","authors":["Lionel Wong","Ayman Ali","Raymond Xiong","Shannon Zeijang Shen","Yoon Kim","Monica Agrawal"],"pdf_url":"https://arxiv.org/pdf/2502.14898v2.pdf","comment":"Position paper in Proceedings of the 42 nd International Conference\n  on Machine Learning"},{"id":"http://arxiv.org/abs/2506.08196v1","updated":"2025-06-09T20:13:32Z","published":"2025-06-09T20:13:32Z","title":"No Stupid Questions: An Analysis of Question Query Generation for\n  Citation Recommendation","summary":"  Existing techniques for citation recommendation are constrained by their\nadherence to article contents and metadata. We leverage GPT-4o-mini's latent\nexpertise as an inquisitive assistant by instructing it to ask questions which,\nwhen answered, could expose new insights about an excerpt from a scientific\narticle. We evaluate the utility of these questions as retrieval queries,\nmeasuring their effectiveness in retrieving and ranking masked target\ndocuments. In some cases, generated questions ended up being better queries\nthan extractive keyword queries generated by the same model. We additionally\npropose MMR-RBO, a variation of Maximal Marginal Relevance (MMR) using\nRank-Biased Overlap (RBO) to identify which questions will perform\ncompetitively with the keyword baseline. As all question queries yield unique\nresult sets, we contend that there are no stupid questions.\n","authors":["Brian D. Zimmerman","Julien Aubert-Béduchaud","Florian Boudin","Akiko Aizawa","Olga Vechtomova"],"pdf_url":"https://arxiv.org/pdf/2506.08196v1.pdf","comment":"6 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2502.03699v2","updated":"2025-06-09T19:53:37Z","published":"2025-02-06T01:22:06Z","title":"LLM Alignment as Retriever Optimization: An Information Retrieval\n  Perspective","summary":"  Large Language Models (LLMs) have revolutionized artificial intelligence with\ncapabilities in reasoning, coding, and communication, driving innovation across\nindustries. Their true potential depends on effective alignment to ensure\ncorrect, trustworthy and ethical behavior, addressing challenges like\nmisinformation, hallucinations, bias and misuse. While existing Reinforcement\nLearning (RL)-based alignment methods are notoriously complex, direct\noptimization approaches offer a simpler alternative. In this work, we introduce\na novel direct optimization approach for LLM alignment by drawing on\nestablished Information Retrieval (IR) principles. We present a systematic\nframework that bridges LLM alignment and IR methodologies, mapping LLM\ngeneration and reward models to IR's retriever-reranker paradigm. Building on\nthis foundation, we propose LLM Alignment as Retriever Preference Optimization\n(LarPO), a new alignment method that enhances overall alignment quality.\nExtensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %\naveraged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work\nopens new avenues for advancing LLM alignment by integrating IR foundations,\noffering a promising direction for future research.\n","authors":["Bowen Jin","Jinsung Yoon","Zhen Qin","Ziqi Wang","Wei Xiong","Yu Meng","Jiawei Han","Sercan O. Arik"],"pdf_url":"https://arxiv.org/pdf/2502.03699v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2506.08074v1","updated":"2025-06-09T17:58:35Z","published":"2025-06-09T17:58:35Z","title":"Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval","summary":"  Retrieval-Augmented Generation (RAG) grounds large language models in\nexternal evidence, yet it still falters when answers must be pieced together\nacross semantically distant documents. We close this gap with the Hierarchical\nLexical Graph (HLG), a three-tier index that (i) traces every atomic\nproposition to its source, (ii) clusters propositions into latent topics, and\n(iii) links entities and relations to expose cross-document paths. On top of\nHLG we build two complementary, plug-and-play retrievers: StatementGraphRAG,\nwhich performs fine-grained entity-aware beam search over propositions for\nhigh-precision factoid questions, and TopicGraphRAG, which selects coarse\ntopics before expanding along entity links to supply broad yet relevant context\nfor exploratory queries. Additionally, existing benchmarks lack the complexity\nrequired to rigorously evaluate multi-hop summarization systems, often focusing\non single-document queries or limited datasets. To address this, we introduce a\nsynthetic dataset generation pipeline that curates realistic, multi-document\nquestion-answer pairs, enabling robust evaluation of multi-hop retrieval\nsystems. Extensive experiments across five datasets demonstrate that our\nmethods outperform naive chunk-based RAG achieving an average relative\nimprovement of 23.1% in retrieval recall and correctness. Open-source Python\nlibrary is available at https://github.com/awslabs/graphrag-toolkit.\n","authors":["Abdellah Ghassel","Ian Robinson","Gabriel Tanase","Hal Cooper","Bryan Thompson","Zhen Han","Vassilis N. Ioannidis","Soji Adeshina","Huzefa Rangwala"],"pdf_url":"https://arxiv.org/pdf/2506.08074v1.pdf","comment":"KDD '25"},{"id":"http://arxiv.org/abs/2504.11284v2","updated":"2025-06-09T17:51:57Z","published":"2025-04-15T15:25:27Z","title":"Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation","summary":"  Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal Area Under the ROC Curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. We show that\nwhile both approaches can yield Pareto-optimal solutions, loss aggregation can\nexhibit label dictatorship: one can inadvertently (and undesirably) favor one\nlabel over others. This suggests that label aggregation can be preferable to\nloss aggregation, which we empirically verify.\n","authors":["Michal Lukasik","Lin Chen","Harikrishna Narasimhan","Aditya Krishna Menon","Wittawat Jitkrittum","Felix X. Yu","Sashank J. Reddi","Gang Fu","Mohammadhossein Bateni","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2504.11284v2.pdf","comment":"Accepted by ICML 2025"},{"id":"http://arxiv.org/abs/2504.21838v2","updated":"2025-06-09T17:49:36Z","published":"2025-04-30T17:48:43Z","title":"Learning Universal User Representations Leveraging Cross-domain User\n  Intent at Snapchat","summary":"  The development of powerful user representations is a key factor in the\nsuccess of recommender systems (RecSys). Online platforms employ a range of\nRecSys techniques to personalize user experience across diverse in-app\nsurfaces. User representations are often learned individually through user's\nhistorical interactions within each surface and user representations across\ndifferent surfaces can be shared post-hoc as auxiliary features or additional\nretrieval sources. While effective, such schemes cannot directly encode\ncollaborative filtering signals across different surfaces, hindering its\ncapacity to discover complex relationships between user behaviors and\npreferences across the whole platform. To bridge this gap at Snapchat, we seek\nto conduct universal user modeling (UUM) across different in-app surfaces,\nlearning general-purpose user representations which encode behaviors across\nsurfaces. Instead of replacing domain-specific representations, UUM\nrepresentations capture cross-domain trends, enriching existing representations\nwith complementary information. This work discusses our efforts in developing\ninitial UUM versions, practical challenges, technical choices and modeling and\nresearch directions with promising offline performance. Following successful\nA/B testing, UUM representations have been launched in production, powering\nmultiple use cases and demonstrating their value. UUM embedding has been\nincorporated into (i) Long-form Video embedding-based retrieval, leading to\n2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking,\nwith 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking,\nleading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking,\nwith 0.87% increase in Notification Open Rate.\n","authors":["Clark Mingxuan Ju","Leonardo Neves","Bhuvesh Kumar","Liam Collins","Tong Zhao","Yuwei Qiu","Qing Dou","Yang Zhou","Sohail Nizam","Rengim Ozturk","Yvette Liu","Sen Yang","Manish Malik","Neil Shah"],"pdf_url":"https://arxiv.org/pdf/2504.21838v2.pdf","comment":"Accepted to the industrial track of SIGIR'25"},{"id":"http://arxiv.org/abs/2506.13778v1","updated":"2025-06-09T16:15:11Z","published":"2025-06-09T16:15:11Z","title":"Knowledge Compression via Question Generation: Enhancing Multihop\n  Document Retrieval without Fine-tuning","summary":"  This study presents a question-based knowledge encoding approach that\nimproves retrieval-augmented generation (RAG) systems without requiring\nfine-tuning or traditional chunking. We encode textual content using generated\nquestions that span the lexical and semantic space, creating targeted retrieval\ncues combined with a custom syntactic reranking method.\n  In single-hop retrieval over 109 scientific papers, our approach achieves a\nRecall@3 of 0.84, outperforming traditional chunking methods by 60 percent. We\nalso introduce \"paper-cards\", concise paper summaries under 300 characters,\nwhich enhance BM25 retrieval, increasing MRR@3 from 0.56 to 0.85 on simplified\ntechnical queries.\n  For multihop tasks, our reranking method reaches an F1 score of 0.52 with\nLLaMA2-Chat-7B on the LongBench 2WikiMultihopQA dataset, surpassing chunking\nand fine-tuned baselines which score 0.328 and 0.412 respectively.\n  This method eliminates fine-tuning requirements, reduces retrieval latency,\nenables intuitive question-driven knowledge access, and decreases vector\nstorage demands by 80%, positioning it as a scalable and efficient RAG\nalternative.\n","authors":["Anvi Alex Eponon","Moein Shahiki-Tash","Ildar Batyrshin","Christian E. Maldonado-Sifuentes","Grigori Sidorov","Alexander Gelbukh"],"pdf_url":"https://arxiv.org/pdf/2506.13778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12452v2","updated":"2025-06-09T15:40:03Z","published":"2025-05-18T15:04:02Z","title":"Introspective Growth: Automatically Advancing LLM Expertise in\n  Technology Judgment","summary":"  Large language models (LLMs) increasingly demonstrate signs of conceptual\nunderstanding, yet much of their internal knowledge remains latent, loosely\nstructured, and difficult to access or evaluate. We propose self-questioning as\na lightweight and scalable strategy to improve LLMs' understanding,\nparticularly in domains where success depends on fine-grained semantic\ndistinctions. To evaluate this approach, we introduce a challenging new\nbenchmark of 1.3 million post-2015 computer science patent pairs, characterized\nby dense technical jargon and strategically complex writing. The benchmark\ncenters on a pairwise differentiation task: can a model distinguish between\nclosely related but substantively different inventions? We show that compared\nto placebo scientific information, prompting LLMs to generate and answer their\nown questions - targeting the background knowledge required for the task -\nsignificantly improves performance. These self-generated questions and answers\nactivate otherwise underutilized internal knowledge. Allowing LLMs to retrieve\nanswers from external scientific texts further enhances performance, suggesting\nthat model knowledge is compressed and lacks the full richness of the training\ndata. We also find that chain-of-thought prompting and self-questioning\nconverge, though self-questioning remains more effective for improving\nunderstanding of technical concepts. Notably, we uncover an asymmetry in\nprompting: smaller models often generate more fundamental, more open-ended,\nbetter-aligned questions for mid-sized models than large models do, revealing a\nnew strategy for cross-model collaboration. Altogether, our findings establish\nself-questioning as both a practical mechanism for automatically improving LLM\ncomprehension, especially in domains with sparse and underrepresented\nknowledge, and a diagnostic probe of how internal and external knowledge are\norganized.\n","authors":["Siyang Wu","Honglin Bao","Nadav Kunievsky","James A. Evans"],"pdf_url":"https://arxiv.org/pdf/2505.12452v2.pdf","comment":"We open-source our patent dataset at\n  https://huggingface.co/datasets/UchiKlab/patent_understanding"},{"id":"http://arxiv.org/abs/2506.07853v1","updated":"2025-06-09T15:18:36Z","published":"2025-06-09T15:18:36Z","title":"A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of\n  Legal Norms","summary":"  Effectively representing legal norms for automated processing is a critical\nchallenge, particularly in tracking the diachronic evolution of their\nhierarchical components (e.g., articles, paragraphs). While foundational\nframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legal\ndocuments at a macro level, they lack native mechanisms for granular,\ncomponent-level versioning. This limitation hinders the deterministic\npoint-in-time reconstruction of legal texts, a fundamental capability for\nreliable Legal Tech and AI applications. This paper proposes a structured,\ntemporal model that extends the FRBRoo framework to address this gap. It\nintroduces specialized subclasses of Expressio - Temporal Version (TV) and\nLanguage Version (LV - to represent the state of a legal norm and its\nlinguistic variations at specific points in time. The model applies this same\nparadigm hierarchically, introducing Component Work (CW), Component Temporal\nVersion (CTV), and Component Language Version (CLV) to track the lifecycle of\nindividual articles, paragraphs, and clauses. Using the Brazilian Federal\nConstitution as a case study, the paper demonstrates how each amendment creates\nnew Component Temporal Versions for affected provisions, while unaffected\ncomponents retain their existing versions. This fine-grained, time-aware\narchitecture enables the precise, deterministic retrieval and reconstruction of\nany part of a legal text as it existed on a specific date. The model provides a\nrobust foundation for developing advanced legal information systems, knowledge\ngraphs, and AI tools capable of accurate historical analysis and impact\nassessment, overcoming the limitations of current generative models.\n","authors":["Hudson de Martim"],"pdf_url":"https://arxiv.org/pdf/2506.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15239v4","updated":"2025-06-09T14:08:47Z","published":"2024-07-21T18:08:44Z","title":"Benchmark Granularity and Model Robustness for Image-Text Retrieval","summary":"  Image-Text Retrieval (ITR) systems are central to multimodal information\naccess, with Vision-Language Models (VLMs) showing strong performance on\nstandard benchmarks. However, these benchmarks predominantly rely on\ncoarse-grained annotations, limiting their ability to reveal how models perform\nunder real-world conditions, where query granularity varies. Motivated by this\ngap, we examine how dataset granularity and query perturbations affect\nretrieval performance and robustness across four architecturally diverse VLMs\n(ALIGN, AltCLIP, CLIP, and GroupViT). Using both standard benchmarks (MS-COCO,\nFlickr30k) and their fine-grained variants, we show that richer captions\nconsistently enhance retrieval, especially in text-to-image tasks, where we\nobserve an average improvement of 16.23%, compared to 6.44% in image-to-text.\nTo assess robustness, we introduce a taxonomy of perturbations and conduct\nextensive experiments, revealing that while perturbations typically degrade\nperformance, they can also unexpectedly improve retrieval, exposing nuanced\nmodel behaviors. Notably, word order emerges as a critical factor --\ncontradicting prior assumptions of model insensitivity to it. Our results\nhighlight variation in model robustness and a dataset-dependent relationship\nbetween caption granularity and perturbation sensitivity and emphasize the\nnecessity of evaluating models on datasets of varying granularity.\n","authors":["Mariya Hendriksen","Shuo Zhang","Ridho Reinanda","Mohamed Yahya","Edgar Meij","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2407.15239v4.pdf","comment":"accepted at SIGIR 2025"},{"id":"http://arxiv.org/abs/2504.20118v3","updated":"2025-06-09T13:34:27Z","published":"2025-04-28T08:04:44Z","title":"OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese\n  Medicine Knowledge Retrieval and Diagnosis","summary":"  Traditional Chinese Medicine (TCM) represents a rich repository of ancient\nmedical knowledge that continues to play an important role in modern\nhealthcare. Due to the complexity and breadth of the TCM literature, the\nintegration of AI technologies is critical for its modernization and broader\naccessibility. However, this integration poses considerable challenges,\nincluding the interpretation of obscure classical Chinese texts and the\nmodeling of intricate semantic relationships among TCM concepts. In this paper,\nwe develop OpenTCM, an LLM-based system that combines a domain-specific TCM\nknowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG).\nFirst, we extract more than 3.73 million classical Chinese characters from 68\ngynecological books in the Chinese Medical Classics Database, with the help of\nTCM and gynecology experts. Second, we construct a comprehensive\nmulti-relational knowledge graph comprising more than 48,000 entities and\n152,000 interrelationships, using customized prompts and Chinese-oriented LLMs\nsuch as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last,\nwe integrate OpenTCM with this knowledge graph, enabling high-fidelity\ningredient knowledge retrieval and diagnostic question-answering without model\nfine-tuning. Experimental evaluations demonstrate that OpenTCM achieves mean\nexpert scores (MES) of 4.378 in ingredient information retrieval and 4.045 in\ndiagnostic question-answering tasks, outperforming state-of-the-art solutions\nin real-world TCM use cases.\n","authors":["Jinglin He","Yunqi Guo","Lai Kwan Lam","Waikei Leung","Lixing He","Yuanan Jiang","Chi Chiu Wang","Guoliang Xing","Hongkai Chen"],"pdf_url":"https://arxiv.org/pdf/2504.20118v3.pdf","comment":"8 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.20580v2","updated":"2025-06-09T12:41:13Z","published":"2024-10-27T20:21:14Z","title":"Coherence-guided Preference Disentanglement for Cross-domain\n  Recommendations","summary":"  Discovering user preferences across different domains is pivotal in\ncross-domain recommendation systems, particularly when platforms lack\ncomprehensive user-item interactive data. The limited presence of shared users\noften hampers the effective modeling of common preferences. While leveraging\nshared items' attributes, such as category and popularity, can enhance\ncross-domain recommendation performance, the scarcity of shared items between\ndomains has limited research in this area. To address this, we propose a\nCoherence-guided Preference Disentanglement (CoPD) method aimed at improving\ncross-domain recommendation by i) explicitly extracting shared item attributes\nto guide the learning of shared user preferences and ii) disentangling these\npreferences to identify specific user interests transferred between domains.\nCoPD introduces coherence constraints on item embeddings of shared and specific\ndomains, aiding in extracting shared attributes. Moreover, it utilizes these\nattributes to guide the disentanglement of user preferences into separate\nembeddings for interest and conformity through a popularity-weighted loss.\nExperiments conducted on real-world datasets demonstrate the superior\nperformance of our proposed CoPD over existing competitive baselines,\nhighlighting its effectiveness in enhancing cross-domain recommendation\nperformance.\n","authors":["Zongyi Xiang","Yan Zhang","Lixin Duan","Hongzhi Yin","Ivor W. Tsang"],"pdf_url":"https://arxiv.org/pdf/2410.20580v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2506.11117v1","updated":"2025-06-09T11:47:13Z","published":"2025-06-09T11:47:13Z","title":"ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific\n  Research","summary":"  Scientific researchers need intensive information about datasets to\neffectively evaluate and develop theories and methodologies. The information\nneeds regarding datasets are implicitly embedded in particular research tasks,\nrather than explicitly expressed in search queries. However, existing\nscientific retrieval and question-answering (QA) datasets typically address\nstraightforward questions, which do not align with the distribution of\nreal-world research inquiries. To bridge this gap, we developed ScIRGen, a\ndataset generation framework for scientific QA \\& retrieval that more\naccurately reflects the information needs of professional science researchers,\nand uses it to create a large-scale scientific retrieval-augmented generation\n(RAG) dataset with realistic queries, datasets and papers. Technically, we\ndesigned a dataset-oriented information extraction method that leverages\nacademic papers to augment the dataset representation. We then proposed a\nquestion generation framework by employing cognitive taxonomy to ensure the\nquality of synthesized questions. We also design a method to automatically\nfilter synthetic answers based on the perplexity shift of LLMs, which is highly\naligned with human judgment of answers' validity. Collectively, these\nmethodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We\nbenchmarked representative methods on the ScIRGen-Geo dataset for their\nquestion-answering and retrieval capabilities, finding out that current methods\nstill suffer from reasoning from complex questions. This work advances the\ndevelopment of more sophisticated tools to support the intricate information\nneeds of the scientific community.\n","authors":["Junyong Lin","Lu Dai","Ruiqian Han","Yijie Sui","Ruilin Wang","Xingliang Sun","Qinglin Wu","Min Feng","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2506.11117v1.pdf","comment":"KDD 2025 Accepted"},{"id":"http://arxiv.org/abs/2506.03100v3","updated":"2025-06-09T10:35:22Z","published":"2025-06-03T17:31:53Z","title":"Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified\n  Theory and Risk Bounds","summary":"  Retrieval-augmented generation (RAG) has seen many empirical successes in\nrecent years by aiding the LLM with external knowledge. However, its\ntheoretical aspect has remained mostly unexplored. In this paper, we propose\nthe first finite-sample generalization bound for RAG in in-context linear\nregression and derive an exact bias-variance tradeoff. Our framework views the\nretrieved texts as query-dependent noisy in-context examples and recovers the\nclassical in-context learning (ICL) and standard RAG as the limit cases. Our\nanalysis suggests that an intrinsic ceiling on generalization error exists on\nRAG as opposed to the ICL. Furthermore, our framework is able to model\nretrieval both from the training data and from external corpora by introducing\nuniform and non-uniform RAG noise. In line with our theory, we show the sample\nefficiency of ICL and RAG empirically with experiments on common QA benchmarks,\nsuch as Natural Questions and TriviaQA.\n","authors":["Yang Guo","Yutian Tao","Yifei Ming","Robert D. Nowak","Yingyu Liang"],"pdf_url":"https://arxiv.org/pdf/2506.03100v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2506.07606v1","updated":"2025-06-09T10:06:25Z","published":"2025-06-09T10:06:25Z","title":"PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels","summary":"  Stance detection identifies the viewpoint expressed in text toward a specific\ntarget, such as a political figure. While previous datasets have focused\nprimarily on tweet-level stances from established platforms, user-level stance\nresources, especially on emerging platforms like Bluesky remain scarce.\nUser-level stance detection provides a more holistic view by considering a\nuser's complete posting history rather than isolated posts. We present the\nfirst stance detection dataset for the 2024 U.S. presidential election,\ncollected from Bluesky and centered on Kamala Harris and Donald Trump. The\ndataset comprises 16,044 user-target stance pairs enriched with engagement\nmetadata, interaction graphs, and user posting histories. PolitiSky24 was\ncreated using a carefully evaluated pipeline combining advanced information\nretrieval and large language models, which generates stance labels with\nsupporting rationales and text spans for transparency. The labeling approach\nachieves 81\\% accuracy with scalable LLMs. This resource addresses gaps in\npolitical stance analysis through its timeliness, open-data nature, and\nuser-level perspective. The dataset is available at\nhttps://doi.org/10.5281/zenodo.15616911\n","authors":["Peyman Rostami","Vahid Rahimzadeh","Ali Adibi","Azadeh Shakery"],"pdf_url":"https://arxiv.org/pdf/2506.07606v1.pdf","comment":"The dataset is available at https://doi.org/10.5281/zenodo.15616911"},{"id":"http://arxiv.org/abs/2506.05069v2","updated":"2025-06-09T09:08:12Z","published":"2025-06-05T14:16:44Z","title":"Reason-to-Recommend: Using Interaction-of-Thought Reasoning to Enhance\n  LLM Recommendation","summary":"  Driven by advances in Large Language Models (LLMs), integrating them into\nrecommendation tasks has gained interest due to their strong semantic\nunderstanding and prompt flexibility. Prior work encoded user-item interactions\nor metadata into prompts for recommendations. In parallel, LLM reasoning,\nboosted by test-time scaling and reinforcement learning, has excelled in fields\nlike mathematics and code, where reasoning traces and correctness signals are\nclear, enabling high performance and interpretability. However, directly\napplying these reasoning methods to recommendation is ineffective because user\nfeedback is implicit and lacks reasoning supervision. To address this, we\npropose $\\textbf{R2Rec}$, a reasoning-enhanced recommendation framework that\nsamples interaction chains from the user-item graph and converts them into\nstructured interaction-of-thoughts via a progressive masked prompting strategy,\nwith each thought representing stepwise reasoning grounded in interaction\ncontext. This allows LLMs to simulate step-by-step decision-making based on\nimplicit patterns. We design a two-stage training pipeline: supervised\nfine-tuning teaches basic reasoning from high-quality traces, and reinforcement\nlearning refines reasoning via reward signals, alleviating sparse explicit\nsupervision. Experiments on three real-world datasets show R2Rec outperforms\nclassical and LLM-based baselines with an average $\\textbf{10.48%}$ improvement\nin HitRatio@1 and $\\textbf{131.81%}$ gain over the original LLM. Furthermore,\nthe explicit reasoning chains enhance interpretability by revealing the\ndecision process. Our code is available at:\nhttps://anonymous.4open.science/r/R2Rec-7C5D.\n","authors":["Keyu Zhao","Fengli Xu","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2506.05069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07517v1","updated":"2025-06-09T07:50:21Z","published":"2025-06-09T07:50:21Z","title":"Addressing Correlated Latent Exogenous Variables in Debiased Recommender\n  Systems","summary":"  Recommendation systems (RS) aim to provide personalized content, but they\nface a challenge in unbiased learning due to selection bias, where users only\ninteract with items they prefer. This bias leads to a distorted representation\nof user preferences, which hinders the accuracy and fairness of\nrecommendations. To address the issue, various methods such as error imputation\nbased, inverse propensity scoring, and doubly robust techniques have been\ndeveloped. Despite the progress, from the structural causal model perspective,\nprevious debiasing methods in RS assume the independence of the exogenous\nvariables. In this paper, we release this assumption and propose a learning\nalgorithm based on likelihood maximization to learn a prediction model. We\nfirst discuss the correlation and difference between unmeasured confounding and\nour scenario, then we propose a unified method that effectively handles latent\nexogenous variables. Specifically, our method models the data generation\nprocess with latent exogenous variables under mild normality assumptions. We\nthen develop a Monte Carlo algorithm to numerically estimate the likelihood\nfunction. Extensive experiments on synthetic datasets and three real-world\ndatasets demonstrate the effectiveness of our proposed method. The code is at\nhttps://github.com/WallaceSUI/kdd25-background-variable.\n","authors":["Shuqiang Zhang","Yuchao Zhang","Jinkun Chen","Haochen Sui"],"pdf_url":"https://arxiv.org/pdf/2506.07517v1.pdf","comment":"In Proceedings of the 31st ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining V.2 (KDD '25), August 3--7, 2025, Toronto, ON,\n  Canada"},{"id":"http://arxiv.org/abs/2501.08248v3","updated":"2025-06-09T07:37:32Z","published":"2025-01-14T16:38:33Z","title":"Eliciting In-context Retrieval and Reasoning for Long-context Large\n  Language Models","summary":"  Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.\n","authors":["Yifu Qiu","Varun Embar","Yizhe Zhang","Navdeep Jaitly","Shay B. Cohen","Benjamin Han"],"pdf_url":"https://arxiv.org/pdf/2501.08248v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07466v1","updated":"2025-06-09T06:20:23Z","published":"2025-06-09T06:20:23Z","title":"Leveraging Historical and Current Interests for Continual Sequential\n  Recommendation","summary":"  Sequential recommendation models based on the Transformer architecture show\nsuperior performance in harnessing long-range dependencies within user behavior\nvia self-attention. However, naively updating them on continuously arriving\nnon-stationary data streams incurs prohibitive computation costs or leads to\ncatastrophic forgetting. To address this, we propose Continual Sequential\nTransformer for Recommendation (CSTRec) that effectively leverages\nwell-preserved historical user interests while capturing current interests. At\nits core is Continual Sequential Attention (CSA), a linear attention mechanism\nthat retains past knowledge without direct access to old data. CSA integrates\ntwo key components: (1) Cauchy-Schwarz Normalization that stabilizes training\nunder uneven interaction frequencies, and (2) Collaborative Interest Enrichment\nthat mitigates forgetting through shared, learnable interest pools. We further\nintroduce a technique that facilitates learning for cold-start users by\ntransferring historical knowledge from behaviorally similar existing users.\nExtensive experiments on three real-world datasets indicate that CSTRec\noutperforms state-of-the-art baselines in both knowledge retention and\nacquisition.\n","authors":["Gyuseok Lee","Hyunsik Yoo","Junyoung Hwang","SeongKu Kang","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2506.07466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07449v1","updated":"2025-06-09T05:52:03Z","published":"2025-06-09T05:52:03Z","title":"LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework\n  for LLM-Based Ranking","summary":"  Recent advances in Large Language Models (LLMs) have driven their adoption in\nrecommender systems through Retrieval-Augmented Generation (RAG) frameworks.\nHowever, existing RAG approaches predominantly rely on flat, similarity-based\nretrieval that fails to leverage the rich relational structure inherent in\nuser-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass,\nend-to-end trainable framework that integrates personalized knowledge graph\ncontext into LLM-based recommendation ranking. Our approach extends the\nLlamaRec architecture by incorporating a lightweight user preference module\nthat dynamically identifies salient relation paths within a heterogeneous\nknowledge graph constructed from user behavior and item metadata. These\npersonalized subgraphs are seamlessly integrated into prompts for a fine-tuned\nLlama-2 model, enabling efficient and interpretable recommendations through a\nunified inference step. Comprehensive experiments on ML-100K and Amazon Beauty\ndatasets demonstrate consistent and significant improvements over LlamaRec\nacross key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates\nthe critical value of structured reasoning in LLM-based recommendations and\nestablishes a foundation for scalable, knowledge-aware personalization in\nnext-generation recommender systems. Code is available\nat~\\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.\n","authors":["Vahid Azizi","Fatemeh Koochaki"],"pdf_url":"https://arxiv.org/pdf/2506.07449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12519v2","updated":"2025-06-09T05:51:50Z","published":"2024-09-19T07:20:10Z","title":"Multi-View Adaptive Contrastive Learning for Information Retrieval Based\n  Fault Localization","summary":"  Most studies focused on information retrieval-based techniques for fault\nlocalization, which built representations for bug reports and source code files\nand matched their semantic vectors through similarity measurement. However,\nsuch approaches often ignore some useful information that might help improve\nlocalization performance, such as 1) the interaction relationship between bug\nreports and source code files; 2) the similarity relationship between bug\nreports; and 3) the co-citation relationship between source code files. In this\npaper, we propose a novel approach named Multi-View Adaptive Contrastive\nLearning for Information Retrieval Fault Localization (MACL-IRFL) to learn the\nabove-mentioned relationships for software fault localization. Specifically, we\nfirst generate data augmentations from report-code interaction view,\nreport-report similarity view and code-code co-citation view separately, and\nadopt graph neural network to aggregate the information of bug reports or\nsource code files from the three views in the embedding process. Moreover, we\nperform contrastive learning across these views. Our design of contrastive\nlearning task will force the bug report representations to encode information\nshared by report-report and report-code views,and the source code file\nrepresentations shared by code-code and report-code views, thereby alleviating\nthe noise from auxiliary information. Finally, to evaluate the performance of\nour approach, we conduct extensive experiments on five open-source Java\nprojects. The results show that our model can improve over the best baseline up\nto 28.93%, 25.57% and 20.35% on Accuracy@1, MAP and MRR, respectively.\n","authors":["Chunying Zhou","Xiaoyuan Xie","Gong Chen","Peng He","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2409.12519v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15378v2","updated":"2025-06-09T03:44:25Z","published":"2025-01-26T03:27:11Z","title":"How to Mitigate Information Loss in Knowledge Graphs for GraphRAG:\n  Leveraging Triple Context Restoration and Query-Driven Feedback","summary":"  Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently\npropelled significant advances in complex reasoning tasks, thanks to their\nbroad domain knowledge and contextual awareness. Unfortunately, current methods\noften assume KGs to be complete, which is impractical given the inherent\nlimitations of KG construction and the potential loss of contextual cues when\nconverting unstructured text into entity-relation triples. In response, this\npaper proposes the Triple Context Restoration and Query-driven Feedback\n(TCR-QF) framework, which reconstructs the textual context underlying each\ntriple to mitigate information loss, while dynamically refining the KG\nstructure by iteratively incorporating query-relevant missing knowledge.\nExperiments on five benchmark question-answering datasets substantiate the\neffectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1%\nimprovement in Exact Match and a 15.5% improvement in F1 over its\nstate-of-the-art GraphRAG competitors.\n","authors":["Manzong Huang","Chenyang Bu","Yi He","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2501.15378v2.pdf","comment":"This paper has been accepted to IJCAI 2025"}],"Databases":[{"id":"http://arxiv.org/abs/2506.08276v1","updated":"2025-06-09T22:43:30Z","published":"2025-06-09T22:43:30Z","title":"LEANN: A Low-Storage Vector Index","summary":"  Embedding-based search is widely used in applications such as recommendation\nand retrieval-augmented generation (RAG). Recently, there is a growing demand\nto support these capabilities over personal data stored locally on devices.\nHowever, maintaining the necessary data structure associated with the\nembedding-based search is often infeasible due to its high storage overhead.\nFor example, indexing 100 GB of raw data requires 150 to 700 GB of storage,\nmaking local deployment impractical. Reducing this overhead while maintaining\nsearch quality and latency becomes a critical challenge. In this paper, we\npresent LEANN, a storage-efficient approximate nearest neighbor (ANN) search\nindex optimized for resource-constrained personal devices. LEANN combines a\ncompact graph-based structure with an efficient on-the-fly recomputation\nstrategy to enable fast and accurate retrieval with minimal storage overhead.\nOur evaluation shows that LEANN reduces index size to under 5% of the original\nraw data, achieving up to 50 times smaller storage than standard indexes, while\nmaintaining 90% top-3 recall in under 2 seconds on real-world question\nanswering benchmarks.\n","authors":["Yichuan Wang","Shu Liu","Zhifei Li","Yongji Wu","Ziming Mao","Yilong Zhao","Xiao Yan","Zhiying Xu","Yang Zhou","Ion Stoica","Sewon Min","Matei Zaharia","Joseph E. Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2506.08276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08249v1","updated":"2025-06-09T21:32:47Z","published":"2025-06-09T21:32:47Z","title":"RADAR: Benchmarking Language Models on Imperfect Tabular Data","summary":"  Language models (LMs) are increasingly being deployed to perform autonomous\ndata analyses. However, their data awareness -- the ability to recognize,\nreason over, and appropriately handle data artifacts such as missing values,\noutliers, and logical inconsistencies -- remains underexplored. These artifacts\nare especially common in real-world tabular data and, if mishandled, can\nsignificantly compromise the validity of analytical conclusions. To address\nthis gap, we present RADAR, a benchmark for systematically evaluating\ndata-aware reasoning on tabular data. We develop a framework to simulate data\nartifacts via programmatic perturbations to enable targeted evaluation of model\nbehavior. RADAR comprises 2980 table query pairs, grounded in real-world data\nspanning 9 domains and 5 data artifact types. In addition to evaluating\nartifact handling, RADAR systematically varies table size to study how\nreasoning performance holds when increasing table size. Our evaluation reveals\nthat, despite decent performance on tables without data artifacts, frontier\nmodels degrade significantly when data artifacts are introduced, exposing\ncritical gaps in their capacity for robust, data-aware analysis. Designed to be\nflexible and extensible, RADAR supports diverse perturbation types and\ncontrollable table sizes, offering a valuable resource for advancing tabular\nreasoning.\n","authors":["Ken Gu","Zhihan Zhang","Kate Lin","Yuwei Zhang","Akshay Paruchuri","Hong Yu","Mehran Kazemi","Kumar Ayush","A. Ali Heydari","Maxwell A. Xu","Girish Narayanswamy","Yun Liu","Ming-Zher Poh","Yuzhe Yang","Mark Malhotra","Shwetak Patel","Hamid Palangi","Xuhai Xu","Daniel McDuff","Tim Althoff","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2506.08249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01173v2","updated":"2025-06-09T15:46:46Z","published":"2025-06-01T21:13:26Z","title":"SIFBench: An Extensive Benchmark for Fatigue Analysis","summary":"  Fatigue-induced crack growth is a leading cause of structural failure across\ncritical industries such as aerospace, civil engineering, automotive, and\nenergy. Accurate prediction of stress intensity factors (SIFs) -- the key\nparameters governing crack propagation in linear elastic fracture mechanics --\nis essential for assessing fatigue life and ensuring structural integrity.\nWhile machine learning (ML) has shown great promise in SIF prediction, its\nadvancement has been severely limited by the lack of rich, transparent,\nwell-organized, and high-quality datasets.\n  To address this gap, we introduce SIFBench, an open-source, large-scale\nbenchmark database designed to support ML-based SIF prediction. SIFBench\ncontains over 5 million different crack and component geometries derived from\nhigh-fidelity finite element simulations across 37 distinct scenarios, and\nprovides a unified Python interface for seamless data access and customization.\nWe report baseline results using a range of popular ML models -- including\nrandom forests, support vector machines, feedforward neural networks, and\nFourier neural operators -- alongside comprehensive evaluation metrics and\ntemplate code for model training, validation, and assessment. By offering a\nstandardized and scalable resource, SIFBench substantially lowers the entry\nbarrier and fosters the development and application of ML methods in damage\ntolerance design and predictive maintenance.\n","authors":["Tushar Gautam","Robert M. Kirby","Jacob Hochhalter","Shandian Zhe"],"pdf_url":"https://arxiv.org/pdf/2506.01173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07675v1","updated":"2025-06-09T11:51:27Z","published":"2025-06-09T11:51:27Z","title":"QUITE: A Query Rewrite System Beyond Rules with LLM Agents","summary":"  Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.\n","authors":["Yuyang Song","Hanxu Yan","Jiale Lao","Yibo Wang","Yufei Li","Yuanchun Zhou","Jianguo Wang","Mingjie Tang"],"pdf_url":"https://arxiv.org/pdf/2506.07675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07552v1","updated":"2025-06-09T08:46:56Z","published":"2025-06-09T08:46:56Z","title":"Quantum Information-Theoretical Size Bounds for Conjunctive Queries with\n  Functional Dependencies","summary":"  Deriving formulations for computing and estimating tight worst-case size\nincreases for conjunctive queries with various constraints has been at the core\nof theoretical database research. If the problem has no constraints or only one\nconstraint, such as functional dependencies or degree constraints, tight\nworst-case size bounds have been proven, and they are even practically\ncomputable. If the problem has more than one constraint, computing tight bounds\ncan be difficult in practice and may even require an infinite number of linear\ninequalities in its optimization formulation. While these challenges have been\naddressed with varying methods, no prior research has employed quantum\ninformation theory to address this problem. In this work, we establish a\nconnection between earlier work on estimating size bounds for conjunctive\nqueries with classical information theory and the field of quantum information\ntheory. We propose replacing the classical Shannon entropy formulation with the\nquantum R\\'enyi entropy. Whereas classical Shannon entropy requires infinitely\nmany inequalities to characterize the optimization space, R\\'enyi entropy\nrequires only one type of inequality, which is non-negativity. Although this is\na promising modification, optimization with respect to the quantum states\ninstead of classical distributions creates a new set of challenges that prevent\nus from finding a practically computable, tight worst-case size bound. In this\nline, we propose a quantum version to derive worst-case size bounds. The\nprevious tight classical worst-case size bound can be viewed as a special limit\nof this quantum bound. We also provide a comprehensive background on prior\nresearch and discuss the future possibilities of quantum information theory in\ntheoretical database research.\n","authors":["Valter Uotila","Jiaheng Lu"],"pdf_url":"https://arxiv.org/pdf/2506.07552v1.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.04678v2","updated":"2025-06-09T01:41:08Z","published":"2025-06-05T06:54:25Z","title":"BVLSM: Write-Efficient LSM-Tree Storage via WAL-Time Key-Value\n  Separation","summary":"  Modern data-intensive applications increasingly store and process big-value\nitems, such as multimedia objects and machine learning embeddings, which\nexacerbate storage inefficiencies in Log-Structured Merge-Tree (LSM)-based\nkey-value stores. This paper presents BVLSM, a Write-Ahead Log (WAL)-time\nkey-value separation mechanism designed to address three key challenges in\nLSM-Tree storage systems: write amplification, poor memory utilization, and I/O\njitter under big-value workloads. Unlike state-of-the-art approaches that delay\nkey-value separation until the flush stage, leading to redundant data in\nMemTables and repeated writes. BVLSM proactively decouples keys and values\nduring the WAL phase. The MemTable stores only lightweight metadata, allowing\nmulti-queue parallel store for big value. The benchmark results show that BVLSM\nsignificantly outperforms both RocksDB and BlobDB under 64KB random write\nworkloads. In asynchronous WAL mode, it achieves throughput improvements of\n7.6x over RocksDB and 1.9x over BlobDB.\n","authors":["Ming Li","Wendi Cheng","Jiahe Wei","Xueqiang Shan","Weikai Liu","Xiaonan Zhao","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.04678v2.pdf","comment":null}]},"2025-06-08T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.23630v2","updated":"2025-06-08T23:11:09Z","published":"2025-03-31T00:04:01Z","title":"Finding Interest Needle in Popularity Haystack: Improving Retrieval by\n  Modeling Item Exposure","summary":"  Recommender systems operate in closed feedback loops, where user interactions\nreinforce popularity bias, leading to over-recommendation of already popular\nitems while under-exposing niche or novel content. Existing bias mitigation\nmethods, such as Inverse Propensity Scoring (IPS) and Off-Policy Correction\n(OPC), primarily operate at the ranking stage or during training, lacking\nexplicit real-time control over exposure dynamics. In this work, we introduce\nan exposure-aware retrieval scoring approach, which explicitly models item\nexposure probability and adjusts retrieval-stage ranking at inference time.\nUnlike prior work, this method decouples exposure effects from engagement\nlikelihood, enabling controlled trade-offs between fairness and engagement in\nlarge-scale recommendation platforms. We validate our approach through online\nA/B experiments in a real-world video recommendation system, demonstrating a\n25% increase in uniquely retrieved items and a 40% reduction in the dominance\nof over-popular content, all while maintaining overall user engagement levels.\nOur results establish a scalable, deployable solution for mitigating popularity\nbias at the retrieval stage, offering a new paradigm for bias-aware\npersonalization.\n","authors":["Rahul Agarwal","Amit Jaspal","Saurabh Gupta","Omkar Vichare"],"pdf_url":"https://arxiv.org/pdf/2503.23630v2.pdf","comment":"2 pages. UMAP '25: 33rd ACM Conference on User Modeling, Adaptation\n  and Personalization, New York City, USA, June 2025"},{"id":"http://arxiv.org/abs/2506.07296v1","updated":"2025-06-08T21:39:08Z","published":"2025-06-08T21:39:08Z","title":"HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language\n  Models for Efficient Multimodal Hotel Retrieval","summary":"  We present HotelMatch-LLM, a multimodal dense retrieval model for the travel\ndomain that enables natural language property search, addressing the\nlimitations of traditional travel search engines which require users to start\nwith a destination and editing search parameters. HotelMatch-LLM features three\nkey innovations: (1) Domain-specific multi-task optimization with three novel\nretrieval, visual, and language modeling objectives; (2) Asymmetrical dense\nretrieval architecture combining a small language model (SLM) for efficient\nonline query processing and a large language model (LLM) for embedding hotel\ndata; and (3) Extensive image processing to handle all property image\ngalleries. Experiments on four diverse test sets show HotelMatch-LLM\nsignificantly outperforms state-of-the-art models, including VISTA and MARVEL.\nSpecifically, on the test set -- main query type -- we achieve 0.681 for\nHotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our\nanalysis highlights the impact of our multi-task optimization, the\ngeneralizability of HotelMatch-LLM across LLM architectures, and its\nscalability for processing large image galleries.\n","authors":["Arian Askari","Emmanouil Stergiadis","Ilya Gusev","Moran Beladev"],"pdf_url":"https://arxiv.org/pdf/2506.07296v1.pdf","comment":"Accepted at ACL 2025, Main track. 13 Pages, 1 figure"},{"id":"http://arxiv.org/abs/2506.07285v1","updated":"2025-06-08T21:10:30Z","published":"2025-06-08T21:10:30Z","title":"Research Knowledge Graphs: the Shifting Paradigm of Scholarly\n  Information Representation","summary":"  Sharing and reusing research artifacts, such as datasets, publications, or\nmethods is a fundamental part of scientific activity, where heterogeneity of\nresources and metadata and the common practice of capturing information in\nunstructured publications pose crucial challenges. Reproducibility of research\nand finding state-of-the-art methods or data have become increasingly\nchallenging. In this context, the concept of Research Knowledge Graphs (RKGs)\nhas emerged, aiming at providing an easy to use and machine-actionable\nrepresentation of research artifacts and their relations. That is facilitated\nthrough the use of established principles for data representation, the\nconsistent adoption of globally unique persistent identifiers and the reuse and\nlinking of vocabularies and data. This paper provides the first\nconceptualisation of the RKG vision, a categorisation of in-use RKGs together\nwith a description of RKG building blocks and principles. We also survey\nreal-world RKG implementations differing with respect to scale, schema, data,\nused vocabulary, and reliability of the contained data. We also characterise\ndifferent RKG construction methodologies and provide a forward-looking\nperspective on the diverse applications, opportunities, and challenges\nassociated with the RKG vision.\n","authors":["Matthäus Zloch","Danilo Dessì","Jennifer D'Souza","Leyla Jael Castro","Benjamin Zapilko","Saurav Karmakar","Brigitte Mathiak","Markus Stocker","Wolfgang Otto","Sören Auer","Stefan Dietze"],"pdf_url":"https://arxiv.org/pdf/2506.07285v1.pdf","comment":"Extended Semantic Web Conference 2025, In-use track, 10 pages, 1\n  figure"},{"id":"http://arxiv.org/abs/2506.07261v1","updated":"2025-06-08T19:21:46Z","published":"2025-06-08T19:21:46Z","title":"RADAR: Recall Augmentation through Deferred Asynchronous Retrieval","summary":"  Modern large-scale recommender systems employ multi-stage ranking funnel\n(Retrieval, Pre-ranking, Ranking) to balance engagement and computational\nconstraints (latency, CPU). However, the initial retrieval stage, often relying\non efficient but less precise methods like K-Nearest Neighbors (KNN), struggles\nto effectively surface the most engaging items from billion-scale catalogs,\nparticularly distinguishing highly relevant and engaging candidates from merely\nrelevant ones. We introduce Recall Augmentation through Deferred Asynchronous\nRetrieval (RADAR), a novel framework that leverages asynchronous, offline\ncomputation to pre-rank a significantly larger candidate set for users using\nthe full complexity ranking model. These top-ranked items are stored and\nutilized as a high-quality retrieval source during online inference, bypassing\nonline retrieval and pre-ranking stages for these candidates. We demonstrate\nthrough offline experiments that RADAR significantly boosts recall (2X\nRecall@200 vs DNN retrieval baseline) by effectively combining a larger\nretrieved candidate set with a more powerful ranking model. Online A/B tests\nconfirm a +0.8% lift in topline engagement metrics, validating RADAR as a\npractical and effective method to improve recommendation quality under strict\nonline serving constraints.\n","authors":["Amit Jaspal","Qian Dang","Ajantha Ramineni"],"pdf_url":"https://arxiv.org/pdf/2506.07261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01142v2","updated":"2025-06-08T17:17:01Z","published":"2025-02-03T08:22:45Z","title":"DeepRAG: Thinking to Retrieve Step by Step for Large Language Models","summary":"  Large Language Models (LLMs) have shown remarkable reasoning capabilities,\nwhile their practical applications are limited by severe factual hallucinations\ndue to limitations in the timeliness, accuracy, and comprehensiveness of their\nparametric knowledge. Meanwhile, enhancing retrieval-augmented generation (RAG)\nwith reasoning remains challenging due to ineffective task decomposition and\nredundant retrieval, which can introduce noise and degrade response quality. In\nthis paper, we propose DeepRAG, a framework that models retrieval-augmented\nreasoning as a Markov Decision Process (MDP), enabling reasonable and adaptive\nretrieval. By iteratively decomposing queries, DeepRAG dynamically determines\nwhether to retrieve external knowledge or rely on parametric reasoning at each\nstep. Experiments show that DeepRAG improves retrieval efficiency and boosts\nanswer accuracy by 26.4%, demonstrating its effectiveness in enhancing\nretrieval-augmented reasoning.\n","authors":["Xinyan Guan","Jiali Zeng","Fandong Meng","Chunlei Xin","Yaojie Lu","Hongyu Lin","Xianpei Han","Le Sun","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.01142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11112v1","updated":"2025-06-08T16:25:35Z","published":"2025-06-08T16:25:35Z","title":"Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational\n  Agents: A Framework for Evaluation (CAFE)","summary":"  During the workshop, we deeply discussed what CONversational Information\nACcess (CONIAC) is and its unique features, proposing a world model abstracting\nit, and defined the Conversational Agents Framework for Evaluation (CAFE) for\nthe evaluation of CONIAC systems, consisting of six major components: 1) goals\nof the system's stakeholders, 2) user tasks to be studied in the evaluation, 3)\naspects of the users carrying out the tasks, 4) evaluation criteria to be\nconsidered, 5) evaluation methodology to be applied, and 6) measures for the\nquantitative criteria chosen.\n","authors":["Christine Bauer","Li Chen","Nicola Ferro","Norbert Fuhr","Avishek Anand","Timo Breuer","Guglielmo Faggioli","Ophir Frieder","Hideo Joho","Jussi Karlgren","Johannes Kiesel","Bart P. Knijnenburg","Aldo Lipani","Lien Michiels","Andrea Papenmeier","Maria Soledad Pera","Mark Sanderson","Scott Sanner","Benno Stein","Johanne R. Trippas","Karin Verspoor","Martijn C Willemsen"],"pdf_url":"https://arxiv.org/pdf/2506.11112v1.pdf","comment":"43 pages; 10 figures; Dagstuhl manifesto"},{"id":"http://arxiv.org/abs/2502.11116v2","updated":"2025-06-08T15:59:44Z","published":"2025-02-16T13:23:39Z","title":"Gumbel Reranking: Differentiable End-to-End Reranker Optimization","summary":"  RAG systems rely on rerankers to identify relevant documents. However,\nfine-tuning these models remains challenging due to the scarcity of annotated\nquery-document pairs. Existing distillation-based approaches suffer from\ntraining-inference misalignment and fail to capture interdependencies among\ncandidate documents. To overcome these limitations, we reframe the reranking\nprocess as an attention-mask problem and propose Gumbel Reranking, an\nend-to-end training framework for rerankers aimed at minimizing the\ntraining-inference gap. In our approach, reranker optimization is reformulated\nas learning a stochastic, document-wise Top-$k$ attention mask using the Gumbel\nTrick and Relaxed Top-$k$ Sampling. This formulation enables end-to-end\noptimization by minimizing the overall language loss. Experiments across\nvarious settings consistently demonstrate performance gains, including a 10.4\\%\nimprovement in recall on HotpotQA for distinguishing indirectly relevant\ndocuments.\n","authors":["Siyuan Huang","Zhiyuan Ma","Jintao Du","Changhua Meng","Weiqiang Wang","Jingwen Leng","Minyi Guo","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2502.11116v2.pdf","comment":"ACL 2025 Main"},{"id":"http://arxiv.org/abs/2502.13595v3","updated":"2025-06-08T15:10:54Z","published":"2025-02-19T10:13:43Z","title":"MMTEB: Massive Multilingual Text Embedding Benchmark","summary":"  Text embeddings are typically evaluated on a limited set of tasks, which are\nconstrained by language, domain, and task diversity. To address these\nlimitations and provide a more comprehensive evaluation, we introduce the\nMassive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,\ncommunity-driven expansion of MTEB, covering over 500 quality-controlled\nevaluation tasks across 250+ languages. MMTEB includes a diverse set of\nchallenging, novel tasks such as instruction following, long-document\nretrieval, and code retrieval, representing the largest multilingual collection\nof evaluation tasks for embedding models to date. Using this collection, we\ndevelop several highly multilingual benchmarks, which we use to evaluate a\nrepresentative set of models. We find that while large language models (LLMs)\nwith billions of parameters can achieve state-of-the-art performance on certain\nlanguage subsets and task categories, the best-performing publicly available\nmodel is multilingual-e5-large-instruct with only 560 million parameters. To\nfacilitate accessibility and reduce computational cost, we introduce a novel\ndownsampling method based on inter-task correlation, ensuring a diverse\nselection while preserving relative model rankings. Furthermore, we optimize\ntasks such as retrieval by sampling hard negatives, creating smaller but\neffective splits. These optimizations allow us to introduce benchmarks that\ndrastically reduce computational demands. For instance, our newly introduced\nzero-shot English benchmark maintains a ranking order similar to the full-scale\nversion but at a fraction of the computational cost.\n","authors":["Kenneth Enevoldsen","Isaac Chung","Imene Kerboua","Márton Kardos","Ashwin Mathur","David Stap","Jay Gala","Wissam Siblini","Dominik Krzemiński","Genta Indra Winata","Saba Sturua","Saiteja Utpala","Mathieu Ciancone","Marion Schaeffer","Gabriel Sequeira","Diganta Misra","Shreeya Dhakal","Jonathan Rystrøm","Roman Solomatin","Ömer Çağatan","Akash Kundu","Martin Bernstorff","Shitao Xiao","Akshita Sukhlecha","Bhavish Pahwa","Rafał Poświata","Kranthi Kiran GV","Shawon Ashraf","Daniel Auras","Björn Plüster","Jan Philipp Harries","Loïc Magne","Isabelle Mohr","Mariya Hendriksen","Dawei Zhu","Hippolyte Gisserot-Boukhlef","Tom Aarsen","Jan Kostkan","Konrad Wojtasik","Taemin Lee","Marek Šuppa","Crystina Zhang","Roberta Rocca","Mohammed Hamdy","Andrianos Michail","John Yang","Manuel Faysse","Aleksei Vatolin","Nandan Thakur","Manan Dey","Dipam Vasani","Pranjal Chitale","Simone Tedeschi","Nguyen Tai","Artem Snegirev","Michael Günther","Mengzhou Xia","Weijia Shi","Xing Han Lù","Jordan Clive","Gayatri Krishnakumar","Anna Maksimova","Silvan Wehrli","Maria Tikhonova","Henil Panchal","Aleksandr Abramov","Malte Ostendorff","Zheng Liu","Simon Clematide","Lester James Miranda","Alena Fenogenova","Guangyu Song","Ruqiya Bin Safi","Wen-Ding Li","Alessia Borghini","Federico Cassano","Hongjin Su","Jimmy Lin","Howard Yen","Lasse Hansen","Sara Hooker","Chenghao Xiao","Vaibhav Adlakha","Orion Weller","Siva Reddy","Niklas Muennighoff"],"pdf_url":"https://arxiv.org/pdf/2502.13595v3.pdf","comment":"Accepted for ICLR: https://openreview.net/forum?id=zl3pfz4VCV"},{"id":"http://arxiv.org/abs/2503.18941v2","updated":"2025-06-08T12:15:41Z","published":"2025-03-24T17:59:03Z","title":"Exploring Training and Inference Scaling Laws in Generative Retrieval","summary":"  Generative retrieval reformulates retrieval as an autoregressive generation\ntask, where large language models (LLMs) generate target documents directly\nfrom a query. As a novel paradigm, the mechanisms that underpin its performance\nand scalability remain largely unexplored. We systematically investigate\ntraining and inference scaling laws in generative retrieval, exploring how\nmodel size, training data scale, and inference-time compute jointly influence\nperformance. We propose a novel evaluation metric inspired by contrastive\nentropy and generation loss, providing a continuous performance signal that\nenables robust comparisons across diverse generative retrieval methods. Our\nexperiments show that n-gram-based methods align strongly with training and\ninference scaling laws. We find that increasing model size, training data\nscale, and inference-time compute all contribute to improved performance,\nhighlighting the complementary roles of these factors in enhancing generative\nretrieval. Across these settings, LLaMA models consistently outperform T5\nmodels, suggesting a particular advantage for larger decoder-only models in\ngenerative retrieval. Our findings underscore that model sizes, data\navailability, and inference computation interact to unlock the full potential\nof generative retrieval, offering new insights for designing and optimizing\nfuture systems.\n","authors":["Hongru Cai","Yongqi Li","Ruifeng Yuan","Wenjie Wang","Zhen Zhang","Wenjie Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.18941v2.pdf","comment":"Accepted to SIGIR 2025"},{"id":"http://arxiv.org/abs/2506.07050v1","updated":"2025-06-08T09:15:46Z","published":"2025-06-08T09:15:46Z","title":"From Swath to Full-Disc: Advancing Precipitation Retrieval with\n  Multimodal Knowledge Expansion","summary":"  Accurate near-real-time precipitation retrieval has been enhanced by\nsatellite-based technologies. However, infrared-based algorithms have low\naccuracy due to weak relations with surface precipitation, whereas passive\nmicrowave and radar-based methods are more accurate but limited in range. This\nchallenge motivates the Precipitation Retrieval Expansion (PRE) task, which\naims to enable accurate, infrared-based full-disc precipitation retrievals\nbeyond the scanning swath. We introduce Multimodal Knowledge Expansion, a\ntwo-stage pipeline with the proposed PRE-Net model. In the Swath-Distilling\nstage, PRE-Net transfers knowledge from a multimodal data integration model to\nan infrared-based model within the scanning swath via Coordinated Masking and\nWavelet Enhancement (CoMWE). In the Full-Disc Adaptation stage, Self-MaskTune\nrefines predictions across the full disc by balancing multimodal and full-disc\ninfrared knowledge. Experiments on the introduced PRE benchmark demonstrate\nthat PRE-Net significantly advanced precipitation retrieval performance,\noutperforming leading products like PERSIANN-CCS, PDIR, and IMERG. The code\nwill be available at https://github.com/Zjut-MultimediaPlus/PRE-Net.\n","authors":["Zheng Wang","Kai Ying","Bin Xu","Chunjiao Wang","Cong Bai"],"pdf_url":"https://arxiv.org/pdf/2506.07050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06989v1","updated":"2025-06-08T04:10:14Z","published":"2025-06-08T04:10:14Z","title":"Correcting for Position Bias in Learning to Rank: A Control Function\n  Approach","summary":"  Implicit feedback data, such as user clicks, is commonly used in\nlearning-to-rank (LTR) systems because it is easy to collect and it often\nreflects user preferences. However, this data is prone to various biases, and\ntraining an LTR system directly on biased data can result in suboptimal ranking\nperformance. One of the most prominent and well-studied biases in implicit\nfeedback data is position bias, which occurs because users are more likely to\ninteract with higher-ranked documents regardless of their true relevance. In\nthis paper, we propose a novel control function-based method that accounts for\nposition bias in a two-stage process. The first stage uses exogenous variation\nfrom the residuals of the ranking process to correct for position bias in the\nsecond stage click equation. Unlike previous position bias correction methods,\nour method does not require knowledge of the click or propensity model and\nallows for nonlinearity in the underlying ranking model. Moreover, our method\nis general and allows for debiasing any state-of-the-art ranking algorithm by\nplugging it into the second stage. We also introduce a technique to debias\nvalidation clicks for hyperparameter tuning to select the optimal model in the\nabsence of unbiased validation data. Experimental results demonstrate that our\nmethod outperforms state-of-the-art approaches in correcting for position bias.\n","authors":["Md Aminul Islam","Kathryn Vasilaky","Elena Zheleva"],"pdf_url":"https://arxiv.org/pdf/2506.06989v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2412.05561v2","updated":"2025-06-08T19:02:31Z","published":"2024-12-07T06:50:12Z","title":"Can the Rookies Cut the Tough Cookie? Exploring the Use of LLMs for SQL\n  Equivalence Checking","summary":"  Equivalence checking of SQL queries is an intractable problem often\nencountered in settings ranging from grading SQL submissions to debugging query\noptimizers. Despite recent work toward developing practical solutions, only\nsimple queries written using a small subset of SQL are supported, leaving the\nequivalence checking of sophisticated SQL queries at the mercy of intensive,\npotentially error-prone, manual analysis. In this paper, we explore how LLMs\ncan be used to reason with SQL queries to address this challenging problem.\nTowards this, we introduce a novel, realistic, and sufficiently complex\nbenchmark called SQLEquiQuest for SQL query equivalence checking that reflects\nreal-world settings. We establish strong baselines for SQL equivalence checking\nby leveraging the ability of LLMs to reason with SQL queries. We conduct a\ndetailed evaluation of several state-of-the-art LLMs using various prompting\nstrategies and carefully constructed in-context learning examples, including\nlogical plans generated by SQL query processors. Our empirical evaluation shows\nthat LLMs go well beyond the current capabilities of formal models for SQL\nequivalence, going from a mere 30% supported query pairs to full coverage,\nachieving up to 82% accuracy on Spider+DIN. However, a critical limitation of\nLLMs revealed by our analysis is that they exhibit a strong bias for\nequivalence predictions, with consistently poor performance over non-equivalent\npairs, opening a new direction for potential future research.\n","authors":["Rajat Singh","Srikanta Bedathur"],"pdf_url":"https://arxiv.org/pdf/2412.05561v2.pdf","comment":null}]},"2025-06-07T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2504.05307v2","updated":"2025-06-07T23:07:07Z","published":"2025-02-13T21:58:27Z","title":"Toward Total Recall: Enhancing FAIRness through AI-Driven Metadata\n  Standardization","summary":"  Scientific metadata often suffer from incompleteness, inconsistency, and\nformatting errors, which hinder effective discovery and reuse of the associated\ndatasets. We present a method that combines GPT-4 with structured metadata\ntemplates from the CEDAR knowledge base to automatically standardize metadata\nand to ensure compliance with established standards. A CEDAR template specifies\nthe expected fields of a metadata submission and their permissible values. Our\nstandardization process involves using CEDAR templates to guide GPT-4 in\naccurately correcting and refining metadata entries in bulk, resulting in\nsignificant improvements in metadata retrieval performance, especially in\nrecall -- the proportion of relevant datasets retrieved from the total relevant\ndatasets available. Using the BioSample and GEO repositories maintained by the\nNational Center for Biotechnology Information (NCBI), we demonstrate that\nretrieval of datasets whose metadata are altered by GPT-4 when provided with\nCEDAR templates (GPT-4+CEDAR) is substantially better than retrieval of\ndatasets whose metadata are in their original state and that of datasets whose\nmetadata are altered using GPT-4 with only data-dictionary guidance (GPT-4+DD).\nThe average recall increases dramatically, from 17.65\\% with baseline raw\nmetadata to 62.87\\% with GPT-4+CEDAR. Furthermore, we evaluate the robustness\nof our approach by comparing GPT-4 against other large language models,\nincluding LLaMA-3 and MedLLaMA2, demonstrating consistent performance\nadvantages for GPT-4+CEDAR. These results underscore the transformative\npotential of combining advanced language models with symbolic models of\nstandardized metadata structures for more effective and reliable data\nretrieval, thus accelerating scientific discoveries and data-driven research.\n","authors":["Sowmya S Sundaram","Rafael S. Gonçalves","Mark A Musen"],"pdf_url":"https://arxiv.org/pdf/2504.05307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06913v1","updated":"2025-06-07T20:24:05Z","published":"2025-06-07T20:24:05Z","title":"OneSug: The Unified End-to-End Generative Framework for E-commerce Query\n  Suggestion","summary":"  Query suggestion plays a crucial role in enhancing user experience in\ne-commerce search systems by providing relevant query recommendations that\nalign with users' initial input. This module helps users navigate towards\npersonalized preference needs and reduces typing effort, thereby improving\nsearch experience. Traditional query suggestion modules usually adopt\nmulti-stage cascading architectures, for making a well trade-off between system\nresponse time and business conversion. But they often suffer from\ninefficiencies and suboptimal performance due to inconsistent optimization\nobjectives across stages. To address these, we propose OneSug, the first\nend-to-end generative framework for e-commerce query suggestion. OneSug\nincorporates a prefix2query representation enhancement module to enrich\nprefixes using semantically and interactively related queries to bridge content\nand business characteristics, an encoder-decoder generative model that unifies\nthe query suggestion process, and a reward-weighted ranking strategy with\nbehavior-level weights to capture fine-grained user preferences. Extensive\nevaluations on large-scale industry datasets demonstrate OneSug's ability for\neffective and efficient query suggestion. Furthermore, OneSug has been\nsuccessfully deployed for the entire traffic on the e-commerce search engine in\nKuaishou platform for over 1 month, with statistically significant improvements\nin user top click position (-9.33%), CTR (+2.01%), Order (+2.04%), and Revenue\n(+1.69%) over the online multi-stage strategy, showing great potential in\ne-commercial conversion.\n","authors":["Xian Guo","Ben Chen","Siyuan Wang","Ying Yang","Chenyi Lei","Yuqing Ding","Han Li"],"pdf_url":"https://arxiv.org/pdf/2506.06913v1.pdf","comment":"11 pages, 8 figures, and 6 tables"},{"id":"http://arxiv.org/abs/2506.02916v3","updated":"2025-06-07T11:50:16Z","published":"2025-06-03T14:18:19Z","title":"Transferable Sequential Recommendation with Vanilla Cross-Entropy Loss","summary":"  Sequential Recommendation (SR) systems model user preferences by analyzing\ninteraction histories. Although transferable multi-modal SR architectures\ndemonstrate superior performance compared to traditional ID-based approaches,\ncurrent methods incur substantial fine-tuning costs when adapting to new\ndomains due to complex optimization requirements and negative transfer effects\n- a significant deployment bottleneck that hinders engineers from efficiently\nrepurposing pre-trained models for novel application scenarios with minimal\ntuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential\nRecommendation), a novel multi-modal SR framework that incorporates a dedicated\nalgebraic constraint mechanism for efficient transfer learning. By combining\nState Space Duality (SSD)'s temporal decay properties with a time-aware\nmodeling design, our model dynamically prioritizes key modality information,\novercoming limitations of Transformer-based approaches. The framework\nimplements a constrained two-stage process: (1) sequence-level cross-modal\nalignment via shared projection matrices, followed by (2) temporal fusion using\nour newly designed Cross-SSD module and dual-channel Fourier adaptive\nfiltering. This architecture maintains semantic consistency while suppressing\nnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple\ncross-entropy loss, significantly improving multi-modal recommendation accuracy\nwhile maintaining strong transferability. Extensive experiments demonstrate\nMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10\nimprovement over existing models and exhibiting 10 times faster average\nconvergence speed when transferring to large-scale downstream datasets.\n","authors":["Hao Fan","Yanrong Hu","Kai Fang","Qingyang Liu","Hongjiu Liu"],"pdf_url":"https://arxiv.org/pdf/2506.02916v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06743v1","updated":"2025-06-07T10:19:37Z","published":"2025-06-07T10:19:37Z","title":"The State-of-the-Art in Lifelog Retrieval: A Review of Progress at the\n  ACM Lifelog Search Challenge Workshop 2022-24","summary":"  The ACM Lifelog Search Challenge (LSC) is a venue that welcomes and compares\nsystems that support the exploration of lifelog data, and in particular the\nretrieval of specific information, through an interactive competition format.\nThis paper reviews the recent advances in interactive lifelog retrieval as\ndemonstrated at the ACM LSC from 2022 to 2024. Through a detailed comparative\nanalysis, we highlight key improvements across three main retrieval tasks:\nknown-item search, question answering, and ad-hoc search. Our analysis\nidentifies trends such as the widespread adoption of embedding-based retrieval\nmethods (e.g., CLIP, BLIP), increased integration of large language models\n(LLMs) for conversational retrieval, and continued innovation in multimodal and\ncollaborative search interfaces. We further discuss how specific retrieval\ntechniques and user interface (UI) designs have impacted system performance,\nemphasizing the importance of balancing retrieval complexity with usability.\nOur findings indicate that embedding-driven approaches combined with LLMs show\npromise for lifelog retrieval systems. Likewise, improving UI design can\nenhance usability and efficiency. Additionally, we recommend reconsidering\nmulti-instance system evaluations within the expert track to better manage\nvariability in user familiarity and configuration effectiveness.\n","authors":["Allie Tran","Werner Bailer","Duc-Tien Dang-Nguyen","Graham Healy","Steve Hodges","Björn Þór Jónsson","Luca Rossetto","Klaus Schoeffmann","Minh-Triet Tran","Lucia Vadicamo","Cathal Gurrin"],"pdf_url":"https://arxiv.org/pdf/2506.06743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06704v1","updated":"2025-06-07T07:59:33Z","published":"2025-06-07T07:59:33Z","title":"Dynamic and Parametric Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) has become a foundational paradigm for\nequipping large language models (LLMs) with external knowledge, playing a\ncritical role in information retrieval and knowledge-intensive applications.\nHowever, conventional RAG systems typically adopt a static\nretrieve-then-generate pipeline and rely on in-context knowledge injection,\nwhich can be suboptimal for complex tasks that require multihop reasoning,\nadaptive information access, and deeper integration of external knowledge.\nMotivated by these limitations, the research community has moved beyond static\nretrieval and in-context knowledge injection. Among the emerging directions,\nthis tutorial delves into two rapidly growing and complementary research areas\non RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when\nand what to retrieve during the LLM's generation process, enabling real-time\nadaptation to the LLM's evolving information needs. Parametric RAG rethinks how\nretrieved knowledge should be injected into LLMs, transitioning from\ninput-level to parameter-level knowledge injection for enhanced efficiency and\neffectiveness. This tutorial offers a comprehensive overview of recent advances\nin these emerging research areas. It also shares theoretical foundations and\npractical insights to support and inspire further research in RAG.\n","authors":["Weihang Su","Qingyao Ai","Jingtao Zhan","Qian Dong","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2506.06704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11106v1","updated":"2025-06-07T07:17:14Z","published":"2025-06-07T07:17:14Z","title":"Graph-based RAG Enhancement via Global Query Disambiguation and\n  Dependency-Aware Reranking","summary":"  Contemporary graph-based retrieval-augmented generation (RAG) methods\ntypically begin by extracting entities from user queries and then leverage\npre-constructed knowledge graphs to retrieve related relationships and\nmetadata. However, this pipeline's exclusive reliance on entity-level\nextraction can lead to the misinterpretation or omission of latent yet critical\ninformation and relations. As a result, retrieved content may be irrelevant or\ncontradictory, and essential knowledge may be excluded, exacerbating\nhallucination risks and degrading the fidelity of generated responses. To\naddress these limitations, we introduce PankRAG, a framework that combines a\nglobally aware, hierarchical query-resolution strategy with a novel\ndependency-aware reranking mechanism. PankRAG first constructs a multi-level\nresolution path that captures both parallel and sequential interdependencies\nwithin a query, guiding large language models (LLMs) through structured\nreasoning. It then applies its dependency-aware reranker to exploit the\ndependency structure among resolved sub-questions, enriching and validating\nretrieval results for subsequent sub-questions. Empirical evaluations\ndemonstrate that PankRAG consistently outperforms state-of-the-art approaches\nacross multiple benchmarks, underscoring its robustness and generalizability.\n","authors":["Ningyuan Li","Junrui Liu","Yi Shan","Minghui Huang","Tong Li"],"pdf_url":"https://arxiv.org/pdf/2506.11106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08208v3","updated":"2025-06-07T04:28:59Z","published":"2024-08-15T15:18:46Z","title":"LLM4DSR: Leveraging Large Language Model for Denoising Sequential\n  Recommendation","summary":"  Sequential Recommenders generate recommendations based on users' historical\ninteraction sequences. However, in practice, these collected sequences are\noften contaminated by noisy interactions, which significantly impairs\nrecommendation performance. Accurately identifying such noisy interactions\nwithout additional information is particularly challenging due to the absence\nof explicit supervisory signals indicating noise. Large Language Models (LLMs),\nequipped with extensive open knowledge and semantic reasoning abilities, offer\na promising avenue to bridge this information gap. However, employing LLMs for\ndenoising in sequential recommendation presents notable challenges: 1) Direct\napplication of pretrained LLMs may not be competent for the denoising task,\nfrequently generating nonsensical responses; 2) Even after fine-tuning, the\nreliability of LLM outputs remains questionable, especially given the\ncomplexity of the denoising task and the inherent hallucinatory issue of LLMs.\n  To tackle these challenges, we propose LLM4DSR, a tailored approach for\ndenoising sequential recommendation using LLMs. We constructed a\nself-supervised fine-tuning task to activate LLMs' capabilities to identify\nnoisy items and suggest replacements. Furthermore, we developed an uncertainty\nestimation module that ensures only high-confidence responses are utilized for\nsequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing corrected\nsequences to be flexibly applied across various recommendation models.\nExtensive experiments validate the superiority of LLM4DSR over existing\nmethods.\n","authors":["Bohao Wang","Feng Liu","Changwang Zhang","Jiawei Chen","Yudi Wu","Sheng Zhou","Xingyu Lou","Jun Wang","Yan Feng","Chun Chen","Can Wang"],"pdf_url":"https://arxiv.org/pdf/2408.08208v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04178v4","updated":"2025-06-07T03:59:52Z","published":"2025-04-05T13:48:33Z","title":"MSL: Not All Tokens Are What You Need for Tuning LLM as a Recommender","summary":"  Large language models (LLMs), known for their comprehension capabilities and\nextensive knowledge, have been increasingly applied to recommendation systems\n(RS). Given the fundamental gap between the mechanism of LLMs and the\nrequirement of RS, researchers have focused on fine-tuning LLMs with\nrecommendation-specific data to enhance their performance. Language Modeling\nLoss (LML), originally designed for language generation tasks, is commonly\nadopted. However, we identify two critical limitations of LML: 1) it exhibits\nsignificant divergence from the recommendation objective; 2) it erroneously\ntreats all fictitious item descriptions as negative samples, introducing\nmisleading training signals.\n  To address these limitations, we propose a novel Masked Softmax Loss (MSL)\ntailored for fine-tuning LLMs on recommendation. MSL improves LML by\nidentifying and masking invalid tokens that could lead to fictitious item\ndescriptions during loss computation. This strategy can effectively avoid the\ninterference from erroneous negative signals and ensure well alignment with the\nrecommendation objective supported by theoretical guarantees. During\nimplementation, we identify a potential challenge related to gradient vanishing\nof MSL. To overcome this, we further introduce the temperature coefficient and\npropose an Adaptive Temperature Strategy (ATS) that adaptively adjusts the\ntemperature without requiring extensive hyperparameter tuning. Extensive\nexperiments conducted on four public datasets further validate the\neffectiveness of MSL, achieving an average improvement of 42.24% in NDCG@10.\nThe code is available at https://github.com/WANGBohaO-jpg/MSL.\n","authors":["Bohao Wang","Feng Liu","Jiawei Chen","Xingyu Lou","Changwang Zhang","Jun Wang","Yuegang Sun","Yan Feng","Chun Chen","Can Wang"],"pdf_url":"https://arxiv.org/pdf/2504.04178v4.pdf","comment":"Accepted by SIGIR2025"}]},"2025-06-06T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2406.14572v4","updated":"2025-06-06T22:20:55Z","published":"2024-06-13T17:53:29Z","title":"Bioptic B1: A Target-Agnostic Potency-Based Small Molecules Search\n  Engine","summary":"  Recent successes in virtual screening have been made possible by large models\nand extensive chemical libraries. However, combining these elements is\nchallenging: the larger the model, the more expensive it is to run, making\nultra-large libraries unfeasible. To address this, we developed a\ntarget-agnostic, efficacy-based molecule search model, which allows us to find\nstructurally dissimilar molecules with similar biological activities. We used\nthe best practices to design fast retrieval system, based on\nprocessor-optimized SIMD instructions, enabling us to screen the ultra-large\n40B Enamine REAL library with 100\\% recall rate. We extensively benchmarked our\nmodel and several state-of-the-art models for both speed performance and\nretrieval quality of novel molecules.\n","authors":["Vlad Vinogradov","Ivan Izmailov","Simon Steshin","Kong T. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2406.14572v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06557v1","updated":"2025-06-06T22:09:44Z","published":"2025-06-06T22:09:44Z","title":"Infinity Search: Approximate Vector Search with Projections on q-Metric\n  Spaces","summary":"  Despite the ubiquity of vector search applications, prevailing search\nalgorithms overlook the metric structure of vector embeddings, treating it as a\nconstraint rather than exploiting its underlying properties. In this paper, we\ndemonstrate that in $q$-metric spaces, metric trees can leverage a stronger\nversion of the triangle inequality to reduce comparisons for exact search.\nNotably, as $q$ approaches infinity, the search complexity becomes logarithmic.\nTherefore, we propose a novel projection method that embeds vector datasets\nwith arbitrary dissimilarity measures into $q$-metric spaces while preserving\nthe nearest neighbor. We propose to learn an approximation of this projection\nto efficiently transform query points to a space where euclidean distances\nsatisfy the desired properties. Our experimental results with text and image\nvector embeddings show that learning $q$-metric approximations enables classic\nmetric tree algorithms -- which typically underperform with high-dimensional\ndata -- to achieve competitive performance against state-of-the-art search\nmethods.\n","authors":["Antonio Pariente","Ignacio Hounie","Santiago Segarra","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2506.06557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04548v3","updated":"2025-06-06T21:23:31Z","published":"2024-06-06T23:09:54Z","title":"GNNAnatomy: Rethinking Model-Level Explanations for Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) achieve outstanding performance across\ngraph-based tasks but remain difficult to interpret. In this paper, we revisit\nfoundational assumptions underlying model-level explanation methods for GNNs,\nnamely: (1) maximizing classification confidence yields representative\nexplanations, (2) a single explanation suffices for an entire class of graphs,\nand (3) explanations are inherently trustworthy. We identify pitfalls resulting\nfrom these assumptions: methods that optimize for classification confidence may\noverlook partially learned patterns; topological diversity across graph subsets\nwithin the same class is often underrepresented; and explanations alone offer\nlimited support for building user trust when applied to new datasets or models.\nThis paper introduces GNNAnatomy, a distillation-based method designed to\ngenerate explanations while avoiding these pitfalls. GNNAnatomy first\ncharacterizes graph topology using graphlets, a set of fundamental\nsubstructures. We then train a transparent multilayer perceptron surrogate to\ndirectly approximate GNN predictions based on the graphlet representations. By\nanalyzing the weights assigned to each graphlet, we identify the most\ndiscriminative topologies, which serve as GNN explanations. To account for\nstructural diversity within a class, GNNAnatomy generates explanations at the\nrequired granularity through an interface that supports human-AI teaming. This\ninterface helps users identify subsets of graphs where distinct critical\nsubstructures drive class differentiation, enabling multi-grained explanations.\nAdditionally, by enabling exploration and linking explanations back to input\ngraphs, the interface fosters greater transparency and trust. We evaluate\nGNNAnatomy on both synthetic and real-world datasets through quantitative\nmetrics and qualitative comparisons with state-of-the-art model-level\nexplainable GNN methods.\n","authors":["Hsiao-Ying Lu","Yiran Li","Ujwal Pratap Krishna Kaluvakolanu Thyagarajan","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2406.04548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03437v2","updated":"2025-06-06T19:58:25Z","published":"2025-06-03T22:37:37Z","title":"Quake: Adaptive Indexing for Vector Search","summary":"  Vector search, the task of finding the k-nearest neighbors of a query vector\nagainst a database of high-dimensional vectors, underpins many machine learning\napplications, including retrieval-augmented generation, recommendation systems,\nand information retrieval. However, existing approximate nearest neighbor (ANN)\nmethods perform poorly under dynamic and skewed workloads where data\ndistributions evolve. We introduce Quake, an adaptive indexing system that\nmaintains low latency and high recall in such environments. Quake employs a\nmulti-level partitioning scheme that adjusts to updates and changing access\npatterns, guided by a cost model that predicts query latency based on partition\nsizes and access frequencies. Quake also dynamically sets query execution\nparameters to meet recall targets using a novel recall estimation model.\nFurthermore, Quake utilizes NUMA-aware intra-query parallelism for improved\nmemory bandwidth utilization during search. To evaluate Quake, we prepare a\nWikipedia vector search workload and develop a workload generator to create\nvector search workloads with configurable access patterns. Our evaluation shows\nthat on dynamic workloads, Quake achieves query latency reductions of 1.5-38x\nand update latency reductions of 4.5-126x compared to state-of-the-art indexes\nsuch as SVS, DiskANN, HNSW, and SCANN.\n","authors":["Jason Mohoney","Devesh Sarda","Mengze Tang","Shihabur Rahman Chowdhury","Anil Pacaci","Ihab F. Ilyas","Theodoros Rekatsinas","Shivaram Venkataraman"],"pdf_url":"https://arxiv.org/pdf/2506.03437v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.21398v2","updated":"2025-06-06T18:20:41Z","published":"2025-04-30T07:54:04Z","title":"In a Few Words: Comparing Weak Supervision and LLMs for Short Query\n  Intent Classification","summary":"  User intent classification is an important task in information retrieval.\nPreviously, user intents were classified manually and automatically; the latter\nhelped to avoid hand labelling of large datasets. Recent studies explored\nwhether LLMs can reliably determine user intent. However, researchers have\nrecognized the limitations of using generative LLMs for classification tasks.\nIn this study, we empirically compare user intent classification into\ninformational, navigational, and transactional categories, using weak\nsupervision and LLMs. Specifically, we evaluate LLaMA-3.1-8B-Instruct and\nLLaMA-3.1-70B-Instruct for in-context learning and LLaMA-3.1-8B-Instruct for\nfine-tuning, comparing their performance to an established baseline classifier\ntrained using weak supervision (ORCAS-I). Our results indicate that while LLMs\noutperform weak supervision in recall, they continue to struggle with\nprecision, which shows the need for improved methods to balance both metrics\neffectively.\n","authors":["Daria Alexander","Arjen P. de Vries"],"pdf_url":"https://arxiv.org/pdf/2504.21398v2.pdf","comment":"accepted at International ACM SIGIR Conference on Research and\n  Development in Information Retrieval (SIGIR '25), July 13--18, 2025, Padua,\n  Italy"},{"id":"http://arxiv.org/abs/2506.12075v1","updated":"2025-06-06T17:20:02Z","published":"2025-06-06T17:20:02Z","title":"T-TExTS (Teaching Text Expansion for Teacher Scaffolding): Enhancing\n  Text Selection in High School Literature through Knowledge Graph-Based\n  Recommendation","summary":"  The implementation of transformational pedagogy in secondary education\nclassrooms requires a broad multiliteracy approach. Due to limited planning\ntime and resources, high school English Literature teachers often struggle to\ncurate diverse, thematically aligned literature text sets. This study addresses\nthe critical need for a tool that provides scaffolds for novice educators in\nselecting literature texts that are diverse -- in terms of genre, theme,\nsubtheme, and author -- yet similar in context and pedagogical merits. We have\ndeveloped a recommendation system, Teaching Text Expansion for Teacher\nScaffolding (T-TExTS), that suggests high school English Literature books based\non pedagogical merits, genre, and thematic relevance using a knowledge graph.\nWe constructed a domain-specific ontology using the KNowledge Acquisition and\nRepresentation Methodology (KNARM), transformed into a knowledge graph, which\nwas then embedded using DeepWalk, biased random walk, and a hybrid of both\napproaches. The system was evaluated using link prediction and recommendation\nperformance metrics, including Area Under the Curve (AUC), Mean Reciprocal Rank\n(MRR), Hits@K, and normalized Discounted Cumulative Gain (nDCG). DeepWalk\noutperformed in most ranking metrics, with the highest AUC (0.9431), whereas\nthe hybrid model offered balanced performance. These findings demonstrate the\nimportance of semantic, ontology-driven approaches in recommendation systems\nand suggest that T-TExTS can significantly ease the burden of English\nLiterature text selection for high school educators, promoting more informed\nand inclusive curricular decisions. The source code for T-TExTS is available\nat: https://github.com/koncordantlab/TTExTS\n","authors":["Nirmal Gelal","Chloe Snow","Ambyr Rios","Hande Küçük McGinty"],"pdf_url":"https://arxiv.org/pdf/2506.12075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04525v2","updated":"2025-06-06T17:19:41Z","published":"2025-06-05T00:14:40Z","title":"User Altruism in Recommendation Systems","summary":"  Users of social media platforms based on recommendation systems (RecSys)\n(e.g. TikTok, X, YouTube) strategically interact with platform content to\ninfluence future recommendations. On some such platforms, users have been\ndocumented to form large-scale grassroots movements encouraging others to\npurposefully interact with algorithmically suppressed content in order to\n\"boost\" its recommendation; we term this behavior user altruism. To capture\nthis behavior, we study a game between users and a RecSys, where users provide\nthe RecSys (potentially manipulated) preferences over the contents available to\nthem, and the RecSys -- limited by data and computation constraints -- creates\na low-rank approximation preference matrix, and ultimately provides each user\nher (approximately) most-preferred item. We compare the users' social welfare\nunder truthful preference reporting and under a class of strategies capturing\nuser altruism. In our theoretical analysis, we provide sufficient conditions to\nensure strict increases in user social welfare under user altruism, and provide\nan algorithm to find an effective altruistic strategy. Interestingly, we show\nthat for commonly assumed recommender utility functions, effectively altruistic\nstrategies also improve the utility of the RecSys! We show that our results are\nrobust to several model misspecifications, thus strengthening our conclusions.\nOur theoretical analysis is complemented by empirical results of effective\naltruistic strategies on the GoodReads dataset, and an online survey on how\nreal-world users behave altruistically in RecSys. Overall, our findings serve\nas a proof-of-concept of the reasons why traditional RecSys may incentivize\nusers to form collectives and/or follow altruistic strategies when interacting\nwith them.\n","authors":["Ekaterina Fedorova","Madeline Kitch","Chara Podimata"],"pdf_url":"https://arxiv.org/pdf/2506.04525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06239v1","updated":"2025-06-06T17:00:20Z","published":"2025-06-06T17:00:20Z","title":"Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for\n  Item-to-Item Retrieval in Recommendation","summary":"  The task of item-to-item (I2I) retrieval is to identify a set of relevant and\nhighly engaging items based on a given trigger item. It is a crucial component\nin modern recommendation systems, where users' previously engaged items serve\nas trigger items to retrieve relevant content for future engagement. However,\nexisting I2I retrieval models in industry are primarily built on co-engagement\ndata and optimized using the recall measure, which overly emphasizes\nco-engagement patterns while failing to capture semantic relevance. This often\nleads to overfitting short-term co-engagement trends at the expense of\nlong-term benefits such as discovering novel interests and promoting content\ndiversity. To address this challenge, we propose MTMH, a Multi-Task and\nMulti-Head I2I retrieval model that achieves both high recall and semantic\nrelevance. Our model consists of two key components: 1) a multi-task learning\nloss for formally optimizing the trade-off between recall and semantic\nrelevance, and 2) a multi-head I2I retrieval architecture for retrieving both\nhighly co-engaged and semantically relevant items. We evaluate MTMH using\nproprietary data from a commercial platform serving billions of users and\ndemonstrate that it can improve recall by up to 14.4% and semantic relevance by\nup to 56.6% compared with prior state-of-the-art models. We also conduct live\nexperiments to verify that MTMH can enhance both short-term consumption metrics\nand long-term user-experience-related metrics. Our work provides a principled\napproach for jointly optimizing I2I recall and semantic relevance, which has\nsignificant implications for improving the overall performance of\nrecommendation systems.\n","authors":["Jiang Zhang","Sumit Kumar","Wei Chang","Yubo Wang","Feng Zhang","Weize Mao","Hanchao Yu","Aashu Singh","Min Li","Qifan Wang"],"pdf_url":"https://arxiv.org/pdf/2506.06239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.24782v2","updated":"2025-06-06T16:42:11Z","published":"2025-05-30T16:43:28Z","title":"Context is Gold to find the Gold Passage: Evaluating and Training\n  Contextual Document Embeddings","summary":"  A limitation of modern document retrieval embedding methods is that they\ntypically encode passages (chunks) from the same documents independently, often\noverlooking crucial contextual information from the rest of the document that\ncould greatly improve individual chunk representations.\n  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), a\nbenchmark designed to evaluate retrieval models on their ability to leverage\ndocument-wide context. Our results show that state-of-the-art embedding models\nstruggle in retrieval scenarios where context is required. To address this\nlimitation, we propose InSeNT (In-sequence Negative Training), a novel\ncontrastive post-training approach which combined with late chunking pooling\nenhances contextual representation learning while preserving computational\nefficiency. Our method significantly improves retrieval quality on ConTEB\nwithout sacrificing base model performance. We further find chunks embedded\nwith our method are more robust to suboptimal chunking strategies and larger\nretrieval corpus sizes. We open-source all artifacts at\nhttps://github.com/illuin-tech/contextual-embeddings.\n","authors":["Max Conti","Manuel Faysse","Gautier Viaud","Antoine Bosselut","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2505.24782v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2506.06162v1","updated":"2025-06-06T15:27:23Z","published":"2025-06-06T15:27:23Z","title":"Recommender systems, stigmergy, and the tyranny of popularity","summary":"  Scientific recommender systems, such as Google Scholar and Web of Science,\nare essential tools for discovery. Search algorithms that power work through\nstigmergy, a collective intelligence mechanism that surfaces useful paths\nthrough repeated engagement. While generally effective, this\n``rich-get-richer'' dynamic results in a small number of high-profile papers\nthat dominate visibility. This essay argues argue that these algorithm\nover-reliance on popularity fosters intellectual homogeneity and exacerbates\nstructural inequities, stifling innovative and diverse perspectives critical\nfor scientific progress. We propose an overhaul of search platforms to\nincorporate user-specific calibration, allowing researchers to manually adjust\nthe weights of factors like popularity, recency, and relevance. We also advise\nplatform developers on how word embeddings and LLMs could be implemented in\nways that increase user autonomy. While our suggestions are particularly\npertinent to aligning recommender systems with scientific values, these ideas\nare broadly applicable to information access systems in general. Designing\nplatforms that increase user autonomy is an important step toward more robust\nand dynamic information\n","authors":["Zackary Okun Dunivin","Paul E. Smaldino"],"pdf_url":"https://arxiv.org/pdf/2506.06162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06144v1","updated":"2025-06-06T15:02:30Z","published":"2025-06-06T15:02:30Z","title":"CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval","summary":"  Online video web content is richly multimodal: a single video blends vision,\nspeech, ambient audio, and on-screen text. Retrieval systems typically treat\nthese modalities as independent retrieval sources, which can lead to noisy and\nsubpar retrieval. We explore multimodal video content retrieval, where\nrelevance can be scored from one particular modality or jointly across multiple\nmodalities simultaneously. Consequently, an effective retriever must\ndynamically choose which modality (or set of modalities) best addresses the\nquery. We introduce CLaMR, a multimodal, late-interaction retriever that\njointly indexes 4 modalities: video frames, transcribed speech, on-screen text,\nand metadata. CLaMR jointly encodes all modalities with a unified multimodal\nbackbone for improved contextualization and is trained to enhance dynamic\nmodality selection via two key innovations. First, given the lack of training\ndata for multimodal retrieval, we introduce MultiVENT 2.0++, a large-scale\nsynthetic training dataset built on MultiVENT 2.0 (event-centric videos in\nvarious languages paired with queries) with modality-targeted queries. Next, we\npropose a modality-aware loss that jointly trains according to a standard\ncontrastive objective alongside an objective for learning correct modality\nusage. On the test sets of MultiVENT 2.0++ and MSRVTT, conventional aggregation\nstrategies, such as averaging similarities for baseline retrievers, degrade\nperformance by introducing noise from irrelevant modalities. In contrast, CLaMR\nconsistently outperforms existing retrievers: on MultiVENT 2.0++, CLaMR\nimproves nDCG@10 by 25.6 over the best single-modality retriever and by 35.4\nover the best multi-modality retriever. We illustrate CLaMR's downstream\nutility on long-video QA, retrieving relevant frames and obtaining a 3.50%\nboost over LanguageBind on Video-MME and 1.42% over dense sampling on\nLongVideoBench.\n","authors":["David Wan","Han Wang","Elias Stengel-Eskin","Jaemin Cho","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2506.06144v1.pdf","comment":"18 pages. Code and data: https://github.com/meetdavidwan/clamr"},{"id":"http://arxiv.org/abs/2506.06117v1","updated":"2025-06-06T14:25:18Z","published":"2025-06-06T14:25:18Z","title":"Phonetically-Augmented Discriminative Rescoring for Voice Search Error\n  Correction","summary":"  End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using\npaired audio-text samples that are expensive to obtain, since high-quality\nground-truth data requires human annotators. Voice search applications, such as\ndigital media players, leverage ASR to allow users to search by voice as\nopposed to an on-screen keyboard. However, recent or infrequent movie titles\nmay not be sufficiently represented in the E2E ASR system's training data, and\nhence, may suffer poor recognition.\n  In this paper, we propose a phonetic correction system that consists of (a) a\nphonetic search based on the ASR model's output that generates phonetic\nalternatives that may not be considered by the E2E system, and (b) a rescorer\ncomponent that combines the ASR model recognition and the phonetic\nalternatives, and select a final system output.\n  We find that our approach improves word error rate between 4.4 and 7.6%\nrelative on benchmarks of popular movie titles over a series of competitive\nbaselines.\n","authors":["Christophe Van Gysel","Maggie Wu","Lyan Verwimp","Caglar Tirkaz","Marco Bertola","Zhihong Lei","Youssef Oualil"],"pdf_url":"https://arxiv.org/pdf/2506.06117v1.pdf","comment":"To appear at Interspeech '25"},{"id":"http://arxiv.org/abs/2506.06083v1","updated":"2025-06-06T13:43:12Z","published":"2025-06-06T13:43:12Z","title":"A Novel, Human-in-the-Loop Computational Grounded Theory Framework for\n  Big Social Data","summary":"  The availability of big data has significantly influenced the possibilities\nand methodological choices for conducting large-scale behavioural and social\nscience research. In the context of qualitative data analysis, a major\nchallenge is that conventional methods require intensive manual labour and are\noften impractical to apply to large datasets. One effective way to address this\nissue is by integrating emerging computational methods to overcome scalability\nlimitations. However, a critical concern for researchers is the trustworthiness\nof results when Machine Learning (ML) and Natural Language Processing (NLP)\ntools are used to analyse such data. We argue that confidence in the\ncredibility and robustness of results depends on adopting a 'human-in-the-loop'\nmethodology that is able to provide researchers with control over the\nanalytical process, while retaining the benefits of using ML and NLP. With this\nin mind, we propose a novel methodological framework for Computational Grounded\nTheory (CGT) that supports the analysis of large qualitative datasets, while\nmaintaining the rigour of established Grounded Theory (GT) methodologies. To\nillustrate the framework's value, we present the results of testing it on a\ndataset collected from Reddit in a study aimed at understanding tutors'\nexperiences in the gig economy.\n","authors":["Lama Alqazlan","Zheng Fang","Michael Castelle","Rob Procter"],"pdf_url":"https://arxiv.org/pdf/2506.06083v1.pdf","comment":"24 pages, 2 figures, 15 tables"},{"id":"http://arxiv.org/abs/2407.18327v2","updated":"2025-06-06T12:06:06Z","published":"2024-07-04T15:58:02Z","title":"The Structure of Financial Equity Research Reports -- Identification of\n  the Most Frequently Asked Questions in Financial Analyst Reports to Automate\n  Equity Research Using Llama 3 and GPT-4","summary":"  This research dissects financial equity research reports (ERRs) by mapping\ntheir content into categories. There is insufficient empirical analysis of the\nquestions answered in ERRs. In particular, it is not understood how frequently\ncertain information appears, what information is considered essential, and what\ninformation requires human judgment to distill into an ERR. The study analyzes\n72 ERRs sentence-by-sentence, classifying their 4940 sentences into 169 unique\nquestion archetypes. We did not predefine the questions but derived them solely\nfrom the statements in the ERRs. This approach provides an unbiased view of the\ncontent of the observed ERRs. Subsequently, we used public corporate reports to\nclassify the questions' potential for automation. Answers were labeled\n\"text-extractable\" if the answers to the question were accessible in corporate\nreports. 78.7% of the questions in ERRs can be automated. Those automatable\nquestion consist of 48.2% text-extractable (suited to processing by large\nlanguage models, LLMs) and 30.5% database-extractable questions. Only 21.3% of\nquestions require human judgment to answer. We empirically validate using\nLlama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language\ngeneration and information extraction enable the automation of approximately\n80% of the statements in ERRs. Surprisingly, the models complement each other's\nstrengths and weaknesses well. The research confirms that the current writing\nprocess of ERRs can likely benefit from additional automation, improving\nquality and efficiency. The research thus allows us to quantify the potential\nimpacts of introducing large language models in the ERR writing process. The\nfull question list, including the archetypes and their frequency, will be made\navailable online after peer review.\n","authors":["Adria Pop","Jan Spörer"],"pdf_url":"https://arxiv.org/pdf/2407.18327v2.pdf","comment":"JEL classes: C45; G11; G12; G14"},{"id":"http://arxiv.org/abs/2506.06015v1","updated":"2025-06-06T12:02:14Z","published":"2025-06-06T12:02:14Z","title":"On the Merits of LLM-Based Corpus Enrichment","summary":"  Generative AI (genAI) technologies -- specifically, large language models\n(LLMs) -- and search have evolving relations. We argue for a novel perspective:\nusing genAI to enrich a document corpus so as to improve query-based retrieval\neffectiveness. The enrichment is based on modifying existing documents or\ngenerating new ones. As an empirical proof of concept, we use LLMs to generate\ndocuments relevant to a topic which are more retrievable than existing ones. In\naddition, we demonstrate the potential merits of using corpus enrichment for\nretrieval augmented generation (RAG) and answer attribution in question\nanswering.\n","authors":["Gal Zur","Tommy Mordo","Moshe Tennenholtz","Oren Kurland"],"pdf_url":"https://arxiv.org/pdf/2506.06015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05939v1","updated":"2025-06-06T10:07:21Z","published":"2025-06-06T10:07:21Z","title":"Respecting Temporal-Causal Consistency: Entity-Event Knowledge Graphs\n  for Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) based on large language models often\nfalters on narrative documents with inherent temporal structures. Standard\nunstructured RAG methods rely solely on embedding-similarity matching and lack\nany general mechanism to encode or exploit chronological information, while\nknowledge graph RAG (KG-RAG) frameworks collapse every mention of an entity\ninto a single node, erasing the evolving context that drives many queries. To\nformalize this challenge and draw the community's attention, we construct\nChronoQA, a robust and discriminative QA benchmark that measures temporal,\ncausal, and character consistency understanding in narrative documents (e.g.,\nnovels) under the RAG setting. We then introduce Entity-Event RAG (E^2RAG), a\ndual-graph framework that keeps separate entity and event subgraphs linked by a\nbipartite mapping, thereby preserving the temporal and causal facets needed for\nfine-grained reasoning. Across ChronoQA, our approach outperforms\nstate-of-the-art unstructured and KG-based RAG baselines, with notable gains on\ncausal and character consistency queries. E^2RAG therefore offers a practical\npath to more context-aware retrieval for tasks that require precise answers\ngrounded in chronological information.\n","authors":["Ze Yu Zhang","Zitao Li","Yaliang Li","Bolin Ding","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2506.05939v1.pdf","comment":"24 pages, 4 figures"},{"id":"http://arxiv.org/abs/2506.05903v1","updated":"2025-06-06T09:22:21Z","published":"2025-06-06T09:22:21Z","title":"The NetMob25 Dataset: A High-resolution Multi-layered View of Individual\n  Mobility in Greater Paris Region","summary":"  High-quality mobility data remains scarce despite growing interest from\nresearchers and urban stakeholders in understanding individual-level movement\npatterns. The Netmob25 Data Challenge addresses this gap by releasing a unique\nGPS-based mobility dataset derived from the EMG 2023 GNSS-based mobility survey\nconducted in the Ile-de-France region (Greater Paris area), France. This\ndataset captures detailed daily mobility over a full week for 3,337 volunteer\nresidents aged 16 to 80, collected between October 2022 and May 2023. Each\nparticipant was equipped with a dedicated GPS tracking device configured to\nrecord location points every 2-3 seconds and was asked to maintain a digital or\npaper logbook of their trips. All inferred mobility traces were algorithmically\nprocessed and validated through follow-up phone interviews.\n  The dataset includes three components: (i) an Individuals database describing\ndemographic, socioeconomic, and household characteristics; (ii) a Trips\ndatabase with over 80,000 annotated displacements including timestamps,\ntransport modes, and trip purposes; and (iii) a Raw GPS Traces database\ncomprising about 500 million high-frequency points. A statistical weighting\nmechanism is provided to support population-level estimates. An extensive\nanonymization pipeline was applied to the GPS traces to ensure GDPR compliance\nwhile preserving analytical value. Access to the dataset requires acceptance of\nthe challenge's Terms and Conditions and signing a Non-Disclosure Agreement.\nThis paper describes the survey design, collection protocol, processing\nmethodology, and characteristics of the released dataset.\n","authors":["Alexandre Chasse","Anne J. Kouam","Aline C. Viana","Razvan Stanica","Wellington V. Lobato","Geymerson Ramos","Geoffrey Deperle","Abdelmounaim Bouroudi","Suzanne Bussod","Fernando Molano"],"pdf_url":"https://arxiv.org/pdf/2506.05903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05873v1","updated":"2025-06-06T08:41:33Z","published":"2025-06-06T08:41:33Z","title":"Research on Personalized Financial Product Recommendation by Integrating\n  Large Language Models and Graph Neural Networks","summary":"  With the rapid growth of fintech, personalized financial product\nrecommendations have become increasingly important. Traditional methods like\ncollaborative filtering or content-based models often fail to capture users'\nlatent preferences and complex relationships. We propose a hybrid framework\nintegrating large language models (LLMs) and graph neural networks (GNNs). A\npre-trained LLM encodes text data (e.g., user reviews) into rich feature\nvectors, while a heterogeneous user-product graph models interactions and\nsocial ties. Through a tailored message-passing mechanism, text and graph\ninformation are fused within the GNN to jointly optimize embeddings.\nExperiments on public and real-world financial datasets show our model\noutperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong\ninterpretability. This work offers new insights for personalized financial\nrecommendations and cross-modal fusion in broader recommendation tasks.\n","authors":["Yushang Zhao","Yike Peng","Dannier Li","Yuxin Yang","Chengrui Zhou","Jing Dong"],"pdf_url":"https://arxiv.org/pdf/2506.05873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05167v2","updated":"2025-06-06T07:57:28Z","published":"2025-06-05T15:43:49Z","title":"ECoRAG: Evidentiality-guided Compression for Long Context RAG","summary":"  Large Language Models (LLMs) have shown remarkable performance in Open-Domain\nQuestion Answering (ODQA) by leveraging external documents through\nRetrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer\ncontext, context compression is necessary. However, prior compression methods\ndo not focus on filtering out non-evidential information, which limit the\nperformance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or\nECoRAG framework. ECoRAG improves LLM performance by compressing retrieved\ndocuments based on evidentiality, ensuring whether answer generation is\nsupported by the correct evidence. As an additional step, ECoRAG reflects\nwhether the compressed content provides sufficient evidence, and if not,\nretrieves more until sufficient. Experiments show that ECoRAG improves LLM\nperformance on ODQA tasks, outperforming existing compression methods.\nFurthermore, ECoRAG is highly cost-efficient, as it not only reduces latency\nbut also minimizes token usage by retaining only the necessary information to\ngenerate the correct answer. Code is available at\nhttps://github.com/ldilab/ECoRAG.\n","authors":["Yeonseok Jeong","Jinsu Kim","Dohyeon Lee","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2506.05167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01713v3","updated":"2025-06-06T07:47:56Z","published":"2025-03-03T16:25:58Z","title":"SAGE: A Framework of Precise Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.\n","authors":["Jintao Zhang","Guoliang Li","Jinyang Su"],"pdf_url":"https://arxiv.org/pdf/2503.01713v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05781v1","updated":"2025-06-06T06:20:37Z","published":"2025-06-06T06:20:37Z","title":"Generating Long Semantic IDs in Parallel for Recommendation","summary":"  Semantic ID-based recommendation models tokenize each item into a small\nnumber of discrete tokens that preserve specific semantics, leading to better\nperformance, scalability, and memory efficiency. While recent models adopt a\ngenerative approach, they often suffer from inefficient inference due to the\nreliance on resource-intensive beam search and multiple forward passes through\nthe neural sequence model. As a result, the length of semantic IDs is typically\nrestricted (e.g. to just 4 tokens), limiting their expressiveness. To address\nthese challenges, we propose RPG, a lightweight framework for semantic ID-based\nrecommendation. The key idea is to produce unordered, long semantic IDs,\nallowing the model to predict all tokens in parallel. We train the model to\npredict each token independently using a multi-token prediction loss, directly\nintegrating semantics into the learning objective. During inference, we\nconstruct a graph connecting similar semantic IDs and guide decoding to avoid\ngenerating invalid IDs. Experiments show that scaling up semantic ID length to\n64 enables RPG to outperform generative baselines by an average of 12.6% on the\nNDCG@10, while also improving inference efficiency. Code is available at:\nhttps://github.com/facebookresearch/RPG_KDD2025.\n","authors":["Yupeng Hou","Jiacheng Li","Ashley Shin","Jinsung Jeon","Abhishek Santhanam","Wei Shao","Kaveh Hassani","Ning Yao","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2506.05781v1.pdf","comment":"KDD 2025"},{"id":"http://arxiv.org/abs/2502.13581v2","updated":"2025-06-06T06:11:42Z","published":"2025-02-19T09:45:29Z","title":"ActionPiece: Contextually Tokenizing Action Sequences for Generative\n  Recommendation","summary":"  Generative recommendation (GR) is an emerging paradigm where user actions are\ntokenized into discrete token patterns and autoregressively generated as\npredictions. However, existing GR models tokenize each action independently,\nassigning the same fixed tokens to identical actions across all sequences\nwithout considering contextual relationships. This lack of context-awareness\ncan lead to suboptimal performance, as the same action may hold different\nmeanings depending on its surrounding context. To address this issue, we\npropose ActionPiece to explicitly incorporate context when tokenizing action\nsequences. In ActionPiece, each action is represented as a set of item\nfeatures. Given the action sequence corpora, we construct the vocabulary by\nmerging feature patterns as new tokens, based on their co-occurrence frequency\nboth within individual sets and across adjacent sets. Considering the unordered\nnature of feature sets, we further introduce set permutation regularization,\nwhich produces multiple segmentations of action sequences with the same\nsemantics. Our code is available at:\nhttps://github.com/google-deepmind/action_piece.\n","authors":["Yupeng Hou","Jianmo Ni","Zhankui He","Noveen Sachdeva","Wang-Cheng Kang","Ed H. Chi","Julian McAuley","Derek Zhiyuan Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.13581v2.pdf","comment":"ICML 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2504.14493v3","updated":"2025-06-06T04:46:36Z","published":"2025-04-20T04:58:14Z","title":"FinSage: A Multi-aspect RAG System for Financial Filings Question\n  Answering","summary":"  Leveraging large language models in real-world settings often entails a need\nto utilize domain-specific data and tools in order to follow the complex\nregulations that need to be followed for acceptable use. Within financial\nsectors, modern enterprises increasingly rely on Retrieval-Augmented Generation\n(RAG) systems to address complex compliance requirements in financial document\nworkflows. However, existing solutions struggle to account for the inherent\nheterogeneity of data (e.g., text, tables, diagrams) and evolving nature of\nregulatory standards used in financial filings, leading to compromised accuracy\nin critical information extraction. We propose the FinSage framework as a\nsolution, utilizing a multi-aspect RAG framework tailored for regulatory\ncompliance analysis in multi-modal financial documents. FinSage introduces\nthree innovative components: (1) a multi-modal pre-processing pipeline that\nunifies diverse data formats and generates chunk-level metadata summaries, (2)\na multi-path sparse-dense retrieval system augmented with query expansion\n(HyDE) and metadata-aware semantic search, and (3) a domain-specialized\nre-ranking module fine-tuned via Direct Preference Optimization (DPO) to\nprioritize compliance-critical content. Extensive experiments demonstrate that\nFinSage achieves an impressive recall of 92.51% on 75 expert-curated questions\nderived from surpasses the best baseline method on the FinanceBench question\nanswering datasets by 24.06% in accuracy. Moreover, FinSage has been\nsuccessfully deployed as financial question-answering agent in online meetings,\nwhere it has already served more than 1,200 people.\n","authors":["Xinyu Wang","Jijun Chi","Zhenghan Tai","Tung Sum Thomas Kwok","Muzhi Li","Zhuhong Li","Hailin He","Yuchen Hua","Peng Lu","Suyuchen Wang","Yihong Wu","Jerry Huang","Jingrui Tian","Fengran Mo","Yufei Cui","Ling Zhou"],"pdf_url":"https://arxiv.org/pdf/2504.14493v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02883v3","updated":"2025-06-06T03:39:22Z","published":"2024-07-03T07:58:20Z","title":"CoIR: A Comprehensive Benchmark for Code Information Retrieval Models","summary":"  Despite the substantial success of Information Retrieval (IR) in various NLP\ntasks, most IR systems predominantly handle queries and corpora in natural\nlanguage, neglecting the domain of code retrieval. Code retrieval is critically\nimportant yet remains under-explored, with existing methods and benchmarks\ninadequately representing the diversity of code in various domains and tasks.\nAddressing this gap, we present COIR (Code Information Retrieval Benchmark), a\nrobust and comprehensive benchmark specifically designed to assess code\nretrieval capabilities. COIR comprises ten meticulously curated code datasets,\nspanning eight distinctive retrieval tasks across seven diverse domains. We\nfirst discuss the construction of COIR and its diverse dataset composition.\nFurther, we evaluate nine widely used retrieval models using COIR, uncovering\nsignificant difficulties in performing code retrieval tasks even with\nstate-of-the-art systems. To facilitate easy adoption and integration within\nexisting research workflows, COIR has been developed as a user-friendly Python\nframework, readily installable via pip. It shares same data schema as other\npopular benchmarks like MTEB and BEIR, enabling seamless cross-benchmark\nevaluations. Through COIR, we aim to invigorate research in the code retrieval\ndomain, providing a versatile benchmarking tool that encourages further\ndevelopment and exploration of code retrieval systems.\nhttps://github.com/CoIR-team/coir.\n","authors":["Xiangyang Li","Kuicai Dong","Yi Quan Lee","Wei Xia","Hao Zhang","Xinyi Dai","Yasheng Wang","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2407.02883v3.pdf","comment":"ACL 2025 Main"},{"id":"http://arxiv.org/abs/2412.17156v2","updated":"2025-06-06T02:27:49Z","published":"2024-12-22T20:45:15Z","title":"LLM-based relevance assessment still can't replace human relevance\n  assessment","summary":"  The use of large language models (LLMs) for relevance assessment in\ninformation retrieval has gained significant attention, with recent studies\nsuggesting that LLM-based judgments provide comparable evaluations to human\njudgments. Notably, based on TREC 2024 data, Upadhyay et al. make a bold claim\nthat LLM-based relevance assessments, such as those generated by the UMBRELA\nsystem, can fully replace traditional human relevance assessments in TREC-style\nevaluations. This paper critically examines this claim, highlighting practical\nand theoretical limitations that undermine the validity of this conclusion.\nFirst, we question whether the evidence provided by Upadhyay et al. really\nsupports their claim, particularly if a test collection is used asa benchmark\nfor future improvements. Second, through a submission deliberately intended to\ndo so, we demonstrate the ease with which automatic evaluation metrics can be\nsubverted, showing that systems designed to exploit these evaluations can\nachieve artificially high scores. Theoretical challenges -- such as the\ninherent narcissism of LLMs, the risk of overfitting to LLM-based metrics, and\nthe potential degradation of future LLM performance -- must be addressed before\nLLM-based relevance assessments can be considered a viable replacement for\nhuman judgments.\n","authors":["Charles L. A. Clarke","Laura Dietz"],"pdf_url":"https://arxiv.org/pdf/2412.17156v2.pdf","comment":"To appear in \"11th International Workshop on Evaluating Information\n  Access (EVIA 2025)\""},{"id":"http://arxiv.org/abs/2506.05685v1","updated":"2025-06-06T02:25:14Z","published":"2025-06-06T02:25:14Z","title":"NGA: Non-autoregressive Generative Auction with Global Externalities for\n  Advertising Systems","summary":"  Online advertising auctions are fundamental to internet commerce, demanding\nsolutions that not only maximize revenue but also ensure incentive\ncompatibility, high-quality user experience, and real-time efficiency. While\nrecent learning-based auction frameworks have improved context modeling by\ncapturing intra-list dependencies among ads, they remain limited in addressing\nglobal externalities and often suffer from inefficiencies caused by sequential\nprocessing. In this work, we introduce the Non-autoregressive Generative\nAuction with global externalities (NGA), a novel end-to-end framework designed\nfor industrial online advertising. NGA explicitly models global externalities\nby jointly capturing the relationships among ads as well as the effects of\nadjacent organic content. To further enhance efficiency, NGA utilizes a\nnon-autoregressive, constraint-based decoding strategy and a parallel\nmulti-tower evaluator for unified list-wise reward and payment computation.\nExtensive offline experiments and large-scale online A/B testing on commercial\nadvertising platforms demonstrate that NGA consistently outperforms existing\nmethods in both effectiveness and efficiency.\n","authors":["Zuowu Zheng","Ze Wang","Fan Yang","Wenqing Ye","Weihua Huang","Wenqiang He","Teng Zhang","Xingxing Wang"],"pdf_url":"https://arxiv.org/pdf/2506.05685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.14887v2","updated":"2025-06-06T00:23:25Z","published":"2025-03-19T04:30:20Z","title":"Pseudo Relevance Feedback is Enough to Close the Gap Between Small and\n  Large Dense Retrieval Models","summary":"  Scaling dense retrievers to larger large language model (LLM) backbones has\nbeen a dominant strategy for improving their retrieval effectiveness. However,\nthis has substantial cost implications: larger backbones require more expensive\nhardware (e.g. GPUs with more memory) and lead to higher indexing and querying\ncosts (latency, energy consumption). In this paper, we challenge this paradigm\nby introducing PromptPRF, a feature-based pseudo-relevance feedback (PRF)\nframework that enables small LLM-based dense retrievers to achieve\neffectiveness comparable to much larger models.\n  PromptPRF uses LLMs to extract query-independent, structured and unstructured\nfeatures (e.g., entities, summaries, chain-of-thought keywords, essay) from\ntop-ranked documents. These features are generated offline and integrated into\ndense query representations via prompting, enabling efficient retrieval without\nadditional training. Unlike prior methods such as GRF, which rely on online,\nquery-specific generation and sparse retrieval, PromptPRF decouples feedback\ngeneration from query processing and supports dense retrievers in a fully\nzero-shot setting.\n  Experiments on TREC DL and BEIR benchmarks demonstrate that PromptPRF\nconsistently improves retrieval effectiveness and offers favourable\ncost-effectiveness trade-offs. We further present ablation studies to\nunderstand the role of positional feedback and analyse the interplay between\nfeature extractor size, PRF depth, and model performance. Our findings\ndemonstrate that with effective PRF design, scaling the retriever is not always\nnecessary, narrowing the gap between small and large models while reducing\ninference cost.\n","authors":["Hang Li","Xiao Wang","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2503.14887v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.06541v1","updated":"2025-06-06T21:18:45Z","published":"2025-06-06T21:18:45Z","title":"KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over\n  Data Lakes","summary":"  Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench.\n","authors":["Eugenie Lai","Gerardo Vitagliano","Ziyu Zhang","Sivaprasad Sudhir","Om Chabra","Anna Zeng","Anton A. Zabreyko","Chenning Li","Ferdi Kossmann","Jialin Ding","Jun Chen","Markos Markakis","Matthew Russo","Weiyang Wang","Ziniu Wu","Michael J. Cafarella","Lei Cao","Samuel Madden","Tim Kraska"],"pdf_url":"https://arxiv.org/pdf/2506.06541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06784v2","updated":"2025-06-06T19:36:51Z","published":"2025-02-10T18:58:40Z","title":"RelGNN: Composite Message Passing for Relational Deep Learning","summary":"  Predictive tasks on relational databases are critical in real-world\napplications spanning e-commerce, healthcare, and social media. To address\nthese tasks effectively, Relational Deep Learning (RDL) encodes relational data\nas graphs, enabling Graph Neural Networks (GNNs) to exploit relational\nstructures for improved predictions. However, existing RDL methods often\noverlook the intrinsic structural properties of the graphs built from\nrelational databases, leading to modeling inefficiencies, particularly in\nhandling many-to-many relationships. Here we introduce RelGNN, a novel GNN\nframework specifically designed to leverage the unique structural\ncharacteristics of the graphs built from relational databases. At the core of\nour approach is the introduction of atomic routes, which are simple paths that\nenable direct single-hop interactions between the source and destination nodes.\nBuilding upon these atomic routes, RelGNN designs new composite message passing\nand graph attention mechanisms that reduce redundancy, highlight key signals,\nand enhance predictive accuracy. RelGNN is evaluated on 30 diverse real-world\ntasks from Relbench (Fey et al., 2024), and achieves state-of-the-art\nperformance on the vast majority of tasks, with improvements of up to 25%. Code\nis available at https://github.com/snap-stanford/RelGNN.\n","authors":["Tianlang Chen","Charilaos Kanatsoulis","Jure Leskovec"],"pdf_url":"https://arxiv.org/pdf/2502.06784v2.pdf","comment":"17 pages, 4 figures, 7 tables. ICML 2025"},{"id":"http://arxiv.org/abs/2306.02194v3","updated":"2025-06-06T15:54:16Z","published":"2023-06-03T20:53:22Z","title":"PathFinder: A unified approach for handling paths in graph query\n  languages","summary":"  Path queries are a core feature of modern graph query languages such as\nCypher, SQL/PGQ, and GQL. These languages provide a rich set of features for\nmatching paths, such as restricting to certain path modes (shortest, simple,\ntrail) and constraining the edge labels along the path by a regular expression.\nIn this paper we present PathFinder, a unifying approach for dealing with path\nqueries in all these query languages. PathFinder leverages a compact\nrepresentation of the (potentially exponential number of) paths that can match\na given query, extends it with pipelined execution, and supports all commonly\nused path modes. In the paper we describe the algorithmic backbone of\nPathFinder, provide a reference implementation, and test it over a large set of\nreal-world queries and datasets. Our results show that PathFinder exhibits very\nstable behavior, even on large data and complex queries, and its performance is\nan order of magnitude better than that of many modern graph engines.\n","authors":["Benjamín Farías","Wim Martens","Carlos Rojas","Domagoj Vrgoč"],"pdf_url":"https://arxiv.org/pdf/2306.02194v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06147v1","updated":"2025-06-06T15:09:32Z","published":"2025-06-06T15:09:32Z","title":"Stream DaQ: Stream-First Data Quality Monitoring","summary":"  Data quality is fundamental to modern data science workflows, where data\ncontinuously flows as unbounded streams feeding critical downstream tasks, from\nelementary analytics to advanced artificial intelligence models. Existing data\nquality approaches either focus exclusively on static data or treat streaming\nas an extension of batch processing, lacking the temporal granularity and\ncontextual awareness required for true streaming applications. In this paper,\nwe present a novel data quality monitoring model specifically designed for\nunbounded data streams. Our model introduces stream-first concepts, such as\nconfigurable windowing mechanisms, dynamic constraint adaptation, and\ncontinuous assessment that produces quality meta-streams for real-time pipeline\nawareness. To demonstrate practical applicability, we developed Stream DaQ, an\nopen-source Python framework that implements our theoretical model. Stream DaQ\nunifies and adapts over 30 quality checks fragmented across existing static\ntools into a comprehensive streaming suite, enabling practitioners to define\nsophisticated, context-aware quality constraints through compositional\nexpressiveness. Our evaluation demonstrates that the model's implementation\nsignificantly outperforms a production-grade alternative in both execution time\nand throughput while offering richer functionality via native streaming\ncapabilities compared to other choices. Through its Python-native design,\nStream DaQ seamlessly integrates with modern data science workflows, making\ncontinuous quality monitoring accessible to the broader data science community.\n","authors":["Vasileios Papastergios","Anastasios Gounaris"],"pdf_url":"https://arxiv.org/pdf/2506.06147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10720v3","updated":"2025-06-06T11:44:47Z","published":"2024-07-15T13:47:32Z","title":"Rethinking OWL Expressivity: Semantic Units for FAIR and Cognitively\n  Interoperable Knowledge Graphs Why OWLs don't have to understand everything\n  they say","summary":"  Semantic knowledge graphs are foundational to implementing the FAIR\nPrinciples, yet RDF/OWL representations often lack the semantic flexibility and\ncognitive interoperability required in scientific domains. We present a novel\nframework for semantic modularization based on semantic units (i.e., modular,\nsemantically coherent subgraphs enhancing expressivity, reusability, and\ninterpretability), combined with four new representational resource types\n(some-instance, most-instances, every-instance, all-instances) for modelling\nassertional, contingent, prototypical, and universal statements. The framework\nenables the integration of knowledge modelled using different logical\nframeworks (e.g., OWL, First-Order Logic, or none), provided each semantic unit\nis internally consistent and annotated with its logic base. This allows, for\nexample, querying all OWL 2.0-compliant units for reasoning purposes while\npreserving the full graph for broader knowledge discovery. Our framework\naddresses twelve core limitations of OWL/RDF modeling, including negation,\ncardinality, complex class axioms, conditional and directive statements, and\nlogical arguments, while improving cognitive accessibility for domain experts.\nWe provide schemata and translation patterns to demonstrate semantic\ninteroperability and reasoning potential, establishing a scalable foundation\nfor constructing FAIR-aligned, semantically rich knowledge graphs.\n","authors":["Lars Vogt"],"pdf_url":"https://arxiv.org/pdf/2407.10720v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2301.01227"},{"id":"http://arxiv.org/abs/2506.05900v1","updated":"2025-06-06T09:14:45Z","published":"2025-06-06T09:14:45Z","title":"Differentially Private Explanations for Clusters","summary":"  The dire need to protect sensitive data has led to various flavors of privacy\ndefinitions. Among these, Differential privacy (DP) is considered one of the\nmost rigorous and secure notions of privacy, enabling data analysis while\npreserving the privacy of data contributors. One of the fundamental tasks of\ndata analysis is clustering , which is meant to unravel hidden patterns within\ncomplex datasets. However, interpreting clustering results poses significant\nchallenges, and often necessitates an extensive analytical process.\nInterpreting clustering results under DP is even more challenging, as analysts\nare provided with noisy responses to queries, and longer, manual exploration\nsessions require additional noise to meet privacy constraints. While increasing\nattention has been given to clustering explanation frameworks that aim at\nassisting analysts by automatically uncovering the characteristics of each\ncluster, such frameworks may also disclose sensitive information within the\ndataset, leading to a breach in privacy. To address these challenges, we\npresent DPClustX, a framework that provides explanations for black-box\nclustering results while satisfying DP. DPClustX takes as input the sensitive\ndataset alongside privately computed clustering labels, and outputs a global\nexplanation, emphasizing prominent characteristics of each cluster while\nguaranteeing DP. We perform an extensive experimental analysis of DPClustX on\nreal data, showing that it provides insightful and accurate explanations even\nunder tight privacy constraints.\n","authors":["Amir Gilad","Tova Milo","Kathy Razmadze","Ron Zadicario"],"pdf_url":"https://arxiv.org/pdf/2506.05900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.12730v3","updated":"2025-06-06T08:22:50Z","published":"2025-03-17T01:47:50Z","title":"TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic\n  Interpretability Research","summary":"  Mechanistic interpretability research faces a gap between analyzing simple\ncircuits in toy tasks and discovering features in large models. To bridge this\ngap, we propose text-to-SQL generation as an ideal task to study, as it\ncombines the formal structure of toy tasks with real-world complexity. We\nintroduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL\noperations, and train models ranging from 33M to 1B parameters to establish a\ncomprehensive testbed for interpretability. We apply multiple complementary\ninterpretability techniques, including Edge Attribution Patching and Sparse\nAutoencoders, to identify minimal circuits and components supporting SQL\ngeneration. We compare circuits for different SQL subskills, evaluating their\nminimality, reliability, and identifiability. Finally, we conduct a layerwise\nlogit lens analysis to reveal how models compose SQL queries across layers:\nfrom intent recognition to schema resolution to structured generation. Our work\nprovides a robust framework for probing and comparing interpretability methods\nin a structured, progressively complex setting.\n","authors":["Abir Harrasse","Philip Quirke","Clement Neo","Dhruv Nathawani","Luke Marks","Amir Abdullah"],"pdf_url":"https://arxiv.org/pdf/2503.12730v3.pdf","comment":"9 pages, 19 figures, 7 tables, 18 trained models"},{"id":"http://arxiv.org/abs/2506.05853v1","updated":"2025-06-06T08:16:07Z","published":"2025-06-06T08:16:07Z","title":"Training-Free Query Optimization via LLM-Based Plan Similarity","summary":"  Large language model (LLM) embeddings offer a promising new avenue for\ndatabase query optimization. In this paper, we explore how pre-trained\nexecution plan embeddings can guide SQL query execution without the need for\nadditional model training. We introduce LLM-PM (LLM-based Plan Mapping), a\nframework that embeds the default execution plan of a query, finds its k\nnearest neighbors among previously executed plans, and recommends database\nhintsets based on neighborhood voting. A lightweight consistency check\nvalidates the selected hint, while a fallback mechanism searches the full hint\nspace when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM\nachieves an average speed-up of 21% query latency reduction. This work\nhighlights the potential of LLM-powered embeddings to deliver practical\nimprovements in query performance and opens new directions for training-free,\nembedding-based optimizer guidance systems.\n","authors":["Nikita Vasilenko","Alexander Demin","Vladimir Boorlakov"],"pdf_url":"https://arxiv.org/pdf/2506.05853v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.01713v3","updated":"2025-06-06T07:47:56Z","published":"2025-03-03T16:25:58Z","title":"SAGE: A Framework of Precise Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.\n","authors":["Jintao Zhang","Guoliang Li","Jinyang Su"],"pdf_url":"https://arxiv.org/pdf/2503.01713v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.15820v2","updated":"2025-06-06T07:34:47Z","published":"2025-02-06T12:02:23Z","title":"Common Data Format (CDF): A Standardized Format for Match-Data in\n  Football (Soccer)","summary":"  During football matches, a variety of different parties (e.g., companies)\neach collect (possibly overlapping) data about the match ranging from basic\ninformation (e.g., starting players) to detailed positional data. This data is\nprovided to clubs, federations, and other organizations who are increasingly\ninterested in leveraging this data to inform their decision making.\nUnfortunately, analyzing such data pose significant barriers because each\nprovider may (1) collect different data, (2) use different specifications even\nwithin the same category of data, (3) represent the data differently, and (4)\ndelivers the data in a different manner (e.g., file format, protocol).\nConsequently, working with these data requires a significant investment of time\nand money. The goal of this work is to propose a uniform and standardized\nformat for football data called the Common Data Format (CDF). The CDF specifies\na minimal schema for five types of match data: match sheet data, video footage,\nevent data, tracking data, and match meta data. It aims to ensure that the\nprovided data is clear, sufficiently contextualized (e.g., its provenance is\nclear), and complete such that it enables common downstream analysis tasks.\nConcretely, this paper will detail the technical specifications of the CDF, the\nrepresentational choices that were made to help ensure the clarity of the\nprovided data, and a concrete approach for delivering data in the CDF.\n","authors":["Gabriel Anzer","Kilian Arnsmeyer","Pascal Bauer","Joris Bekkers","Ulf Brefeld","Jesse Davis","Nicolas Evans","Matthias Kempe","Samuel J Robertson","Joshua Wyatt Smith","Jan Van Haaren"],"pdf_url":"https://arxiv.org/pdf/2505.15820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13284v3","updated":"2025-06-06T03:37:27Z","published":"2024-02-19T09:07:59Z","title":"Structure Guided Large Language Model for SQL Generation","summary":"  Recent advancements in large language models (LLMs) have shown promise in\nbridging the gap between natural language queries and database management\nsystems, enabling users to interact with databases without the background of\nSQL. However, LLMs often struggle to comprehend complex database structures and\naccurately interpret user intentions. Decomposition-based methods have been\nproposed to enhance the performance of LLMs on complex tasks, but decomposing\nSQL generation into subtasks is non-trivial due to the declarative structure of\nSQL syntax and the intricate connections between query concepts and database\nelements. In this paper, we propose a novel Structure GUided text-to-SQL\nframework~(SGU-SQL) that incorporates syntax-based prompting to enhance the SQL\ngeneration capabilities of LLMs. Specifically, SGU-SQL establishes\nstructure-aware links between user queries and database schema and decomposes\nthe complex generation task using syntax-based prompting to enable more\naccurate LLM-based SQL generation. Extensive experiments on two benchmark\ndatasets demonstrate that SGU-SQL consistently outperforms state-of-the-art\ntext-to-SQL models.\n","authors":["Qinggang Zhang","Hao Chen","Junnan Dong","Shengyuan Chen","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2402.13284v3.pdf","comment":"The 42nd International Conference on Machine Learning"}]},"2025-06-05T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.05625v1","updated":"2025-06-05T22:58:24Z","published":"2025-06-05T22:58:24Z","title":"Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning","summary":"  Graph-based recommendation systems use higher-order user and item embeddings\nfor next-item predictions. Dynamically adding collaborative signals from\nneighbors helps to use similar users' preferences during learning. While\nitem-item correlations and their impact on recommendations have been studied,\nthe efficacy of temporal item sequences for recommendations is much less\nexplored. In this paper, we examine temporal item sequence (sequel-aware)\nembeddings along with higher-order user embeddings and show that sequel-aware\nGraph Neural Networks have better (or comparable) recommendation performance\nthan graph-based recommendation systems that do not consider sequel\ninformation. Extensive empirical results comparing Heterogeneous Sequel-aware\nGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning\n(such as transformers, graph neural networks, auto-encoders) are presented on\nthree synthetic and three real-world datasets. Our results indicate that the\nincorporation of sequence information from items greatly enhances\nrecommendations.\n","authors":["Anushka Tiwari","Haimonti Dutta","Shahrzad Khanizadeh"],"pdf_url":"https://arxiv.org/pdf/2506.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.19868v2","updated":"2025-06-05T18:19:20Z","published":"2025-03-25T17:32:31Z","title":"GENIUS: A Generative Framework for Universal Multimodal Search","summary":"  Generative retrieval is an emerging approach in information retrieval that\ngenerates identifiers (IDs) of target data based on a query, providing an\nefficient alternative to traditional embedding-based retrieval methods.\nHowever, existing models are task-specific and fall short of embedding-based\nretrieval in performance. This paper proposes GENIUS, a universal generative\nretrieval framework supporting diverse tasks across multiple modalities and\ndomains. At its core, GENIUS introduces modality-decoupled semantic\nquantization, transforming multimodal data into discrete IDs encoding both\nmodality and semantics. Moreover, to enhance generalization, we propose a query\naugmentation that interpolates between a query and its target, allowing GENIUS\nto adapt to varied query forms. Evaluated on the M-BEIR benchmark, it surpasses\nprior generative methods by a clear margin. Unlike embedding-based retrieval,\nGENIUS consistently maintains high retrieval speed across database size, with\ncompetitive performance across multiple benchmarks. With additional re-ranking,\nGENIUS often achieves results close to those of embedding-based methods while\npreserving efficiency.\n","authors":["Sungyeon Kim","Xinliang Zhu","Xiaofan Lin","Muhammet Bastan","Douglas Gray","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2503.19868v2.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2506.05334v1","updated":"2025-06-05T17:59:26Z","published":"2025-06-05T17:59:26Z","title":"Search Arena: Analyzing Search-Augmented LLMs","summary":"  Search-augmented language models combine web search with Large Language\nModels (LLMs) to improve response groundedness and freshness. However,\nanalyzing these systems remains challenging: existing datasets are limited in\nscale and narrow in scope, often constrained to static, single-turn,\nfact-checking questions. In this work, we introduce Search Arena, a\ncrowd-sourced, large-scale, human-preference dataset of over 24,000 paired\nmulti-turn user interactions with search-augmented LLMs. The dataset spans\ndiverse intents and languages, and contains full system traces with around\n12,000 human preference votes. Our analysis reveals that user preferences are\ninfluenced by the number of citations, even when the cited content does not\ndirectly support the attributed claims, uncovering a gap between perceived and\nactual credibility. Furthermore, user preferences vary across cited sources,\nrevealing that community-driven platforms are generally preferred and static\nencyclopedic sources are not always appropriate and reliable. To assess\nperformance across different settings, we conduct cross-arena analyses by\ntesting search-augmented LLMs in a general-purpose chat environment and\nconventional LLMs in search-intensive settings. We find that web search does\nnot degrade and may even improve performance in non-search settings; however,\nthe quality in search settings is significantly affected if solely relying on\nthe model's parametric knowledge. We open-sourced the dataset to support future\nresearch in this direction. Our dataset and code are available at:\nhttps://github.com/lmarena/search-arena.\n","authors":["Mihran Miroyan","Tsung-Han Wu","Logan King","Tianle Li","Jiayi Pan","Xinyan Hu","Wei-Lin Chiang","Anastasios N. Angelopoulos","Trevor Darrell","Narges Norouzi","Joseph E. Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2506.05334v1.pdf","comment":"Preprint. Code: https://github.com/lmarena/search-arena. Dataset:\n  https://huggingface.co/datasets/lmarena-ai/search-arena-24k"},{"id":"http://arxiv.org/abs/2406.05085v3","updated":"2025-06-05T15:57:36Z","published":"2024-06-07T16:59:38Z","title":"Multi-Head RAG: Solving Multi-Aspect Problems with LLMs","summary":"  Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer's multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving observation is that different attention\nheads learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, multi-aspect datasets, and real-world\nuse cases to demonstrate MRAG's effectiveness. We show MRAG's design advantages\nover 18 RAG baselines, empirical improvements of up to 20% in retrieval success\nratios, and benefits for downstream LLM generation. MRAG can be seamlessly\nintegrated with existing RAG frameworks and benchmarks.\n","authors":["Maciej Besta","Ales Kubicek","Robert Gerstenberger","Marcin Chrapek","Roman Niggli","Patrik Okanovic","Yi Zhu","Patrick Iff","Michal Podstawski","Lucas Weitzendorf","Mingyuan Chi","Joanna Gajda","Piotr Nyczyk","Jürgen Müller","Hubert Niewiadomski","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2406.05085v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05182v1","updated":"2025-06-05T15:52:44Z","published":"2025-06-05T15:52:44Z","title":"On the Comprehensibility of Multi-structured Financial Documents using\n  LLMs and Pre-processing Tools","summary":"  The proliferation of complex structured data in hybrid sources, such as PDF\ndocuments and web pages, presents unique challenges for current Large Language\nModels (LLMs) and Multi-modal Large Language Models (MLLMs) in providing\naccurate answers. Despite the recent advancements of MLLMs, they still often\nfalter when interpreting intricately structured information, such as nested\ntables and multi-dimensional plots, leading to hallucinations and erroneous\noutputs. This paper explores the capabilities of LLMs and MLLMs in\nunderstanding and answering questions from complex data structures found in PDF\ndocuments by leveraging industrial and open-source tools as part of a\npre-processing pipeline. Our findings indicate that GPT-4o, a popular MLLM,\nachieves an accuracy of 56% on multi-structured documents when fed documents\ndirectly, and that integrating pre-processing tools raises the accuracy of LLMs\nto 61.3% for GPT-4o and 76% for GPT-4, and with lower overall cost. The code is\npublicly available at https://github.com/OGCDS/FinancialQA.\n","authors":["Shivani Upadhyay","Messiah Ataey","Shariyar Murtuza","Yifan Nie","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2506.05182v1.pdf","comment":"15 pages, 5 figures, 9 tables"},{"id":"http://arxiv.org/abs/2506.05154v1","updated":"2025-06-05T15:34:15Z","published":"2025-06-05T15:34:15Z","title":"Knowledgeable-r1: Policy Optimization for Knowledge Exploration in\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) is a mainstream method for improving\nperformance on knowledge-intensive tasks. However,current RAG systems often\nplace too much emphasis on retrieved contexts. This can lead to reliance on\ninaccurate sources and overlook the model's inherent knowledge, especially when\ndealing with misleading or excessive information. To resolve this imbalance, we\npropose Knowledgeable-r1 that using joint sampling and define multi policy\ndistributions in knowledge capability exploration to stimulate large language\nmodels'self-integrated utilization of parametric and contextual knowledge.\nExperiments show that Knowledgeable-r1 significantly enhances robustness and\nreasoning accuracy in both parameters and contextual conflict tasks and general\nRAG tasks, especially outperforming baselines by 17.07% in counterfactual\nscenarios and demonstrating consistent gains across RAG tasks. Our code are\navailable at https://github.com/lcy80366872/ knowledgeable-r1.\n","authors":["Chenyu Lin","Yilin Wen","Du Su","Fei Sun","Muhan Chen","Chenfu Bao","Zhonghou Lv"],"pdf_url":"https://arxiv.org/pdf/2506.05154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05044v1","updated":"2025-06-05T13:52:57Z","published":"2025-06-05T13:52:57Z","title":"Rethinking Contrastive Learning in Session-based Recommendation","summary":"  Session-based recommendation aims to predict intents of anonymous users based\non limited behaviors. With the ability in alleviating data sparsity,\ncontrastive learning is prevailing in the task. However, we spot that existing\ncontrastive learning based methods still suffer from three obstacles: (1) they\noverlook item-level sparsity and primarily focus on session-level sparsity; (2)\nthey typically augment sessions using item IDs like crop, mask and reorder,\nfailing to ensure the semantic consistency of augmented views; (3) they treat\nall positive-negative signals equally, without considering their varying\nutility. To this end, we propose a novel multi-modal adaptive contrastive\nlearning framework called MACL for session-based recommendation. In MACL, a\nmulti-modal augmentation is devised to generate semantically consistent views\nat both item and session levels by leveraging item multi-modal features.\nBesides, we present an adaptive contrastive loss that distinguishes varying\ncontributions of positive-negative signals to improve self-supervised learning.\nExtensive experiments on three real-world datasets demonstrate the superiority\nof MACL over state-of-the-art methods.\n","authors":["Xiaokun Zhang","Bo Xu","Fenglong Ma","Zhizheng Wang","Liang Yang","Hongfei Lin"],"pdf_url":"https://arxiv.org/pdf/2506.05044v1.pdf","comment":"This work has been accepted by Pattern Recognition"},{"id":"http://arxiv.org/abs/2506.04997v1","updated":"2025-06-05T13:06:01Z","published":"2025-06-05T13:06:01Z","title":"Towards Storage-Efficient Visual Document Retrieval: An Empirical Study\n  on Reducing Patch-Level Embeddings","summary":"  Despite the strong performance of ColPali/ColQwen2 in Visualized Document\nRetrieval (VDR), it encodes each page into multiple patch-level embeddings and\nleads to excessive memory usage. This empirical study investigates methods to\nreduce patch embeddings per page at minimum performance degradation. We\nevaluate two token-reduction strategies: token pruning and token merging.\nRegarding token pruning, we surprisingly observe that a simple random strategy\noutperforms other sophisticated pruning methods, though still far from\nsatisfactory. Further analysis reveals that pruning is inherently unsuitable\nfor VDR as it requires removing certain page embeddings without query-specific\ninformation. Turning to token merging (more suitable for VDR), we search for\nthe optimal combinations of merging strategy across three dimensions and\ndevelop Light-ColPali/ColQwen2. It maintains 98.2% of retrieval performance\nwith only 11.8% of original memory usage, and preserves 94.6% effectiveness at\n2.8% memory footprint. We expect our empirical findings and resulting\nLight-ColPali/ColQwen2 offer valuable insights and establish a competitive\nbaseline for future research towards efficient VDR.\n","authors":["Yubo Ma","Jinsong Li","Yuhang Zang","Xiaobao Wu","Xiaoyi Dong","Pan Zhang","Yuhang Cao","Haodong Duan","Jiaqi Wang","Yixin Cao","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2506.04997v1.pdf","comment":"Accepted by ACL 2025 findings"},{"id":"http://arxiv.org/abs/2506.04790v1","updated":"2025-06-05T09:17:30Z","published":"2025-06-05T09:17:30Z","title":"LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff\n  Table","summary":"  Approximate nearest neighbor search (ANNS) is an essential building block for\napplications like RAG but can sometimes yield results that are overly similar\nto each other. In certain scenarios, search results should be similar to the\nquery and yet diverse. We propose LotusFilter, a post-processing module to\ndiversify ANNS results. We precompute a cutoff table summarizing vectors that\nare close to each other. During the filtering, LotusFilter greedily looks up\nthe table to delete redundant vectors from the candidates. We demonstrated that\nthe LotusFilter operates fast (0.02 [ms/query]) in settings resembling\nreal-world RAG applications, utilizing features such as OpenAI embeddings. Our\ncode is publicly available at https://github.com/matsui528/lotf.\n","authors":["Yusuke Matsui"],"pdf_url":"https://arxiv.org/pdf/2506.04790v1.pdf","comment":"CVPR 2025. GitHub: https://github.com/matsui528/lotf"},{"id":"http://arxiv.org/abs/2506.04762v1","updated":"2025-06-05T08:45:48Z","published":"2025-06-05T08:45:48Z","title":"GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner\n  for Query Expansion in Information Retrieval","summary":"  Large language models (LLMs)-based query expansion for information retrieval\naugments queries with generated hypothetical documents with LLMs. However, its\nperformance relies heavily on the scale of the language models (LMs),\nnecessitating larger, more advanced LLMs. This approach is costly,\ncomputationally intensive, and often has limited accessibility. To address\nthese limitations, we introduce GOLFer - Smaller LMs-Generated Documents\nHallucination Filter & Combiner - a novel method leveraging smaller open-source\nLMs for query expansion. GOLFer comprises two modules: a hallucination filter\nand a documents combiner. The former detects and removes non-factual and\ninconsistent sentences in generated documents, a common issue with smaller LMs,\nwhile the latter combines the filtered content with the query using a weight\nvector to balance their influence. We evaluate GOLFer alongside dominant\nLLM-based query expansion methods on three web search and ten low-resource\ndatasets. Experimental results demonstrate that GOLFer consistently outperforms\nother methods using smaller LMs, and maintains competitive performance against\nmethods using large-size LLMs, demonstrating its effectiveness.\n","authors":["Lingyuan Liu","Mengxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.04762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04760v1","updated":"2025-06-05T08:44:34Z","published":"2025-06-05T08:44:34Z","title":"Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using\n  Large Language Model-based Query Expansion","summary":"  Large Language Models (LLMs) have shown potential in generating hypothetical\ndocuments for query expansion, thereby enhancing information retrieval\nperformance. However, the efficacy of this method is highly dependent on the\nquality of the generated documents, which often requires complex prompt\nstrategies and the integration of advanced dense retrieval techniques. This can\nbe both costly and computationally intensive. To mitigate these limitations, we\nexplore the use of zero-shot LLM-based query expansion to improve sparse\nretrieval, particularly for learned sparse retrievers. We introduce a novel\nfusion ranking framework, Exp4Fuse, which enhances the performance of sparse\nretrievers through an indirect application of zero-shot LLM-based query\nexpansion. Exp4Fuse operates by simultaneously considering two retrieval\nroutes-one based on the original query and the other on the LLM-augmented\nquery. It then generates two ranked lists using a sparse retriever and fuses\nthem using a modified reciprocal rank fusion method. We conduct extensive\nevaluations of Exp4Fuse against leading LLM-based query expansion methods and\nadvanced retrieval techniques on three MS MARCO-related datasets and seven\nlow-resource datasets. Experimental results reveal that Exp4Fuse not only\nsurpasses existing LLM-based query expansion methods in enhancing sparse\nretrievers but also, when combined with advanced sparse retrievers, achieves\nSOTA results on several benchmarks. This highlights the superior performance\nand effectiveness of Exp4Fuse in improving query expansion for sparse\nretrieval.\n","authors":["Lingyuan Liu","Mengxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.04760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04551v1","updated":"2025-06-05T01:57:36Z","published":"2025-06-05T01:57:36Z","title":"PUB: An LLM-Enhanced Personality-Driven User Behaviour Simulator for\n  Recommender System Evaluation","summary":"  Traditional offline evaluation methods for recommender systems struggle to\ncapture the complexity of modern platforms due to sparse behavioural signals,\nnoisy data, and limited modelling of user personality traits. While simulation\nframeworks can generate synthetic data to address these gaps, existing methods\nfail to replicate behavioural diversity, limiting their effectiveness. To\novercome these challenges, we propose the Personality-driven User Behaviour\nSimulator (PUB), an LLM-based simulation framework that integrates the Big Five\npersonality traits to model personalised user behaviour. PUB dynamically infers\nuser personality from behavioural logs (e.g., ratings, reviews) and item\nmetadata, then generates synthetic interactions that preserve statistical\nfidelity to real-world data. Experiments on the Amazon review datasets show\nthat logs generated by PUB closely align with real user behaviour and reveal\nmeaningful associations between personality traits and recommendation outcomes.\nThese results highlight the potential of the personality-driven simulator to\nadvance recommender system evaluation, offering scalable, controllable,\nhigh-fidelity alternatives to resource-intensive real-world experiments.\n","authors":["Chenglong Ma","Ziqi Xu","Yongli Ren","Danula Hettiachchi","Jeffrey Chan"],"pdf_url":"https://arxiv.org/pdf/2506.04551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12072v1","updated":"2025-06-05T01:48:09Z","published":"2025-06-05T01:48:09Z","title":"WebTrust: An AI-Driven Data Scoring System for Reliable Information\n  Retrieval","summary":"  As access to information becomes more open and widespread, people are\nincreasingly using AI tools for assistance. However, many of these tools\nstruggle to estimate the trustworthiness of the information. Although today's\nsearch engines include AI features, they often fail to offer clear indicators\nof data reliability. To address this gap, we introduce WebTrust, a system\ndesigned to simplify the process of finding and judging credible information\nonline. Built on a fine-tuned version of IBM's Granite-1B model and trained on\na custom dataset, WebTrust works by assigning a reliability score (from 0.1 to\n1) to each statement it processes. In addition, it offers a clear justification\nfor why a piece of information received that score. Evaluated using prompt\nengineering, WebTrust consistently achieves superior performance compared to\nother small-scale LLMs and rule-based approaches, outperforming them across all\nexperiments on MAE, RMSE, and R2. User testing showed that when reliability\nscores are displayed alongside search results, people feel more confident and\nsatisfied with the information they find. With its accuracy, transparency, and\nease of use, WebTrust offers a practical solution to help combat misinformation\nand make trustworthy information more accessible to everyone.\n","authors":["Joydeep Chandra","Aleksandr Algazinov","Satyam Kumar Navneet","Rim El Filali","Matt Laing","Andrew Hanna"],"pdf_url":"https://arxiv.org/pdf/2506.12072v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.05587v1","updated":"2025-06-05T21:05:03Z","published":"2025-06-05T21:05:03Z","title":"MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark","summary":"  Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.\n","authors":["Junjie Xing","Yeye He","Mengyu Zhou","Haoyu Dong","Shi Han","Lingjiao Chen","Dongmei Zhang","Surajit Chaudhuri","H. V. Jagadish"],"pdf_url":"https://arxiv.org/pdf/2506.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06396v1","updated":"2025-06-05T20:52:13Z","published":"2025-06-05T20:52:13Z","title":"Natural Language Interaction with Databases on Edge Devices in the\n  Internet of Battlefield Things","summary":"  The expansion of the Internet of Things (IoT) in the battlefield, Internet of\nBattlefield Things (IoBT), gives rise to new opportunities for enhancing\nsituational awareness. To increase the potential of IoBT for situational\nawareness in critical decision making, the data from these devices must be\nprocessed into consumer-ready information objects, and made available to\nconsumers on demand. To address this challenge we propose a workflow that makes\nuse of natural language processing (NLP) to query a database technology and\nreturn a response in natural language. Our solution utilizes Large Language\nModels (LLMs) that are sized for edge devices to perform NLP as well as\ngraphical databases which are well suited for dynamic connected networks which\nare pervasive in the IoBT. Our architecture employs LLMs for both mapping\nquestions in natural language to Cypher database queries as well as to\nsummarize the database output back to the user in natural language. We evaluate\nseveral medium sized LLMs for both of these tasks on a database representing\npublicly available data from the US Army's Multipurpose Sensing Area (MSA) at\nthe Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion\nparameters) outperforms the other models across all the considered metrics.\nMost importantly, we note that, unlike current methods, our two step approach\nallows the relaxation of the Exact Match (EM) requirement of the produced\nCypher queries with ground truth code and, in this way, it achieves a 19.4%\nincrease in accuracy. Our workflow lays the ground work for deploying LLMs on\nedge devices to enable natural language interactions with databases containing\ninformation objects for critical decision making.\n","authors":["Christopher D. Molek","Roberto Fronteddu","K. Brent Venable","Niranjan Suri"],"pdf_url":"https://arxiv.org/pdf/2506.06396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02345v2","updated":"2025-06-05T20:30:55Z","published":"2025-06-03T00:52:06Z","title":"PandasBench: A Benchmark for the Pandas API","summary":"  The Pandas API has been central to the success of pandas and its\nalternatives. Despite its importance, there is no benchmark for it, and we\nargue that we cannot repurpose existing benchmarks (from other domains) for the\nPandas API.\n  In this paper, we introduce requirements that are necessary for a Pandas API\nenchmark, and present the first benchmark that fulfills them: PandasBench. We\nargue that it should evaluate the real-world coverage of a technique. Yet,\nreal-world coverage is not sufficient for a useful benchmark, and so we also:\ncleaned it from irrelevant code, adapted it for benchmark usage, and introduced\ninput scaling. We claim that uniform scaling used in other benchmarks (e.g.,\nTPC-H) is too coarse-grained for PandasBench, and use a non-uniform scaling\nscheme. PandasBench is the largest Pandas API benchmark to date, with 102\nnotebooks and 3,721 cells.\n  We used PandasBench to evaluate Modin, Dask, Koalas, and Dias. This is the\nlargest-scale evaluation of all these techniques to date. Prior works report\nsignificant speedups using constrained benchmarks, but we show that on a larger\nbenchmark with real-world code, the most notebooks that got a speedup were\n8/102 (~8%) for Modin, and 0 for both Koalas and Dask. Dias showed speedups in\nup to 55 notebooks (~54%), but it rewrites code incorrectly in certain cases,\nwhich had not been observed in prior work. Second, we identified many failures:\nModin runs only 72/102 (~70%) notebooks, Dask 4 (~4%), Koalas 10 (~10%), and\nDias 97 (95%).\n","authors":["Alex Broihier","Stefanos Baziotis","Daniel Kang","Charith Mendis"],"pdf_url":"https://arxiv.org/pdf/2506.02345v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05071v1","updated":"2025-06-05T14:19:05Z","published":"2025-06-05T14:19:05Z","title":"Memory Hierarchy Design for Caching Middleware in the Age of NVM","summary":"  Advances in storage technology have introduced Non-Volatile Memory, NVM, as a\nnew storage medium. NVM, along with Dynamic Random Access Memory (DRAM), Solid\nState Disk (SSD), and Disk present a system designer with a wide array of\noptions in designing caching middleware. Moreover, design decisions to\nreplicate a data item in more than one level of a caching memory hierarchy may\nenhance the overall system performance with a faster recovery time in the event\nof a memory failure. Given a fixed budget, the key configuration questions are:\nWhich storage media should constitute the memory hierarchy? What is the storage\ncapacity of each hierarchy? Should data be replicated or partitioned across the\ndifferent levels of the hierarchy? We model these cache configuration questions\nas an instance of the Multiple Choice Knapsack Problem (MCKP). This model is\nguided by the specification of each type of memory along with an application's\ndatabase characteristics and its workload. Although MCKP is NP-complete, its\nlinear programming relaxation is efficiently solvable and can be used to\nclosely approximate the optimal solution. We use the resulting simple algorithm\nto evaluate design tradeoffs in the context of a memory hierarchy for a\nKey-Value Store (e.g., memcached) as well as a host-side cache (e.g.,\nFlashcache). The results show selective replication is appropriate with certain\nfailure rates and workload characteristics. With a slim failure rate and\nfrequent data updates, tiering of data across the different storage media that\nconstitute the cache is superior to replication.\n","authors":["Shahram Ghandeharizadeh","Sandy Irani","Jenny Lam"],"pdf_url":"https://arxiv.org/pdf/2506.05071v1.pdf","comment":"A shorter version appeared in the IEEE 34th International Conference\n  on Data Engineering (ICDE), Paris, France, 2018, pp. 1380-1383, doi:\n  10.1109/ICDE.2018.00155"},{"id":"http://arxiv.org/abs/2406.03965v2","updated":"2025-06-05T14:04:28Z","published":"2024-06-06T11:22:57Z","title":"More Bang For Your Buck(et): Fast and Space-efficient\n  Hardware-accelerated Coarse-granular Indexing on GPUs","summary":"  In recent work, we have shown that NVIDIA's raytracing cores on RTX video\ncards can be exploited to realize hardware-accelerated lookups for GPU-resident\ndatabase indexes. On a high level, the concept materializes all keys as\ntriangles in a 3D scene and indexes them. Lookups are performed by firing rays\ninto the scene and utilizing the index structure to detect hits in a\nhardware-accelerated fashion. While this approach called RTIndeX (or short RX)\nis indeed promising, it currently suffers from three limitations: (1)\nsignificant memory overhead per key, (2) slow range-lookups, and (3) poor\nupdateability. In this work, we show that all three problems can be tackled by\na single design change: Generalizing RX to become a coarse-granular index cgRX.\nInstead of indexing individual keys, cgRX indexes buckets of keys which are\npost-filtered after retrieval. This drastically reduces the memory overhead,\nleads to the generation of a smaller and more efficient index structure, and\nenables fast range-lookups as well as updates. We will see that representing\nthe buckets in the 3D space such that the lookup of a key is performed both\ncorrectly and efficiently requires the careful orchestration of firing rays in\na specific sequence. Our experimental evaluation shows that cgRX offers the\nmost bang for the buck(et) by providing a throughput in relation to the memory\nfootprint that is 1.5-3x higher than for the comparable range-lookup supporting\nbaselines. At the same time, cgRX improves the range-lookup performance over RX\nby up to 2x and offers practical updateability that is up to 5.6x faster than\nrebuilding from scratch.\n","authors":["Justus Henneberg","Felix Schuhknecht","Rosina Kharal","Trevor Brown"],"pdf_url":"https://arxiv.org/pdf/2406.03965v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03308v2","updated":"2025-06-05T08:23:12Z","published":"2025-06-03T18:48:17Z","title":"Hermes: High-Performance Homomorphically Encrypted Vector Databases","summary":"  Fully Homomorphic Encryption (FHE) has long promised the ability to compute\nover encrypted data without revealing sensitive contents -- a foundational goal\nfor secure cloud analytics. Yet despite decades of cryptographic advances,\npractical integration of FHE into real-world relational databases remains\nelusive. This paper presents \\textbf{Hermes}, the first system to enable\nFHE-native vector query processing inside a standard SQL engine. By leveraging\nthe multi-slot capabilities of modern schemes, Hermes introduces a novel data\nmodel that packs multiple records per ciphertext and embeds encrypted auxiliary\nstatistics (e.g., local sums) to support in-place updates and aggregation. To\nreconcile ciphertext immutability with record-level mutability, we develop new\nhomomorphic algorithms based on slot masking, shifting, and rewriting. Hermes\nis implemented as native C++ loadable functions in MySQL using OpenFHE v1.2.4,\ncomprising over 3,500 lines of code. Experiments on real-world datasets show up\nto 1{,}600$\\times$ throughput gain in encryption and over 30$\\times$ speedup in\ninsertion compared to per-tuple baselines. Hermes brings FHE from cryptographic\npromise to practical reality -- realizing a long-standing vision at the\nintersection of databases and secure computation.\n","authors":["Dongfang Zhao"],"pdf_url":"https://arxiv.org/pdf/2506.03308v2.pdf","comment":null}]},"2025-06-04T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.04422v1","updated":"2025-06-04T20:13:42Z","published":"2025-06-04T20:13:42Z","title":"I'm Sorry Dave, I'm Afraid I Can't Return That: On YouTube Search API\n  Use in Research","summary":"  YouTube is among the most widely-used platforms worldwide, and has seen a lot\nof recent academic attention. Despite its popularity and the number of studies\nconducted on it, much less is understood about the way in which YouTube's Data\nAPI, and especially the Search endpoint, operates. In this paper, we analyze\nthe API's behavior by running identical queries across a period of 12 weeks.\nOur findings suggest that the search endpoint returns highly inconsistent\nresults between queries in ways that are not officially documented.\nSpecifically, the API seems to randomize returned videos based on the relative\npopularity of the respective topic during the query period, making it nearly\nimpossible to obtain representative historical video samples, especially during\nnon-peak topical periods. Our results also suggest that the API may prioritize\nshorter, more popular videos, although the role of channel popularity is not as\nclear. We conclude with suggested strategies for researchers using the API for\ndata collection, as well as future research directions on expanding the API's\nuse-cases.\n","authors":["Alexandros Efstratiou"],"pdf_url":"https://arxiv.org/pdf/2506.04422v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2505.18247v2","updated":"2025-06-04T20:03:54Z","published":"2025-05-23T17:18:45Z","title":"MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized\n  Domain Question-Answering","summary":"  Retrieval-Augmented Generation (RAG) struggles with domain-specific\nenterprise datasets, often isolated behind firewalls and rich in complex,\nspecialized terminology unseen by LLMs during pre-training. Semantic\nvariability across domains like medicine, networking, or law hampers RAG's\ncontext precision, while fine-tuning solutions are costly, slow, and lack\ngeneralization as new data emerges. Achieving zero-shot precision with\nretrievers without fine-tuning still remains a key challenge. We introduce\n'MetaGen Blended RAG', a novel enterprise search approach that enhances\nsemantic retrievers through a metadata generation pipeline and hybrid query\nindexes using dense and sparse vectors. By leveraging key concepts, topics, and\nacronyms, our method creates metadata-enriched semantic indexes and boosted\nhybrid queries, delivering robust, scalable performance without fine-tuning. On\nthe biomedical PubMedQA dataset, MetaGen Blended RAG achieves 82% retrieval\naccuracy and 77% RAG accuracy, surpassing all prior zero-shot RAG benchmarks\nand even rivaling fine-tuned models on that dataset, while also excelling on\ndatasets like SQuAD and NQ. This approach redefines enterprise search using a\nnew approach to building semantic retrievers with unmatched generalization\nacross specialized domains.\n","authors":["Kunal Sawarkar","Shivam R. Solanki","Abhilasha Mangal"],"pdf_url":"https://arxiv.org/pdf/2505.18247v2.pdf","comment":"Preprint. Paper Submitted for NeurIPS 2025- The Thirty-Ninth Annual\n  Conference on Neural Information Processing Systems"},{"id":"http://arxiv.org/abs/2506.04140v1","updated":"2025-06-04T16:31:44Z","published":"2025-06-04T16:31:44Z","title":"Quantifying Query Fairness Under Unawareness","summary":"  Traditional ranking algorithms are designed to retrieve the most relevant\nitems for a user's query, but they often inherit biases from data that can\nunfairly disadvantage vulnerable groups. Fairness in information access systems\n(IAS) is typically assessed by comparing the distribution of groups in a\nranking to a target distribution, such as the overall group distribution in the\ndataset. These fairness metrics depend on knowing the true group labels for\neach item. However, when groups are defined by demographic or sensitive\nattributes, these labels are often unknown, leading to a setting known as\n\"fairness under unawareness\". To address this, group membership can be inferred\nusing machine-learned classifiers, and group prevalence is estimated by\ncounting the predicted labels. Unfortunately, such an estimation is known to be\nunreliable under dataset shift, compromising the accuracy of fairness\nevaluations. In this paper, we introduce a robust fairness estimator based on\nquantification that effectively handles multiple sensitive attributes beyond\nbinary classifications. Our method outperforms existing baselines across\nvarious sensitive attributes and, to the best of our knowledge, is the first to\nestablish a reliable protocol for measuring fairness under unawareness across\nmultiple queries and groups.\n","authors":["Thomas Jaenich","Alejandro Moreo","Alessandro Fabris","Graham McDonald","Andrea Esuli","Iadh Ounis","Fabrizio Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2506.04140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.11085v1","updated":"2025-06-04T16:09:54Z","published":"2025-06-04T16:09:54Z","title":"LeanExplore: A search engine for Lean 4 declarations","summary":"  The expanding Lean 4 ecosystem poses challenges for navigating its vast\nlibraries. This paper introduces LeanExplore, a search engine for Lean 4\ndeclarations. LeanExplore enables users to semantically search for statements,\nboth formally and informally, across select Lean 4 packages (including\nBatteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is\npowered by a hybrid ranking strategy, integrating scores from a multi-source\nsemantic embedding model (capturing conceptual meaning from formal Lean code,\ndocstrings, AI-generated informal translations, and declaration titles), BM25+\nfor keyword-based lexical relevance, and a PageRank-based score reflecting\ndeclaration importance and interconnectedness. The search engine is accessible\nvia a dedicated website (https://www.leanexplore.com/) and a Python API\n(https://github.com/justincasher/lean-explore). Furthermore, the database can\nbe downloaded, allowing users to self-host the service. LeanExplore integrates\neasily with LLMs via the model context protocol (MCP), enabling users to chat\nwith an AI assistant about Lean declarations or utilize the search engine for\nbuilding theorem-proving agents. This work details LeanExplore's architecture,\ndata processing, functionalities, and its potential to enhance Lean 4 workflows\nand AI-driven mathematical research\n","authors":["Justin Asher"],"pdf_url":"https://arxiv.org/pdf/2506.11085v1.pdf","comment":"16 pages, 1 figure. Project website: https://www.leanexplore.com/ ,\n  Code: https://github.com/justincasher/lean-explore"},{"id":"http://arxiv.org/abs/2503.18223v2","updated":"2025-06-04T15:54:37Z","published":"2025-03-23T21:51:58Z","title":"MammAlps: A multi-view video behavior monitoring dataset of wild mammals\n  in the Swiss Alps","summary":"  Monitoring wildlife is essential for ecology and ethology, especially in\nlight of the increasing human impact on ecosystems. Camera traps have emerged\nas habitat-centric sensors enabling the study of wildlife populations at scale\nwith minimal disturbance. However, the lack of annotated video datasets limits\nthe development of powerful video understanding models needed to process the\nvast amount of fieldwork data collected. To advance research in wild animal\nbehavior monitoring we present MammAlps, a multimodal and multi-view dataset of\nwildlife behavior monitoring from 9 camera-traps in the Swiss National Park.\nMammAlps contains over 14 hours of video with audio, 2D segmentation maps and\n8.5 hours of individual tracks densely labeled for species and behavior. Based\non 6135 single animal clips, we propose the first hierarchical and multimodal\nanimal behavior recognition benchmark using audio, video and reference scene\nsegmentation maps as inputs. Furthermore, we also propose a second\necology-oriented benchmark aiming at identifying activities, species, number of\nindividuals and meteorological conditions from 397 multi-view and long-term\necological events, including false positive triggers. We advocate that both\ntasks are complementary and contribute to bridging the gap between machine\nlearning and ecology. Code and data are available at:\nhttps://github.com/eceo-epfl/MammAlps\n","authors":["Valentin Gabeff","Haozhe Qi","Brendan Flaherty","Gencer Sumbül","Alexander Mathis","Devis Tuia"],"pdf_url":"https://arxiv.org/pdf/2503.18223v2.pdf","comment":"CVPR 2025; Benchmark and code at:\n  https://github.com/eceo-epfl/MammAlps. After submission of v1, we noticed\n  that a few audio files were not correctly aligned with the corresponding\n  video. We fixed the issue, which had little to no impact on performance. We\n  also now report results for three runs"},{"id":"http://arxiv.org/abs/2506.12071v1","updated":"2025-06-04T15:50:55Z","published":"2025-06-04T15:50:55Z","title":"T$^2$-RAGBench: Text-and-Table Benchmark for Evaluating\n  Retrieval-Augmented Generation","summary":"  While most financial documents contain a combination of textual and tabular\ninformation, robust Retrieval-Augmented Generation (RAG) systems are essential\nfor effectively accessing and reasoning over such content to perform complex\nnumerical tasks. This paper introduces T$^2$-RAGBench, a benchmark comprising\n32,908 question-context-answer triples, designed to evaluate RAG methods on\nreal-world financial data. Unlike typical QA datasets that operate under\nOracle-context settings, where the relevant context is explicitly provided,\nT$^2$-RAGBench challenges models to first retrieve the correct context before\nconducting numerical reasoning. Existing QA datasets involving text and tables\ntypically contain context-dependent questions, which may yield multiple correct\nanswers depending on the provided context. To address this, we transform these\ndatasets into a context-independent format, enabling reliable RAG evaluation.\nWe conduct a comprehensive evaluation of popular RAG methods. Our analysis\nidentifies Hybrid BM25, a technique that combines dense and sparse vectors, as\nthe most effective approach for text-and-table data. However, results\ndemonstrate that T$^2$-RAGBench remains challenging even for SOTA LLMs and RAG\nmethods. Further ablation studies examine the impact of embedding models and\ncorpus size on retrieval performance. T$^2$-RAGBench provides a realistic and\nrigorous benchmark for existing RAG methods on text-and-table data. Code and\ndataset are available online.\n","authors":["Jan Strich","Enes Kutay Isgorur","Maximilian Trescher","Chris Biemann","Martin Semmann"],"pdf_url":"https://arxiv.org/pdf/2506.12071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04083v1","updated":"2025-06-04T15:44:50Z","published":"2025-06-04T15:44:50Z","title":"A Generative Adaptive Replay Continual Learning Model for Temporal\n  Knowledge Graph Reasoning","summary":"  Recent Continual Learning (CL)-based Temporal Knowledge Graph Reasoning\n(TKGR) methods focus on significantly reducing computational cost and\nmitigating catastrophic forgetting caused by fine-tuning models with new data.\nHowever, existing CL-based TKGR methods still face two key limitations: (1)\nThey usually one-sidedly reorganize individual historical facts, while\noverlooking the historical context essential for accurately understanding the\nhistorical semantics of these facts; (2) They preserve historical knowledge by\nsimply replaying historical facts, while ignoring the potential conflicts\nbetween historical and emerging facts. In this paper, we propose a Deep\nGenerative Adaptive Replay (DGAR) method, which can generate and adaptively\nreplay historical entity distribution representations from the whole historical\ncontext. To address the first challenge, historical context prompts as sampling\nunits are built to preserve the whole historical context information. To\novercome the second challenge, a pre-trained diffusion model is adopted to\ngenerate the historical distribution. During the generation process, the common\nfeatures between the historical and current distributions are enhanced under\nthe guidance of the TKGR model. In addition, a layer-by-layer adaptive replay\nmechanism is designed to effectively integrate historical and current\ndistributions. Experimental results demonstrate that DGAR significantly\noutperforms baselines in reasoning and mitigating forgetting.\n","authors":["Zhiyu Zhang","Wei Chen","Youfang Lin","Huaiyu Wan"],"pdf_url":"https://arxiv.org/pdf/2506.04083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09492v3","updated":"2025-06-04T14:47:48Z","published":"2025-03-12T15:52:51Z","title":"Learning Cascade Ranking as One Network","summary":"  Cascade Ranking is a prevalent architecture in large-scale top-k selection\nsystems like recommendation and advertising platforms. Traditional training\nmethods focus on single-stage optimization, neglecting interactions between\nstages. Recent advances have introduced interaction-aware training paradigms,\nbut still struggle to 1) align training objectives with the goal of the entire\ncascade ranking (i.e., end-to-end recall of ground-truth items) and 2) learn\neffective collaboration patterns for different stages. To address these\nchallenges, we propose LCRON, which introduces a novel surrogate loss function\nderived from the lower bound probability that ground truth items are selected\nby cascade ranking, ensuring alignment with the overall objective of the\nsystem. According to the properties of the derived bound, we further design an\nauxiliary loss for each stage to drive the reduction of this bound, leading to\na more robust and effective top-k selection. LCRON enables end-to-end training\nof the entire cascade ranking system as a unified network. Experimental results\ndemonstrate that LCRON achieves significant improvement over existing methods\non public benchmarks and industrial applications, addressing key limitations in\ncascade ranking training and significantly enhancing system performance.\n","authors":["Yunli Wang","Zhen Zhang","Zhiqiang Wang","Zixuan Yang","Yu Li","Jian Yang","Shiyang Wen","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2503.09492v3.pdf","comment":"Accepted by ICML 2025"},{"id":"http://arxiv.org/abs/2506.04015v1","updated":"2025-06-04T14:46:18Z","published":"2025-06-04T14:46:18Z","title":"GORACS: Group-level Optimal Transport-guided Coreset Selection for\n  LLM-based Recommender Systems","summary":"  Although large language models (LLMs) have shown great potential in\nrecommender systems, the prohibitive computational costs for fine-tuning LLMs\non entire datasets hinder their successful deployment in real-world scenarios.\nTo develop affordable and effective LLM-based recommender systems, we focus on\nthe task of coreset selection which identifies a small subset of fine-tuning\ndata to optimize the test loss, thereby facilitating efficient LLMs'\nfine-tuning. Although there exist some intuitive solutions of subset selection,\nincluding distribution-based and importance-based approaches, they often lead\nto suboptimal performance due to the misalignment with downstream fine-tuning\nobjectives or weak generalization ability caused by individual-level sample\nselection. To overcome these challenges, we propose GORACS, which is a novel\nGroup-level Optimal tRAnsport-guided Coreset Selection framework for LLM-based\nrecommender systems. GORACS is designed based on two key principles for coreset\nselection: 1) selecting the subsets that minimize the test loss to align with\nfine-tuning objectives, and 2) enhancing model generalization through\ngroup-level data selection. Corresponding to these two principles, GORACS has\ntwo key components: 1) a Proxy Optimization Objective (POO) leveraging optimal\ntransport and gradient information to bound the intractable test loss, thus\nreducing computational costs by avoiding repeated LLM retraining, and 2) a\ntwo-stage Initialization-Then-Refinement Algorithm (ITRA) for efficient\ngroup-level selection. Our extensive experiments across diverse recommendation\ndatasets and tasks validate that GORACS significantly reduces fine-tuning costs\nof LLMs while achieving superior performance over the state-of-the-art\nbaselines and full data training. The source code of GORACS are available at\nhttps://github.com/Mithas-114/GORACS.\n","authors":["Tiehua Mei","Hengrui Chen","Peng Yu","Jiaqing Liang","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2506.04015v1.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2502.16540v2","updated":"2025-06-04T13:17:52Z","published":"2025-02-23T11:19:44Z","title":"D2S-FLOW: Automated Parameter Extraction from Datasheets for SPICE Model\n  Generation Using Large Language Models","summary":"  In electronic design, engineers often manually search through extensive\ndocuments to retrieve component parameters required for constructing SPICE\nmodels, a process that is both labor-intensive and time-consuming. To address\nthis challenge, we present an automated framework called D2S-FLOW that\nleverages large language models (LLMs) to extract electrical parameters from\ndatasheets and generate SPICE models with high precision and efficiency,\nsignificantly reducing the need for manual intervention. Unlike traditional RAG\nsystems, D2S-FLOW employs a workflow to enhance precision in handling\nunstructured documents and inconsistent naming conventions through three\ninnovative mechanisms: Attention-Guided Document Focusing (AGDF), Hierarchical\nDocument-Enhanced Retrieval (HDER), and Heterogeneous Named Entity\nNormalization (HNEN). AGDF narrows retrieval to user-selected documents, HDER\nutilizes document structure for precise parameter localization, and HNEN\nstandardizes terminology via semantic inference. Experimental results\ndemonstrate that the framework achieves an Exact Match (EM) of 0.86, an F1\nscore of 0.92, and an Exact Correctness (EC) of 0.96, outperforming the\nstrongest baseline by 19.4%, 5.7%, and 13.1%, respectively. Additionally, it\nreduces API token consumption by 38% and minimizes the irrelevant information\nratio to 4%, showcasing substantial improvements in resource efficiency. This\nresearch provides an effective automated solution for circuit design.\n","authors":["Hong Cai Chen","Yi Pin Xu","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.16540v2.pdf","comment":"14 pages, 18 figures"},{"id":"http://arxiv.org/abs/2506.03895v1","updated":"2025-06-04T12:43:17Z","published":"2025-06-04T12:43:17Z","title":"Graph-Embedding Empowered Entity Retrieval","summary":"  In this research, we investigate methods for entity retrieval using graph\nembeddings. While various methods have been proposed over the years, most\nutilize a single graph embedding and entity linking approach. This hinders our\nunderstanding of how different graph embedding and entity linking methods\nimpact entity retrieval. To address this gap, we investigate the effects of\nthree different categories of graph embedding techniques and five different\nentity linking methods. We perform a reranking of entities using the distance\nbetween the embeddings of annotated entities and the entities we wish to\nrerank. We conclude that the selection of both graph embeddings and entity\nlinkers significantly impacts the effectiveness of entity retrieval. For graph\nembeddings, methods that incorporate both graph structure and textual\ndescriptions of entities are the most effective. For entity linking, both\nprecision and recall concerning concepts are important for optimal retrieval\nperformance. Additionally, it is essential for the graph to encompass as many\nentities as possible.\n","authors":["Emma J. Gerritse","Faegheh Hasibi","Arjen P. de Vries"],"pdf_url":"https://arxiv.org/pdf/2506.03895v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2005.02843"},{"id":"http://arxiv.org/abs/2505.16865v2","updated":"2025-06-04T11:31:59Z","published":"2025-05-22T16:22:54Z","title":"LARES: Latent Reasoning for Sequential Recommendation","summary":"  Sequential recommender systems have become increasingly important in\nreal-world applications that model user behavior sequences to predict their\npreferences. However, existing sequential recommendation methods predominantly\nrely on non-reasoning paradigms, which may limit the model's computational\ncapacity and result in suboptimal recommendation performance. To address these\nlimitations, we present LARES, a novel and scalable LAtent REasoning framework\nfor Sequential recommendation that enhances model's representation capabilities\nthrough increasing the computation density of parameters by depth-recurrent\nlatent reasoning. Our proposed approach employs a recurrent architecture that\nallows flexible expansion of reasoning depth without increasing parameter\ncomplexity, thereby effectively capturing dynamic and intricate user interest\npatterns. A key difference of LARES lies in refining all input tokens at each\nimplicit reasoning step to improve the computation utilization. To fully unlock\nthe model's reasoning potential, we design a two-phase training strategy: (1)\nSelf-supervised pre-training (SPT) with dual alignment objectives; (2)\nReinforcement post-training (RPT). During the first phase, we introduce\ntrajectory-level alignment and step-level alignment objectives, which enable\nthe model to learn recommendation-oriented latent reasoning patterns without\nrequiring supplementary annotated data. The subsequent phase utilizes\nreinforcement learning (RL) to harness the model's exploratory ability, further\nrefining its reasoning capabilities. Comprehensive experiments on real-world\nbenchmarks demonstrate our framework's superior performance. Notably, LARES\nexhibits seamless compatibility with existing advanced models, further\nimproving their recommendation performance. Our code is available at\nhttps://anonymous.4open.science/r/LARES-E458/.\n","authors":["Enze Liu","Bowen Zheng","Xiaolei Wang","Wayne Xin Zhao","Jinpeng Wang","Sheng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2505.16865v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03827v1","updated":"2025-06-04T10:57:18Z","published":"2025-06-04T10:57:18Z","title":"Multi-objective Aligned Bidword Generation Model for E-commerce Search\n  Advertising","summary":"  Retrieval systems primarily address the challenge of matching user queries\nwith the most relevant advertisements, playing a crucial role in e-commerce\nsearch advertising. The diversity of user needs and expressions often produces\nmassive long-tail queries that cannot be matched with merchant bidwords or\nproduct titles, which results in some advertisements not being recalled,\nultimately harming user experience and search efficiency. Existing query\nrewriting research focuses on various methods such as query log mining,\nquery-bidword vector matching, or generation-based rewriting. However, these\nmethods often fail to simultaneously optimize the relevance and authenticity of\nthe user's original query and rewrite and maximize the revenue potential of\nrecalled ads.\n  In this paper, we propose a Multi-objective aligned Bidword Generation Model\n(MoBGM), which is composed of a discriminator, generator, and preference\nalignment module, to address these challenges. To simultaneously improve the\nrelevance and authenticity of the query and rewrite and maximize the platform\nrevenue, we design a discriminator to optimize these key objectives. Using the\nfeedback signal of the discriminator, we train a multi-objective aligned\nbidword generator that aims to maximize the combined effect of the three\nobjectives. Extensive offline and online experiments show that our proposed\nalgorithm significantly outperforms the state of the art. After deployment, the\nalgorithm has created huge commercial value for the platform, further verifying\nits feasibility and robustness.\n","authors":["Zhenhui Liu","Chunyuan Yuan","Ming Pang","Zheng Fang","Li Yuan","Xue Jiang","Changping Peng","Zhangang Lin","Zheng Luo","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2506.03827v1.pdf","comment":"Accepted by SIGIR2025"},{"id":"http://arxiv.org/abs/2506.03822v1","updated":"2025-06-04T10:52:55Z","published":"2025-06-04T10:52:55Z","title":"CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents","summary":"  Publication databases rely on accurate metadata extraction from diverse web\nsources, yet variations in web layouts and data formats present challenges for\nmetadata providers. This paper introduces CRAWLDoc, a new method for contextual\nranking of linked web documents. Starting with a publication's URL, such as a\ndigital object identifier, CRAWLDoc retrieves the landing page and all linked\nweb resources, including PDFs, ORCID profiles, and supplementary materials. It\nembeds these resources, along with anchor texts and the URLs, into a unified\nrepresentation. For evaluating CRAWLDoc, we have created a new, manually\nlabeled dataset of 600 publications from six top publishers in computer\nscience. Our method CRAWLDoc demonstrates a robust and layout-independent\nranking of relevant documents across publishers and data formats. It lays the\nfoundation for improved metadata extraction from web documents with various\nlayouts and formats. Our source code and dataset can be accessed at\nhttps://github.com/FKarl/CRAWLDoc.\n","authors":["Fabian Karl","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2506.03822v1.pdf","comment":"Accepted at SCOLIA 2025"},{"id":"http://arxiv.org/abs/2506.03807v1","updated":"2025-06-04T10:27:22Z","published":"2025-06-04T10:27:22Z","title":"Understanding Mental Models of Generative Conversational Search and The\n  Effect of Interface Transparency","summary":"  The experience and adoption of conversational search is tied to the accuracy\nand completeness of users' mental models -- their internal frameworks for\nunderstanding and predicting system behaviour. Thus, understanding these models\ncan reveal areas for design interventions. Transparency is one such\nintervention which can improve system interpretability and enable mental model\nalignment. While past research has explored mental models of search engines,\nthose of generative conversational search remain underexplored, even while the\npopularity of these systems soars. To address this, we conducted a study with\n16 participants, who performed 4 search tasks using 4 conversational interfaces\nof varying transparency levels. Our analysis revealed that most user mental\nmodels were too abstract to support users in explaining individual search\ninstances. These results suggest that 1) mental models may pose a barrier to\nappropriate trust in conversational search, and 2) hybrid web-conversational\nsearch is a promising novel direction for future search interface design.\n","authors":["Chadha Degachi","Samuel Kernan Freire","Evangelos Niforatos","Gerd Kortuem"],"pdf_url":"https://arxiv.org/pdf/2506.03807v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2504.14175v2","updated":"2025-06-04T09:32:19Z","published":"2025-04-19T04:32:38Z","title":"Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query\n  Expansion","summary":"  Query expansion methods powered by large language models (LLMs) have\ndemonstrated effectiveness in zero-shot retrieval tasks. These methods assume\nthat LLMs can generate hypothetical documents that, when incorporated into a\nquery vector, enhance the retrieval of real evidence. However, we challenge\nthis assumption by investigating whether knowledge leakage in benchmarks\ncontributes to the observed performance gains. Using fact verification as a\ntestbed, we analyze whether the generated documents contain information\nentailed by ground-truth evidence and assess their impact on performance. Our\nfindings indicate that, on average, performance improvements consistently\noccurred for claims whose generated documents included sentences entailed by\ngold evidence. This suggests that knowledge leakage may be present in\nfact-verification benchmarks, potentially inflating the perceived performance\nof LLM-based query expansion methods.\n","authors":["Yejun Yoon","Jaeyoon Jung","Seunghyun Yoon","Kunwoo Park"],"pdf_url":"https://arxiv.org/pdf/2504.14175v2.pdf","comment":"ACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2409.05546v3","updated":"2025-06-04T09:22:33Z","published":"2024-09-09T12:11:53Z","title":"Generative Recommender with End-to-End Learnable Item Tokenization","summary":"  Generative recommendation systems have gained increasing attention as an\ninnovative approach that directly generates item identifiers for recommendation\ntasks. Despite their potential, a major challenge is the effective construction\nof item identifiers that align well with recommender systems. Current\napproaches often treat item tokenization and generative recommendation training\nas separate processes, which can lead to suboptimal performance. To overcome\nthis issue, we introduce ETEGRec, a novel End-To-End Generative Recommender\nthat unifies item tokenization and generative recommendation into a cohesive\nframework. Built on a dual encoder-decoder architecture, ETEGRec consists of an\nitem tokenizer and a generative recommender. To enable synergistic interaction\nbetween these components, we propose a recommendation-oriented alignment\nstrategy, which includes two key optimization objectives: sequence-item\nalignment and preference-semantic alignment. These objectives tightly couple\nthe learning processes of the item tokenizer and the generative recommender,\nfostering mutual enhancement. Additionally, we develop an alternating\noptimization technique to ensure stable and efficient end-to-end training of\nthe entire framework. Extensive experiments demonstrate the superior\nperformance of our approach compared to traditional sequential recommendation\nmodels and existing generative recommendation baselines. Our code is available\nat https://github.com/RUCAIBox/ETEGRec.\n","authors":["Enze Liu","Bowen Zheng","Cheng Ling","Lantao Hu","Han Li","Wayne Xin Zhao"],"pdf_url":"https://arxiv.org/pdf/2409.05546v3.pdf","comment":"Accepted by SIGIR 2025 Research Track"},{"id":"http://arxiv.org/abs/2503.06474v2","updated":"2025-06-04T08:32:02Z","published":"2025-03-09T06:20:24Z","title":"ROGRAG: A Robustly Optimized GraphRAG Framework","summary":"  Large language models (LLMs) commonly struggle with specialized or emerging\ntopics which are rarely seen in the training corpus. Graph-based\nretrieval-augmented generation (GraphRAG) addresses this by structuring domain\nknowledge as a graph for dynamic retrieval. However, existing pipelines involve\ncomplex engineering workflows, making it difficult to isolate the impact of\nindividual components. It is also challenging to evaluate the retrieval\neffectiveness due to the overlap between the pretraining and evaluation\ndatasets. In this work, we introduce ROGRAG, a Robustly Optimized GraphRAG\nframework. Specifically, we propose a multi-stage retrieval mechanism that\nintegrates dual-level with logic form retrieval methods to improve retrieval\nrobustness without increasing computational cost. To further refine the system,\nwe incorporate various result verification methods and adopt an incremental\ndatabase construction approach. Through extensive ablation experiments, we\nrigorously assess the effectiveness of each component. Our implementation\nincludes comparative experiments on SeedBench, where Qwen2.5-7B-Instruct\ninitially underperformed. ROGRAG significantly improves the score from 60.0% to\n75.0% and outperforms mainstream methods. Experiments on domain-specific\ndatasets reveal that dual-level retrieval enhances fuzzy matching, while logic\nform retrieval improves structured reasoning, highlighting the importance of\nmulti-stage retrieval.ROGRAG is released as an open-source resource and\nsupports installation with pip.\n","authors":["Zhefan Wang","Huanjun Kong","Jie Ying","Wanli Ouyang","Nanqing Dong"],"pdf_url":"https://arxiv.org/pdf/2503.06474v2.pdf","comment":"ACL2025 demo track, 10 pages"},{"id":"http://arxiv.org/abs/2506.03699v1","updated":"2025-06-04T08:31:33Z","published":"2025-06-04T08:31:33Z","title":"Scaling Transformers for Discriminative Recommendation via Generative\n  Pretraining","summary":"  Discriminative recommendation tasks, such as CTR (click-through rate) and CVR\n(conversion rate) prediction, play critical roles in the ranking stage of\nlarge-scale industrial recommender systems. However, training a discriminative\nmodel encounters a significant overfitting issue induced by data sparsity.\nMoreover, this overfitting issue worsens with larger models, causing them to\nunderperform smaller ones. To address the overfitting issue and enhance model\nscalability, we propose a framework named GPSD (\\textbf{G}enerative\n\\textbf{P}retraining for \\textbf{S}calable \\textbf{D}iscriminative\nRecommendation), drawing inspiration from generative training, which exhibits\nno evident signs of overfitting. GPSD leverages the parameters learned from a\npretrained generative model to initialize a discriminative model, and\nsubsequently applies a sparse parameter freezing strategy. Extensive\nexperiments conducted on both industrial-scale and publicly available datasets\ndemonstrate the superior performance of GPSD. Moreover, it delivers remarkable\nimprovements in online A/B tests. GPSD offers two primary advantages: 1) it\nsubstantially narrows the generalization gap in model training, resulting in\nbetter test performance; and 2) it leverages the scalability of Transformers,\ndelivering consistent performance gains as models are scaled up. Specifically,\nwe observe consistent performance improvements as the model dense parameters\nscale from 13K to 0.3B, closely adhering to power laws. These findings pave the\nway for unifying the architectures of recommendation models and language\nmodels, enabling the direct application of techniques well-established in large\nlanguage models to recommendation models.\n","authors":["Chunqi Wang","Bingchao Wu","Zheng Chen","Lei Shen","Bing Wang","Xiaoyi Zeng"],"pdf_url":"https://arxiv.org/pdf/2506.03699v1.pdf","comment":"KDD'25"},{"id":"http://arxiv.org/abs/2404.17589v5","updated":"2025-06-04T08:19:53Z","published":"2024-04-19T08:43:03Z","title":"An Offline Reinforcement Learning Algorithm Customized for Multi-Task\n  Fusion in Large-Scale Recommender Systems","summary":"  As the last critical stage of RSs, Multi-Task Fusion (MTF) is responsible for\ncombining multiple scores outputted by Multi-Task Learning (MTL) into a final\nscore to maximize user satisfaction, which determines the ultimate\nrecommendation results. Recently, to optimize long-term user satisfaction\nwithin a recommendation session, Reinforcement Learning (RL) is used for MTF in\nthe industry. However, the offline RL algorithms used for MTF so far have the\nfollowing severe problems: 1) to avoid out-of-distribution (OOD) problem, their\nconstraints are overly strict, which seriously damage their performance; 2)\nthey are unaware of the exploration policy used for producing training data and\nnever interact with real environment, so only suboptimal policy can be learned;\n3) the traditional exploration policies are inefficient and hurt user\nexperience. To solve the above problems, we propose a novel method named\nIntegratedRL-MTF customized for MTF in large-scale RSs. IntegratedRL-MTF\nintegrates offline RL model with our online exploration policy to relax\noverstrict and complicated constraints, which significantly improves its\nperformance. We also design an extremely efficient exploration policy, which\neliminates low-value exploration space and focuses on exploring potential\nhigh-value state-action pairs. Moreover, we adopt progressive training mode to\nfurther enhance our model's performance with the help of our exploration\npolicy. We conduct extensive offline and online experiments in the short video\nchannel of Tencent News. The results demonstrate that our model outperforms\nother models remarkably. IntegratedRL-MTF has been fully deployed in our RS and\nother large-scale RSs in Tencent, which have achieved significant improvements.\n","authors":["Peng Liu","Cong Xu","Ming Zhao","Jiawei Zhu","Bin Wang","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2404.17589v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.03734v2","updated":"2025-06-04T07:36:34Z","published":"2023-08-07T17:32:33Z","title":"Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity\n  Resolution","summary":"  The entity resolution problem requires finding pairs across datasets that\nbelong to different owners but refer to the same entity in the real world. To\ntrain and evaluate solutions (either rule-based or machine-learning-based) to\nthe entity resolution problem, generating a ground truth dataset with entity\npairs or clusters is needed. However, such a data annotation process involves\nhumans as domain oracles to review the plaintext data for all candidate record\npairs from different parties, which inevitably infringes the privacy of data\nowners, especially in privacy-sensitive cases like medical records. To the best\nof our knowledge, there is no prior work on privacy-preserving ground truth\ndataset generation, especially in the domain of entity resolution. We propose a\nnovel blind annotation protocol based on homomorphic encryption that allows\ndomain oracles to collaboratively label ground truths without sharing data in\nplaintext with other parties. In addition, we design a domain-specific\neasy-to-use language that hides the sophisticated underlying homomorphic\nencryption layer. Rigorous proof of the privacy guarantee is provided and our\nempirical experiments via an annotation simulator indicate the feasibility of\nour privacy-preserving protocol (f-measure on average achieves more than 90\\%\ncompared with the real ground truths).\n","authors":["Yixiang Yao","Weizhao Jin","Srivatsan Ravi"],"pdf_url":"https://arxiv.org/pdf/2308.03734v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02544v2","updated":"2025-06-04T06:31:54Z","published":"2025-06-03T07:32:40Z","title":"CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG","summary":"  Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to\nenhance Multimodal Large Language Models by incorporating externally retrieved\nmultimodal knowledge, but it introduces two challenges: Parametric-Retrieved\nKnowledge Inconsistency (PRKI), where discrepancies between parametric and\nretrieved knowledge create uncertainty in determining reliability, and\nVisual-Textual Knowledge Inconsistency (VTKI), where misalignment between\nvisual and textual sources disrupts entity representation. To address these\nchallenges, we propose Cross-source knowledge \\textbf{Re}conciliation for\nMultimodal RAG (CoRe-MMRAG), a novel end-to-end framework that effectively\nreconciles inconsistencies across knowledge sources. CoRe-MMRAG follows a\nfour-stage pipeline: it first generates an internal response from parametric\nknowledge, then selects the most relevant multimodal evidence via joint\nsimilarity assessment, generates an external response, and finally integrates\nboth to produce a reliable answer. Additionally, a specialized training\nparadigm enhances knowledge source discrimination, multimodal integration, and\nunified answer generation. Experiments on KB-VQA benchmarks show that\nCoRe-MMRAG achieves substantial improvements over baseline methods, achieving\n5.6% and 9.3% performance gains on InfoSeek and Encyclopedic-VQA, respectively.\n","authors":["Yang Tian","Fan Liu","Jingyuan Zhang","Victoria W.","Yupeng Hu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2506.02544v2.pdf","comment":"Accepted to ACL 2025 Main"},{"id":"http://arxiv.org/abs/2506.12069v1","updated":"2025-06-04T03:09:07Z","published":"2025-06-04T03:09:07Z","title":"Algorithms for estimating linear function in data mining","summary":"  The main goal of this topic is to showcase several studied algorithms for\nestimating the linear utility function to predict the users preferences. For\nexample, if a user comes to buy a car that has several attributes including\nspeed, color, age, etc in a linear function, the algorithms that we present in\nthis paper help with estimating this linear function to filter out a small\nsubset that would be of best interest to the user among a million tuples in a\nvery large database. In addition, the estimating linear function could also be\napplicable in getting to know what the data can do or predicting the future\nbased on the data that is used in data science, which is demonstrated by the\nGNN, PLOD algorithms. In the ever-evolving field of data science, deriving\nvaluable insights from large datasets is critical for informed decision-making,\nparticularly in predictive applications. Data analysts often identify\nhigh-quality datasets without missing values, duplicates, or inconsistencies\nbefore merging diverse attributes for analysis. Taking housing price prediction\nas a case study, various attributes must be considered, including location\nfactors (proximity to urban centers, crime rates), property features (size,\nstyle, modernity), and regional policies (tax implications). Experts in the\nfield typically rank these attributes to establish a predictive utility\nfunction, which machine learning models use to forecast outcomes like housing\nprices. Several data discovery algorithms, including those that address the\nchallenges of predefined utility functions and human input for attribute\nranking, which often result in a time-consuming iterative process, that the\nwork of cannot overcome.\n","authors":["Thomas Hoang"],"pdf_url":"https://arxiv.org/pdf/2506.12069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03487v1","updated":"2025-06-04T02:00:44Z","published":"2025-06-04T02:00:44Z","title":"ProRank: Prompt Warmup via Reinforcement Learning for Small Language\n  Models Reranking","summary":"  Reranking is fundamental to information retrieval and retrieval-augmented\ngeneration, with recent Large Language Models (LLMs) significantly advancing\nreranking quality. While recent advances with LLMs have significantly improved\ndocument reranking quality, current approaches primarily rely on large-scale\nLLMs (>7B parameters) through zero-shot prompting, presenting high\ncomputational costs. Small Language Models (SLMs) offer a promising alternative\nbecause of their efficiency, but our preliminary quantitative analysis reveals\nthey struggle with understanding task prompts without fine-tuning. This limits\ntheir effectiveness for document reranking tasks. To address this issue, we\nintroduce a novel two-stage training approach, ProRank, for SLM-based document\nreranking. First, we propose a prompt warmup stage using reinforcement learning\nGRPO to steer SLMs to understand task prompts and generate more accurate\ncoarse-grained binary relevance scores for document reranking. Then, we\ncontinuously fine-tune the SLMs with a fine-grained score learning stage\nwithout introducing additional layers to further improve the reranking quality.\nComprehensive experimental results demonstrate that the proposed ProRank\nconsistently outperforms both the most advanced open-source and proprietary\nreranking models. Notably, our lightweight ProRank-0.5B model even surpasses\nthe powerful 32B LLM reranking model on the BEIR benchmark, establishing that\nproperly trained SLMs can achieve superior document reranking performance while\nmaintaining computational efficiency.\n","authors":["Xianming Li","Aamir Shakir","Rui Huang","Julius Lipp","Jing Li"],"pdf_url":"https://arxiv.org/pdf/2506.03487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20730v2","updated":"2025-06-04T00:54:43Z","published":"2025-05-27T05:18:57Z","title":"What LLMs Miss in Recommendations: Bridging the Gap with\n  Retrieval-Augmented Collaborative Signals","summary":"  User-item interactions contain rich collaborative signals that form the\nbackbone of many successful recommender systems. While recent work has explored\nthe use of large language models (LLMs) for recommendation, it remains unclear\nwhether LLMs can effectively reason over this type of collaborative\ninformation. In this paper, we conduct a systematic comparison between LLMs and\nclassical matrix factorization (MF) models to assess LLMs' ability to leverage\nuser-item interaction data. We further introduce a simple retrieval-augmented\ngeneration (RAG) method that enhances LLMs by grounding their predictions in\nstructured interaction data. Our experiments reveal that current LLMs often\nfall short in capturing collaborative patterns inherent to MF models, but that\nour RAG-based approach substantially improves recommendation\nquality-highlighting a promising direction for future LLM-based recommenders.\n","authors":["Shahrooz Pouryousef","Ali Montazeralghaem"],"pdf_url":"https://arxiv.org/pdf/2505.20730v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.04006v1","updated":"2025-06-04T14:33:41Z","published":"2025-06-04T14:33:41Z","title":"TransClean: Finding False Positives in Multi-Source Entity Matching\n  under Real-World Conditions via Transitive Consistency","summary":"  We present TransClean, a method for detecting false positive predictions of\nentity matching algorithms under real-world conditions characterized by\nlarge-scale, noisy, and unlabeled multi-source datasets that undergo\ndistributional shifts. TransClean is explicitly designed to operate with\nmultiple data sources in an efficient, robust and fast manner while accounting\nfor edge cases and requiring limited manual labeling. TransClean leverages the\nTransitive Consistency of a matching, a measure of the consistency of a\npairwise matching model f_theta on the matching it produces G_f_theta, based\nboth on its predictions on directly evaluated record pairs and its predictions\non implied record pairs. TransClean iteratively modifies a matching through\ngradually removing false positive matches while removing as few true positive\nmatches as possible. In each of these steps, the estimation of the Transitive\nConsistency is exclusively done through model evaluations and produces\nquantities that can be used as proxies of the amounts of true and false\npositives in the matching while not requiring any manual labeling, producing an\nestimate of the quality of the matching and indicating which record groups are\nlikely to contain false positives. In our experiments, we compare combining\nTransClean with a naively trained pairwise matching model (DistilBERT) and with\na state-of-the-art end-to-end matching method (CLER) and illustrate the\nflexibility of TransClean in being able to detect most of the false positives\nof either setup across a variety of datasets. Our experiments show that\nTransClean induces an average +24.42 F1 score improvement for entity matching\nin a multi-source setting when compared to traditional pair-wise matching\nalgorithms.\n","authors":["Fernando de Meer Pardo","Branka Hadji Misheva","Martin Braschler","Kurt Stockinger"],"pdf_url":"https://arxiv.org/pdf/2506.04006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04920v4","updated":"2025-06-04T10:58:03Z","published":"2024-11-07T17:57:03Z","title":"Enabling LLM Knowledge Analysis via Extensive Materialization","summary":"  Large language models (LLMs) have majorly advanced NLP and AI, and next to\ntheir ability to perform a wide range of procedural tasks, a major success\nfactor is their internalized factual knowledge. Since Petroni et al. (2019),\nanalyzing this knowledge has gained attention. However, most approaches\ninvestigate one question at a time via modest-sized pre-defined samples,\nintroducing an ``availability bias'' (Tversky&Kahnemann, 1973) that prevents\nthe analysis of knowledge (or beliefs) of LLMs beyond the experimenter's\npredisposition.\n  To address this challenge, we propose a novel methodology to comprehensively\nmaterialize an LLM's factual knowledge through recursive querying and result\nconsolidation. Our approach is a milestone for LLM research, for the first time\nproviding constructive insights into the scope and structure of LLM knowledge\n(or beliefs).\n  As a prototype, we build GPTKB, a knowledge base (KB) comprising 101 million\nrelational triples for over 2.9 million entities from GPT-4o-mini. We use GPTKB\nto exemplarily analyze GPT-4o-mini's factual knowledge in terms of scale,\naccuracy, bias, cutoff and consistency, at the same time. GPTKB is accessible\nat https://gptkb.org\n","authors":["Yujia Hu","Tuan-Phong Nguyen","Shrestha Ghosh","Simon Razniewski"],"pdf_url":"https://arxiv.org/pdf/2411.04920v4.pdf","comment":"14 pages, 4 tables, 12 figures"},{"id":"http://arxiv.org/abs/2506.03826v1","updated":"2025-06-04T10:54:44Z","published":"2025-06-04T10:54:44Z","title":"Signals as a First-Class Citizen When Querying Knowledge Graphs","summary":"  Cyber-Physical Systems (CPSs) tightly integrate computation with physical\nentities, often generating vast amounts of time series data from thousands of\nsensors. Although knowledge graphs offer a powerful means to contextualize\nthese data, existing approaches to integrating knowledge graphs with time\nseries data lack a concept to model the continuous temporal values inherent in\nCPSs. This gap can make expressing computations on the sensor data cumbersome.\nIn this work, we propose the integration of knowledge graphs and signals, a\nproven concept for modeling temporal values. By treating signals as first-class\ncitizens in query languages, we can enable seamless querying over knowledge\ngraphs and signals. While the knowledge graph captures information on the CPS,\nsignals represent its run-time data from sensors. We discuss the implications\nof such an approach and propose SigSPARQL, an extension to the SPARQL query\nlanguage, to demonstrate these concepts. Furthermore, we evaluate the\nfeasibility of implementing SigSPARQL with a prototype and demonstrate the\napplicability of the query language for a monitoring use case within a CPS.\n","authors":["Tobias Schwarzinger","Gernot Steindl","Thomas Frühwirth","Thomas Preindl","Konrad Diwold","Katrin Ehrenmüller","Fajar J. Ekaputra"],"pdf_url":"https://arxiv.org/pdf/2506.03826v1.pdf","comment":null}]},"2025-06-03T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.03424v1","updated":"2025-06-03T22:10:39Z","published":"2025-06-03T22:10:39Z","title":"DistRAG: Towards Distance-Based Spatial Reasoning in LLMs","summary":"  Many real world tasks where Large Language Models (LLMs) can be used require\nspatial reasoning, like Point of Interest (POI) recommendation and itinerary\nplanning. However, on their own LLMs lack reliable spatial reasoning\ncapabilities, especially about distances. To address this problem, we develop a\nnovel approach, DistRAG, that enables an LLM to retrieve relevant spatial\ninformation not explicitly learned during training. Our method encodes the\ngeodesic distances between cities and towns in a graph and retrieves a context\nsubgraph relevant to the question. Using this technique, our method enables an\nLLM to answer distance-based reasoning questions that it otherwise cannot\nanswer. Given the vast array of possible places an LLM could be asked about,\nDistRAG offers a flexible first step towards providing a rudimentary `world\nmodel' to complement the linguistic knowledge held in LLMs.\n","authors":["Nicole R Schneider","Nandini Ramachandran","Kent O'Sullivan","Hanan Samet"],"pdf_url":"https://arxiv.org/pdf/2506.03424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03391v1","updated":"2025-06-03T21:00:34Z","published":"2025-06-03T21:00:34Z","title":"Universal Reusability in Recommender Systems: The Case for Dataset- and\n  Task-Independent Frameworks","summary":"  Recommender systems are pivotal in delivering personalized experiences across\nindustries, yet their adoption and scalability remain hindered by the need for\nextensive dataset- and task-specific configurations. Existing systems often\nrequire significant manual intervention, domain expertise, and engineering\neffort to adapt to new datasets or tasks, creating barriers to entry and\nlimiting reusability. In contrast, recent advancements in large language models\n(LLMs) have demonstrated the transformative potential of reusable systems,\nwhere a single model can handle diverse tasks without significant\nreconfiguration. Inspired by this paradigm, we propose the Dataset- and\nTask-Independent Recommender System (DTIRS), a framework aimed at maximizing\nthe reusability of recommender systems while minimizing barriers to entry.\nUnlike LLMs, which achieve task generalization directly, DTIRS focuses on\neliminating the need to rebuild or reconfigure recommendation pipelines for\nevery new dataset or task, even though models may still need retraining on new\ndata. By leveraging the novel Dataset Description Language (DsDL), DTIRS\nenables standardized dataset descriptions and explicit task definitions,\nallowing autonomous feature engineering, model selection, and optimization.\nThis paper introduces the concept of DTIRS and establishes a roadmap for\ntransitioning from Level-1 automation (dataset-agnostic but task-specific\nsystems) to Level-2 automation (fully dataset- and task-independent systems).\nAchieving this paradigm would maximize code reusability and lower barriers to\nadoption. We discuss key challenges, including the trade-offs between\ngeneralization and specialization, computational overhead, and scalability,\nwhile presenting DsDL as a foundational tool for this vision.\n","authors":["Tri Kurniawan Wijaya","Xinyang Shao","Gonzalo Fiz Pontiveros","Edoardo D'Amico"],"pdf_url":"https://arxiv.org/pdf/2506.03391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03369v1","updated":"2025-06-03T20:26:14Z","published":"2025-06-03T20:26:14Z","title":"Impact of Rankings and Personalized Recommendations in Marketplaces","summary":"  Individuals often navigate several options with incomplete knowledge of their\nown preferences. Information provisioning tools such as public rankings and\npersonalized recommendations have become central to helping individuals make\nchoices, yet their value proposition under different marketplace environments\nremains unexplored. This paper studies a stylized model to explore the impact\nof these tools in two marketplace settings: uncapacitated supply, where items\ncan be selected by any number of agents, and capacitated supply, where each\nitem is constrained to be matched to a single agent. We model the agents\nutility as a weighted combination of a common term which depends only on the\nitem, reflecting the item's population level quality, and an idiosyncratic\nterm, which depends on the agent item pair capturing individual specific\ntastes. Public rankings reveal the common term, while personalized\nrecommendations reveal both terms. In the supply unconstrained settings, both\npublic rankings and personalized recommendations improve welfare, with their\nrelative value determined by the degree of preference heterogeneity. Public\nrankings are effective when preferences are relatively homogeneous, while\npersonalized recommendations become critical as heterogeneity increases. In\ncontrast, in supply constrained settings, revealing just the common term, as\ndone by public rankings, provides limited benefit since the total common value\navailable is limited by capacity constraints, whereas personalized\nrecommendations, by revealing both common and idiosyncratic terms,\nsignificantly enhance welfare by enabling agents to match with items they\nidiosyncratically value highly. These results illustrate the interplay between\nsupply constraints and preference heterogeneity in determining the\neffectiveness of information provisioning tools, offering insights for their\ndesign and deployment in diverse settings.\n","authors":["Omar Besbes","Yash Kanoria","Akshit Kumar"],"pdf_url":"https://arxiv.org/pdf/2506.03369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05395v1","updated":"2025-06-03T19:44:49Z","published":"2025-06-03T19:44:49Z","title":"TriPSS: A Tri-Modal Keyframe Extraction Framework Using Perceptual,\n  Structural, and Semantic Representations","summary":"  Efficient keyframe extraction is critical for effective video summarization\nand retrieval, yet capturing the complete richness of video content remains\nchallenging. In this work, we present TriPSS, a novel tri-modal framework that\neffectively integrates perceptual cues from color features in the CIELAB space,\ndeep structural embeddings derived from ResNet-50, and semantic context from\nframe-level captions generated by Llama-3.2-11B-Vision-Instruct. By fusing\nthese diverse modalities using principal component analysis, TriPSS constructs\nrobust multi-modal embeddings that enable adaptive segmentation of video\ncontent via HDBSCAN clustering. A subsequent refinement stage incorporating\nquality assessment and duplicate filtering ensures that the final keyframe set\nis both concise and semantically rich. Comprehensive evaluations on benchmark\ndatasets TVSum20 and SumMe demonstrate that TriPSS achieves state-of-the-art\nperformance, substantially outperforming traditional unimodal and previous\nmulti-modal methods. These results underscore TriPSS's ability to capture\nnuanced visual and semantic information, thereby setting a new benchmark for\nvideo content understanding in large-scale retrieval scenarios.\n","authors":["Mert Can Cakmak","Nitin Agarwal","Diwash Poudel"],"pdf_url":"https://arxiv.org/pdf/2506.05395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18460v2","updated":"2025-06-03T17:47:36Z","published":"2025-02-25T18:59:07Z","title":"DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense\n  Retrievers","summary":"  Large language models (LLMs) have demonstrated strong effectiveness and\nrobustness while fine-tuned as dense retrievers. However, their large parameter\nsize brings significant inference time computational challenges, including high\nencoding costs for large-scale corpora and increased query latency, limiting\ntheir practical deployment. While smaller retrievers offer better efficiency,\nthey often fail to generalize effectively with limited supervised fine-tuning\ndata. In this work, we introduce DRAMA, a training framework that leverages\nLLMs to train smaller generalizable dense retrievers. In particular, we adopt\npruned LLMs as the backbone and train on diverse LLM-augmented data in a\nsingle-stage contrastive learning setup. Experiments show that DRAMA offers\nbetter multilingual and long-context capabilities than traditional\nencoder-based retrievers, and achieves strong performance across multiple tasks\nand languages. These highlight the potential of connecting the training of\nsmaller retrievers with the growing advancements in LLMs, bridging the gap\nbetween efficiency and generalization.\n","authors":["Xueguang Ma","Xi Victoria Lin","Barlas Oguz","Jimmy Lin","Wen-tau Yih","Xilun Chen"],"pdf_url":"https://arxiv.org/pdf/2502.18460v2.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2506.03035v1","updated":"2025-06-03T16:18:45Z","published":"2025-06-03T16:18:45Z","title":"Leveraging Information Retrieval to Enhance Spoken Language\n  Understanding Prompts in Few-Shot Learning","summary":"  Understanding user queries is fundamental in many applications, such as home\nassistants, booking systems, or recommendations. Accordingly, it is crucial to\ndevelop accurate Spoken Language Understanding (SLU) approaches to ensure the\nreliability of the considered system. Current State-of-the-Art SLU techniques\nrely on large amounts of training data; however, only limited annotated\nexamples are available for specific tasks or languages.\n  In the meantime, instruction-tuned large language models (LLMs) have shown\nexceptional performance on unseen tasks in a few-shot setting when provided\nwith adequate prompts. In this work, we propose to explore example selection by\nleveraging Information retrieval (IR) approaches to build an enhanced prompt\nthat is applied to an SLU task. We evaluate the effectiveness of the proposed\nmethod on several SLU benchmarks. Experimental results show that lexical IR\nmethods significantly enhance performance without increasing prompt length.\n","authors":["Pierre Lepagnol","Sahar Ghannay","Thomas Gerald","Christophe Servan","Sophie Rosset"],"pdf_url":"https://arxiv.org/pdf/2506.03035v1.pdf","comment":"Conference paper accepted to INTERSPEECH 2025"},{"id":"http://arxiv.org/abs/2411.06256v4","updated":"2025-06-03T14:58:07Z","published":"2024-11-09T19:07:58Z","title":"Annotative Indexing","summary":"  This paper introduces annotative indexing, a novel framework that unifies and\ngeneralizes traditional inverted indexes, column stores, object stores, and\ngraph databases. As a result, annotative indexing can provide the underlying\nindexing framework for databases that support retrieval augmented generation,\nknowledge graphs, entity retrieval, semi-structured data, and ranked retrieval.\nWhile we primarily focus on human language data in the form of text, annotative\nindexing is sufficiently general to support a range of other datatypes, and we\nprovide examples of SQL-like queries over a JSON store that includes numbers\nand dates. Taking advantage of the flexibility of annotative indexing, we also\ndemonstrate a fully dynamic annotative index incorporating support for ACID\nproperties of transactions with hundreds of multiple concurrent readers and\nwriters.\n","authors":["Charles L. A. Clarke"],"pdf_url":"https://arxiv.org/pdf/2411.06256v4.pdf","comment":"Code at https://github.com/claclark/Cottontail"},{"id":"http://arxiv.org/abs/2506.02924v1","updated":"2025-06-03T14:25:12Z","published":"2025-06-03T14:25:12Z","title":"INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and\n  Prompt-Based Approaches to Depression Symptom Identification","summary":"  In this work, we describe our team's approach to eRisk's 2025 Task 1: Search\nfor Symptoms of Depression. Given a set of sentences and the Beck's Depression\nInventory - II (BDI) questionnaire, participants were tasked with submitting up\nto 1,000 sentences per depression symptom in the BDI, sorted by relevance.\nParticipant submissions were evaluated according to standard Information\nRetrieval (IR) metrics, including Average Precision (AP) and R-Precision\n(R-PREC). The provided training data, however, consisted of sentences labeled\nas to whether a given sentence was relevant or not w.r.t. one of BDI's\nsymptoms. Due to this labeling limitation, we framed our development as a\nbinary classification task for each BDI symptom, and evaluated accordingly. To\nthat end, we split the available labeled data into training and validation\nsets, and explored foundation model fine-tuning, sentence similarity, Large\nLanguage Model (LLM) prompting, and ensemble techniques. The validation results\nrevealed that fine-tuning foundation models yielded the best performance,\nparticularly when enhanced with synthetic data to mitigate class imbalance. We\nalso observed that the optimal approach varied by symptom. Based on these\ninsights, we devised five independent test runs, two of which used ensemble\nmethods. These runs achieved the highest scores in the official IR evaluation,\noutperforming submissions from 16 other teams.\n","authors":["Diogo A. P. Nunes","Eugénio Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2506.02924v1.pdf","comment":"12 pages, 1 figure, 6 tables"},{"id":"http://arxiv.org/abs/2505.12574v4","updated":"2025-06-03T14:13:57Z","published":"2025-05-18T23:22:53Z","title":"PoisonArena: Uncovering Competing Poisoning Attacks in\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) systems, widely used to improve the\nfactual grounding of large language models (LLMs), are increasingly vulnerable\nto poisoning attacks, where adversaries inject manipulated content into the\nretriever's corpus. While prior research has predominantly focused on\nsingle-attacker settings, real-world scenarios often involve multiple,\ncompeting attackers with conflicting objectives. In this work, we introduce\nPoisonArena, the first benchmark to systematically study and evaluate competing\npoisoning attacks in RAG. We formalize the multi-attacker threat model, where\nattackers vie to control the answer to the same query using mutually exclusive\nmisinformation. PoisonArena leverages the Bradley-Terry model to quantify each\nmethod's competitive effectiveness in such adversarial environments. Through\nextensive experiments on the Natural Questions and MS MARCO datasets, we\ndemonstrate that many attack strategies successful in isolation fail under\ncompetitive pressure. Our findings highlight the limitations of conventional\nevaluation metrics like Attack Success Rate (ASR) and F1 score and underscore\nthe need for competitive evaluation to assess real-world attack robustness.\nPoisonArena provides a standardized framework to benchmark and develop future\nattack and defense strategies under more realistic, multi-adversary conditions.\n","authors":["Liuji Chen","Xiaofang Yang","Yuanzhuo Lu","Jinghao Zhang","Xin Sun","Qiang Liu","Shu Wu","Jing Dong","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2505.12574v4.pdf","comment":"Project page: https://poison-arena.github.io/"},{"id":"http://arxiv.org/abs/2505.20322v2","updated":"2025-06-03T13:40:17Z","published":"2025-05-23T17:59:18Z","title":"Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering\n  Target Atoms","summary":"  Precise control over language model generation is vital for ensuring both\nsafety and reliability. Although prompt engineering and steering are commonly\nused to intervene in model behaviors, the vast number of parameters in models\noften results in highly intertwined internal representations. This\ninterdependency can limit control precision and sometimes lead to unintended\nside effects. Recent research has explored the use of sparse autoencoders (SAE)\nto disentangle knowledge in high-dimensional spaces for steering. However,\nthese applications have been limited to toy tasks owing to the nontrivial issue\nof locating atomic knowledge components. In this paper, we propose Steering\nTarget Atoms (STA), a novel method that isolates and manipulates disentangled\nknowledge components to enhance safety. Comprehensive experiments demonstrate\nthe effectiveness of our approach. Further analysis reveals that steering\nexhibits superior robustness and flexibility, particularly in adversarial\nscenarios. We also apply the steering strategy to the large reasoning model,\nconfirming its effectiveness in precise reasoning control.\n","authors":["Mengru Wang","Ziwen Xu","Shengyu Mao","Shumin Deng","Zhaopeng Tu","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2505.20322v2.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2506.02872v1","updated":"2025-06-03T13:37:44Z","published":"2025-06-03T13:37:44Z","title":"Token and Span Classification for Entity Recognition in French\n  Historical Encyclopedias","summary":"  Named Entity Recognition (NER) in historical texts presents unique challenges\ndue to non-standardized language, archaic orthography, and nested or\noverlapping entities. This study benchmarks a diverse set of NER approaches,\nranging from classical Conditional Random Fields (CRFs) and spaCy-based models\nto transformer-based architectures such as CamemBERT and sequence-labeling\nmodels like Flair. Experiments are conducted on the GeoEDdA dataset, a richly\nannotated corpus derived from 18th-century French encyclopedias. We propose\nframing NER as both token-level and span-level classification to accommodate\ncomplex nested entity structures typical of historical documents. Additionally,\nwe evaluate the emerging potential of few-shot prompting with generative\nlanguage models for low-resource scenarios. Our results demonstrate that while\ntransformer-based models achieve state-of-the-art performance, especially on\nnested entities, generative models offer promising alternatives when labeled\ndata are scarce. The study highlights ongoing challenges in historical NER and\nsuggests avenues for hybrid approaches combining symbolic and neural methods to\nbetter capture the intricacies of early modern French text.\n","authors":["Ludovic Moncla","Hédi Zeghidi"],"pdf_url":"https://arxiv.org/pdf/2506.02872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.23908v2","updated":"2025-06-03T13:32:45Z","published":"2025-05-29T18:02:16Z","title":"Transforming Podcast Preview Generation: From Expert Models to LLM-Based\n  Systems","summary":"  Discovering and evaluating long-form talk content such as videos and podcasts\nposes a significant challenge for users, as it requires a considerable time\ninvestment. Previews offer a practical solution by providing concise snippets\nthat showcase key moments of the content, enabling users to make more informed\nand confident choices. We propose an LLM-based approach for generating podcast\nepisode previews and deploy the solution at scale, serving hundreds of\nthousands of podcast previews in a real-world application. Comprehensive\noffline evaluations and online A/B testing demonstrate that LLM-generated\npreviews consistently outperform a strong baseline built on top of various ML\nexpert models, showcasing a significant reduction in the need for meticulous\nfeature engineering. The offline results indicate notable enhancements in\nunderstandability, contextual clarity, and interest level, and the online A/B\ntest shows a 4.6% increase in user engagement with preview content, along with\na 5x boost in processing efficiency, offering a more streamlined and performant\nsolution compared to the strong baseline of feature-engineered expert models.\n","authors":["Winstead Zhu","Ann Clifton","Azin Ghazimatin","Edgar Tanaka","Edward Ronan"],"pdf_url":"https://arxiv.org/pdf/2505.23908v2.pdf","comment":"9 pages, 2 figures, accepted at ACL 2025 Industry Track"},{"id":"http://arxiv.org/abs/2506.02839v1","updated":"2025-06-03T13:08:17Z","published":"2025-06-03T13:08:17Z","title":"DeepShop: A Benchmark for Deep Research Shopping Agents","summary":"  Web agents for online shopping have shown great promise in automating user\ninteractions across e-commerce platforms. Benchmarks for assessing such agents\ndo not reflect the complexity of real-world shopping scenarios, as they often\nconsist of overly simple queries with deterministic paths, such as \"Find iPhone\n15.\" Real shopping scenarios are inherently more layered, involving\nmulti-dimensional product attributes, search filters, and user-specific sorting\npreferences. To address this gap, we introduce DeepShop, a benchmark designed\nto evaluate web agents in complex and realistic online shopping environments.\nDeepShop comprises three key components. (1) Query diversity evolution:\nStarting from real user queries, we generate diverse queries across five\npopular online shopping domains. (2) Query complexity evolution: We further\nevolve these queries to increase complexity, considering product attributes,\nsearch filters, and sorting preferences, and classify them into three levels:\neasy, medium, and hard, based on the number of evolutions. (3) Fine-grained and\nholistic evaluation: We propose an automated evaluation framework that assesses\nagent performance in terms of fine-grained aspects (product attributes, search\nfilters, and sorting preferences) and reports the overall success rate through\nholistic evaluation. We conduct a systematic evaluation of retrieval-augmented\ngeneration (RAG) methods, web agents, and deep research systems. Results show\nthat RAG struggles with complex queries due to its lack of web interaction,\nwhile other methods face significant challenges with filters and sorting\npreferences, leading to low overall success rates. We also perform\ncross-category, complexity-based evaluations and error analyses to support the\nadvancement of deep research shopping agents.\n","authors":["Yougang Lyu","Xiaoyu Zhang","Lingyong Yan","Maarten de Rijke","Zhaochun Ren","Xiuying Chen"],"pdf_url":"https://arxiv.org/pdf/2506.02839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02834v1","updated":"2025-06-03T13:04:00Z","published":"2025-06-03T13:04:00Z","title":"Combining social relations and interaction data in Recommender System\n  with Graph Convolution Collaborative Filtering","summary":"  A recommender system is an important subject in the field of data mining,\nwhere the item rating information from users is exploited and processed to make\nsuitable recommendations with all other users. The recommender system creates\nconvenience for e-commerce users and stimulates the consumption of items that\nare suitable for users. In addition to e-commerce, a recommender system is also\nused to provide recommendations on books to read, movies to watch, courses to\ntake or websites to visit. Similarity between users is an important impact for\nrecommendation, which could be calculated from the data of past user ratings of\nthe item by methods of collaborative filtering, matrix factorization or\nsingular vector decomposition. In the development of graph data mining\ntechniques, the relationships between users and items can be represented by\nmatrices from which collaborative filtering could be done with the larger\ndatabase, more accurate and faster in calculation. All these data can be\nrepresented graphically and mined by today's highly developed graph neural\nnetwork models. On the other hand, users' social friendship data also influence\nconsumption habits because recommendations from friends will be considered more\ncarefully than information sources. However, combining a user's friend\ninfluence and the similarity between users whose similar shopping habits is\nchallenging. Because the information is noisy and it affects each particular\ndata set in different ways. In this study, we present the input data processing\nmethod to remove outliers which are single reviews or users with little\ninteraction with the items; the next proposed model will combine the social\nrelationship data and the similarity in the rating history of users to improve\nthe accuracy and recall of the recommender system.\n","authors":["Tin T. Tran","Vaclav Snasel","Loc Tan Nguyen"],"pdf_url":"https://arxiv.org/pdf/2506.02834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02784v1","updated":"2025-06-03T12:11:34Z","published":"2025-06-03T12:11:34Z","title":"UTCS: Effective Unsupervised Temporal Community Search with Pre-training\n  of Temporal Dynamics and Subgraph Knowledge","summary":"  In many real-world applications, the evolving relationships between entities\ncan be modeled as temporal graphs, where each edge has a timestamp representing\nthe interaction time.\n  As a fundamental problem in graph analysis, {\\it community search (CS)} in\ntemporal graphs has received growing attention but exhibits two major\nlimitations: (1) Traditional methods typically require predefined subgraph\nstructures, which are not always known in advance. (2) Learning-based methods\nstruggle to capture temporal interaction information. To fill this research\ngap, in this paper, we propose an effective \\textbf{U}nsupervised\n\\textbf{T}emporal \\textbf{C}ommunity \\textbf{S}earch with pre-training of\ntemporal dynamics and subgraph knowledge model (\\textbf{\\model}).\n\\model~contains two key stages: offline pre-training and online search. In the\nfirst stage, we introduce multiple learning objectives to facilitate the\npre-training process in the unsupervised learning setting. In the second stage,\nwe identify a candidate subgraph and compute community scores using the\npre-trained node representations and a novel scoring mechanism to determine the\nfinal community members. Experiments on five real-world datasets demonstrate\nthe effectiveness.\n","authors":["Yue Zhang","Yankai Chen","Yingli Zhou","Yucan Guo","Xiaolin Han","Chenhao Ma"],"pdf_url":"https://arxiv.org/pdf/2506.02784v1.pdf","comment":"Accepted by SIGIR'25 short paper track"},{"id":"http://arxiv.org/abs/2506.02750v1","updated":"2025-06-03T11:11:43Z","published":"2025-06-03T11:11:43Z","title":"Learning Binarized Representations with Pseudo-positive Sample\n  Enhancement for Efficient Graph Collaborative Filtering","summary":"  Learning vectorized embeddings is fundamental to many recommender systems for\nuser-item matching. To enable efficient online inference, representation\nbinarization, which embeds latent features into compact binary sequences, has\nrecently shown significant promise in optimizing both memory usage and\ncomputational overhead. However, existing approaches primarily focus on\nnumerical quantization, neglecting the associated information loss, which often\nresults in noticeable performance degradation. To address these issues, we\nstudy the problem of graph representation binarization for efficient\ncollaborative filtering. Our findings indicate that explicitly mitigating\ninformation loss at various stages of embedding binarization has a significant\npositive impact on performance. Building on these insights, we propose an\nenhanced framework, BiGeaR++, which specifically leverages supervisory signals\nfrom pseudo-positive samples, incorporating both real item data and latent\nembedding samples. Compared to its predecessor BiGeaR, BiGeaR++ introduces a\nfine-grained inference distillation mechanism and an effective embedding sample\nsynthesis approach. Empirical evaluations across five real-world datasets\ndemonstrate that the new designs in BiGeaR++ work seamlessly well with other\nmodules, delivering substantial improvements of around 1%-10% over BiGeaR and\nthus achieving state-of-the-art performance compared to the competing methods.\nOur implementation is available at https://github.com/QueYork/BiGeaR-SS.\n","authors":["Yankai Chen","Yue Que","Xinni Zhang","Chen Ma","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2506.02750v1.pdf","comment":"Accepted by TOIS"},{"id":"http://arxiv.org/abs/2505.11582v2","updated":"2025-06-03T09:18:51Z","published":"2025-05-16T17:06:35Z","title":"Comparing Lexical and Semantic Vector Search Methods When Classifying\n  Medical Documents","summary":"  Classification is a common AI problem, and vector search is a typical\nsolution. This transforms a given body of text into a numerical representation,\nknown as an embedding, and modern improvements to vector search focus on\noptimising speed and predictive accuracy. This is often achieved through neural\nmethods that aim to learn language semantics. However, our results suggest that\nthese are not always the best solution. Our task was to classify\nrigidly-structured medical documents according to their content, and we found\nthat using off-the-shelf semantic vector search produced slightly worse\npredictive accuracy than creating a bespoke lexical vector search model, and\nthat it required significantly more time to execute. These findings suggest\nthat traditional methods deserve to be contenders in the information retrieval\ntoolkit, despite the prevalence and success of neural models.\n","authors":["Lee Harris"],"pdf_url":"https://arxiv.org/pdf/2505.11582v2.pdf","comment":"This project was funded by a UKRI grant, number: 10048265"},{"id":"http://arxiv.org/abs/2501.03835v4","updated":"2025-06-03T09:02:22Z","published":"2025-01-07T14:45:30Z","title":"TACLR: A Scalable and Efficient Retrieval-based Method for Industrial\n  Product Attribute Value Identification","summary":"  Product Attribute Value Identification (PAVI) involves identifying attribute\nvalues from product profiles, a key task for improving product search,\nrecommendation, and business analytics on e-commerce platforms. However,\nexisting PAVI methods face critical challenges, such as inferring implicit\nvalues, handling out-of-distribution (OOD) values, and producing normalized\noutputs. To address these limitations, we introduce Taxonomy-Aware Contrastive\nLearning Retrieval (TACLR), the first retrieval-based method for PAVI. TACLR\nformulates PAVI as an information retrieval task by encoding product profiles\nand candidate values into embeddings and retrieving values based on their\nsimilarity. It leverages contrastive training with taxonomy-aware hard negative\nsampling and employs adaptive inference with dynamic thresholds. TACLR offers\nthree key advantages: (1) it effectively handles implicit and OOD values while\nproducing normalized outputs; (2) it scales to thousands of categories, tens of\nthousands of attributes, and millions of values; and (3) it supports efficient\ninference for high-load industrial deployment. Extensive experiments on\nproprietary and public datasets validate the effectiveness and efficiency of\nTACLR. Further, it has been successfully deployed on the real-world e-commerce\nplatform Xianyu, processing millions of product listings daily with frequently\nupdated, large-scale attribute taxonomies. We release the code to facilitate\nreproducibility and future research at https://github.com/SuYindu/TACLR.\n","authors":["Yindu Su","Huike Zou","Lin Sun","Ting Zhang","Haiyang Yang","Liyu Chen","David Lo","Qingheng Zhang","Shuguang Han","Jufeng Chen"],"pdf_url":"https://arxiv.org/pdf/2501.03835v4.pdf","comment":"Accepted at ACL 2025"},{"id":"http://arxiv.org/abs/2502.09304v2","updated":"2025-06-03T08:45:42Z","published":"2025-02-13T13:16:16Z","title":"KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for\n  Graph-RAG","summary":"  Graph-RAG constructs a knowledge graph from text chunks to improve retrieval\nin Large Language Model (LLM)-based question answering. It is particularly\nuseful in domains such as biomedicine, law, and political science, where\nretrieval often requires multi-hop reasoning over proprietary documents. Some\nexisting Graph-RAG systems construct KNN graphs based on text chunk relevance,\nbut this coarse-grained approach fails to capture entity relationships within\ntexts, leading to sub-par retrieval and generation quality. To address this,\nrecent solutions leverage LLMs to extract entities and relationships from text\nchunks, constructing triplet-based knowledge graphs. However, this approach\nincurs significant indexing costs, especially for large document collections.\n  To ensure a good result accuracy while reducing the indexing cost, we propose\nKET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small\nset of key text chunks and leverages an LLM to construct a knowledge graph\nskeleton. It then builds a text-keyword bipartite graph from all text chunks,\nserving as a lightweight alternative to a full knowledge graph. During\nretrieval, KET-RAG searches both structures: it follows the local search\nstrategy of existing Graph-RAG systems on the skeleton while mimicking this\nsearch on the bipartite graph to improve retrieval quality. We evaluate 13\nsolutions on three real-world datasets, demonstrating that KET-RAG outperforms\nall competitors in indexing cost, retrieval effectiveness, and generation\nquality. Notably, it achieves comparable or superior retrieval quality to\nMicrosoft's Graph-RAG while reducing indexing costs by over an order of\nmagnitude. Additionally, it improves the generation quality by up to 32.4%\nwhile lowering indexing costs by around 20%.\n","authors":["Yiqian Huang","Shiqi Zhang","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2502.09304v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00622v2","updated":"2025-06-03T08:31:06Z","published":"2025-05-31T16:20:14Z","title":"Improving Dialogue State Tracking through Combinatorial Search for\n  In-Context Examples","summary":"  In dialogue state tracking (DST), in-context learning comprises a retriever\nthat selects labeled dialogues as in-context examples and a DST model that uses\nthese examples to infer the dialogue state of the query dialogue. Existing\nmethods for constructing training data for retrievers suffer from three key\nlimitations: (1) the synergistic effect of examples is not considered, (2) the\nlinguistic characteristics of the query are not sufficiently factored in, and\n(3) scoring is not directly optimized for DST performance. Consequently, the\nretriever can fail to retrieve examples that would substantially improve DST\nperformance. To address these issues, we present CombiSearch, a method that\nscores effective in-context examples based on their combinatorial impact on DST\nperformance. Our evaluation on MultiWOZ shows that retrievers trained with\nCombiSearch surpass state-of-the-art models, achieving a 20x gain in data\nefficiency and generalizing well to the SGD dataset. Moreover, CombiSearch\nattains a 12% absolute improvement in the upper bound DST performance over\ntraditional approaches when no retrieval errors are assumed. This significantly\nincreases the headroom for practical DST performance while demonstrating that\nexisting methods rely on suboptimal data for retriever training.\n","authors":["Haesung Pyun","Yoonah Park","Yohan Jo"],"pdf_url":"https://arxiv.org/pdf/2506.00622v2.pdf","comment":"This paper has been accepted for publication at ACL 2025"},{"id":"http://arxiv.org/abs/2506.02589v1","updated":"2025-06-03T08:11:16Z","published":"2025-06-03T08:11:16Z","title":"Evaluating Named Entity Recognition Models for Russian Cultural News\n  Texts: From BERT to LLM","summary":"  This paper addresses the challenge of Named Entity Recognition (NER) for\nperson names within the specialized domain of Russian news texts concerning\ncultural events. The study utilizes the unique SPbLitGuide dataset, a\ncollection of event announcements from Saint Petersburg spanning 1999 to 2019.\nA comparative evaluation of diverse NER models is presented, encompassing\nestablished transformer-based architectures such as DeepPavlov, RoBERTa, and\nSpaCy, alongside recent Large Language Models (LLMs) including GPT-3.5, GPT-4,\nand GPT-4o. Key findings highlight the superior performance of GPT-4o when\nprovided with specific prompting for JSON output, achieving an F1 score of\n0.93. Furthermore, GPT-4 demonstrated the highest precision at 0.99. The\nresearch contributes to a deeper understanding of current NER model\ncapabilities and limitations when applied to morphologically rich languages\nlike Russian within the cultural heritage domain, offering insights for\nresearchers and practitioners. Follow-up evaluation with GPT-4.1 (April 2025)\nachieves F1=0.94 for both simple and structured prompts, demonstrating rapid\nprogress across model families and simplified deployment requirements.\n","authors":["Maria Levchenko"],"pdf_url":"https://arxiv.org/pdf/2506.02589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.23809v2","updated":"2025-06-03T07:39:21Z","published":"2025-05-27T08:40:11Z","title":"LLM-Driven E-Commerce Marketing Content Optimization: Balancing\n  Creativity and Conversion","summary":"  As e-commerce competition intensifies, balancing creative content with\nconversion effectiveness becomes critical. Leveraging LLMs' language generation\ncapabilities, we propose a framework that integrates prompt engineering,\nmulti-objective fine-tuning, and post-processing to generate marketing copy\nthat is both engaging and conversion-driven. Our fine-tuning method combines\nsentiment adjustment, diversity enhancement, and CTA embedding. Through offline\nevaluations and online A/B tests across categories, our approach achieves a\n12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content\nnovelty. This provides a practical solution for automated copy generation and\nsuggests paths for future multimodal, real-time personalization.\n","authors":["Haowei Yang","Haotian Lyu","Tianle Zhang","Dingzhou Wang","Yushang Zhao"],"pdf_url":"https://arxiv.org/pdf/2505.23809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01705v2","updated":"2025-06-03T07:35:59Z","published":"2025-06-02T14:11:21Z","title":"SPOT-Trip: Dual-Preference Driven Out-of-Town Trip Recommendation","summary":"  Out-of-town trip recommendation aims to generate a sequence of Points of\nInterest (POIs) for users traveling from their hometowns to previously\nunvisited regions based on personalized itineraries, e.g., origin, destination,\nand trip duration. Modeling the complex user preferences--which often exhibit a\ntwo-fold nature of static and dynamic interests--is critical for effective\nrecommendations. However, the sparsity of out-of-town check-in data presents\nsignificant challenges in capturing such user preferences. Meanwhile, existing\nmethods often conflate the static and dynamic preferences, resulting in\nsuboptimal performance. In this paper, we for the first time systematically\nstudy the problem of out-of-town trip recommendation. A novel framework\nSPOT-Trip is proposed to explicitly learns the dual static-dynamic user\npreferences. Specifically, to handle scarce data, we construct a POI attribute\nknowledge graph to enrich the semantic modeling of users' hometown and\nout-of-town check-ins, enabling the static preference modeling through\nattribute relation-aware aggregation. Then, we employ neural ordinary\ndifferential equations (ODEs) to capture the continuous evolution of latent\ndynamic user preferences and innovatively combine a temporal point process to\ndescribe the instantaneous probability of each preference behavior. Further, a\nstatic-dynamic fusion module is proposed to merge the learned static and\ndynamic user preferences. Extensive experiments on real data offer insight into\nthe effectiveness of the proposed solutions, showing that SPOT-Trip achieves\nperformance improvement by up to 17.01%.\n","authors":["Yinghui Liu","Hao Miao","Guojiang Shen","Yan Zhao","Xiangjie Kong","Ivan Lee"],"pdf_url":"https://arxiv.org/pdf/2506.01705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02527v1","updated":"2025-06-03T07:05:49Z","published":"2025-06-03T07:05:49Z","title":"Multilingual Information Retrieval with a Monolingual Knowledge Base","summary":"  Multilingual information retrieval has emerged as powerful tools for\nexpanding knowledge sharing across languages. On the other hand, resources on\nhigh quality knowledge base are often scarce and in limited languages,\ntherefore an effective embedding model to transform sentences from different\nlanguages into a feature vector space same as the knowledge base language\nbecomes the key ingredient for cross language knowledge sharing, especially to\ntransfer knowledge available in high-resource languages to low-resource ones.\nIn this paper we propose a novel strategy to fine-tune multilingual embedding\nmodels with weighted sampling for contrastive learning, enabling multilingual\ninformation retrieval with a monolingual knowledge base. We demonstrate that\nthe weighted sampling strategy produces performance gains compared to standard\nones by up to 31.03\\% in MRR and up to 33.98\\% in Recall@3. Additionally, our\nproposed methodology is language agnostic and applicable for both multilingual\nand code switching use cases.\n","authors":["Yingying Zhuang","Aman Gupta","Anurag Beniwal"],"pdf_url":"https://arxiv.org/pdf/2506.02527v1.pdf","comment":"6 pages, accepted at GENNEXT@SIGIR25"},{"id":"http://arxiv.org/abs/2502.18017v2","updated":"2025-06-03T05:34:30Z","published":"2025-02-25T09:26:12Z","title":"ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic\n  Iterative Reasoning Agents","summary":"  Understanding information from visually rich documents remains a significant\nchallenge for traditional Retrieval-Augmented Generation (RAG) methods.\nExisting benchmarks predominantly focus on image-based question answering (QA),\noverlooking the fundamental challenges of efficient retrieval, comprehension,\nand reasoning within dense visual documents. To bridge this gap, we introduce\nViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich\ndocuments requiring complex reasoning. Based on it, we identify key limitations\nin current RAG approaches: (i) purely visual retrieval methods struggle to\neffectively integrate both textual and visual features, and (ii) previous\napproaches often allocate insufficient reasoning tokens, limiting their\neffectiveness. To address these challenges, we propose ViDoRAG, a novel\nmulti-agent RAG framework tailored for complex reasoning across visual\ndocuments. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy\nto effectively handle multi-modal retrieval. To further elicit the model's\nreasoning capabilities, we introduce an iterative agent workflow incorporating\nexploration, summarization, and reflection, providing a framework for\ninvestigating test-time scaling in RAG domains. Extensive experiments on\nViDoSeek validate the effectiveness and generalization of our approach.\nNotably, ViDoRAG outperforms existing methods by over 10% on the competitive\nViDoSeek benchmark. The code is available at\nhttps://github.com/Alibaba-NLP/ViDoRAG.\n","authors":["Qiuchen Wang","Ruixue Ding","Zehui Chen","Weiqi Wu","Shihang Wang","Pengjun Xie","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.18017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09891v2","updated":"2025-06-03T03:38:31Z","published":"2025-02-14T03:28:36Z","title":"ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented\n  Generation","summary":"  Retrieval-Augmented Generation (RAG) has proven effective in integrating\nexternal knowledge into large language models (LLMs) for solving\nquestion-answer (QA) tasks. The state-of-the-art RAG approaches often use the\ngraph data as the external data since they capture the rich semantic\ninformation and link relationships between entities. However, existing\ngraph-based RAG approaches cannot accurately identify the relevant information\nfrom the graph and also consume large numbers of tokens in the online retrieval\nprocess. To address these issues, we introduce a novel graph-based RAG\napproach, called Attributed Community-based Hierarchical RAG (ArchRAG), by\naugmenting the question using attributed communities, and also introducing a\nnovel LLM-based hierarchical clustering method. To retrieve the most relevant\ninformation from the graph for the question, we build a novel hierarchical\nindex structure for the attributed communities and develop an effective online\nretrieval method. Experimental results demonstrate that ArchRAG outperforms\nexisting methods in both accuracy and token cost. Moreover, ArchRAG has been\nsuccessfully applied to domain knowledge QA in Huawei Cloud Computing.\n","authors":["Shu Wang","Yixiang Fang","Yingli Zhou","Xilin Liu","Yuchi Ma"],"pdf_url":"https://arxiv.org/pdf/2502.09891v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.05031v2","updated":"2025-06-03T02:55:09Z","published":"2025-05-08T08:06:34Z","title":"LSRP: A Leader-Subordinate Retrieval Framework for Privacy-Preserving\n  Cloud-Device Collaboration","summary":"  Cloud-device collaboration leverages on-cloud Large Language Models (LLMs)\nfor handling public user queries and on-device Small Language Models (SLMs) for\nprocessing private user data, collectively forming a powerful and\nprivacy-preserving solution. However, existing approaches often fail to fully\nleverage the scalable problem-solving capabilities of on-cloud LLMs while\nunderutilizing the advantage of on-device SLMs in accessing and processing\npersonalized data. This leads to two interconnected issues: 1) Limited\nutilization of the problem-solving capabilities of on-cloud LLMs, which fail to\nalign with personalized user-task needs, and 2) Inadequate integration of user\ndata into on-device SLM responses, resulting in mismatches in contextual user\ninformation.\n  In this paper, we propose a Leader-Subordinate Retrieval framework for\nPrivacy-preserving cloud-device collaboration (LSRP), a novel solution that\nbridges these gaps by: 1) enhancing on-cloud LLM guidance to on-device SLM\nthrough a dynamic selection of task-specific leader strategies named as\nuser-to-user retrieval-augmented generation (U-U-RAG), and 2) integrating the\ndata advantages of on-device SLMs through small model feedback Direct\nPreference Optimization (SMFB-DPO) for aligning the on-cloud LLM with the\non-device SLM. Experiments on two datasets demonstrate that LSRP consistently\noutperforms state-of-the-art baselines, significantly improving question-answer\nrelevance and personalization, while preserving user privacy through efficient\non-device retrieval. Our code is available at:\nhttps://github.com/Applied-Machine-Learning-Lab/LSRP.\n","authors":["Yingyi Zhang","Pengyue Jia","Xianneng Li","Derong Xu","Maolin Wang","Yichao Wang","Zhaocheng Du","Huifeng Guo","Yong Liu","Ruiming Tang","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2505.05031v2.pdf","comment":"Accepted at KDD'25"},{"id":"http://arxiv.org/abs/2505.16133v4","updated":"2025-06-03T02:49:46Z","published":"2025-05-22T02:22:11Z","title":"HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine\n  Retrieval and Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) encounters efficiency challenges when\nscaling to massive knowledge bases while preserving contextual relevance. We\npropose Hash-RAG, a framework that integrates deep hashing techniques with\nsystematic optimizations to address these limitations. Our queries directly\nlearn binary hash codes from knowledgebase code, eliminating intermediate\nfeature extraction steps, and significantly reducing storage and computational\noverhead. Building upon this hash-based efficient retrieval framework, we\nestablish the foundation for fine-grained chunking. Consequently, we design a\nPrompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved\nhash-indexed propositions and their original document segments through prompt\nengineering to enhance the LLM's contextual awareness. Experimental evaluations\non NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a\n90% reduction in retrieval time compared to conventional methods while\nmaintaining considerate recall performance. Additionally, The proposed system\noutperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.\n","authors":["Jinyu Guo","Xunlei Chen","Qiyang Xia","Zhaokun Wang","Jie Ou","Libo Qin","Shunyu Yao","Wenhong Tian"],"pdf_url":"https://arxiv.org/pdf/2505.16133v4.pdf","comment":"Accepted at Findings of ACL 2025"},{"id":"http://arxiv.org/abs/2506.02368v1","updated":"2025-06-03T02:08:55Z","published":"2025-06-03T02:08:55Z","title":"NextQuill: Causal Preference Modeling for Enhancing LLM Personalization","summary":"  Personalizing large language models (LLMs) for individual users has become\nincreasingly important as they are progressively integrated into real-world\napplications to support users' daily lives. However, existing personalization\napproaches often fail to distinguish which components of model predictions and\ntraining data truly reflect user preferences, leading to superficial\npersonalization alignment. In this paper, we introduce NextQuill, a novel LLM\npersonalization alignment framework grounded in causal preference modeling. We\napproach personalization from a causal perspective, treating both model\npredictions and ground-truth data generation as outcomes influenced by user\npreferences, along with other factors. We define the true preference effect as\nthe causal impact of user history (which reflects preferences) on each token\nprediction or data generation instance, estimated through causal intervention\ntechniques. Building on this insight, NextQuill introduces two complementary\nalignment strategies: (1) aligning model-internal causal preference effects on\npredictions with those reflected in ground-truth data, rather than\nindiscriminately fitting predictions, and (2) focusing on fitting\npreference-bearing tokens identified via ground-truth data preference effects,\nrather than treating all tokens uniformly. By integrating these strategies,\nNextQuill shifts the alignment process toward learning from causal preference\neffects, facilitating more effective and personalized adaptation. Experiments\nacross multiple personalization benchmarks demonstrate that NextQuill\nsignificantly improves personalization quality, offering a principled, causal\nfoundation for LLM personalization. Our codes are available on\nhttps://github.com/juntaoyou/NextQuill.\n","authors":["Xiaoyan Zhao","Juntao You","Yang Zhang","Wenjie Wang","Hong Cheng","Fuli Feng","See-Kiong Ng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2506.02368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00261v2","updated":"2025-06-03T02:07:40Z","published":"2025-05-30T21:50:29Z","title":"GPR: Empowering Generation with Graph-Pretrained Retriever","summary":"  Graph retrieval-augmented generation (GRAG) places high demands on\ngraph-specific retrievers. However, existing retrievers often rely on language\nmodels pretrained on plain text, limiting their effectiveness due to domain\nmisalignment and structure ignorance. To address these challenges, we propose\nGPR, a graph-based retriever pretrained directly on knowledge graphs. GPR\naligns natural language questions with relevant subgraphs through LLM-guided\ngraph augmentation and employs a structure-aware objective to learn\nfine-grained retrieval strategies. Experiments on two datasets, three LLM\nbackbones, and five baselines show that GPR consistently improves both\nretrieval quality and downstream generation, demonstrating its effectiveness as\na robust retrieval solution for GRAG.\n","authors":["Xiaochen Wang","Zongyu Wu","Yuan Zhong","Xiang Zhang","Suhang Wang","Fenglong Ma"],"pdf_url":"https://arxiv.org/pdf/2506.00261v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2506.03391v1","updated":"2025-06-03T21:00:34Z","published":"2025-06-03T21:00:34Z","title":"Universal Reusability in Recommender Systems: The Case for Dataset- and\n  Task-Independent Frameworks","summary":"  Recommender systems are pivotal in delivering personalized experiences across\nindustries, yet their adoption and scalability remain hindered by the need for\nextensive dataset- and task-specific configurations. Existing systems often\nrequire significant manual intervention, domain expertise, and engineering\neffort to adapt to new datasets or tasks, creating barriers to entry and\nlimiting reusability. In contrast, recent advancements in large language models\n(LLMs) have demonstrated the transformative potential of reusable systems,\nwhere a single model can handle diverse tasks without significant\nreconfiguration. Inspired by this paradigm, we propose the Dataset- and\nTask-Independent Recommender System (DTIRS), a framework aimed at maximizing\nthe reusability of recommender systems while minimizing barriers to entry.\nUnlike LLMs, which achieve task generalization directly, DTIRS focuses on\neliminating the need to rebuild or reconfigure recommendation pipelines for\nevery new dataset or task, even though models may still need retraining on new\ndata. By leveraging the novel Dataset Description Language (DsDL), DTIRS\nenables standardized dataset descriptions and explicit task definitions,\nallowing autonomous feature engineering, model selection, and optimization.\nThis paper introduces the concept of DTIRS and establishes a roadmap for\ntransitioning from Level-1 automation (dataset-agnostic but task-specific\nsystems) to Level-2 automation (fully dataset- and task-independent systems).\nAchieving this paradigm would maximize code reusability and lower barriers to\nadoption. We discuss key challenges, including the trade-offs between\ngeneralization and specialization, computational overhead, and scalability,\nwhile presenting DsDL as a foundational tool for this vision.\n","authors":["Tri Kurniawan Wijaya","Xinyang Shao","Gonzalo Fiz Pontiveros","Edoardo D'Amico"],"pdf_url":"https://arxiv.org/pdf/2506.03391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13989v1","updated":"2025-06-03T15:28:09Z","published":"2025-06-03T15:28:09Z","title":"AMLgentex: Mobilizing Data-Driven Research to Combat Money Laundering","summary":"  Money laundering enables organized crime by allowing illicit funds to enter\nthe legitimate economy. Although trillions of dollars are laundered each year,\nonly a small fraction is ever uncovered. This stems from a range of factors,\nincluding deliberate evasion by launderers, the rarity of confirmed cases, and\nthe limited visibility each financial institution has into the global\ntransaction network. While several synthetic datasets are available, they fail\nto model the structural and behavioral complexity of real-world money\nlaundering. In particular, they often overlook partial observability, sparse\nand uncertain labels, strategic behavior, temporal dynamics, class imbalance,\nand network-level dependencies. To address these limitations, we present\nAMLGentex, an open-source suite for generating realistic, configurable\ntransaction data and benchmarking detection methods. It enables systematic\nevaluation of anti-money laundering (AML) systems in a controlled environment\nthat captures key real-world challenges. We demonstrate how the framework can\nbe used to rigorously evaluate methods under conditions that reflect the\ncomplexity of practical AML scenarios.\n","authors":["Johan Östman","Edvin Callisen","Anton Chen","Kristiina Ausmees","Emanuel Gårdh","Jovan Zamac","Jolanta Goldsteine","Hugo Wefer","Simon Whelan","Markus Reimegård"],"pdf_url":"https://arxiv.org/pdf/2506.13989v1.pdf","comment":"21 figures, 22 pages"},{"id":"http://arxiv.org/abs/2505.19988v2","updated":"2025-06-03T15:23:03Z","published":"2025-05-26T13:43:43Z","title":"Automatic Metadata Extraction for Text-to-SQL","summary":"  Large Language Models (LLMs) have recently become sophisticated enough to\nautomate many tasks ranging from pattern finding to writing assistance to code\ngeneration. In this paper, we examine text-to-SQL generation. We have observed\nfrom decades of experience that the most difficult part of query development\nlies in understanding the database contents. These experiences inform the\ndirection of our research.\n  Text-to-SQL benchmarks such as SPIDER and Bird contain extensive metadata\nthat is generally not available in practice. Human-generated metadata requires\nthe use of expensive Subject Matter Experts (SMEs), who are often not fully\naware of many aspects of their databases. In this paper, we explore techniques\nfor automatic metadata extraction to enable text-to-SQL generation.\n  Ee explore the use of two standard and one newer metadata extraction\ntechniques: profiling, query log analysis, and SQL-to text generation using an\nLLM. We use BIRD benchmark [JHQY+23] to evaluate the effectiveness of these\ntechniques. BIRD does not provide query logs on their test database, so we\nprepared a submission that uses profiling alone, and does not use any specially\ntuned model (we used GPT-4o). From Sept 1 to Sept 23, 2024, and Nov 11 through\nNov 23, 2024 we achieved the highest score both with and without using the\n\"oracle\" information provided with the question set. We regained the number 1\nspot on Mar 11, 2025, and are still at #1 at the time of the writing (May,\n2025).\n","authors":["Vladislav Shkapenyuk","Divesh Srivastava","Theodore Johnson","Parisa Ghane"],"pdf_url":"https://arxiv.org/pdf/2505.19988v2.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2506.02830v1","updated":"2025-06-03T12:59:36Z","published":"2025-06-03T12:59:36Z","title":"Process Mining on Distributed Data Sources","summary":"  Major domains such as logistics, healthcare, and smart cities increasingly\nrely on sensor technologies and distributed infrastructures to monitor complex\nprocesses in real time. These developments are transforming the data landscape\nfrom discrete, structured records stored in centralized systems to continuous,\nfine-grained, and heterogeneous event streams collected across distributed\nenvironments. As a result, traditional process mining techniques, which assume\ncentralized event logs from enterprise systems, are no longer sufficient. In\nthis paper, we discuss the conceptual and methodological foundations for this\nemerging field. We identify three key shifts: from offline to online analysis,\nfrom centralized to distributed computing, and from event logs to sensor data.\nThese shifts challenge traditional assumptions about process data and call for\nnew approaches that integrate infrastructure, data, and user perspectives. To\nthis end, we define a research agenda that addresses six interconnected fields,\neach spanning multiple system dimensions. We advocate a principled methodology\ngrounded in algorithm engineering, combining formal modeling with empirical\nevaluation. This approach enables the development of scalable, privacy-aware,\nand user-centric process mining techniques suitable for distributed\nenvironments. Our synthesis provides a roadmap for advancing process mining\nbeyond its classical setting, toward a more responsive and decentralized\nparadigm of process intelligence.\n","authors":["Maximilian Weisenseel","Julia Andersen","Samira Akili","Christian Imenkamp","Hendrik Reiter","Christoffer Rubensson","Wilhelm Hasselbring","Olaf Landsiedel","Xixi Lu","Jan Mendling","Florian Tschorsch","Matthias Weidlich","Agnes Koschmider"],"pdf_url":"https://arxiv.org/pdf/2506.02830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02802v1","updated":"2025-06-03T12:32:56Z","published":"2025-06-03T12:32:56Z","title":"A Learned Cost Model-based Cross-engine Optimizer for SQL Workloads","summary":"  Lakehouse systems enable the same data to be queried with multiple execution\nengines. However, selecting the engine best suited to run a SQL query still\nrequires a priori knowledge of the query computational requirements and an\nengine capability, a complex and manual task that only becomes more difficult\nwith the emergence of new engines and workloads. In this paper, we address this\nlimitation by proposing a cross-engine optimizer that can automate engine\nselection for diverse SQL queries through a learned cost model. Optimized with\nhints, a query plan is used for query cost prediction and routing. Cost\nprediction is formulated as a multi-task learning problem, and multiple\npredictor heads, corresponding to different engines and provisionings, are used\nin the model architecture. This eliminates the need to train engine-specific\nmodels and allows the flexible addition of new engines at a minimal fine-tuning\ncost. Results on various databases and engines show that using a query\noptimized logical plan for cost estimation decreases the average Q-error by\neven 12.6% over using unoptimized plans as input. Moreover, the proposed\ncross-engine optimizer reduces the total workload runtime by up to 25.2% in a\nzero-shot setting and 30.4% in a few-shot setting when compared to random\nrouting.\n","authors":["András Strausz","Niels Pardon","Ioana Giurgiu"],"pdf_url":"https://arxiv.org/pdf/2506.02802v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2506.02509v1","updated":"2025-06-03T06:39:18Z","published":"2025-06-03T06:39:18Z","title":"In-context Clustering-based Entity Resolution with Large Language\n  Models: A Design Space Exploration","summary":"  Entity Resolution (ER) is a fundamental data quality improvement task that\nidentifies and links records referring to the same real-world entity.\nTraditional ER approaches often rely on pairwise comparisons, which can be\ncostly in terms of time and monetary resources, especially with large datasets.\nRecently, Large Language Models (LLMs) have shown promising results in ER\ntasks. However, existing methods typically focus on pairwise matching, missing\nthe potential of LLMs to perform clustering directly in a more cost-effective\nand scalable manner. In this paper, we propose a novel in-context clustering\napproach for ER, where LLMs are used to cluster records directly, reducing both\ntime complexity and monetary costs. We systematically investigate the design\nspace for in-context clustering, analyzing the impact of factors such as set\nsize, diversity, variation, and ordering of records on clustering performance.\nBased on these insights, we develop LLM-CER (LLM-powered Clustering-based ER),\nwhich achieves high-quality ER results while minimizing LLM API calls. Our\napproach addresses key challenges, including efficient cluster merging and LLM\nhallucination, providing a scalable and effective solution for ER. Extensive\nexperiments on nine real-world datasets demonstrate that our method\nsignificantly improves result quality, achieving up to 150% higher accuracy,\n10% increase in the F-measure, and reducing API calls by up to 5 times, while\nmaintaining comparable monetary cost to the most cost-effective baseline.\n","authors":["Jiajie Fu","Haitong Tang","Arijit Khan","Sharad Mehrotra","Xiangyu Ke","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2506.02509v1.pdf","comment":"Accept by SIGMOD26"}]},"2025-06-02T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.16311v2","updated":"2025-06-02T22:52:12Z","published":"2024-12-20T19:49:12Z","title":"HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational\n  Knowledge Bases","summary":"  Given a semi-structured knowledge base (SKB), where text documents are\ninterconnected by relations, how can we effectively retrieve relevant\ninformation to answer user questions? Retrieval-Augmented Generation (RAG)\nretrieves documents to assist large language models (LLMs) in question\nanswering; while Graph RAG (GRAG) uses structured knowledge bases as its\nknowledge source. However, many questions require both textual and relational\ninformation from SKB - referred to as \"hybrid\" questions - which complicates\nthe retrieval process and underscores the need for a hybrid retrieval method\nthat leverages both information. In this paper, through our empirical analysis,\nwe identify key insights that show why existing methods may struggle with\nhybrid question answering (HQA) over SKB. Based on these insights, we propose\nHybGRAG for HQA consisting of a retriever bank and a critic module, with the\nfollowing advantages: (1) Agentic, it automatically refines the output by\nincorporating feedback from the critic module, (2) Adaptive, it solves hybrid\nquestions requiring both textual and relational information with the retriever\nbank, (3) Interpretable, it justifies decision making with intuitive refinement\npath, and (4) Effective, it surpasses all baselines on HQA benchmarks. In\nexperiments on the STaRK benchmark, HybGRAG achieves significant performance\ngains, with an average relative improvement in Hit@1 of 51%.\n","authors":["Meng-Chieh Lee","Qi Zhu","Costas Mavromatis","Zhen Han","Soji Adeshina","Vassilis N. Ioannidis","Huzefa Rangwala","Christos Faloutsos"],"pdf_url":"https://arxiv.org/pdf/2412.16311v2.pdf","comment":"Accepted to ACL 2025"},{"id":"http://arxiv.org/abs/2503.05037v2","updated":"2025-06-02T22:19:43Z","published":"2025-03-06T23:23:13Z","title":"Collapse of Dense Retrievers: Short, Early, and Literal Biases\n  Outranking Factual Evidence","summary":"  Dense retrieval models are commonly used in Information Retrieval (IR)\napplications, such as Retrieval-Augmented Generation (RAG). Since they often\nserve as the first step in these systems, their robustness is critical to avoid\ndownstream failures. In this work, we repurpose a relation extraction dataset\n(e.g., Re-DocRED) to design controlled experiments that quantify the impact of\nheuristic biases, such as a preference for shorter documents, on retrievers\nlike Dragon+ and Contriever. We uncover major vulnerabilities, showing\nretrievers favor shorter documents, early positions, repeated entities, and\nliteral matches, all while ignoring the answer's presence! Notably, when\nmultiple biases combine, models exhibit catastrophic performance degradation,\nselecting the answer-containing document in less than 10% of cases over a\nsynthetic biased document without the answer. Furthermore, we show that these\nbiases have direct consequences for downstream applications like RAG, where\nretrieval-preferred documents can mislead LLMs, resulting in a 34% performance\ndrop than providing no documents at all.\nhttps://huggingface.co/datasets/mohsenfayyaz/ColDeR\n","authors":["Mohsen Fayyaz","Ali Modarressi","Hinrich Schuetze","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2503.05037v2.pdf","comment":"ACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2506.02291v1","updated":"2025-06-02T22:04:06Z","published":"2025-06-02T22:04:06Z","title":"Entity Image and Mixed-Modal Image Retrieval Datasets","summary":"  Despite advances in multimodal learning, challenging benchmarks for\nmixed-modal image retrieval that combines visual and textual information are\nlacking. This paper introduces a novel benchmark to rigorously evaluate image\nretrieval that demands deep cross-modal contextual understanding. We present\ntwo new datasets: the Entity Image Dataset (EI), providing canonical images for\nWikipedia entities, and the Mixed-Modal Image Retrieval Dataset (MMIR), derived\nfrom the WIT dataset. The MMIR benchmark features two challenging query types\nrequiring models to ground textual descriptions in the context of provided\nvisual entities: single entity-image queries (one entity image with descriptive\ntext) and multi-entity-image queries (multiple entity images with relational\ntext). We empirically validate the benchmark's utility as both a training\ncorpus and an evaluation set for mixed-modal retrieval. The quality of both\ndatasets is further affirmed through crowd-sourced human annotations. The\ndatasets are accessible through the GitHub page:\nhttps://github.com/google-research-datasets/wit-retrieval.\n","authors":["Cristian-Ioan Blaga","Paul Suganthan","Sahil Dua","Krishna Srinivasan","Enrique Alfonseca","Peter Dornbach","Tom Duerig","Imed Zitouni","Zhe Dong"],"pdf_url":"https://arxiv.org/pdf/2506.02291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02267v1","updated":"2025-06-02T21:15:20Z","published":"2025-06-02T21:15:20Z","title":"TransAct V2: Lifelong User Action Sequence Modeling on Pinterest\n  Recommendation","summary":"  Modeling user action sequences has become a popular focus in industrial\nrecommendation system research, particularly for Click-Through Rate (CTR)\nprediction tasks. However, industry-scale CTR models often rely on short user\nsequences, limiting their ability to capture long-term behavior. Additionally,\nthese models typically lack an integrated action-prediction task within a\npoint-wise ranking framework, reducing their predictive power. They also rarely\naddress the infrastructure challenges involved in efficiently serving\nlarge-scale sequential models. In this paper, we introduce TransAct V2, a\nproduction model for Pinterest's Homefeed ranking system, featuring three key\ninnovations: (1) leveraging very long user sequences to improve CTR\npredictions, (2) integrating a Next Action Loss function for enhanced user\naction forecasting, and (3) employing scalable, low-latency deployment\nsolutions tailored to handle the computational demands of extended user action\nsequences.\n","authors":["Xue Xia","Saurabh Vishwas Joshi","Kousik Rajesh","Kangnan Li","Yangyi Lu","Nikil Pancha","Dhruvil Deven Badani","Jiajing Xu","Pong Eksombatchai"],"pdf_url":"https://arxiv.org/pdf/2506.02267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02261v1","updated":"2025-06-02T21:09:29Z","published":"2025-06-02T21:09:29Z","title":"Towards Human-like Preference Profiling in Sequential Recommendation","summary":"  Sequential recommendation systems aspire to profile users by interpreting\ntheir interaction histories, echoing how humans make decisions by weighing\nexperience, relative preference strength, and situational relevance. Yet,\nexisting large language model (LLM)-based recommenders often fall short of\nmimicking the flexible, context-aware decision strategies humans exhibit,\nneglecting the structured, dynamic, and context-aware mechanisms fundamental to\nhuman behaviors. To bridge this gap, we propose RecPO, a preference\noptimization framework that models structured feedback and contextual delay to\nemulate human-like prioritization in sequential recommendation RecPO exploits\nadaptive reward margins based on inferred preference hierarchies and temporal\nsignals, enabling the model to favor immediately relevant items and to\ndistinguish between varying degrees of preference and aversion. Extensive\nexperiments across five real-world datasets demonstrate that RecPO not only\nyields performance gains over state-of-the-art baselines, but also mirrors key\ncharacteristics of human decision-making: favoring timely satisfaction,\nmaintaining coherent preferences, and exercising discernment under shifting\ncontexts.\n","authors":["Zhongyu Ouyang","Qianlong Wen","Chunhui Zhang","Yanfang Ye","Soroush Vosoughi"],"pdf_url":"https://arxiv.org/pdf/2506.02261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02160v1","updated":"2025-06-02T18:43:37Z","published":"2025-06-02T18:43:37Z","title":"A Dynamic Framework for Semantic Grouping of Common Data Elements (CDE)\n  Using Embeddings and Clustering","summary":"  This research aims to develop a dynamic and scalable framework to facilitate\nharmonization of Common Data Elements (CDEs) across heterogeneous biomedical\ndatasets by addressing challenges such as semantic heterogeneity, structural\nvariability, and context dependence to streamline integration, enhance\ninteroperability, and accelerate scientific discovery. Our methodology\nleverages Large Language Models (LLMs) for context-aware text embeddings that\nconvert CDEs into dense vectors capturing semantic relationships and patterns.\nThese embeddings are clustered using Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) to group semantically similar\nCDEs. The framework incorporates four key steps: (1) LLM-based text embedding\nto mathematically represent semantic context, (2) unsupervised clustering of\nembeddings via HDBSCAN, (3) automated labeling using LLM summarization, and (4)\nsupervised learning to train a classifier assigning new or unclustered CDEs to\nlabeled clusters. Evaluated on the NIH NLM CDE Repository with over 24,000\nCDEs, the system identified 118 meaningful clusters at an optimized minimum\ncluster size of 20. The classifier achieved 90.46 percent overall accuracy,\nperforming best in larger categories. External validation against Gravity\nProjects Social Determinants of Health domains showed strong agreement\n(Adjusted Rand Index 0.52, Normalized Mutual Information 0.78), indicating that\nembeddings effectively capture cluster characteristics. This adaptable and\nscalable approach offers a practical solution to CDE harmonization, improving\nselection efficiency and supporting ongoing data interoperability.\n","authors":["Madan Krishnamurthy","Daniel Korn","Melissa A Haendel","Christopher J Mungall","Anne E Thessen"],"pdf_url":"https://arxiv.org/pdf/2506.02160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01903v1","updated":"2025-06-02T17:24:30Z","published":"2025-06-02T17:24:30Z","title":"Getting almost all the bits from a quantum random access code","summary":"  A quantum random access code (QRAC) is a map $x\\mapsto\\rho_x$ that encodes\n$n$-bit strings $x$ into $m$-qubit quantum states $\\rho_x$, in a way that\nallows us to recover any one bit of $x$ with success probability $\\geq p$. The\nmeasurement on $\\rho_x$ that is used to recover, say, $x_1$ may destroy all the\ninformation about the other bits; this is in fact what happens in the\nwell-known QRAC that encodes $n=2$ bits into $m=1$ qubits. Does this generalize\nto large $n$, i.e., could there exist QRACs that are so \"obfuscated\" that one\ncannot get much more than one bit out of them? Here we show that this is not\nthe case: for every QRAC there exists a measurement that (with high\nprobability) recovers the full $n$-bit string $x$ up to small Hamming distance,\neven for the worst-case $x$.\n","authors":["Han-Hsuan Lin","Ronald de Wolf"],"pdf_url":"https://arxiv.org/pdf/2506.01903v1.pdf","comment":"14 pages LaTeX"},{"id":"http://arxiv.org/abs/2502.08826v3","updated":"2025-06-02T17:15:08Z","published":"2025-02-12T22:33:41Z","title":"Ask in Any Modality: A Comprehensive Survey on Multimodal\n  Retrieval-Augmented Generation","summary":"  Large Language Models (LLMs) suffer from hallucinations and outdated\nknowledge due to their reliance on static training data. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by integrating external dynamic\ninformation for improved factual grounding. With advances in multimodal\nlearning, Multimodal RAG extends this approach by incorporating multiple\nmodalities such as text, images, audio, and video to enhance the generated\noutputs. However, cross-modal alignment and reasoning introduce unique\nchallenges beyond those in unimodal RAG. This survey offers a structured and\ncomprehensive analysis of Multimodal RAG systems, covering datasets,\nbenchmarks, metrics, evaluation, methodologies, and innovations in retrieval,\nfusion, augmentation, and generation. We review training strategies, robustness\nenhancements, loss functions, and agent-based approaches, while also exploring\nthe diverse Multimodal RAG scenarios. In addition, we outline open challenges\nand future directions to guide research in this evolving field. This survey\nlays the foundation for developing more capable and reliable AI systems that\neffectively leverage multimodal dynamic external knowledge bases. All resources\nare publicly available at https://github.com/llm-lab-org/Multimodal-RAG-Survey.\n","authors":["Mohammad Mahdi Abootorabi","Amirhosein Zobeiri","Mahdi Dehghani","Mohammadali Mohammadkhani","Bardia Mohammadi","Omid Ghahroodi","Mahdieh Soleymani Baghshah","Ehsaneddin Asgari"],"pdf_url":"https://arxiv.org/pdf/2502.08826v3.pdf","comment":"GitHub repository:\n  https://github.com/llm-lab-org/Multimodal-RAG-Survey"},{"id":"http://arxiv.org/abs/2506.01877v1","updated":"2025-06-02T17:06:35Z","published":"2025-06-02T17:06:35Z","title":"When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting\n  Out-of-Distribution Corpora Using GradNormIR","summary":"  Dense retrievers encode texts into embeddings to efficiently retrieve\nrelevant documents from large databases in response to user queries. However,\nreal-world corpora continually evolve, leading to a shift from the original\ntraining distribution of the retriever. Without timely updates or retraining,\nindexing newly emerging documents can degrade retrieval performance for future\nqueries. Thus, identifying when a dense retriever requires an update is\ncritical for maintaining robust retrieval systems. In this paper, we propose a\nnovel task of predicting whether a corpus is out-of-distribution (OOD) relative\nto a dense retriever before indexing. Addressing this task allows us to\nproactively manage retriever updates, preventing potential retrieval failures.\nWe introduce GradNormIR, an unsupervised approach that leverages gradient norms\nto detect OOD corpora effectively. Experiments on the BEIR benchmark\ndemonstrate that GradNormIR enables timely updates of dense retrievers in\nevolving document collections, significantly enhancing retrieval robustness and\nefficiency.\n","authors":["Dayoon Ko","Jinyoung Kim","Sohyeon Kim","Jinhyuk Kim","Jaehoon Lee","Seonghak Song","Minyoung Lee","Gunhee Kim"],"pdf_url":"https://arxiv.org/pdf/2506.01877v1.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2506.01829v1","updated":"2025-06-02T16:15:34Z","published":"2025-06-02T16:15:34Z","title":"CiteEval: Principle-Driven Citation Evaluation for Source Attribution","summary":"  Citation quality is crucial in information-seeking systems, directly\ninfluencing trust and the effectiveness of information access. Current\nevaluation frameworks, both human and automatic, mainly rely on Natural\nLanguage Inference (NLI) to assess binary or ternary supportiveness from cited\nsources, which we argue is a suboptimal proxy for citation evaluation. In this\nwork we introduce CiteEval, a citation evaluation framework driven by\nprinciples focusing on fine-grained citation assessment within a broad context,\nencompassing not only the cited sources but the full retrieval context, user\nquery, and generated text. Guided by the proposed framework, we construct\nCiteBench, a multi-domain benchmark with high-quality human annotations on\ncitation quality. To enable efficient evaluation, we further develop\nCiteEval-Auto, a suite of model-based metrics that exhibit strong correlation\nwith human judgments. Experiments across diverse systems demonstrate\nCiteEval-Auto's superior ability to capture the multifaceted nature of\ncitations compared to existing metrics, offering a principled and scalable\napproach to evaluate and improve model-generated citations.\n","authors":["Yumo Xu","Peng Qi","Jifan Chen","Kunlun Liu","Rujun Han","Lan Liu","Bonan Min","Vittorio Castelli","Arshit Gupta","Zhiguo Wang"],"pdf_url":"https://arxiv.org/pdf/2506.01829v1.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2412.00639v2","updated":"2025-06-02T15:22:19Z","published":"2024-12-01T01:36:41Z","title":"Needle: A Generative AI-Powered Multi-modal Database for Answering\n  Complex Natural Language Queries","summary":"  Multi-modal datasets, like those involving images, often miss the detailed\ndescriptions that properly capture the rich information encoded in each item.\nThis makes answering complex natural language queries a major challenge in this\ndomain. In particular, unlike the traditional nearest neighbor search, where\nthe tuples and the query are represented as points in a single metric space,\nthese settings involve queries and tuples embedded in fundamentally different\nspaces, making the traditional query answering methods inapplicable. Existing\nliterature addresses this challenge for image datasets through vector\nrepresentations jointly trained on natural language and images. This technique,\nhowever, underperforms for complex queries due to various reasons.\n  This paper takes a step towards addressing this challenge by introducing a\nGenerative-based Monte Carlo method that utilizes foundation models to generate\nsynthetic samples that capture the complexity of the natural language query and\nrepresent it in the same metric space as the multi-modal data.\n  Following this method, we propose Needle, a database for image data\nretrieval. Instead of relying on contrastive learning or metadata-searching\napproaches, our system is based on synthetic data generation to capture the\ncomplexities of natural language queries. Our system is open-source and ready\nfor deployment, designed to be easily adopted by researchers and developers.\nThe comprehensive experiments on various benchmark datasets verify that this\nsystem significantly outperforms state-of-the-art text-to-image retrieval\nmethods in the literature. Any foundation model and embedder can be easily\nintegrated into Needle to improve the performance, piggybacking on the\nadvancements in these technologies.\n","authors":["Mahdi Erfanian","Mohsen Dehghankar","Abolfazl Asudeh"],"pdf_url":"https://arxiv.org/pdf/2412.00639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19755v2","updated":"2025-06-02T13:46:57Z","published":"2025-05-26T09:33:54Z","title":"EGA-V1: Unifying Online Advertising with End-to-End Learning","summary":"  Modern industrial advertising systems commonly employ Multi-stage Cascading\nArchitectures (MCA) to balance computational efficiency with ranking accuracy.\nHowever, this approach presents two fundamental challenges: (1) performance\ninconsistencies arising from divergent optimization targets and capability\ndifferences between stages, and (2) failure to account for advertisement\nexternalities - the complex interactions between candidate ads during ranking.\nThese limitations ultimately compromise system effectiveness and reduce\nplatform profitability. In this paper, we present EGA-V1, an end-to-end\ngenerative architecture that unifies online advertising ranking as one model.\nEGA-V1 replaces cascaded stages with a single model to directly generate\noptimal ad sequences from the full candidate ad corpus in location-based\nservices (LBS). The primary challenges associated with this approach stem from\nhigh costs of feature processing and computational bottlenecks in modeling\nexternalities of large-scale candidate pools. To address these challenges,\nEGA-V1 introduces an algorithm and engine co-designed hybrid feature service to\ndecouple user and ad feature processing, reducing latency while preserving\nexpressiveness. To efficiently extract intra- and cross-sequence mutual\ninformation, we propose RecFormer with an innovative cluster-attention\nmechanism as its core architectural component. Furthermore, we propose a\nbi-stage training strategy that integrates pre-training with reinforcement\nlearning-based post-training to meet sophisticated platform and advertising\nobjectives. Extensive offline evaluations on public benchmarks and large-scale\nonline A/B testing on industrial advertising platform have demonstrated the\nsuperior performance of EGA-V1 over state-of-the-art MCAs.\n","authors":["Junyan Qiu","Ze Wang","Fan Zhang","Zuowu Zheng","Jile Zhu","Jiangke Fan","Teng Zhang","Haitao Wang","Yongkang Wang","Xingxing Wang"],"pdf_url":"https://arxiv.org/pdf/2505.19755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01673v1","updated":"2025-06-02T13:42:46Z","published":"2025-06-02T13:42:46Z","title":"GRAM: Generative Recommendation via Semantic-aware Multi-granular Late\n  Fusion","summary":"  Generative recommendation is an emerging paradigm that leverages the\nextensive knowledge of large language models by formulating recommendations\ninto a text-to-text generation task. However, existing studies face two key\nlimitations in (i) incorporating implicit item relationships and (ii) utilizing\nrich yet lengthy item information. To address these challenges, we propose a\nGenerative Recommender via semantic-Aware Multi-granular late fusion (GRAM),\nintroducing two synergistic innovations. First, we design semantic-to-lexical\ntranslation to encode implicit hierarchical and collaborative item\nrelationships into the vocabulary space of LLMs. Second, we present\nmulti-granular late fusion to integrate rich semantics efficiently with minimal\ninformation loss. It employs separate encoders for multi-granular prompts,\ndelaying the fusion until the decoding stage. Experiments on four benchmark\ndatasets show that GRAM outperforms eight state-of-the-art generative\nrecommendation models, achieving significant improvements of 11.5-16.0% in\nRecall@5 and 5.3-13.6% in NDCG@5. The source code is available at\nhttps://github.com/skleee/GRAM.\n","authors":["Sunkyung Lee","Minjin Choi","Eunseong Choi","Hye-young Kim","Jongwuk Lee"],"pdf_url":"https://arxiv.org/pdf/2506.01673v1.pdf","comment":"ACL 2025 (Main Conference)"},{"id":"http://arxiv.org/abs/2506.01668v1","updated":"2025-06-02T13:38:45Z","published":"2025-06-02T13:38:45Z","title":"Small Stickers, Big Meanings: A Multilingual Sticker Semantic\n  Understanding Dataset with a Gamified Approach","summary":"  Stickers, though small, are a highly condensed form of visual expression,\nubiquitous across messaging platforms and embraced by diverse cultures,\ngenders, and age groups. Despite their popularity, sticker retrieval remains an\nunderexplored task due to the significant human effort and subjectivity\ninvolved in constructing high-quality sticker query datasets. Although large\nlanguage models (LLMs) excel at general NLP tasks, they falter when confronted\nwith the nuanced, intangible, and highly specific nature of sticker query\ngeneration.\n  To address this challenge, we propose a threefold solution. First, we\nintroduce Sticktionary, a gamified annotation framework designed to gather\ndiverse, high-quality, and contextually resonant sticker queries. Second, we\npresent StickerQueries, a multilingual sticker query dataset containing 1,115\nEnglish and 615 Chinese queries, annotated by over 60 contributors across 60+\nhours. Lastly, Through extensive quantitative and qualitative evaluation, we\ndemonstrate that our approach significantly enhances query generation quality,\nretrieval accuracy, and semantic understanding in the sticker domain. To\nsupport future research, we publicly release our multilingual dataset along\nwith two fine-tuned query generation models.\n","authors":["Heng Er Metilda Chee","Jiayin Wang","Zhiqiang Guo","Weizhi Ma","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.01668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01659v1","updated":"2025-06-02T13:30:39Z","published":"2025-06-02T13:30:39Z","title":"Engram Memory Encoding and Retrieval: A Neurocomputational Perspective","summary":"  Despite substantial research into the biological basis of memory, the precise\nmechanisms by which experiences are encoded, stored, and retrieved in the brain\nremain incompletely understood. A growing body of evidence supports the engram\ntheory, which posits that sparse populations of neurons undergo lasting\nphysical and biochemical changes to support long-term memory. Yet, a\ncomprehensive computational framework that integrates biological findings with\nmechanistic models remains elusive. This work synthesizes insights from\ncellular neuroscience and computational modeling to address key challenges in\nengram research: how engram neurons are identified and manipulated; how\nsynaptic plasticity mechanisms contribute to stable memory traces; and how\nsparsity promotes efficient, interference-resistant representations. Relevant\ncomputational approaches -- such as sparse regularization, engram gating, and\nbiologically inspired architectures like Sparse Distributed Memory and spiking\nneural networks -- are also examined. Together, these findings suggest that\nmemory efficiency, capacity, and stability emerge from the interaction of\nplasticity and sparsity constraints. By integrating neurobiological and\ncomputational perspectives, this paper provides a comprehensive theoretical\nfoundation for engram research and proposes a roadmap for future inquiry into\nthe mechanisms underlying memory, with implications for the diagnosis and\ntreatment of memory-related disorders.\n","authors":["Daniel Szelogowski"],"pdf_url":"https://arxiv.org/pdf/2506.01659v1.pdf","comment":"18 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.21801v2","updated":"2025-06-02T13:26:30Z","published":"2024-10-29T07:13:47Z","title":"PerSRV: Personalized Sticker Retrieval with Vision-Language Model","summary":"  Instant Messaging is a popular means for daily communication, allowing users\nto send text and stickers. As the saying goes, \"a picture is worth a thousand\nwords\", so developing an effective sticker retrieval technique is crucial for\nenhancing user experience. However, existing sticker retrieval methods rely on\nlabeled data to interpret stickers, and general-purpose Vision-Language Models\n(VLMs) often struggle to capture the unique semantics of stickers.\nAdditionally, relevant-based sticker retrieval methods lack personalization,\ncreating a gap between diverse user expectations and retrieval results. To\naddress these, we propose the Personalized Sticker Retrieval with\nVision-Language Model framework, namely PerSRV, structured into offline\ncalculations and online processing modules. The online retrieval part follows\nthe paradigm of relevant recall and personalized ranking, supported by the\noffline pre-calculation parts, which are sticker semantic understanding,\nutility evaluation and personalization modules. Firstly, for sticker-level\nsemantic understanding, we supervised fine-tuned LLaVA-1.5-7B to generate\nhuman-like sticker semantics, complemented by textual content extracted from\nfigures and historical interaction queries. Secondly, we investigate three\ncrowd-sourcing metrics for sticker utility evaluation. Thirdly, we cluster\nstyle centroids based on users' historical interactions to achieve personal\npreference modeling. Finally, we evaluate our proposed PerSRV method on a\npublic sticker retrieval dataset from WeChat, containing 543,098 candidates and\n12,568 interactions. Experimental results show that PerSRV significantly\noutperforms existing methods in multi-modal sticker retrieval. Additionally,\nour fine-tuned VLM delivers notable improvements in sticker semantic\nunderstandings.\n","authors":["Heng Er Metilda Chee","Jiayin Wang","Zhiqiang Guo","Weizhi Ma","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21801v2.pdf","comment":"Accepted at WWW '25"},{"id":"http://arxiv.org/abs/2503.05315v2","updated":"2025-06-02T12:19:34Z","published":"2025-03-07T10:50:45Z","title":"LoRACode: LoRA Adapters for Code Embeddings","summary":"  Code embeddings are essential for semantic code search; however, current\napproaches often struggle to capture the precise syntactic and contextual\nnuances inherent in code. Open-source models such as CodeBERT and UniXcoder\nexhibit limitations in scalability and efficiency, while high-performing\nproprietary systems impose substantial computational costs. We introduce a\nparameter-efficient fine-tuning method based on Low-Rank Adaptation (LoRA) to\nconstruct task-specific adapters for code retrieval. Our approach reduces the\nnumber of trainable parameters to less than two percent of the base model,\nenabling rapid fine-tuning on extensive code corpora (2 million samples in 25\nminutes on two H100 GPUs). Experiments demonstrate an increase of up to 9.1% in\nMean Reciprocal Rank (MRR) for Code2Code search, and up to 86.69% for Text2Code\nsearch tasks across multiple programming languages. Distinction in task-wise\nand language-wise adaptation helps explore the sensitivity of code retrieval\nfor syntactical and linguistic variations. To foster research in this area, we\nmake our code and pre-trained models publicly available.\n","authors":["Saumya Chaturvedi","Aman Chadha","Laurent Bindschaedler"],"pdf_url":"https://arxiv.org/pdf/2503.05315v2.pdf","comment":"Accepted at the Deep Learning for Code (DL4C) Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2505.12499v4","updated":"2025-06-02T10:17:05Z","published":"2025-05-18T17:18:06Z","title":"Contrastive Alignment with Semantic Gap-Aware Corrections in Text-Video\n  Retrieval","summary":"  Recent advances in text-video retrieval have been largely driven by\ncontrastive learning frameworks. However, existing methods overlook a key\nsource of optimization tension: the separation between text and video\ndistributions in the representation space (referred to as the modality gap),\nand the prevalence of false negatives in batch sampling. These factors lead to\nconflicting gradients under the InfoNCE loss, impeding stable alignment. To\nmitigate this, we propose GARE, a Gap-Aware Retrieval framework that introduces\na learnable, pair-specific increment Delta_ij between text t_i and video v_j to\noffload the tension from the global anchor representation. We first derive the\nideal form of Delta_ij via a coupled multivariate first-order Taylor\napproximation of the InfoNCE loss under a trust-region constraint, revealing it\nas a mechanism for resolving gradient conflicts by guiding updates along a\nlocally optimal descent direction. Due to the high cost of directly computing\nDelta_ij, we introduce a lightweight neural module conditioned on the semantic\ngap between each video-text pair, enabling structure-aware correction guided by\ngradient supervision. To further stabilize learning and promote\ninterpretability, we regularize Delta using three components: a trust-region\nconstraint to prevent oscillation, a directional diversity term to promote\nsemantic coverage, and an information bottleneck to limit redundancy.\nExperiments across four retrieval benchmarks show that GARE consistently\nimproves alignment accuracy and robustness to noisy supervision, confirming the\neffectiveness of gap-aware tension mitigation.\n","authors":["Jian Xiao","Zijie Song","Jialong Hu","Hao Cheng","Zhenzhen Hu","Jia Li","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2505.12499v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01488v1","updated":"2025-06-02T09:46:59Z","published":"2025-06-02T09:46:59Z","title":"Argument-Centric Causal Intervention Method for Mitigating Bias in\n  Cross-Document Event Coreference Resolution","summary":"  Cross-document Event Coreference Resolution (CD-ECR) is a fundamental task in\nnatural language processing (NLP) that seeks to determine whether event\nmentions across multiple documents refer to the same real-world occurrence.\nHowever, current CD-ECR approaches predominantly rely on trigger features\nwithin input mention pairs, which induce spurious correlations between\nsurface-level lexical features and coreference relationships, impairing the\noverall performance of the models. To address this issue, we propose a novel\ncross-document event coreference resolution method based on Argument-Centric\nCausal Intervention (ACCI). Specifically, we construct a structural causal\ngraph to uncover confounding dependencies between lexical triggers and\ncoreference labels, and introduce backdoor-adjusted interventions to isolate\nthe true causal effect of argument semantics. To further mitigate spurious\ncorrelations, ACCI integrates a counterfactual reasoning module that quantifies\nthe causal influence of trigger word perturbations, and an argument-aware\nenhancement module to promote greater sensitivity to semantically grounded\ninformation. In contrast to prior methods that depend on costly data\naugmentation or heuristic-based filtering, ACCI enables effective debiasing in\na unified end-to-end framework without altering the underlying training\nprocedure. Extensive experiments demonstrate that ACCI achieves CoNLL F1 of\n88.4% on ECB+ and 85.2% on GVC, achieving state-of-the-art performance. The\nimplementation and materials are available at https://github.com/era211/ACCI.\n","authors":["Long Yao","Wenzhong Yang","Yabo Yin","Fuyuan Wei","Hongzhen Lv","Jiaren Peng","Liejun Wang","Xiaoming Tao"],"pdf_url":"https://arxiv.org/pdf/2506.01488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01451v1","updated":"2025-06-02T09:08:38Z","published":"2025-06-02T09:08:38Z","title":"Building Entity Association Mining Framework for Knowledge Discovery","summary":"  Extracting useful signals or pattern to support important business decisions\nfor example analyzing investment product traction and discovering customer\npreference, risk monitoring etc. from unstructured text is a challenging task.\nCapturing interaction of entities or concepts and association mining is a\ncrucial component in text mining, enabling information extraction and reasoning\nover and knowledge discovery from text. Furthermore, it can be used to enrich\nor filter knowledge graphs to guide exploration processes, descriptive\nanalytics and uncover hidden stories in the text. In this paper, we introduce a\ndomain independent pipeline i.e., generalized framework to enable document\nfiltering, entity extraction using various sources (or techniques) as plug-ins\nand association mining to build any text mining business use-case and\nquantitatively define a scoring metric for ranking purpose. The proposed\nframework has three major components a) Document filtering: filtering\ndocuments/text of interest from massive amount of texts b) Configurable entity\nextraction pipeline: include entity extraction techniques i.e., i) DBpedia\nSpotlight, ii) Spacy NER, iii) Custom Entity Matcher, iv) Phrase extraction (or\ndictionary) based c) Association Relationship Mining: To generates\nco-occurrence graph to analyse potential relationships among entities,\nconcepts. Further, co-occurrence count based frequency statistics provide a\nholistic window to observe association trends or buzz rate in specific business\ncontext. The paper demonstrates the usage of framework as fundamental building\nbox in two financial use-cases namely brand product discovery and vendor risk\nmonitoring. We aim that such framework will remove duplicated effort, minimize\nthe development effort, and encourage reusability and rapid prototyping in\nassociation mining business applications for institutions.\n","authors":["Anshika Rawal","Abhijeet Kumar","Mridul Mishra"],"pdf_url":"https://arxiv.org/pdf/2506.01451v1.pdf","comment":"Presented at Business Analytics and Intelligence Conference, IIM\n  Bengaluru"},{"id":"http://arxiv.org/abs/2410.13248v2","updated":"2025-06-02T08:41:09Z","published":"2024-10-17T06:15:00Z","title":"Disentangling Likes and Dislikes in Personalized Generative Explainable\n  Recommendation","summary":"  Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. The datasets and benchmark\nimplementation are available at: https://github.com/jchanxtarov/sent_xrec.\n","authors":["Ryotaro Shimizu","Takashi Wada","Yu Wang","Johannes Kruse","Sean O'Brien","Sai HtaungKham","Linxin Song","Yuya Yoshikawa","Yuki Saito","Fugee Tsung","Masayuki Goto","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2410.13248v2.pdf","comment":"This manuscript has been accepted for presentation at The Web\n  Conference (WWW) 2025"},{"id":"http://arxiv.org/abs/2506.01361v1","updated":"2025-06-02T06:34:11Z","published":"2025-06-02T06:34:11Z","title":"TimeGraph: Synthetic Benchmark Datasets for Robust Time-Series Causal\n  Discovery","summary":"  Robust causal discovery in time series datasets depends on reliable benchmark\ndatasets with known ground-truth causal relationships. However, such datasets\nremain scarce, and existing synthetic alternatives often overlook critical\ntemporal properties inherent in real-world data, including nonstationarity\ndriven by trends and seasonality, irregular sampling intervals, and the\npresence of unobserved confounders. To address these challenges, we introduce\nTimeGraph, a comprehensive suite of synthetic time-series benchmark datasets\nthat systematically incorporates both linear and nonlinear dependencies while\nmodeling key temporal characteristics such as trends, seasonal effects, and\nheterogeneous noise patterns. Each dataset is accompanied by a fully specified\ncausal graph featuring varying densities and diverse noise distributions and is\nprovided in two versions: one including unobserved confounders and one without,\nthereby offering extensive coverage of real-world complexity while preserving\nmethodological neutrality. We further demonstrate the utility of TimeGraph\nthrough systematic evaluations of state-of-the-art causal discovery algorithms\nincluding PCMCI+, LPCMCI, and FGES across a diverse array of configurations and\nmetrics. Our experiments reveal significant variations in algorithmic\nperformance under realistic temporal conditions, underscoring the need for\nrobust synthetic benchmarks in the fair and transparent assessment of causal\ndiscovery methods. The complete TimeGraph suite, including dataset generation\nscripts, evaluation metrics, and recommended experimental protocols, is freely\navailable to facilitate reproducible research and foster community-driven\nadvancements in time-series causal discovery.\n","authors":["Muhammad Hasan Ferdous","Emam Hossain","Md Osman Gani"],"pdf_url":"https://arxiv.org/pdf/2506.01361v1.pdf","comment":"11 pages, 4 figures, accepted at KDD 2025 (Datasets and Benchmarks\n  Track)"},{"id":"http://arxiv.org/abs/2505.07155v2","updated":"2025-06-02T05:57:53Z","published":"2025-05-12T00:15:02Z","title":"Reassessing Large Language Model Boolean Query Generation for Systematic\n  Reviews","summary":"  Systematic reviews are comprehensive literature reviews that address highly\nfocused research questions and represent the highest form of evidence in\nmedicine. A critical step in this process is the development of complex Boolean\nqueries to retrieve relevant literature. Given the difficulty of manually\nconstructing these queries, recent efforts have explored Large Language Models\n(LLMs) to assist in their formulation. One of the first studies,Wang et al.,\ninvestigated ChatGPT for this task, followed by Staudinger et al., which\nevaluated multiple LLMs in a reproducibility study. However, the latter\noverlooked several key aspects of the original work, including (i) validation\nof generated queries, (ii) output formatting constraints, and (iii) selection\nof examples for chain-of-thought (Guided) prompting. As a result, its findings\ndiverged significantly from the original study. In this work, we systematically\nreproduce both studies while addressing these overlooked factors. Our results\nshow that query effectiveness varies significantly across models and prompt\ndesigns, with guided query formulation benefiting from well-chosen seed\nstudies. Overall, prompt design and model selection are key drivers of\nsuccessful query formulation. Our findings provide a clearer understanding of\nLLMs' potential in Boolean query generation and highlight the importance of\nmodel- and prompt-specific optimisations. The complex nature of systematic\nreviews adds to challenges in both developing and reproducing methods but also\nhighlights the importance of reproducibility studies in this domain.\n","authors":["Shuai Wang","Harrisen Scells","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2505.07155v2.pdf","comment":"Accepted in SIGIR-2025"},{"id":"http://arxiv.org/abs/2506.01308v1","updated":"2025-06-02T04:36:13Z","published":"2025-06-02T04:36:13Z","title":"A Platform for Investigating Public Health Content with Efficient\n  Concern Classification","summary":"  A recent rise in online content expressing concerns with public health\ninitiatives has contributed to already stalled uptake of preemptive measures\nglobally. Future public health efforts must attempt to understand such content,\nwhat concerns it may raise among readers, and how to effectively respond to it.\nTo this end, we present ConcernScope, a platform that uses a teacher-student\nframework for knowledge transfer between large language models and light-weight\nclassifiers to quickly and effectively identify the health concerns raised in a\ntext corpus. The platform allows uploading massive files directly,\nautomatically scraping specific URLs, and direct text editing. ConcernScope is\nbuilt on top of a taxonomy of public health concerns. Intended for public\nhealth officials, we demonstrate several applications of this platform: guided\ndata exploration to find useful examples of common concerns found in online\ncommunity datasets, identification of trends in concerns through an example\ntime series analysis of 186,000 samples, and finding trends in topic frequency\nbefore and after significant events.\n","authors":["Christopher Li","Rickard Stureborg","Bhuwan Dhingra","Jun Yang"],"pdf_url":"https://arxiv.org/pdf/2506.01308v1.pdf","comment":"19 pages, 15 figures"},{"id":"http://arxiv.org/abs/2505.20368v2","updated":"2025-06-02T01:12:15Z","published":"2025-05-26T11:08:23Z","title":"Hierarchical Retrieval with Evidence Curation for Open-Domain Financial\n  Question Answering on Standardized Documents","summary":"  Retrieval-augmented generation (RAG) based large language models (LLMs) are\nwidely used in finance for their excellent performance on knowledge-intensive\ntasks. However, standardized documents (e.g., SEC filing) share similar formats\nsuch as repetitive boilerplate texts, and similar table structures. This\nsimilarity forces traditional RAG methods to misidentify near-duplicate text,\nleading to duplicate retrieval that undermines accuracy and completeness. To\naddress these issues, we propose the Hierarchical Retrieval with Evidence\nCuration (HiREC) framework. Our approach first performs hierarchical retrieval\nto reduce confusion among similar texts. It first retrieve related documents\nand then selects the most relevant passages from the documents. The evidence\ncuration process removes irrelevant passages. When necessary, it automatically\ngenerates complementary queries to collect missing information. To evaluate our\napproach, we construct and release a Large-scale Open-domain Financial (LOFin)\nquestion answering benchmark that includes 145,897 SEC documents and 1,595\nquestion-answer pairs. Our code and data are available at\nhttps://github.com/deep-over/LOFin-bench-HiREC.\n","authors":["Jaeyoung Choe","Jihoon Kim","Woohwan Jung"],"pdf_url":"https://arxiv.org/pdf/2505.20368v2.pdf","comment":"ACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2505.24584v2","updated":"2025-06-02T01:08:24Z","published":"2025-05-30T13:32:00Z","title":"AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for\n  Auto-Generating Chemical Process and Instrumentation Diagrams","summary":"  Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.\n","authors":["Sakhinana Sagar Srinivas","Shivam Gupta","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2505.24584v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2501.04901v3","updated":"2025-06-02T22:58:41Z","published":"2025-01-09T01:26:59Z","title":"ThriftLLM: On Cost-Effective Selection of Large Language Models for\n  Classification Queries","summary":"  In recent years, large language models (LLMs) have demonstrated remarkable\ncapabilities in comprehending and generating natural language content,\nattracting widespread attention in both industry and academia. An increasing\nnumber of services offer LLMs for various tasks via APIs. Different LLMs\ndemonstrate expertise in different domains of queries (e.g., text\nclassification queries). Meanwhile, LLMs of different scales, complexities, and\nperformance are priced diversely. Driven by this, several researchers are\ninvestigating strategies for selecting an ensemble of LLMs, aiming to decrease\noverall usage costs while enhancing performance. However, to the best of our\nknowledge, none of the existing works addresses the problem, how to find an LLM\nensemble subject to a cost budget, which maximizes the ensemble performance\nwith guarantees.\n  In this paper, we formalize the performance of an ensemble of models (LLMs)\nusing the notion of correctness probability, which we formally define. We\ndevelop an approach for aggregating responses from multiple LLMs to enhance\nensemble performance. Building on this, we formulate the Optimal Ensemble\nSelection problem of selecting a set of LLMs subject to a cost budget that\nmaximizes the overall correctness probability. We show that the correctness\nprobability function is non-decreasing and non-submodular and provide evidence\nthat the Optimal Ensemble Selection problem is likely to be NP-hard. By\nleveraging a submodular function that upper bounds correctness probability, we\ndevelop an algorithm called ThriftLLM and prove that it achieves an\ninstance-dependent approximation guarantee with high probability. Our framework\nfunctions as a data processing system that selects appropriate LLM operators to\ndeliver high-quality results under budget constraints.\n","authors":["Keke Huang","Yimin Shi","Dujian Ding","Yifei Li","Yang Fei","Laks Lakshmanan","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2501.04901v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.20369v3","updated":"2025-06-02T18:58:44Z","published":"2025-04-29T02:14:11Z","title":"Perception-aware Sampling for Scatterplot Visualizations","summary":"  Visualizing data is often a crucial first step in data analytics workflows,\nbut growing data sizes pose challenges due to computational and visual\nperception limitations. As a result, data analysts commonly down-sample their\ndata and work with subsets. Deriving representative samples, however, remains a\nchallenge. This paper focuses on scatterplots, a widely-used visualization\ntype, and introduces a novel sampling objective -- perception-awareness --\naiming to improve sample efficacy by targeting humans' perception of a\nvisualization.\n  We make the following contributions: (1) We propose perception-augmented\ndatabases and design PAwS: a novel perception-aware sampling method for\nscatterplots that leverages saliency maps -- a computer vision tool for\npredicting areas of attention focus in visualizations -- and models\nperception-awareness via saliency, density, and coverage objectives. (2) We\ndesign ApproPAwS: a fast, perception-aware method for approximate\nvisualizations, which exploits the fact that small visual perturbations are\noften imperceptible to humans. (3) We introduce the concept of perceptual\nsimilarity as a metric for sample quality, and present a novel method that\ncompares saliency maps to measure it. (4) Our extensive experimental evaluation\nshows that our methods consistently outperform prior art in producing samples\nwith high perceptual similarity, while ApproPAwS achieves up to 100x speed-ups\nwith minimal loss in visual fidelity. Our user study shows that PAwS is often\npreferred by humans, validating our quantitative findings.\n","authors":["Zafeiria Moumoulidou","Hamza Elhamdadi","Ke Yang","Subrata Mitra","Cindy Xiong Bearfield","Alexandra Meliou"],"pdf_url":"https://arxiv.org/pdf/2504.20369v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01883v1","updated":"2025-06-02T17:11:49Z","published":"2025-06-02T17:11:49Z","title":"scDataset: Scalable Data Loading for Deep Learning on Large-Scale\n  Single-Cell Omics","summary":"  Modern single-cell datasets now comprise hundreds of millions of cells,\npresenting significant challenges for training deep learning models that\nrequire shuffled, memory-efficient data loading. While the AnnData format is\nthe community standard for storing single-cell datasets, existing data loading\nsolutions for AnnData are often inadequate: some require loading all data into\nmemory, others convert to dense formats that increase storage demands, and many\nare hampered by slow random disk access. We present scDataset, a PyTorch\nIterableDataset that operates directly on one or more AnnData files without the\nneed for format conversion. The core innovation is a combination of block\nsampling and batched fetching, which together balance randomness and I/O\nefficiency. On the Tahoe 100M dataset, scDataset achieves up to a 48$\\times$\nspeed-up over AnnLoader, a 27$\\times$ speed-up over HuggingFace Datasets, and\nan 18$\\times$ speed-up over BioNeMo in single-core settings. These advances\ndemocratize large-scale single-cell model training for the broader research\ncommunity.\n","authors":["Davide D'Ascenzo","Sebastiano Cultrera di Montesano"],"pdf_url":"https://arxiv.org/pdf/2506.01883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00639v2","updated":"2025-06-02T15:22:19Z","published":"2024-12-01T01:36:41Z","title":"Needle: A Generative AI-Powered Multi-modal Database for Answering\n  Complex Natural Language Queries","summary":"  Multi-modal datasets, like those involving images, often miss the detailed\ndescriptions that properly capture the rich information encoded in each item.\nThis makes answering complex natural language queries a major challenge in this\ndomain. In particular, unlike the traditional nearest neighbor search, where\nthe tuples and the query are represented as points in a single metric space,\nthese settings involve queries and tuples embedded in fundamentally different\nspaces, making the traditional query answering methods inapplicable. Existing\nliterature addresses this challenge for image datasets through vector\nrepresentations jointly trained on natural language and images. This technique,\nhowever, underperforms for complex queries due to various reasons.\n  This paper takes a step towards addressing this challenge by introducing a\nGenerative-based Monte Carlo method that utilizes foundation models to generate\nsynthetic samples that capture the complexity of the natural language query and\nrepresent it in the same metric space as the multi-modal data.\n  Following this method, we propose Needle, a database for image data\nretrieval. Instead of relying on contrastive learning or metadata-searching\napproaches, our system is based on synthetic data generation to capture the\ncomplexities of natural language queries. Our system is open-source and ready\nfor deployment, designed to be easily adopted by researchers and developers.\nThe comprehensive experiments on various benchmark datasets verify that this\nsystem significantly outperforms state-of-the-art text-to-image retrieval\nmethods in the literature. Any foundation model and embedder can be easily\nintegrated into Needle to improve the performance, piggybacking on the\nadvancements in these technologies.\n","authors":["Mahdi Erfanian","Mohsen Dehghankar","Abolfazl Asudeh"],"pdf_url":"https://arxiv.org/pdf/2412.00639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01576v1","updated":"2025-06-02T12:03:17Z","published":"2025-06-02T12:03:17Z","title":"All You Need Is Binary Search! A Practical View on Lightweight Database\n  Indexing on GPUs","summary":"  Performing binary search on a sorted dense array is a widely used baseline\nwhen benchmarking sophisticated index structures: It is simple, fast to build,\nand indexes the dataset with minimal memory footprint. However, the popular\nopinion is that it cannot compete with sophisticated indexes in terms of lookup\nperformance, and hence, should not actually be considered in practice.\n  Interestingly, in our recent works on (even more sophisticated) GPU-resident\nindex structures, we observed the surprisingly good performance of binary\nsearch in a variety of situations. As a consequence, in this work, we analyze\nthe reasons for this and perform three types of optimizations to the standard\nimplementation to push binary search to its limits on GPUs. We show that our\nhighly-optimized version of binary search outperforms the naive variant by up\nto a factor of 2x which makes it a practical alternative to full-fledged\nindexes, such as the state-of-the-art GPU B+-Tree, while consuming considerably\nless space and having a shorter build time. Apart from the optimizations, we\ndiscuss a generalization of binary search in form of K-ary search, which is\nable to consistently outperform the B+-Tree by a factor of 1.5x to 2.7x while\nhaving a negligible space overhead over binary search.\n","authors":["Justus Henneberg","Felix Schuhknecht"],"pdf_url":"https://arxiv.org/pdf/2506.01576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.11396v2","updated":"2025-06-02T09:54:55Z","published":"2025-05-16T16:02:39Z","title":"Finding Counterfactual Evidences for Node Classification","summary":"  Counterfactual learning is emerging as an important paradigm, rooted in\ncausality, which promises to alleviate common issues of graph neural networks\n(GNNs), such as fairness and interpretability. However, as in many real-world\napplication domains where conducting randomized controlled trials is\nimpractical, one has to rely on available observational (factual) data to\ndetect counterfactuals. In this paper, we introduce and tackle the problem of\nsearching for counterfactual evidences for the GNN-based node classification\ntask. A counterfactual evidence is a pair of nodes such that, regardless they\nexhibit great similarity both in the features and in their neighborhood\nsubgraph structures, they are classified differently by the GNN. We develop\neffective and efficient search algorithms and a novel indexing solution that\nleverages both node features and structural information to identify\ncounterfactual evidences, and generalizes beyond any specific GNN. Through\nvarious downstream applications, we demonstrate the potential of counterfactual\nevidences to enhance fairness and accuracy of GNNs.\n","authors":["Dazhuo Qiu","Jinwen Chen","Arijit Khan","Yan Zhao","Francesco Bonchi"],"pdf_url":"https://arxiv.org/pdf/2505.11396v2.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2205.09337v2","updated":"2025-06-02T07:31:16Z","published":"2022-05-19T06:28:31Z","title":"Deep Learning in Business Analytics: A Clash of Expectations and Reality","summary":"  Our fast-paced digital economy shaped by global competition requires\nincreased data-driven decision-making based on artificial intelligence (AI) and\nmachine learning (ML). The benefits of deep learning (DL) are manifold, but it\ncomes with limitations that have, so far, interfered with widespread industry\nadoption. This paper explains why DL, despite its popularity, has difficulties\nspeeding up its adoption within business analytics. It is shown that the\nadoption of deep learning is not only affected by computational complexity,\nlacking big data architecture, lack of transparency (black-box), skill\nshortage, and leadership commitment, but also by the fact that DL does not\noutperform traditional ML models in the case of structured datasets with\nfixed-length feature vectors. Deep learning should be regarded as a powerful\naddition to the existing body of ML models instead of a one size fits all\nsolution. The results strongly suggest that gradient boosting can be seen as\nthe go-to model for predictions on structured datasets within business\nanalytics. In addition to the empirical study based on three industry use\ncases, the paper offers a comprehensive discussion of those results, practical\nimplications, and a roadmap for future research.\n","authors":["Marc Schmitt"],"pdf_url":"https://arxiv.org/pdf/2205.09337v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00393v2","updated":"2025-06-02T06:00:13Z","published":"2025-05-01T08:30:15Z","title":"S3AND: Efficient Subgraph Similarity Search Under Aggregated Neighbor\n  Difference Semantics (Technical Report)","summary":"  For the past decades, the \\textit{subgraph similarity search} over a\nlarge-scale data graph has become increasingly important and crucial in many\nreal-world applications, such as social network analysis, bioinformatics\nnetwork analytics, knowledge graph discovery, and many others. While previous\nworks on subgraph similarity search used various graph similarity metrics such\nas the graph isomorphism, graph edit distance, and so on, in this paper, we\npropose a novel problem, namely \\textit{subgraph similarity search under\naggregated neighbor difference semantics} (S$^3$AND), which identifies\nsubgraphs $g$ in a data graph $G$ that are similar to a given query graph $q$\nby considering both keywords and graph structures (under new keyword/structural\nmatching semantics). To efficiently tackle the S$^3$AND problem, we design two\neffective pruning methods, \\textit{keyword set} and \\textit{aggregated neighbor\ndifference lower bound pruning}, which rule out false alarms of candidate\nvertices/subgraphs to reduce the S$^3$AND search space. Furthermore, we\nconstruct an effective indexing mechanism to facilitate our proposed efficient\nS$^3$AND query answering algorithm. Through extensive experiments, we\ndemonstrate the effectiveness and efficiency of our S$^3$AND approach over both\nreal and synthetic graphs under various parameter settings.\n","authors":["Qi Wen","Yutong Ye","Xiang Lian","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2505.00393v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00600v2","updated":"2025-06-02T02:31:38Z","published":"2025-03-01T19:59:25Z","title":"Semantic Integrity Constraints: Declarative Guardrails for AI-Augmented\n  Data Processing Systems","summary":"  AI-augmented data processing systems (DPSs) integrate large language models\n(LLMs) into query pipelines, allowing powerful semantic operations on\nstructured and unstructured data. However, the reliability (a.k.a. trust) of\nthese systems is fundamentally challenged by the potential for LLMs to produce\nerrors, limiting their adoption in critical domains. To help address this\nreliability bottleneck, we introduce semantic integrity constraints (SICs) -- a\ndeclarative abstraction for specifying and enforcing correctness conditions\nover LLM outputs in semantic queries. SICs generalize traditional database\nintegrity constraints to semantic settings, supporting common types of\nconstraints, such as grounding, soundness, and exclusion, with both proactive\nand reactive enforcement strategies.\n  We argue that SICs provide a foundation for building reliable and auditable\nAI-augmented data systems. Specifically, we present a system design for\nintegrating SICs into query planning and runtime execution and discuss its\nrealization in AI-augmented DPSs. To guide and evaluate the vision, we outline\nseveral design goals -- covering criteria around expressiveness, runtime\nsemantics, integration, performance, and enterprise-scale applicability -- and\ndiscuss how our framework addresses each, along with open research challenges.\n","authors":["Alexander W. Lee","Justin Chan","Michael Fu","Nicolas Kim","Akshay Mehta","Deepti Raghavan","Ugur Cetintemel"],"pdf_url":"https://arxiv.org/pdf/2503.00600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01232v1","updated":"2025-06-02T01:10:05Z","published":"2025-06-02T01:10:05Z","title":"Retrieval-Augmented Generation of Ontologies from Relational Databases","summary":"  Transforming relational databases into knowledge graphs with enriched\nontologies enhances semantic interoperability and unlocks advanced graph-based\nlearning and reasoning over data. However, previous approaches either demand\nsignificant manual effort to derive an ontology from a database schema or\nproduce only a basic ontology. We present RIGOR, Retrieval-augmented Iterative\nGeneration of RDB Ontologies, an LLM-driven approach that turns relational\nschemas into rich OWL ontologies with minimal human effort. RIGOR combines\nthree sources via RAG, the database schema and its documentation, a repository\nof domain ontologies, and a growing core ontology, to prompt a generative LLM\nfor producing successive, provenance-tagged delta ontology fragments. Each\nfragment is refined by a judge-LLM before being merged into the core ontology,\nand the process iterates table-by-table following foreign key constraints until\ncoverage is complete. Applied to real-world databases, our approach outputs\nontologies that score highly on standard quality dimensions such as accuracy,\ncompleteness, conciseness, adaptability, clarity, and consistency, while\nsubstantially reducing manual effort.\n","authors":["Mojtaba Nayyeri","Athish A Yogi","Nadeen Fathallah","Ratan Bahadur Thapa","Hans-Michael Tautenhahn","Anton Schnurpel","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2506.01232v1.pdf","comment":"Under review"}]},"2025-06-01T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.22877v2","updated":"2025-06-01T21:44:34Z","published":"2025-03-28T21:07:43Z","title":"Understanding Inequality of LLM Fact-Checking over Geographic Regions\n  with Agent and Retrieval models","summary":"  Fact-checking is a potentially useful application of Large Language Models\n(LLMs) to combat the growing dissemination of disinformation. However, the\nperformance of LLMs varies across geographic regions. In this paper, we\nevaluate the factual accuracy of open and private models across a diverse set\nof regions and scenarios.\n  Using a dataset containing 600 fact-checked statements balanced across six\nglobal regions we examine three experimental setups of fact-checking a\nstatement: (1) when just the statement is available, (2) when an LLM-based\nagent with Wikipedia access is utilized, and (3) as a best case scenario when a\nRetrieval-Augmented Generation (RAG) system provided with the official fact\ncheck is employed. Our findings reveal that regardless of the scenario and LLM\nused, including GPT-4, Claude Sonnet, and LLaMA, statements from the Global\nNorth perform substantially better than those from the Global South.\nFurthermore, this gap is broadened for the more realistic case of a Wikipedia\nagent-based system, highlighting that overly general knowledge bases have a\nlimited ability to address region-specific nuances. These results underscore\nthe urgent need for better dataset balancing and robust retrieval strategies to\nenhance LLM fact-checking capabilities, particularly in geographically diverse\ncontexts.\n","authors":["Bruno Coelho","Shujaat Mirza","Yuyuan Cui","Christina Pöpper","Damon McCoy"],"pdf_url":"https://arxiv.org/pdf/2503.22877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.09795v3","updated":"2025-06-01T20:17:37Z","published":"2025-05-14T20:45:29Z","title":"Beyond Pairwise Learning-To-Rank At Airbnb","summary":"  There are three fundamental asks from a ranking algorithm: it should scale to\nhandle a large number of items, sort items accurately by their utility, and\nimpose a total order on the items for logical consistency. But here's the\ncatch-no algorithm can achieve all three at the same time. We call this\nlimitation the SAT theorem for ranking algorithms. Given the dilemma, how can\nwe design a practical system that meets user needs? Our current work at Airbnb\nprovides an answer, with a working solution deployed at scale. We start with\npairwise learning-to-rank (LTR) models-the bedrock of search ranking tech\nstacks today. They scale linearly with the number of items ranked and perform\nstrongly on metrics like NDCG by learning from pairwise comparisons. They are\nat a sweet spot of performance vs. cost, making them an ideal choice for\nseveral industrial applications. However, they have a drawback-by ignoring\ninteractions between items, they compromise on accuracy. To improve accuracy,\nwe create a \"true\" pairwise LTR model-one that captures interactions between\nitems during pairwise comparisons. But accuracy comes at the expense of\nscalability and total order, and we discuss strategies to counter these\nchallenges. For greater accuracy, we take each item in the search result, and\ncompare it against the rest of the items along two dimensions: (1) Superiority:\nHow strongly do searchers prefer the given item over the remaining ones? (2)\nSimilarity: How similar is the given item to all the other items? This forms\nthe basis of our \"all-pairwise\" LTR framework, which factors in interactions\nacross all items at once. Looking at items on the search result page all\ntogether-superiority and similarity combined-gives us a deeper understanding of\nwhat searchers truly want. We quantify the resulting improvements in searcher\nexperience through offline and online experiments at Airbnb.\n","authors":["Malay Haldar","Daochen Zha","Huiji Gao","Liwei He","Sanjeev Katariya"],"pdf_url":"https://arxiv.org/pdf/2505.09795v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.22238v2","updated":"2025-06-01T19:48:42Z","published":"2025-05-28T11:12:57Z","title":"Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval","summary":"  We present Yambda-5B, a large-scale open dataset sourced from the Yandex\nMusic streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.\n","authors":["A. Ploshkin","V. Tytskiy","A. Pismenny","V. Baikalov","E. Taychinov","A. Permiakov","D. Burlakov","E. Krofto","N. Savushkin"],"pdf_url":"https://arxiv.org/pdf/2505.22238v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.01063v1","updated":"2025-06-01T16:05:00Z","published":"2025-06-01T16:05:00Z","title":"AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative\n  Contracts","summary":"  Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) are\nreshaping how AI systems extract and organize information from unstructured\ntext. A key challenge is designing AI methods that can incrementally extract,\nstructure, and validate information while preserving hierarchical and\ncontextual relationships. We introduce CDMizer, a template-driven, LLM, and\nRAG-based framework for structured text transformation. By leveraging\ndepth-based retrieval and hierarchical generation, CDMizer ensures a\ncontrolled, modular process that aligns generated outputs with predefined\nschema. Its template-driven approach guarantees syntactic correctness, schema\nadherence, and improved scalability, addressing key limitations of direct\ngeneration methods. Additionally, we propose an LLM-powered evaluation\nframework to assess the completeness and accuracy of structured\nrepresentations. Demonstrated in the transformation of Over-the-Counter (OTC)\nfinancial derivative contracts into the Common Domain Model (CDM), CDMizer\nestablishes a scalable foundation for AI-driven document understanding,\nstructured synthesis, and automated validation in broader contexts.\n","authors":["Maruf Ahmed Mridul","Ian Sloyan","Aparna Gupta","Oshani Seneviratne"],"pdf_url":"https://arxiv.org/pdf/2506.01063v1.pdf","comment":"8 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2505.18458v3","updated":"2025-06-01T16:00:34Z","published":"2025-05-24T01:57:12Z","title":"A Survey of LLM $\\times$ DATA","summary":"  The integration of large language model (LLM) and data management (DATA) is\nrapidly redefining both domains. In this survey, we comprehensively review the\nbidirectional relationships. On the one hand, DATA4LLM, spanning large-scale\ndata processing, storage, and serving, feeds LLMs with high quality, diversity,\nand timeliness of data required for stages like pre-training, post-training,\nretrieval-augmented generation, and agentic workflows: (i) Data processing for\nLLMs includes scalable acquisition, deduplication, filtering, selection, domain\nmixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on\nefficient data and model formats, distributed and heterogeneous storage\nhierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data\nserving for LLMs tackles challenges in RAG (e.g., knowledge post-processing),\nLLM inference (e.g., prompt compression, data provenance), and training\nstrategies (e.g., data packing and shuffling). On the other hand, in LLM4DATA,\nLLMs are emerging as general-purpose engines for data management. We review\nrecent advances in (i) data manipulation, including automatic data cleaning,\nintegration, discovery; (ii) data analysis, covering reasoning over structured,\nsemi-structured, and unstructured data, and (iii) system optimization (e.g.,\nconfiguration tuning, query rewriting, anomaly diagnosis), powered by LLM\ntechniques like retrieval-augmented prompting, task-specialized fine-tuning,\nand multi-agent collaboration.\n","authors":["Xuanhe Zhou","Junxuan He","Wei Zhou","Haodong Chen","Zirui Tang","Haoyu Zhao","Xin Tong","Guoliang Li","Youmin Chen","Jun Zhou","Zhaojun Sun","Binyuan Hui","Shuo Wang","Conghui He","Zhiyuan Liu","Jingren Zhou","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2505.18458v3.pdf","comment":"Please refer to the paper list at:\n  https://github.com/weAIDB/awesome-data-llm"},{"id":"http://arxiv.org/abs/2307.00438v3","updated":"2025-06-01T15:40:04Z","published":"2023-07-01T23:20:38Z","title":"Towards Resource-Efficient Streaming of Large-Scale Medical Image\n  Datasets for Deep Learning","summary":"  Large-scale medical imaging datasets have accelerated deep learning (DL) for\nmedical image analysis. However, the large scale of these datasets poses a\nchallenge for researchers, resulting in increased storage and bandwidth\nrequirements for hosting and accessing them. Since different researchers have\ndifferent use cases and require different resolutions or formats for DL, it is\nneither feasible to anticipate every researcher's needs nor practical to store\ndata in multiple resolutions and formats. To that end, we propose the Medical\nImage Streaming Toolkit (MIST), a format-agnostic database that enables\nstreaming of medical images at different resolutions and formats from a single\nhigh-resolution copy. We evaluated MIST across eight popular, large-scale\nmedical imaging datasets spanning different body parts, modalities, and\nformats. Our results showed that our framework reduced the storage and\nbandwidth requirements for hosting and downloading datasets without impacting\nimage quality. We demonstrate that MIST addresses the challenges posed by\nlarge-scale medical imaging datasets by building a data-efficient and\nformat-agnostic database to meet the diverse needs of researchers and reduce\nbarriers to DL research in medical imaging.\n","authors":["Pranav Kulkarni","Adway Kanhere","Eliot Siegel","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2307.00438v3.pdf","comment":"17 pages, 4 figures, 10 tables, accepted to MIDL'25"},{"id":"http://arxiv.org/abs/2506.02058v1","updated":"2025-06-01T15:32:44Z","published":"2025-06-01T15:32:44Z","title":"Evaluating the Unseen Capabilities: How Many Theorems Do LLMs Know?","summary":"  Accurate evaluation of large language models (LLMs) is crucial for\nunderstanding their capabilities and guiding their development. However,\ncurrent evaluations often inconsistently reflect the actual capacities of these\nmodels. In this paper, we demonstrate that one of many contributing factors to\nthis \\textit{evaluation crisis} is the oversight of unseen knowledge --\ninformation encoded by LLMs but not directly observed or not yet observed\nduring evaluations. We introduce KnowSum, a statistical framework designed to\nprovide a more comprehensive assessment by quantifying the unseen knowledge for\na class of evaluation tasks. KnowSum estimates the unobserved portion by\nextrapolating from the appearance frequencies of observed knowledge instances.\nWe demonstrate the effectiveness and utility of KnowSum across three critical\napplications: estimating total knowledge, evaluating information retrieval\neffectiveness, and measuring output diversity. Our experiments reveal that a\nsubstantial volume of knowledge is omitted when relying solely on observed LLM\nperformance. Importantly, KnowSum yields significantly different comparative\nrankings for several common LLMs based on their internal knowledge.\n","authors":["Xiang Li","Jiayi Xin","Qi Long","Weijie J. Su"],"pdf_url":"https://arxiv.org/pdf/2506.02058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.17549v3","updated":"2025-06-01T14:54:02Z","published":"2025-05-23T06:55:02Z","title":"EGA-V2: An End-to-end Generative Framework for Industrial Advertising","summary":"  Traditional online industrial advertising systems suffer from the limitations\nof multi-stage cascaded architectures, which often discard high-potential\ncandidates prematurely and distribute decision logic across disconnected\nmodules. While recent generative recommendation approaches provide end-to-end\nsolutions, they fail to address critical advertising requirements of key\ncomponents for real-world deployment, such as explicit bidding, creative\nselection, ad allocation, and payment computation. To bridge this gap, we\nintroduce End-to-End Generative Advertising (EGA-V2), the first unified\nframework that holistically models user interests, point-of-interest (POI) and\ncreative generation, ad allocation, and payment optimization within a single\ngenerative model. Our approach employs hierarchical tokenization and\nmulti-token prediction to jointly generate POI recommendations and ad\ncreatives, while a permutation-aware reward model and token-level bidding\nstrategy ensure alignment with both user experiences and advertiser objectives.\nAdditionally, we decouple allocation from payment using a differentiable\nex-post regret minimization mechanism, guaranteeing approximate incentive\ncompatibility at the POI level. Through extensive offline evaluations we\ndemonstrate that EGA-V2 significantly outperforms traditional cascaded systems\nin both performance and practicality. Our results highlight its potential as a\npioneering fully generative advertising solution, paving the way for\nnext-generation industrial ad systems.\n","authors":["Zuowu Zheng","Ze Wang","Fan Yang","Jiangke Fan","Teng Zhang","Yongkang Wang","Xingxing Wang"],"pdf_url":"https://arxiv.org/pdf/2505.17549v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.01136v2","updated":"2025-06-01T12:49:01Z","published":"2025-05-02T09:25:41Z","title":"Descriptor: C++ Self-Admitted Technical Debt Dataset (CppSATD)","summary":"  In software development, technical debt (TD) refers to suboptimal\nimplementation choices made by the developers to meet urgent deadlines and\nlimited resources, posing challenges for future maintenance. Self-Admitted\nTechnical Debt (SATD) is a sub-type of TD, representing specific TD instances\n``openly admitted'' by the developers and often expressed through source code\ncomments. Previous research on SATD has focused predominantly on the Java\nprogramming language, revealing a significant gap in cross-language SATD. Such\na narrow focus limits the generalizability of existing findings as well as SATD\ndetection techniques across multiple programming languages. Our work addresses\nsuch limitation by introducing CppSATD, a dedicated C++ SATD dataset,\ncomprising over 531,000 annotated comments and their source code contexts. Our\ndataset can serve as a foundation for future studies that aim to develop SATD\ndetection methods in C++, generalize the existing findings to other languages,\nor contribute novel insights to cross-language SATD research.\n","authors":["Phuoc Pham","Murali Sridharan","Matteo Esposito","Valentina Lenarduzzi"],"pdf_url":"https://arxiv.org/pdf/2505.01136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00983v1","updated":"2025-06-01T12:30:58Z","published":"2025-06-01T12:30:58Z","title":"Bridging the Gap: From Ad-hoc to Proactive Search in Conversations","summary":"  Proactive search in conversations (PSC) aims to reduce user effort in\nformulating explicit queries by proactively retrieving useful relevant\ninformation given conversational context. Previous work in PSC either directly\nuses this context as input to off-the-shelf ad-hoc retrievers or further\nfine-tunes them on PSC data. However, ad-hoc retrievers are pre-trained on\nshort and concise queries, while the PSC input is longer and noisier. This\ninput mismatch between ad-hoc search and PSC limits retrieval quality. While\nfine-tuning on PSC data helps, its benefits remain constrained by this input\ngap. In this work, we propose Conv2Query, a novel conversation-to-query\nframework that adapts ad-hoc retrievers to PSC by bridging the input gap\nbetween ad-hoc search and PSC. Conv2Query maps conversational context into\nad-hoc queries, which can either be used as input for off-the-shelf ad-hoc\nretrievers or for further fine-tuning on PSC data. Extensive experiments on two\nPSC datasets show that Conv2Query significantly improves ad-hoc retrievers'\nperformance, both when used directly and after fine-tuning on PSC.\n","authors":["Chuan Meng","Francesco Tonolini","Fengran Mo","Nikolaos Aletras","Emine Yilmaz","Gabriella Kazai"],"pdf_url":"https://arxiv.org/pdf/2506.00983v1.pdf","comment":"Accepted as a full paper at SIGIR 2025"},{"id":"http://arxiv.org/abs/2412.19302v3","updated":"2025-06-01T12:04:04Z","published":"2024-12-26T17:51:54Z","title":"RecLM: Recommendation Instruction Tuning","summary":"  Modern recommender systems aim to deeply understand users' complex\npreferences through their past interactions. While deep collaborative filtering\napproaches using Graph Neural Networks (GNNs) excel at capturing user-item\nrelationships, their effectiveness is limited when handling sparse data or\nzero-shot scenarios, primarily due to constraints in ID-based embedding\nfunctions. To address these challenges, we propose a model-agnostic\nrecommendation instruction-tuning paradigm that seamlessly integrates large\nlanguage models with collaborative filtering. Our proposed\n$\\underline{Rec}$ommendation $\\underline{L}$anguage $\\underline{M}$odel (RecLM)\nenhances the capture of user preference diversity through a carefully designed\nreinforcement learning reward function that facilitates self-augmentation of\nlanguage models. Comprehensive evaluations demonstrate significant advantages\nof our approach across various settings, and its plug-and-play compatibility\nwith state-of-the-art recommender systems results in notable performance\nenhancements. The implementation of our RecLM framework is publicly available\nat: https://github.com/HKUDS/RecLM.\n","authors":["Yangqin Jiang","Yuhao Yang","Lianghao Xia","Da Luo","Kangyi Lin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2412.19302v3.pdf","comment":"This paper is accepted by ACL 2025 main conference"},{"id":"http://arxiv.org/abs/2506.00954v1","updated":"2025-06-01T10:56:18Z","published":"2025-06-01T10:56:18Z","title":"AliBoost: Ecological Boosting Framework in Alibaba Platform","summary":"  Maintaining a healthy ecosystem in billion-scale online platforms is\nchallenging, as users naturally gravitate toward popular items, leaving cold\nand less-explored items behind. This ''rich-get-richer'' phenomenon hinders the\ngrowth of potentially valuable cold items and harms the platform's ecosystem.\nExisting cold-start models primarily focus on improving initial recommendation\nperformance for cold items but fail to address users' natural preference for\npopular content. In this paper, we introduce AliBoost, Alibaba's ecological\nboosting framework, designed to complement user-oriented natural\nrecommendations and foster a healthier ecosystem. AliBoost incorporates a\ntiered boosting structure and boosting principles to ensure high-potential\nitems quickly gain exposure while minimizing disruption to low-potential items.\nTo achieve this, we propose the Stacking Fine-Tuning Cold Predictor to enhance\nthe foundation CTR model's performance on cold items for accurate CTR and\npotential prediction. AliBoost then employs an Item-oriented Bidding Boosting\nmechanism to deliver cold items to the most suitable users while balancing\nboosting speed with user-personalized preferences. Over the past six months,\nAliBoost has been deployed across Alibaba's mainstream platforms, successfully\ncold-starting over a billion new items and increasing both clicks and GMV of\ncold items by over 60% within 180 days. Extensive online analysis and A/B\ntesting demonstrate the effectiveness of AliBoost in addressing ecological\nchallenges, offering new insights into the design of billion-scale recommender\nsystems.\n","authors":["Qijie Shen","Yuanchen Bei","Zihong Huang","Jialin Zhu","Keqin Xu","Boya Du","Jiawei Tang","Yuning Jiang","Feiran Huang","Xiao Huang","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2506.00954v1.pdf","comment":"12 pages, 5 figures, accepted by KDD2025"},{"id":"http://arxiv.org/abs/2409.05806v4","updated":"2025-06-01T08:49:57Z","published":"2024-09-09T17:11:51Z","title":"CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics,\n  Facts, and Logic Error Correction in LLMs","summary":"  Chinese, as a linguistic system rich in depth and complexity, is\ncharacterized by distinctive elements such as ancient poetry, proverbs, idioms,\nand other cultural constructs. However, current Large Language Models (LLMs)\nface limitations in these specialized domains, highlighting the need for the\ndevelopment of comprehensive datasets that can assess, continuously update, and\nprogressively improve these culturally-grounded linguistic competencies through\ntargeted training optimizations. To address this gap, we introduce CKnowEdit,\nthe first-ever Chinese knowledge editing dataset designed to correct\nlinguistic, factual, and logical errors in LLMs. We collect seven types of\nknowledge from a wide range of sources, including classical texts, idioms, and\ncontent from Baidu Tieba Ruozhiba, taking into account the unique polyphony,\nantithesis, and logical structures inherent in the Chinese language. By\nanalyzing this dataset, we highlight the challenges current LLMs face in\nmastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge\nediting techniques reveals opportunities to advance the correction of Chinese\nknowledge. Code and dataset are available at\nhttps://github.com/zjunlp/EasyEdit.\n","authors":["Jizhan Fang","Tianhe Lu","Yunzhi Yao","Ziyan Jiang","Xin Xu","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.05806v4.pdf","comment":"ACL 2025; project website is available at\n  https://zjunlp.github.io/project/CKnowEdit code and dataset are available at\n  https://github.com/zjunlp/EasyEdit"},{"id":"http://arxiv.org/abs/2506.06341v1","updated":"2025-06-01T07:36:52Z","published":"2025-06-01T07:36:52Z","title":"NR4DER: Neural Re-ranking for Diversified Exercise Recommendation","summary":"  With the widespread adoption of online education platforms, an increasing\nnumber of students are gaining new knowledge through Massive Open Online\nCourses (MOOCs). Exercise recommendation have made strides toward improving\nstudent learning outcomes. However, existing methods not only struggle with\nhigh dropout rates but also fail to match the diverse learning pace of\nstudents. They frequently face difficulties in adjusting to inactive students'\nlearning patterns and in accommodating individualized learning paces, resulting\nin limited accuracy and diversity in recommendations. To tackle these\nchallenges, we propose Neural Re-ranking for Diversified Exercise\nRecommendation (in short, NR4DER). NR4DER first leverages the mLSTM model to\nimprove the effectiveness of the exercise filter module. It then employs a\nsequence enhancement method to enhance the representation of inactive students,\naccurately matches students with exercises of appropriate difficulty. Finally,\nit utilizes neural re-ranking to generate diverse recommendation lists based on\nindividual students' learning histories. Extensive experimental results\nindicate that NR4DER significantly outperforms existing methods across multiple\nreal-world datasets and effectively caters to the diverse learning pace of\nstudents.\n","authors":["Xinghe Cheng","Xufang Zhou","Liangda Fang","Chaobo He","Yuyu Zhou","Weiqi Luo","Zhiguo Gong","Quanlong Guan"],"pdf_url":"https://arxiv.org/pdf/2506.06341v1.pdf","comment":"accepted for presentation at the SIGIR 2025 Full Papers track"},{"id":"http://arxiv.org/abs/2502.20317v4","updated":"2025-06-01T05:30:58Z","published":"2025-02-27T17:42:52Z","title":"Mixture of Structural-and-Textual Retrieval over Text-rich Graph\n  Knowledge Bases","summary":"  Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for\nanswering queries by providing textual and structural knowledge. However,\ncurrent retrieval methods often retrieve these two types of knowledge in\nisolation without considering their mutual reinforcement and some hybrid\nmethods even bypass structural retrieval entirely after neighboring\naggregation. To fill in this gap, we propose a Mixture of\nStructural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge\nvia a Planning-Reasoning-Organizing framework. In the Planning stage, MoR\ngenerates textual planning graphs delineating the logic for answering queries.\nFollowing planning graphs, in the Reasoning stage, MoR interweaves structural\ntraversal and textual matching to obtain candidates from TG-KBs. In the\nOrganizing stage, MoR further reranks fetched candidates based on their\nstructural trajectory. Extensive experiments demonstrate the superiority of MoR\nin harmonizing structural and textual retrieval with insights, including uneven\nretrieving performance across different query logics and the benefits of\nintegrating structural trajectories for candidate reranking. Our code is\navailable at https://github.com/Yoega/MoR.\n","authors":["Yongjia Lei","Haoyu Han","Ryan A. Rossi","Franck Dernoncourt","Nedim Lipka","Mahantesh M Halappanavar","Jiliang Tang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20317v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06340v1","updated":"2025-06-01T05:07:51Z","published":"2025-06-01T05:07:51Z","title":"Structured Semantics from Unstructured Notes: Language Model Approaches\n  to EHR-Based Decision Support","summary":"  The advent of large language models (LLMs) has opened new avenues for\nanalyzing complex, unstructured data, particularly within the medical domain.\nElectronic Health Records (EHRs) contain a wealth of information in various\nformats, including free text clinical notes, structured lab results, and\ndiagnostic codes. This paper explores the application of advanced language\nmodels to leverage these diverse data sources for improved clinical decision\nsupport. We will discuss how text-based features, often overlooked in\ntraditional high dimensional EHR analysis, can provide semantically rich\nrepresentations and aid in harmonizing data across different institutions.\nFurthermore, we delve into the challenges and opportunities of incorporating\nmedical codes and ensuring the generalizability and fairness of AI models in\nhealthcare.\n","authors":["Wu Hao Ran","Xi Xi","Furong Li","Jingyi Lu","Jian Jiang","Hui Huang","Yuzhuan Zhang","Shi Li"],"pdf_url":"https://arxiv.org/pdf/2506.06340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00828v1","updated":"2025-06-01T04:23:06Z","published":"2025-06-01T04:23:06Z","title":"Breaker: Removing Shortcut Cues with User Clustering for Single-slot\n  Recommendation System","summary":"  In a single-slot recommendation system, users are only exposed to one item at\na time, and the system cannot collect user feedback on multiple items\nsimultaneously. Therefore, only pointwise modeling solutions can be adopted,\nfocusing solely on modeling the likelihood of clicks or conversions for items\nby users to learn user-item preferences, without the ability to capture the\nranking information among different items directly. However, since user-side\ninformation is often much more abundant than item-side information, the model\ncan quickly learn the differences in user intrinsic tendencies, which are\nindependent of the items they are exposed to. This can cause these intrinsic\ntendencies to become a shortcut bias for the model, leading to insufficient\nmining of the most concerned user-item preferences. To solve this challenge, we\nintroduce the Breaker model. Breaker integrates an auxiliary task of user\nrepresentation clustering with a multi-tower structure for cluster-specific\npreference modeling. By clustering user representations, we ensure that users\nwithin each cluster exhibit similar characteristics, which increases the\ncomplexity of the pointwise recommendation task on the user side. This forces\nthe multi-tower structure with cluster-driven parameter learning to better\nmodel user-item preferences, ultimately eliminating shortcut biases related to\nuser intrinsic tendencies. In terms of training, we propose a delayed parameter\nupdate mechanism to enhance training stability and convergence, enabling\nend-to-end joint training of the auxiliary clustering and classification tasks.\nBoth offline and online experiments demonstrate that our method surpasses the\nbaselines. It has already been deployed and is actively serving tens of\nmillions of users daily on Meituan, one of the most popular e-commerce\nplatforms for services.\n","authors":["Chao Wang","Yue Zheng","Yujing Zhang","Yan Feng","Zhe Wang","Xiaowei Shi","An You","Yu Chen"],"pdf_url":"https://arxiv.org/pdf/2506.00828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19189v2","updated":"2025-06-01T01:41:09Z","published":"2025-05-25T15:31:52Z","title":"POQD: Performance-Oriented Query Decomposer for Multi-vector retrieval","summary":"  Although Multi-Vector Retrieval (MVR) has achieved the state of the art on\nmany information retrieval (IR) tasks, its performance highly depends on how to\ndecompose queries into smaller pieces, say phrases or tokens. However,\noptimizing query decomposition for MVR performance is not end-to-end\ndifferentiable. Even worse, jointly solving this problem and training the\ndownstream retrieval-based systems, say RAG systems could be highly\ninefficient. To overcome these challenges, we propose Performance-Oriented\nQuery Decomposer (POQD), a novel query decomposition framework for MVR. POQD\nleverages one LLM for query decomposition and searches the optimal prompt with\nan LLM-based optimizer. We further propose an end-to-end training algorithm to\nalternatively optimize the prompt for query decomposition and the downstream\nmodels. This algorithm can achieve superior MVR performance at a reasonable\ntraining cost as our theoretical analysis suggests. POQD can be integrated\nseamlessly into arbitrary retrieval-based systems such as Retrieval-Augmented\nGeneration (RAG) systems. Extensive empirical studies on representative\nRAG-based QA tasks show that POQD outperforms existing query decomposition\nstrategies in both retrieval performance and end-to-end QA accuracy. POQD is\navailable at https://github.com/PKU-SDS-lab/POQD-ICML25.\n","authors":["Yaoyang Liu","Junlin Li","Yinjun Wu","Zhen Chen"],"pdf_url":"https://arxiv.org/pdf/2505.19189v2.pdf","comment":"Published in ICML 2025"},{"id":"http://arxiv.org/abs/2506.06339v1","updated":"2025-06-01T00:04:58Z","published":"2025-06-01T00:04:58Z","title":"Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core\n  Components","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture\nfor combining the precision of retrieval systems with the fluency of large\nlanguage models. While several studies have investigated RAG pipelines for\nhigh-resource languages, the optimization of RAG components for Arabic remains\nunderexplored. This study presents a comprehensive empirical evaluation of\nstate-of-the-art RAG components-including chunking strategies, embedding\nmodels, rerankers, and language models-across a diverse set of Arabic datasets.\nUsing the RAGAS framework, we systematically compare performance across four\ncore metrics: context precision, context recall, answer faithfulness, and\nanswer relevancy. Our experiments demonstrate that sentence-aware chunking\noutperforms all other segmentation methods, while BGE-M3 and\nMultilingual-E5-large emerge as the most effective embedding models. The\ninclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness\nin complex datasets, and Aya-8B surpasses StableLM in generation quality. These\nfindings provide critical insights for building high-quality Arabic RAG\npipelines and offer practical guidelines for selecting optimal components\nacross different document types.\n","authors":["Jumana Alsubhi","Mohammad D. Alahmadi","Ahmed Alhusayni","Ibrahim Aldailami","Israa Hamdine","Ahmad Shabana","Yazeed Iskandar","Suhayb Khayyat"],"pdf_url":"https://arxiv.org/pdf/2506.06339v1.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2505.18458v3","updated":"2025-06-01T16:00:34Z","published":"2025-05-24T01:57:12Z","title":"A Survey of LLM $\\times$ DATA","summary":"  The integration of large language model (LLM) and data management (DATA) is\nrapidly redefining both domains. In this survey, we comprehensively review the\nbidirectional relationships. On the one hand, DATA4LLM, spanning large-scale\ndata processing, storage, and serving, feeds LLMs with high quality, diversity,\nand timeliness of data required for stages like pre-training, post-training,\nretrieval-augmented generation, and agentic workflows: (i) Data processing for\nLLMs includes scalable acquisition, deduplication, filtering, selection, domain\nmixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on\nefficient data and model formats, distributed and heterogeneous storage\nhierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data\nserving for LLMs tackles challenges in RAG (e.g., knowledge post-processing),\nLLM inference (e.g., prompt compression, data provenance), and training\nstrategies (e.g., data packing and shuffling). On the other hand, in LLM4DATA,\nLLMs are emerging as general-purpose engines for data management. We review\nrecent advances in (i) data manipulation, including automatic data cleaning,\nintegration, discovery; (ii) data analysis, covering reasoning over structured,\nsemi-structured, and unstructured data, and (iii) system optimization (e.g.,\nconfiguration tuning, query rewriting, anomaly diagnosis), powered by LLM\ntechniques like retrieval-augmented prompting, task-specialized fine-tuning,\nand multi-agent collaboration.\n","authors":["Xuanhe Zhou","Junxuan He","Wei Zhou","Haodong Chen","Zirui Tang","Haoyu Zhao","Xin Tong","Guoliang Li","Youmin Chen","Jun Zhou","Zhaojun Sun","Binyuan Hui","Shuo Wang","Conghui He","Zhiyuan Liu","Jingren Zhou","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2505.18458v3.pdf","comment":"Please refer to the paper list at:\n  https://github.com/weAIDB/awesome-data-llm"},{"id":"http://arxiv.org/abs/2503.07219v3","updated":"2025-06-01T14:24:59Z","published":"2025-03-10T12:01:52Z","title":"Bag Semantics Query Containment: The CQ vs. UCQ Case and Other Stories","summary":"  Query Containment Problem (QCP) is a fundamental decision problem in query\nprocessing and optimization. While QCP has for a long time been completely\nunderstood for the case of set semantics, decidability of QCP for conjunctive\nqueries under multi-set semantics ($QCP_{\\text{CQ}}^{\\text{bag}}$) remains one\nof the most intriguing open problems in database theory. Certain effort has\nbeen put, in last 30 years, to solve this problem and some decidable special\ncases of $QCP_{\\text{CQ}}^{\\text{bag}}$ were identified, as well as some\nundecidable extensions, including $QCP_{\\text{UCQ}}^{\\text{bag}}$. In this\npaper we introduce a new technique which produces, for a given UCQ $\\Phi$, a CQ\n$\\phi$ such that the application of $\\phi$ to a database $D$ is, in some sense,\nan approximation of the application of $\\Phi$ to $D$. Using this technique we\ncould analyze the status of $QCP^{\\text{bag}}$ when one of the queries in\nquestion is a CQ and the other is a UCQ, and we reached conclusions which\nsurprised us a little bit. We also tried to use this technique to translate the\nknown undecidability proof for $QCP_{\\text{UCQ}}^{\\text{bag}}$ into a proof of\nundecidability of $QCP_{\\text{CQ}}^{\\text{bag}}$. And, as you are going to see,\nwe got stopped just one infinitely small $\\varepsilon$ before reaching this\nultimate goal.\n","authors":["Jerzy Marcinkowski","Piotr Ostropolski-Nalewaja"],"pdf_url":"https://arxiv.org/pdf/2503.07219v3.pdf","comment":"Expanded explanations to provide better intuitions"},{"id":"http://arxiv.org/abs/2506.00812v1","updated":"2025-06-01T03:27:52Z","published":"2025-06-01T03:27:52Z","title":"VecFlow: A High-Performance Vector Data Management System for\n  Filtered-Search on GPUs","summary":"  Vector search and database systems have become a keystone component in many\nAI applications. While many prior research has investigated how to accelerate\nthe performance of generic vector search, emerging AI applications require\nrunning more sophisticated vector queries efficiently, such as vector search\nwith attribute filters. Unfortunately, recent filtered-ANNS solutions are\nprimarily designed for CPUs, with few exploration and limited performance of\nfiltered-ANNS that take advantage of the massive parallelism offered by GPUs.\nIn this paper, we present VecFlow, a novel high-performance vector filtered\nsearch system that achieves unprecedented high throughput and recall while\nobtaining low latency for filtered-ANNS on GPUs. We propose a novel\nlabel-centric indexing and search algorithm that significantly improves the\nselectivity of ANNS with filters. In addition to algorithmic level\noptimization, we provide architectural-aware optimization for VecFlow's\nfunctional modules, effectively supporting both small batch and large batch\nqueries, and single-label and multi-label query processing. Experimental\nresults on NVIDIA A100 GPU over several public available datasets validate that\nVecFlow achieves 5 million QPS for recall 90%, outperforming state-of-the-art\nCPU-based solutions such as Filtered-DiskANN by up to 135 times. Alternatively,\nVecFlow can easily extend its support to high recall 99% regime, whereas strong\nGPU-based baselines plateau at around 80% recall. The source code is available\nat https://github.com/Supercomputing-System-AI-Lab/VecFlow.\n","authors":["Jingyi Xi","Chenghao Mo","Benjamin Karsin","Artem Chirkin","Mingqin Li","Minjia Zhang"],"pdf_url":"https://arxiv.org/pdf/2506.00812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19189v2","updated":"2025-06-01T01:41:09Z","published":"2025-05-25T15:31:52Z","title":"POQD: Performance-Oriented Query Decomposer for Multi-vector retrieval","summary":"  Although Multi-Vector Retrieval (MVR) has achieved the state of the art on\nmany information retrieval (IR) tasks, its performance highly depends on how to\ndecompose queries into smaller pieces, say phrases or tokens. However,\noptimizing query decomposition for MVR performance is not end-to-end\ndifferentiable. Even worse, jointly solving this problem and training the\ndownstream retrieval-based systems, say RAG systems could be highly\ninefficient. To overcome these challenges, we propose Performance-Oriented\nQuery Decomposer (POQD), a novel query decomposition framework for MVR. POQD\nleverages one LLM for query decomposition and searches the optimal prompt with\nan LLM-based optimizer. We further propose an end-to-end training algorithm to\nalternatively optimize the prompt for query decomposition and the downstream\nmodels. This algorithm can achieve superior MVR performance at a reasonable\ntraining cost as our theoretical analysis suggests. POQD can be integrated\nseamlessly into arbitrary retrieval-based systems such as Retrieval-Augmented\nGeneration (RAG) systems. Extensive empirical studies on representative\nRAG-based QA tasks show that POQD outperforms existing query decomposition\nstrategies in both retrieval performance and end-to-end QA accuracy. POQD is\navailable at https://github.com/PKU-SDS-lab/POQD-ICML25.\n","authors":["Yaoyang Liu","Junlin Li","Yinjun Wu","Zhen Chen"],"pdf_url":"https://arxiv.org/pdf/2505.19189v2.pdf","comment":"Published in ICML 2025"}]},"2025-05-31T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.05710v2","updated":"2025-05-31T23:34:02Z","published":"2024-12-07T17:51:31Z","title":"PromptRefine: Enhancing Few-Shot Performance on Low-Resource Indic\n  Languages with Example Selection from Related Example Banks","summary":"  Large Language Models (LLMs) have recently demonstrated impressive few-shot\nlearning capabilities through in-context learning (ICL). However, ICL\nperformance is highly dependent on the choice of few-shot demonstrations,\nmaking the selection of the most optimal examples a persistent research\nchallenge. This issue is further amplified in low-resource Indic languages,\nwhere the scarcity of ground-truth data complicates the selection process. In\nthis work, we propose PromptRefine, a novel Alternating Minimization approach\nfor example selection that improves ICL performance on low-resource Indic\nlanguages. PromptRefine leverages auxiliary example banks from related\nhigh-resource Indic languages and employs multi-task learning techniques to\nalign language-specific retrievers, enabling effective cross-language\nretrieval. Additionally, we incorporate diversity in the selected examples to\nenhance generalization and reduce bias. Through comprehensive evaluations on\nfour text generation tasks -- Cross-Lingual Question Answering, Multilingual\nQuestion Answering, Machine Translation, and Cross-Lingual Summarization using\nstate-of-the-art LLMs such as LLAMA-3.1-8B, LLAMA-2-7B, Qwen-2-7B, and\nQwen-2.5-7B, we demonstrate that PromptRefine significantly outperforms\nexisting frameworks for retrieving examples.\n","authors":["Soumya Suvra Ghosal","Soumyabrata Pal","Koyel Mukherjee","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2412.05710v2.pdf","comment":"Accepted at NAACL 2025"},{"id":"http://arxiv.org/abs/2506.00723v1","updated":"2025-05-31T21:49:17Z","published":"2025-05-31T21:49:17Z","title":"Pitfalls in Evaluating Language Model Forecasters","summary":"  Large language models (LLMs) have recently been applied to forecasting tasks,\nwith some works claiming these systems match or exceed human performance. In\nthis paper, we argue that, as a community, we should be careful about such\nconclusions as evaluating LLM forecasters presents unique challenges. We\nidentify two broad categories of issues: (1) difficulty in trusting evaluation\nresults due to many forms of temporal leakage, and (2) difficulty in\nextrapolating from evaluation performance to real-world forecasting. Through\nsystematic analysis and concrete examples from prior work, we demonstrate how\nevaluation flaws can raise concerns about current and future performance\nclaims. We argue that more rigorous evaluation methodologies are needed to\nconfidently assess the forecasting abilities of LLMs.\n","authors":["Daniel Paleka","Shashwat Goel","Jonas Geiping","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2506.00723v1.pdf","comment":"20 pages, 8 figures"},{"id":"http://arxiv.org/abs/2506.06336v1","updated":"2025-05-31T19:17:48Z","published":"2025-05-31T19:17:48Z","title":"Research on E-Commerce Long-Tail Product Recommendation Mechanism Based\n  on Large-Scale Language Models","summary":"  As e-commerce platforms expand their product catalogs, accurately\nrecommending long-tail items becomes increasingly important for enhancing both\nuser experience and platform revenue. A key challenge is the long-tail problem,\nwhere extreme data sparsity and cold-start issues limit the performance of\ntraditional recommendation methods. To address this, we propose a novel\nlong-tail product recommendation mechanism that integrates product text\ndescriptions and user behavior sequences using a large-scale language model\n(LLM). First, we introduce a semantic visor, which leverages a pre-trained LLM\nto convert multimodal textual content such as product titles, descriptions, and\nuser reviews into meaningful embeddings. These embeddings help represent\nitem-level semantics effectively. We then employ an attention-based user intent\nencoder that captures users' latent interests, especially toward long-tail\nitems, by modeling collaborative behavior patterns. These components feed into\na hybrid ranking model that fuses semantic similarity scores, collaborative\nfiltering outputs, and LLM-generated recommendation candidates. Extensive\nexperiments on a real-world e-commerce dataset show that our method outperforms\nbaseline models in recall (+12%), hit rate (+9%), and user coverage (+15%).\nThese improvements lead to better exposure and purchase rates for long-tail\nproducts. Our work highlights the potential of LLMs in interpreting product\ncontent and user intent, offering a promising direction for future e-commerce\nrecommendation systems.\n","authors":["Qingyi Lu","Haotian Lyu","Jiayun Zheng","Yang Wang","Li Zhang","Chengrui Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.06336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06335v1","updated":"2025-05-31T13:59:44Z","published":"2025-05-31T13:59:44Z","title":"FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in\n  Finance-Specific Deployment of Large Language Models","summary":"  In natural language processing (NLP), the focus has shifted from encoder-only\ntiny language models like BERT to decoder-only large language models(LLMs) such\nas GPT-3. However, LLMs' practical application in the financial sector has\nrevealed three limitations: (1) LLMs often perform worse than fine-tuned BERT\non discriminative tasks despite costing much higher computational resources,\nsuch as market sentiment analysis in financial reports; (2) Application on\ngenerative tasks heavily relies on retrieval augmented generation (RAG) methods\nto provide current and specialized information, with general retrievers showing\nsuboptimal performance on domain-specific retrieval tasks; (3) There are\nadditional inadequacies in other feature-based scenarios, such as topic\nmodeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained\non a high-quality, financial-specific corpus of 32b tokens. This represents the\nlargest known Chinese financial pretraining corpus for models of this parameter\nsize. As a better backbone, FinBERT2 can bridge the gap in the\nfinancial-specific deployment of LLMs through the following achievements: (1)\nDiscriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT\nvariants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five\nfinancial classification tasks. (2) Contrastive fine-tuned models\n(Fin-Retrievers) outperform both open-source (e.g., +6.8\\% avg improvement over\nBGE-base-zh) and proprietary (e.g., +4.2\\% avg improvement over OpenAI's\ntext-embedding-3-large) embedders across five financial retrieval tasks; (3)\nBuilding on FinBERT2 variants, we construct the Fin-TopicModel, which enables\nsuperior clustering and topic representation for financial titles. Our work\nrevisits financial BERT models through comparative analysis with contemporary\nLLMs and offers practical insights for effectively utilizing FinBERT in the\nLLMs era.\n","authors":["Xuan Xu","Fufang Wen","Beilin Chu","Zhibing Fu","Qinhong Lin","Jiaqi Liu","Binjie Fei","Zhongliang Yang","Linna Zhou","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2506.06335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06334v1","updated":"2025-05-31T12:57:56Z","published":"2025-05-31T12:57:56Z","title":"Preference-based learning for news headline recommendation","summary":"  This study explores strategies for optimizing news headline recommendations\nthrough preference-based learning. Using real-world data of user interactions\nwith French-language online news posts, we learn a headline recommender agent\nunder a contextual bandit setting. This allows us to explore the impact of\ntranslation on engagement predictions, as well as the benefits of different\ninteractive strategies on user engagement during data collection. Our results\nshow that explicit exploration may not be required in the presence of noisy\ncontexts, opening the door to simpler but efficient strategies in practice.\n","authors":["Alexandre Bouras","Audrey Durand","Richard Khoury"],"pdf_url":"https://arxiv.org/pdf/2506.06334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00491v1","updated":"2025-05-31T09:57:07Z","published":"2025-05-31T09:57:07Z","title":"Optimizing Question Semantic Space for Dynamic Retrieval-Augmented\n  Multi-hop Question Answering","summary":"  Retrieval-augmented generation (RAG) is usually integrated into large\nlanguage models (LLMs) to mitigate hallucinations and knowledge obsolescence.\nWhereas,conventional one-step retrieve-and-read methods are insufficient for\nmulti-hop question answering, facing challenges of retrieval semantic\nmismatching and the high cost in handling interdependent subquestions. In this\npaper, we propose Optimizing Question Semantic Space for Dynamic\nRetrieval-Augmented Multi-hop Question Answering (Q-DREAM). Q-DREAM consists of\nthree key modules: (1) the Question Decomposition Module (QDM), which\ndecomposes multi-hop questions into fine-grained subquestions; (2) the\nSubquestion Dependency Optimizer Module (SDOM), which models the interdependent\nrelations of subquestions for better understanding; and (3) the Dynamic Passage\nRetrieval Module (DPRM), which aligns subquestions with relevant passages by\noptimizing the semantic embeddings. Experimental results across various\nbenchmarks demonstrate that Q-DREAM significantly outperforms existing RAG\nmethods, achieving state-of-the-art performance in both in-domain and\nout-of-domain settings. Notably, Q-DREAM also improves retrieval efficiency\nwhile maintaining high accuracy compared with recent baselines.\n","authors":["Linhao Ye","Lang Yu","Zhikai Lei","Qin Chen","Jie Zhou","Liang He"],"pdf_url":"https://arxiv.org/pdf/2506.00491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20243v2","updated":"2025-05-31T09:34:42Z","published":"2025-05-26T17:21:26Z","title":"It's High Time: A Survey of Temporal Information Retrieval and Question\n  Answering","summary":"  Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nInformation Retrieval and Temporal Question Answering, two research areas aimed\nat handling and understanding time-sensitive information. As the amount of\ntime-stamped content from sources like news articles, web archives, and\nknowledge bases increases, systems must address challenges such as detecting\ntemporal intent, normalizing time expressions, ordering events, and reasoning\nover evolving or ambiguous facts. These challenges are critical across many\ndynamic and time-sensitive domains, from news and encyclopedias to science,\nhistory, and social media. We review both traditional approaches and modern\nneural methods, including those that use transformer models and Large Language\nModels (LLMs). We also review recent advances in temporal language modeling,\nmulti-hop reasoning, and retrieval-augmented generation (RAG), alongside\nbenchmark datasets and evaluation strategies that test temporal robustness,\nrecency awareness, and generalization.\n","authors":["Bhawna Piryani","Abdelrahman Abdallah","Jamshid Mozafari","Avishek Anand","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2505.20243v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04796v2","updated":"2025-05-31T09:02:25Z","published":"2025-03-02T11:33:22Z","title":"Optimizing Multi-Hop Document Retrieval Through Intermediate\n  Representations","summary":"  Retrieval-augmented generation (RAG) encounters challenges when addressing\ncomplex queries, particularly multi-hop questions. While several methods tackle\nmulti-hop queries by iteratively generating internal queries and retrieving\nexternal documents, these approaches are computationally expensive. In this\npaper, we identify a three-stage information processing pattern in LLMs during\nlayer-by-layer reasoning, consisting of extraction, processing, and subsequent\nextraction steps. This observation suggests that the representations in\nintermediate layers contain richer information compared to those in other\nlayers. Building on this insight, we propose Layer-wise RAG (L-RAG). Unlike\nprior methods that focus on generating new internal queries, L-RAG leverages\nintermediate representations from the middle layers, which capture next-hop\ninformation, to retrieve external knowledge. L-RAG achieves performance\ncomparable to multi-step approaches while maintaining inference overhead\nsimilar to that of standard RAG. Experimental results show that L-RAG\noutperforms existing RAG methods on open-domain multi-hop question-answering\ndatasets, including MuSiQue, HotpotQA, and 2WikiMultiHopQA. The code is\navailable in https://anonymous.4open.science/r/L-RAG-ADD5/\n","authors":["Jiaen Lin","Jingyu Liu","Yingbo Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04796v2.pdf","comment":"Accepted by ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2506.00450v1","updated":"2025-05-31T08:09:54Z","published":"2025-05-31T08:09:54Z","title":"DV365: Extremely Long User History Modeling at Instagram","summary":"  Long user history is highly valuable signal for recommendation systems, but\neffectively incorporating it often comes with high cost in terms of data center\npower consumption and GPU. In this work, we chose offline embedding over\nend-to-end sequence length optimization methods to enable extremely long user\nsequence modeling as a cost-effective solution, and propose a new user\nembedding learning strategy, multi-slicing and summarization, that generates\nhighly generalizable user representation of user's long-term stable interest.\nHistory length we encoded in this embedding is up to 70,000 and on average\n40,000. This embedding, named as DV365, is proven highly incremental on top of\nadvanced attentive user sequence models deployed in Instagram. Produced by a\nsingle upstream foundational model, it is launched in 15 different models\nacross Instagram and Threads with significant impact, and has been production\nbattle-proven for >1 year since our first launch.\n","authors":["Wenhan Lyu","Devashish Tyagi","Yihang Yang","Ziwei Li","Ajay Somani","Karthikeyan Shanmugasundaram","Nikola Andrejevic","Ferdi Adeputra","Curtis Zeng","Arun K. Singh","Maxime Ransan","Sagar Jain"],"pdf_url":"https://arxiv.org/pdf/2506.00450v1.pdf","comment":"SIGKDD 2025 accepted"},{"id":"http://arxiv.org/abs/2502.19163v2","updated":"2025-05-31T07:53:48Z","published":"2025-02-26T14:17:56Z","title":"TestNUC: Enhancing Test-Time Computing Approaches and Scaling through\n  Neighboring Unlabeled Data Consistency","summary":"  Test-time computing approaches, which leverage additional computational\nresources during inference, have been proven effective in enhancing large\nlanguage model performance. This work introduces a novel, linearly scaling\napproach, TestNUC, that improves test-time predictions by leveraging the local\nconsistency of neighboring unlabeled data-it classifies an input instance by\nconsidering not only the model's prediction on that instance but also on\nneighboring unlabeled instances. We evaluate TestNUC across eight diverse\ndatasets, spanning intent classification, topic mining, domain discovery, and\nemotion detection, demonstrating its consistent superiority over baseline\nmethods such as standard prompting and self-consistency. Furthermore, TestNUC\ncan be seamlessly integrated with existing test-time computing approaches,\nsubstantially boosting their performance. Our analysis reveals that TestNUC\nscales effectively with increasing amounts of unlabeled data and performs\nrobustly across different embedding models, making it practical for real-world\napplications. Our code is available at https://github.com/HenryPengZou/TestNUC.\n","authors":["Henry Peng Zou","Zhengyao Gu","Yue Zhou","Yankai Chen","Weizhi Zhang","Liancheng Fang","Yibo Wang","Yangning Li","Kay Liu","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2502.19163v2.pdf","comment":"Accepted by ACL 2025 main conference"},{"id":"http://arxiv.org/abs/2506.00441v1","updated":"2025-05-31T07:46:42Z","published":"2025-05-31T07:46:42Z","title":"K-order Ranking Preference Optimization for Large Language Models","summary":"  To adapt large language models (LLMs) to ranking tasks, existing list-wise\nmethods, represented by list-wise Direct Preference Optimization (DPO), focus\non optimizing partial-order or full-order list ranking consistency for LLMs to\nenhance their ranking abilities. However, we argue that optimizing top-K\nranking consistency could be more appropriate for real-world applications.\nThere are two main reasons: (1) users are typically concerned with only the\ntop-K results, making top-K ranking more important, and (2) tail items often\nlack precise feedback, making top-K ranking more reliable. Based on this, we\npropose K-order Ranking Preference Optimization (KPO) by extending the DPO's\nPlackett-Luce model to accommodate top-K rankings. Additionally, recognizing\nthat the number of important items can vary across queries, we extend KPO to\ndynamically determine appropriate K for different samples and introduce a\ncurriculum learning strategy to boost training efficiency. Extensive\nexperiments demonstrate the effectiveness of KPO, highlighting its high sample\nefficiency and robustness to noise. The code is available at\nhttps://github.com/Lanyu0303/KPO.\n","authors":["Shihao Cai","Chongming Gao","Yang Zhang","Wentao Shi","Jizhi Zhang","Keqin Bao","Qifan Wang","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2506.00441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06331v1","updated":"2025-05-31T03:36:16Z","published":"2025-05-31T03:36:16Z","title":"How Significant Are the Real Performance Gains? An Unbiased Evaluation\n  Framework for GraphRAG","summary":"  By retrieving contexts from knowledge graphs, graph-based retrieval-augmented\ngeneration (GraphRAG) enhances large language models (LLMs) to generate quality\nanswers for user questions. Many GraphRAG methods have been proposed and\nreported inspiring performance in answer quality. However, we observe that the\ncurrent answer evaluation framework for GraphRAG has two critical flaws, i.e.,\nunrelated questions and evaluation biases, which may lead to biased or even\nwrong conclusions on performance. To tackle the two flaws, we propose an\nunbiased evaluation framework that uses graph-text-grounded question generation\nto produce questions that are more related to the underlying dataset and an\nunbiased evaluation procedure to eliminate the biases in LLM-based answer\nassessment. We apply our unbiased framework to evaluate 3 representative\nGraphRAG methods and find that their performance gains are much more moderate\nthan reported previously. Although our evaluation framework may still have\nflaws, it calls for scientific evaluations to lay solid foundations for\nGraphRAG research.\n","authors":["Qiming Zeng","Xiao Yan","Hao Luo","Yuhao Lin","Yuxiang Wang","Fangcheng Fu","Bo Du","Quanqing Xu","Jiawei Jiang"],"pdf_url":"https://arxiv.org/pdf/2506.06331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02614v2","updated":"2025-05-31T03:25:45Z","published":"2025-03-04T13:34:19Z","title":"Personalized Generation In Large Model Era: A Survey","summary":"  In the era of large models, content generation is gradually shifting to\nPersonalized Generation (PGen), tailoring content to individual preferences and\nneeds. This paper presents the first comprehensive survey on PGen,\ninvestigating existing research in this rapidly growing field. We conceptualize\nPGen from a unified perspective, systematically formalizing its key components,\ncore objectives, and abstract workflows. Based on this unified perspective, we\npropose a multi-level taxonomy, offering an in-depth review of technical\nadvancements, commonly used datasets, and evaluation metrics across multiple\nmodalities, personalized contexts, and tasks. Moreover, we envision the\npotential applications of PGen and highlight open challenges and promising\ndirections for future exploration. By bridging PGen research across multiple\nmodalities, this survey serves as a valuable resource for fostering knowledge\nsharing and interdisciplinary collaboration, ultimately contributing to a more\npersonalized digital landscape.\n","authors":["Yiyan Xu","Jinghao Zhang","Alireza Salemi","Xinting Hu","Wenjie Wang","Fuli Feng","Hamed Zamani","Xiangnan He","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.02614v2.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2506.00363v1","updated":"2025-05-31T03:06:09Z","published":"2025-05-31T03:06:09Z","title":"Adapting General-Purpose Embedding Models to Private Datasets Using\n  Keyword-based Retrieval","summary":"  Text embedding models play a cornerstone role in AI applications, such as\nretrieval-augmented generation (RAG). While general-purpose text embedding\nmodels demonstrate strong performance on generic retrieval benchmarks, their\neffectiveness diminishes when applied to private datasets (e.g.,\ncompany-specific proprietary data), which often contain specialized terminology\nand lingo. In this work, we introduce BMEmbed, a novel method for adapting\ngeneral-purpose text embedding models to private datasets. By leveraging the\nwell-established keyword-based retrieval technique (BM25), we construct\nsupervisory signals from the ranking of keyword-based retrieval results to\nfacilitate model adaptation. We evaluate BMEmbed across a range of domains,\ndatasets, and models, showing consistent improvements in retrieval performance.\nMoreover, we provide empirical insights into how BM25-based signals contribute\nto improving embeddings by fostering alignment and uniformity, highlighting the\nvalue of this approach in adapting models to domain-specific data. We release\nthe source code available at https://github.com/BaileyWei/BMEmbed for the\nresearch community.\n","authors":["Yubai Wei","Jiale Han","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2506.00363v1.pdf","comment":"Link: https://github.com/BaileyWei/BMEmbed"},{"id":"http://arxiv.org/abs/2501.14956v2","updated":"2025-05-31T01:44:04Z","published":"2025-01-24T22:44:22Z","title":"ExPerT: Effective and Explainable Evaluation of Personalized Long-Form\n  Text Generation","summary":"  Evaluating personalized text generated by large language models (LLMs) is\nchallenging, as only the LLM user, i.e., prompt author, can reliably assess the\noutput, but re-engaging the same individuals across studies is infeasible. This\npaper addresses the challenge of evaluating personalized text generation by\nintroducing ExPerT, an explainable reference-based evaluation framework. ExPerT\nleverages an LLM to extract atomic aspects and their evidence from the\ngenerated and reference texts, match the aspects, and evaluate their alignment\nbased on content and writing style -- two key attributes in personalized text\ngeneration. Additionally, ExPerT generates detailed, fine-grained explanations\nfor every step of the evaluation process, enhancing transparency and\ninterpretability. Our experiments demonstrate that ExPerT achieves a 7.2%\nrelative improvement in alignment with human judgments compared to the\nstate-of-the-art text generation evaluation methods. Furthermore, human\nevaluators rated the usability of ExPerT's explanations at 4.7 out of 5,\nhighlighting its effectiveness in making evaluation decisions more\ninterpretable.\n","authors":["Alireza Salemi","Julian Killingback","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2501.14956v2.pdf","comment":null}],"Databases":[{"id":"http://arxiv.org/abs/2502.20576v5","updated":"2025-05-31T18:35:45Z","published":"2025-02-27T22:35:31Z","title":"OmniRouter: Budget and Performance Controllable Multi-LLM Routing","summary":"  Large language models (LLMs) deliver superior performance but require\nsubstantial computational resources and operate with relatively low efficiency,\nwhile smaller models can efficiently handle simpler tasks with fewer resources.\nLLM routing is a crucial paradigm that dynamically selects the most suitable\nlarge language models from a pool of candidates to process diverse inputs,\nensuring optimal resource utilization while maintaining response quality.\nExisting routing frameworks typically model this as a locally optimal\ndecision-making problem, selecting the presumed best-fit LLM for each query\nindividually, which overlook global budget constraints, resulting in\nineffective resource allocation. To tackle this problem, we introduce\nOmniRouter, a fundamentally controllable routing framework for multi-LLM\nserving. Instead of making per-query greedy choices, OmniRouter models the\nrouting task as a constrained optimization problem, assigning models that\nminimize total cost while ensuring the required performance level.\nSpecifically, a hybrid retrieval-augmented predictor is designed to predict the\ncapabilities and costs of LLMs and a constrained optimizer is employed to\ncontrol globally optimal query-model allocation. Experiments show that\nOmniRouter achieves up to 6.30% improvement in response accuracy while\nsimultaneously reducing computational costs by at least 10.15% compared to\ncompetitive router baselines. The code and the dataset are available at\nhttps://github.com/agiresearch/OmniRouter.\n","authors":["Kai Mei","Wujiang Xu","Shuhang Lin","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20576v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00528v1","updated":"2025-05-31T12:22:24Z","published":"2025-05-31T12:22:24Z","title":"Ultra-Quantisation: Efficient Embedding Search via 1.58-bit Encodings","summary":"  Many modern search domains comprise high-dimensional vectors of floating\npoint numbers derived from neural networks, in the form of embeddings. Typical\nembeddings range in size from hundreds to thousands of dimensions, making the\nsize of the embeddings, and the speed of comparison, a significant issue.\n  Quantisation is a class of mechanism which replaces the floating point values\nwith a smaller representation, for example a short integer. This gives an\napproximation of the embedding space in return for a smaller data\nrepresentation and a faster comparison function.\n  Here we take this idea almost to its extreme: we show how vectors of\narbitrary-precision floating point values can be replaced by vectors whose\nelements are drawn from the set {-1,0,1}. This yields very significant savings\nin space and metric evaluation cost, while maintaining a strong correlation for\nsimilarity measurements.\n  This is achieved by way of a class of convex polytopes which exist in the\nhigh-dimensional space. In this article we give an outline description of these\nobjects, and show how they can be used for the basis of such radical\nquantisation while maintaining a surprising degree of accuracy.\n","authors":["Richard Connor","Alan Dearle","Ben Claydon"],"pdf_url":"https://arxiv.org/pdf/2506.00528v1.pdf","comment":"Submitted to SISAP25 International Conference on Similarity Search\n  and Applications"},{"id":"http://arxiv.org/abs/2506.00352v1","updated":"2025-05-31T02:30:22Z","published":"2025-05-31T02:30:22Z","title":"Enabling Secure and Ephemeral AI Workloads in Data Mesh Environments","summary":"  Many large enterprises that operate highly governed and complex ICT\nenvironments have no efficient and effective way to support their Data and AI\nteams in rapidly spinning up and tearing down self-service data and compute\ninfrastructure, to experiment with new data analytic tools, and deploy data\nproducts into operational use. This paper proposes a key piece of the solution\nto the overall problem, in the form of an on-demand self-service data-platform\ninfrastructure to empower de-centralised data teams to build data products on\ntop of centralised templates, policies and governance. The core innovation is\nan efficient method to leverage immutable container operating systems and\ninfrastructure-as-code methodologies for creating, from scratch, vendor-neutral\nand short-lived Kubernetes clusters on-premises and in any cloud environment.\nOur proposed approach can serve as a repeatable, portable and cost-efficient\nalternative or complement to commercial Platform-as-a-Service (PaaS) offerings,\nand this is particularly important in supporting interoperability in complex\ndata mesh environments with a mix of modern and legacy compute infrastructure.\n","authors":["Chinkit Patel","Kee Siong Ng"],"pdf_url":"https://arxiv.org/pdf/2506.00352v1.pdf","comment":"52 pages"}]}}